PaperID,DOI,Title,AuthorNumber,AuthorName,AuthorInstitution,AuthorCity,AuthorCountry,IsHM,IsAward,Abstract
pn4249,https://doi.org/10.1145/3290605.3300764,Exploring How Privacy and Security Factor into IoT Device Purchase Behavior,1,Pardis Emami-Naeini,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite growing concerns about security and privacy of Internet of Things (IoT) devices, consumers generally do not have access to security and privacy information when purchasing these devices. We interviewed 24 participants about IoT devices they purchased. While most had not considered privacy and security prior to purchase, they reported becoming concerned later due to media reports, opinions shared by friends, or observing unexpected device behavior. Those who sought privacy and security information before purchase, reported that it was difficult or impossible to find. We asked interviewees to rank factors they would consider when purchasing IoT devices; after features and price, privacy and security were ranked among the most important. Finally, we showed interviewees our prototype privacy and security label. Almost all found it to be accessible and useful, encouraging them to incorporate privacy and security in their IoT purchase decisions."
pn4249,https://doi.org/10.1145/3290605.3300764,Exploring How Privacy and Security Factor into IoT Device Purchase Behavior,2,Henry Dixon,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite growing concerns about security and privacy of Internet of Things (IoT) devices, consumers generally do not have access to security and privacy information when purchasing these devices. We interviewed 24 participants about IoT devices they purchased. While most had not considered privacy and security prior to purchase, they reported becoming concerned later due to media reports, opinions shared by friends, or observing unexpected device behavior. Those who sought privacy and security information before purchase, reported that it was difficult or impossible to find. We asked interviewees to rank factors they would consider when purchasing IoT devices; after features and price, privacy and security were ranked among the most important. Finally, we showed interviewees our prototype privacy and security label. Almost all found it to be accessible and useful, encouraging them to incorporate privacy and security in their IoT purchase decisions."
pn4249,https://doi.org/10.1145/3290605.3300764,Exploring How Privacy and Security Factor into IoT Device Purchase Behavior,3,Yuvraj Agarwal,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite growing concerns about security and privacy of Internet of Things (IoT) devices, consumers generally do not have access to security and privacy information when purchasing these devices. We interviewed 24 participants about IoT devices they purchased. While most had not considered privacy and security prior to purchase, they reported becoming concerned later due to media reports, opinions shared by friends, or observing unexpected device behavior. Those who sought privacy and security information before purchase, reported that it was difficult or impossible to find. We asked interviewees to rank factors they would consider when purchasing IoT devices; after features and price, privacy and security were ranked among the most important. Finally, we showed interviewees our prototype privacy and security label. Almost all found it to be accessible and useful, encouraging them to incorporate privacy and security in their IoT purchase decisions."
pn4249,https://doi.org/10.1145/3290605.3300764,Exploring How Privacy and Security Factor into IoT Device Purchase Behavior,4,Lorrie Cranor,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite growing concerns about security and privacy of Internet of Things (IoT) devices, consumers generally do not have access to security and privacy information when purchasing these devices. We interviewed 24 participants about IoT devices they purchased. While most had not considered privacy and security prior to purchase, they reported becoming concerned later due to media reports, opinions shared by friends, or observing unexpected device behavior. Those who sought privacy and security information before purchase, reported that it was difficult or impossible to find. We asked interviewees to rank factors they would consider when purchasing IoT devices; after features and price, privacy and security were ranked among the most important. Finally, we showed interviewees our prototype privacy and security label. Almost all found it to be accessible and useful, encouraging them to incorporate privacy and security in their IoT purchase decisions."
pn3082,https://doi.org/10.1145/3290605.3300428,Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes,1,Yaxing Yao,Syracuse University,Syracuse,United States,false,false,"Home is a person's castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers might make a home ""smarter"" but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users' privacy concerns and designing privacy tools only by experts. Our participants' privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy."
pn3082,https://doi.org/10.1145/3290605.3300428,Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes,2,Justin Reed Basdeo,Syracuse University,Syracuse,United States,false,false,"Home is a person's castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers might make a home ""smarter"" but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users' privacy concerns and designing privacy tools only by experts. Our participants' privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy."
pn3082,https://doi.org/10.1145/3290605.3300428,Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes,3,Smirity Kaushik,Syracuse University,Syracuse,United States,false,false,"Home is a person's castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers might make a home ""smarter"" but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users' privacy concerns and designing privacy tools only by experts. Our participants' privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy."
pn3082,https://doi.org/10.1145/3290605.3300428,Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes,4,Yang Wang,Syracuse University,Syracuse,United States,false,false,"Home is a person's castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers might make a home ""smarter"" but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users' privacy concerns and designing privacy tools only by experts. Our participants' privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,1,Peter Mayer,Karlsruhe Institute of Technology,Karlsruhe,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,2,Nina Gerber,Karlsruhe Institute of Technology,Karlsruhe,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,3,Benjamin Reinheimer,Karlsruhe Institute of Technology,Karlsruhe,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,4,Philipp Rack,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,5,Kristoffer Braun,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn7878,https://doi.org/10.1145/3290605.3300779,I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,6,Melanie Volkamer,"SECUSO, Karlsruhe Institute of Technology",Karlsruhe,Germany,false,false,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research."
pn9779,https://doi.org/10.1145/3290605.3300828,Voice Presentation Attack Detection through Text-Converted Voice Command Analysis,1,Il-Youp Kwak,Samsung Research,Seoul,Republic Of Korea,false,false,"Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%."
pn9779,https://doi.org/10.1145/3290605.3300828,Voice Presentation Attack Detection through Text-Converted Voice Command Analysis,2,Jun Ho Huh,Samsung Research,Seoul,Republic Of Korea,false,false,"Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%."
pn9779,https://doi.org/10.1145/3290605.3300828,Voice Presentation Attack Detection through Text-Converted Voice Command Analysis,3,Seung Taek Han,Samsung Research,Seoul,Republic Of Korea,false,false,"Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%."
pn9779,https://doi.org/10.1145/3290605.3300828,Voice Presentation Attack Detection through Text-Converted Voice Command Analysis,4,Iljoo Kim,Samsung Research,Seoul,Republic Of Korea,false,false,"Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%."
pn9779,https://doi.org/10.1145/3290605.3300828,Voice Presentation Attack Detection through Text-Converted Voice Command Analysis,5,Jiwon Yoon,Korea University,Seoul,Republic Of Korea,false,false,"Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%."
pn1441,https://doi.org/10.1145/3290605.3300850,NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists,1,Andrii Matviienko,OFFIS - Institute for Information Technology,Oldenburg,Germany,false,false,"Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists."
pn1441,https://doi.org/10.1145/3290605.3300850,NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists,2,Swamy Ananthanarayan,University of Oldenburg,Oldenburg,Germany,false,false,"Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists."
pn1441,https://doi.org/10.1145/3290605.3300850,NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists,3,Abdallah El Ali,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists."
pn1441,https://doi.org/10.1145/3290605.3300850,NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists,4,Wilko Heuten,OFFIS - Institute for Information Technology,Oldenburg,Germany,false,false,"Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists."
pn1441,https://doi.org/10.1145/3290605.3300850,NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists,5,Susanne Boll,University of Oldenburg,Oldenburg,Germany,false,false,"Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists."
pn7115,https://doi.org/10.1145/3290605.3300270,At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces,1,Michael Braun,"BMW Group Research, New Technologies, Innovations",Garching,Germany,false,false,"This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases."
pn7115,https://doi.org/10.1145/3290605.3300270,At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces,2,Anja Mainz,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases."
pn7115,https://doi.org/10.1145/3290605.3300270,At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces,3,Ronee Chadowitz,"BMW Group Research, New Technologies, Innovations",Garching,Germany,false,false,"This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases."
pn7115,https://doi.org/10.1145/3290605.3300270,At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces,4,Bastian Pfleging,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases."
pn7115,https://doi.org/10.1145/3290605.3300270,At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces,5,Florian Alt,Bundeswehr University Munich,Munich,Germany,false,false,"This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,1,Anna-Katharina Frison,Technische Hochschule Ingolstadt,Ingolstadt,Germany,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,2,Philipp Wintersberger,Technische Hochschule Ingolstadt,Ingolstadt,Germany,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,3,Andreas Riener,Technische Hochschule Ingolstadt,Ingolstadt,Germany,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,4,Clemens Schartmüller,Technische Hochschule Ingolstadt,Ingolstadt,Germany,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,5,Linda Boyle,University of Washington,Seattle,United States,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,6,Erika Miller,Colorado State University,Fort Collins,United States,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn3881,https://doi.org/10.1145/3290605.3300374,In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving,7,Klemens Weigl,Katholic University of Eichstätt-Ingolstadt,Eichstätt,Germany,false,false,"In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception."
pn2059,https://doi.org/10.1145/3290605.3300625,PicMe: Interactive Visual Guidance for Taking Requested Photo Composition,1,Minju Kim,KAIST,Daejeon,Republic Of Korea,false,true,"PicMe is a mobile application that provides interactive on-screen guidance that helps the user take pictures of a composition that another person requires. Once the requester captures a picture of the desired composition and delivers it to the user (photographer), a 2.5D guidance system, called the virtual frame, guides the user in real-time by showing a three-dimensional composition of the target image (i.e., size and shape). In addition, according to the matching accuracy rate, we provide a small-sized target image in an inset window as feedback and edge visualization for further alignment of the detail elements. We implemented PicMe to work fully in mobile environments. We then conducted a preliminary user study to evaluate the effectiveness of PicMe compared to traditional 2D guidance methods. The results show that PicMe helps users reach their target images more accurately and quickly by giving participants more confidence in their tasks."
pn2059,https://doi.org/10.1145/3290605.3300625,PicMe: Interactive Visual Guidance for Taking Requested Photo Composition,2,Jungjin Lee,KAI Inc.,Daejeon,Republic Of Korea,false,true,"PicMe is a mobile application that provides interactive on-screen guidance that helps the user take pictures of a composition that another person requires. Once the requester captures a picture of the desired composition and delivers it to the user (photographer), a 2.5D guidance system, called the virtual frame, guides the user in real-time by showing a three-dimensional composition of the target image (i.e., size and shape). In addition, according to the matching accuracy rate, we provide a small-sized target image in an inset window as feedback and edge visualization for further alignment of the detail elements. We implemented PicMe to work fully in mobile environments. We then conducted a preliminary user study to evaluate the effectiveness of PicMe compared to traditional 2D guidance methods. The results show that PicMe helps users reach their target images more accurately and quickly by giving participants more confidence in their tasks."
pn7926,https://doi.org/10.1145/3290605.3300878,Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers,1,Annu Sible Prabhakar,University of Cincinnati,Cincinnati,United States,false,false,"Life transitions are an integral part of the human experience. However, research shows that lack of support during life transitions can result in adverse health outcomes. To better understand the support needs and structures of low-income women during transition to motherhood, we interviewed 10 women and their 14 supporters during the transition. Our findings suggest that support needs and structures of mothers evolve during transition, and that they also vary by socio-economic contexts. In this paper, we detail our study design and findings. Informed by our findings, we posit that all life-transitions are not the same, and that therefore, the optimal support intervention point varies for different life transitions. Currently there are no tools available to identify optimal support intervention points during life transitions. To this end, we also introduce a preliminary framework - the Strength-Stress-Analysis (SSA) framework - to identify optimal support intervention points during life-transitions."
pn7926,https://doi.org/10.1145/3290605.3300878,Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers,2,Erik Stolterman,Indiana University,Bloomington,United States,false,false,"Life transitions are an integral part of the human experience. However, research shows that lack of support during life transitions can result in adverse health outcomes. To better understand the support needs and structures of low-income women during transition to motherhood, we interviewed 10 women and their 14 supporters during the transition. Our findings suggest that support needs and structures of mothers evolve during transition, and that they also vary by socio-economic contexts. In this paper, we detail our study design and findings. Informed by our findings, we posit that all life-transitions are not the same, and that therefore, the optimal support intervention point varies for different life transitions. Currently there are no tools available to identify optimal support intervention points during life transitions. To this end, we also introduce a preliminary framework - the Strength-Stress-Analysis (SSA) framework - to identify optimal support intervention points during life-transitions."
pn7926,https://doi.org/10.1145/3290605.3300878,Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers,3,Selma Šabanovi?,Indiana University,Bloomington,United States,false,false,"Life transitions are an integral part of the human experience. However, research shows that lack of support during life transitions can result in adverse health outcomes. To better understand the support needs and structures of low-income women during transition to motherhood, we interviewed 10 women and their 14 supporters during the transition. Our findings suggest that support needs and structures of mothers evolve during transition, and that they also vary by socio-economic contexts. In this paper, we detail our study design and findings. Informed by our findings, we posit that all life-transitions are not the same, and that therefore, the optimal support intervention point varies for different life transitions. Currently there are no tools available to identify optimal support intervention points during life transitions. To this end, we also introduce a preliminary framework - the Strength-Stress-Analysis (SSA) framework - to identify optimal support intervention points during life-transitions."
pn7213,https://doi.org/10.1145/3290605.3300411,Accessing a New Land: Designing for a Social Conceptualisation of Access,1,Lizzie Coles-Kemp,Royal Holloway University of London,London,United Kingdom,false,false,"This paper presents a study of mobile phone use by people settling in a new land to access state provided digital services. It shows that digital literacy and access to technology are not the only resources and capabilities needed to successfully access digital services and do not guarantee a straightforward resettlement process. Using creative engagement methods, the research involved 132 ""newcomers"" seeking to settle in Sweden. Ribot and Peluso's theory of access (2003) was employed to examine the complex web of access experienced by our participants. We uncover that when communities are dealing with high levels of precarity, their primary concerns are related to accessing the benefits of a service, rather than controlling access. Broadening the HCI framework, the paper concludes that a sociotechnical model of access needs to connect access control and access benefit to facilitate the design of an effective digital service."
pn7213,https://doi.org/10.1145/3290605.3300411,Accessing a New Land: Designing for a Social Conceptualisation of Access,2,Rikke Jensen,Royal Holloway University of London,London,United Kingdom,false,false,"This paper presents a study of mobile phone use by people settling in a new land to access state provided digital services. It shows that digital literacy and access to technology are not the only resources and capabilities needed to successfully access digital services and do not guarantee a straightforward resettlement process. Using creative engagement methods, the research involved 132 ""newcomers"" seeking to settle in Sweden. Ribot and Peluso's theory of access (2003) was employed to examine the complex web of access experienced by our participants. We uncover that when communities are dealing with high levels of precarity, their primary concerns are related to accessing the benefits of a service, rather than controlling access. Broadening the HCI framework, the paper concludes that a sociotechnical model of access needs to connect access control and access benefit to facilitate the design of an effective digital service."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",1,Guanhong Liu,Tsinghua University,Beijing,China,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",2,Xianghua Ding,Fudan University,Shanghai,China,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",3,Chun Yu,Tsinghua University,Beijing,China,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",4,Lan Gao,Beihang University,Beijing,China,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",5,Xingyu Chi,Kensington Park School,London,United Kingdom,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn3170,https://doi.org/10.1145/3290605.3300602,"""I Bought This for Me to Look More Ordinary"": A Study of Blind People Doing Online Shopping",6,Yuanchun Shi,Tsinghua University,Beijing,China,false,false,"Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices."
pn6860,https://doi.org/10.1145/3290605.3300583,"""I was really, really nervous posting it"": Communicating about Invisible Chronic Illnesses across Social Media Platforms",1,Shruti Sannon,Cornell University,Ithaca,United States,false,false,"People with invisible chronic illnesses (ICIs) can use social media to seek both informational and emotional support, but these individuals also face social and health-related challenges in posting about their often-stigmatized conditions online. To understand how they evaluate different platforms for disclosure, we interviewed 19 people with ICIs who post on general social media about their illnesses, such as Facebook, Instagram, and Twitter. We present a cross-platform analysis of how platforms varied in their suitability to achieve participants' goals, as well as the challenges posed by each platform. We also found that as participants' ICIs progressed, their goals, challenges, and social media use similarly evolved over time. Our findings highlight how people with ICIs select platforms from a broader ecology of social media and suggest a general need to understand shifts in social media use for populations with chronic but changing health concerns."
pn6860,https://doi.org/10.1145/3290605.3300583,"""I was really, really nervous posting it"": Communicating about Invisible Chronic Illnesses across Social Media Platforms",2,Elizabeth Murnane,Stanford University,Stanford,United States,false,false,"People with invisible chronic illnesses (ICIs) can use social media to seek both informational and emotional support, but these individuals also face social and health-related challenges in posting about their often-stigmatized conditions online. To understand how they evaluate different platforms for disclosure, we interviewed 19 people with ICIs who post on general social media about their illnesses, such as Facebook, Instagram, and Twitter. We present a cross-platform analysis of how platforms varied in their suitability to achieve participants' goals, as well as the challenges posed by each platform. We also found that as participants' ICIs progressed, their goals, challenges, and social media use similarly evolved over time. Our findings highlight how people with ICIs select platforms from a broader ecology of social media and suggest a general need to understand shifts in social media use for populations with chronic but changing health concerns."
pn6860,https://doi.org/10.1145/3290605.3300583,"""I was really, really nervous posting it"": Communicating about Invisible Chronic Illnesses across Social Media Platforms",3,Natalya Bazarova,Cornell University,Ithaca,United States,false,false,"People with invisible chronic illnesses (ICIs) can use social media to seek both informational and emotional support, but these individuals also face social and health-related challenges in posting about their often-stigmatized conditions online. To understand how they evaluate different platforms for disclosure, we interviewed 19 people with ICIs who post on general social media about their illnesses, such as Facebook, Instagram, and Twitter. We present a cross-platform analysis of how platforms varied in their suitability to achieve participants' goals, as well as the challenges posed by each platform. We also found that as participants' ICIs progressed, their goals, challenges, and social media use similarly evolved over time. Our findings highlight how people with ICIs select platforms from a broader ecology of social media and suggest a general need to understand shifts in social media use for populations with chronic but changing health concerns."
pn6860,https://doi.org/10.1145/3290605.3300583,"""I was really, really nervous posting it"": Communicating about Invisible Chronic Illnesses across Social Media Platforms",4,Geraldine Gay,Cornell University,Ithaca,United States,false,false,"People with invisible chronic illnesses (ICIs) can use social media to seek both informational and emotional support, but these individuals also face social and health-related challenges in posting about their often-stigmatized conditions online. To understand how they evaluate different platforms for disclosure, we interviewed 19 people with ICIs who post on general social media about their illnesses, such as Facebook, Instagram, and Twitter. We present a cross-platform analysis of how platforms varied in their suitability to achieve participants' goals, as well as the challenges posed by each platform. We also found that as participants' ICIs progressed, their goals, challenges, and social media use similarly evolved over time. Our findings highlight how people with ICIs select platforms from a broader ecology of social media and suggest a general need to understand shifts in social media use for populations with chronic but changing health concerns."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,1,Yuhang Zhao,Cornell Tech,New York,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,2,Edward Cutrell,Microsoft Research,Redmond,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,3,Christian Holz,Microsoft Research,Redmond,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,4,Meredith Morris,Microsoft Research,Redmond,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,5,Eyal Ofek,Microsoft Research,Redmond,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn9785,https://doi.org/10.1145/3290605.3300341,SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision,6,Andrew Wilson,Microsoft Research,Redmond,United States,false,false,"Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,1,Ryan Wedoff,Microsoft,Redmond,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,2,Lindsay Ball,"The College at Brockport, State University of New York",Brockport,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,3,Amelia Wang,University of Washington,Seattle,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,4,Yi Xuan Khoo,University of Iowa,Iowa City,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,5,Lauren Lieberman,"The College at Brockport, State University of New York",Brockport,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn8133,https://doi.org/10.1145/3290605.3300371,Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments,6,Kyle Rector,University of Iowa,Iowa City,United States,false,false,"Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences."
pn2904,https://doi.org/10.1145/3290605.3300605,Examining Augmented Virtuality Impairment Simulation for Mobile App Accessibility Design,1,Kenny Choo,Singapore Management University,Singapore,Singapore,false,false,"With mobile apps rapidly permeating all aspects of daily living with use by all segments of the population, it is crucial to support the evaluation of app usability for specific impaired users to improve app accessibility. In this work, we examine the effects of using our augmented virtuality impairment simulation system--Empath-D--to support experienced designer-developers to redesign a mockup of commonly used mobile application for cataract-impaired users, comparing this with existing tools that aid designing for accessibility. We show that the use of augmented virtuality for assessing usability supports enhanced usability challenge identification, finding more defects and doing so more accurately than with existing methods. Through our user interviews, we also show that augmented virtuality impairment simulation supports realistic interaction and evaluation to provide a concrete understanding over the usability challenges that impaired users face, and complements the existing guidelines-based approaches meant for general accessibility."
pn2904,https://doi.org/10.1145/3290605.3300605,Examining Augmented Virtuality Impairment Simulation for Mobile App Accessibility Design,2,Rajesh Balan,Singapore Management University,Singapore,Singapore,false,false,"With mobile apps rapidly permeating all aspects of daily living with use by all segments of the population, it is crucial to support the evaluation of app usability for specific impaired users to improve app accessibility. In this work, we examine the effects of using our augmented virtuality impairment simulation system--Empath-D--to support experienced designer-developers to redesign a mockup of commonly used mobile application for cataract-impaired users, comparing this with existing tools that aid designing for accessibility. We show that the use of augmented virtuality for assessing usability supports enhanced usability challenge identification, finding more defects and doing so more accurately than with existing methods. Through our user interviews, we also show that augmented virtuality impairment simulation supports realistic interaction and evaluation to provide a concrete understanding over the usability challenges that impaired users face, and complements the existing guidelines-based approaches meant for general accessibility."
pn2904,https://doi.org/10.1145/3290605.3300605,Examining Augmented Virtuality Impairment Simulation for Mobile App Accessibility Design,3,Youngki Lee,Seoul National University,Seoul,Republic Of Korea,false,false,"With mobile apps rapidly permeating all aspects of daily living with use by all segments of the population, it is crucial to support the evaluation of app usability for specific impaired users to improve app accessibility. In this work, we examine the effects of using our augmented virtuality impairment simulation system--Empath-D--to support experienced designer-developers to redesign a mockup of commonly used mobile application for cataract-impaired users, comparing this with existing tools that aid designing for accessibility. We show that the use of augmented virtuality for assessing usability supports enhanced usability challenge identification, finding more defects and doing so more accurately than with existing methods. Through our user interviews, we also show that augmented virtuality impairment simulation supports realistic interaction and evaluation to provide a concrete understanding over the usability challenges that impaired users face, and complements the existing guidelines-based approaches meant for general accessibility."
pn1252,https://doi.org/10.1145/3290605.3300584,The Effect of Field-of-View Restriction on Sex Bias in VR Sickness and Spatial Navigation Performance,1,Majed Al Zayer,University of Nevada,Reno,United States,false,false,"Recent studies show that women are more susceptible to visually-induced VR sickness, which might explain the low adoption rate of VR technology among women. Reducing field-of-view (FOV) during locomotion is already a widely used strategy to reduce VR sickness as it blocks peripheral optical flow perception and mitigates visual/vestibular conflict. Prior studies show that men are more adept at 3D spatial navigation than women, though this sex bias can be minimized by providing women with a larger FOV. Our study provides insight into the relationship between sex and FOV restriction with respect to VR sickness and spatial navigation performance which seem to conflict. We find the use of an FOV restrictor to be effective in mitigating VR sickness in both sexes while we did not find a negative effect of FOV restriction on spatial navigation performance."
pn1252,https://doi.org/10.1145/3290605.3300584,The Effect of Field-of-View Restriction on Sex Bias in VR Sickness and Spatial Navigation Performance,2,Isayas Adhanom,University of Nevada,Reno,United States,false,false,"Recent studies show that women are more susceptible to visually-induced VR sickness, which might explain the low adoption rate of VR technology among women. Reducing field-of-view (FOV) during locomotion is already a widely used strategy to reduce VR sickness as it blocks peripheral optical flow perception and mitigates visual/vestibular conflict. Prior studies show that men are more adept at 3D spatial navigation than women, though this sex bias can be minimized by providing women with a larger FOV. Our study provides insight into the relationship between sex and FOV restriction with respect to VR sickness and spatial navigation performance which seem to conflict. We find the use of an FOV restrictor to be effective in mitigating VR sickness in both sexes while we did not find a negative effect of FOV restriction on spatial navigation performance."
pn1252,https://doi.org/10.1145/3290605.3300584,The Effect of Field-of-View Restriction on Sex Bias in VR Sickness and Spatial Navigation Performance,3,Paul Macneilage,University of Nevada,Reno,United States,false,false,"Recent studies show that women are more susceptible to visually-induced VR sickness, which might explain the low adoption rate of VR technology among women. Reducing field-of-view (FOV) during locomotion is already a widely used strategy to reduce VR sickness as it blocks peripheral optical flow perception and mitigates visual/vestibular conflict. Prior studies show that men are more adept at 3D spatial navigation than women, though this sex bias can be minimized by providing women with a larger FOV. Our study provides insight into the relationship between sex and FOV restriction with respect to VR sickness and spatial navigation performance which seem to conflict. We find the use of an FOV restrictor to be effective in mitigating VR sickness in both sexes while we did not find a negative effect of FOV restriction on spatial navigation performance."
pn1252,https://doi.org/10.1145/3290605.3300584,The Effect of Field-of-View Restriction on Sex Bias in VR Sickness and Spatial Navigation Performance,4,Eelke Folmer,University of Nevada,Reno,United States,false,false,"Recent studies show that women are more susceptible to visually-induced VR sickness, which might explain the low adoption rate of VR technology among women. Reducing field-of-view (FOV) during locomotion is already a widely used strategy to reduce VR sickness as it blocks peripheral optical flow perception and mitigates visual/vestibular conflict. Prior studies show that men are more adept at 3D spatial navigation than women, though this sex bias can be minimized by providing women with a larger FOV. Our study provides insight into the relationship between sex and FOV restriction with respect to VR sickness and spatial navigation performance which seem to conflict. We find the use of an FOV restrictor to be effective in mitigating VR sickness in both sexes while we did not find a negative effect of FOV restriction on spatial navigation performance."
pn5538,https://doi.org/10.1145/3290605.3300352,Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision,1,Rosanna Bellini,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"Work addressing the negative impacts of domestic violence on victim-survivors and service providers has slowly been contributing to the HCI discourse. However, work discussing the necessary, pre-emptive steps for researchers to enter these spaces sensitively and considerately, largely remains opaque. Heavily-politicised specialisms that are imbued with conflicting values and practices, such as domestic violence service delivery can be especially difficult to navigate. In this paper, we report on a mixed methods study consisting of interviews, a design dialogue and an ideation workshop with domestic violence service providers to explore the potential of an online service directory to support their work. Through this three-stage research process, we were able to characterise this unique service delivery landscape and identify tensions in services' access, understandings of technologies and working practices. Drawing from our findings, we discuss opportunities for researchers to work with and sustain complex information ecologies in sensitive settings."
pn5538,https://doi.org/10.1145/3290605.3300352,Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision,2,Angelika Strohmayer,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"Work addressing the negative impacts of domestic violence on victim-survivors and service providers has slowly been contributing to the HCI discourse. However, work discussing the necessary, pre-emptive steps for researchers to enter these spaces sensitively and considerately, largely remains opaque. Heavily-politicised specialisms that are imbued with conflicting values and practices, such as domestic violence service delivery can be especially difficult to navigate. In this paper, we report on a mixed methods study consisting of interviews, a design dialogue and an ideation workshop with domestic violence service providers to explore the potential of an online service directory to support their work. Through this three-stage research process, we were able to characterise this unique service delivery landscape and identify tensions in services' access, understandings of technologies and working practices. Drawing from our findings, we discuss opportunities for researchers to work with and sustain complex information ecologies in sensitive settings."
pn5538,https://doi.org/10.1145/3290605.3300352,Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision,3,Patrick Olivier,Monash University,Melbourne,Australia,true,false,"Work addressing the negative impacts of domestic violence on victim-survivors and service providers has slowly been contributing to the HCI discourse. However, work discussing the necessary, pre-emptive steps for researchers to enter these spaces sensitively and considerately, largely remains opaque. Heavily-politicised specialisms that are imbued with conflicting values and practices, such as domestic violence service delivery can be especially difficult to navigate. In this paper, we report on a mixed methods study consisting of interviews, a design dialogue and an ideation workshop with domestic violence service providers to explore the potential of an online service directory to support their work. Through this three-stage research process, we were able to characterise this unique service delivery landscape and identify tensions in services' access, understandings of technologies and working practices. Drawing from our findings, we discuss opportunities for researchers to work with and sustain complex information ecologies in sensitive settings."
pn5538,https://doi.org/10.1145/3290605.3300352,Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision,4,Clara Crivellaro,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"Work addressing the negative impacts of domestic violence on victim-survivors and service providers has slowly been contributing to the HCI discourse. However, work discussing the necessary, pre-emptive steps for researchers to enter these spaces sensitively and considerately, largely remains opaque. Heavily-politicised specialisms that are imbued with conflicting values and practices, such as domestic violence service delivery can be especially difficult to navigate. In this paper, we report on a mixed methods study consisting of interviews, a design dialogue and an ideation workshop with domestic violence service providers to explore the potential of an online service directory to support their work. Through this three-stage research process, we were able to characterise this unique service delivery landscape and identify tensions in services' access, understandings of technologies and working practices. Drawing from our findings, we discuss opportunities for researchers to work with and sustain complex information ecologies in sensitive settings."
pn2345,https://doi.org/10.1145/3290605.3300882,Technologies for Social Justice: Lessons from Sex Workers on the Front Lines,1,Angelika Strohmayer,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"This paper provides analysis and insight from a collaborative process with a Canadian sex worker rights organization called Stella, l'amie de Maimie, where we reflect on the use of and potential for digital technologies in service delivery. We analyze the Bad Client and Aggressor List – a reporting tool co-produced by sex workers in the community and Stella staff to reduce violence against sex workers. We analyze its current and potential future formats as an artefact for communication, in a context of sex work criminalization and the exclusion of sex workers from traditional routes for reporting violence and accessing governmental systems for justice. This paper addresses a novel aspect of HCI research that relates to digital technologies and social justice. Reflecting on the Bad Client and Aggressor List, we discuss how technologies can interact with justice-oriented service delivery and develop three implications for design."
pn2345,https://doi.org/10.1145/3290605.3300882,Technologies for Social Justice: Lessons from Sex Workers on the Front Lines,2,Jenn Clamen,"Stella, l'amie de Maimie",Montreal,Canada,true,false,"This paper provides analysis and insight from a collaborative process with a Canadian sex worker rights organization called Stella, l'amie de Maimie, where we reflect on the use of and potential for digital technologies in service delivery. We analyze the Bad Client and Aggressor List – a reporting tool co-produced by sex workers in the community and Stella staff to reduce violence against sex workers. We analyze its current and potential future formats as an artefact for communication, in a context of sex work criminalization and the exclusion of sex workers from traditional routes for reporting violence and accessing governmental systems for justice. This paper addresses a novel aspect of HCI research that relates to digital technologies and social justice. Reflecting on the Bad Client and Aggressor List, we discuss how technologies can interact with justice-oriented service delivery and develop three implications for design."
pn2345,https://doi.org/10.1145/3290605.3300882,Technologies for Social Justice: Lessons from Sex Workers on the Front Lines,3,Mary Laing,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"This paper provides analysis and insight from a collaborative process with a Canadian sex worker rights organization called Stella, l'amie de Maimie, where we reflect on the use of and potential for digital technologies in service delivery. We analyze the Bad Client and Aggressor List – a reporting tool co-produced by sex workers in the community and Stella staff to reduce violence against sex workers. We analyze its current and potential future formats as an artefact for communication, in a context of sex work criminalization and the exclusion of sex workers from traditional routes for reporting violence and accessing governmental systems for justice. This paper addresses a novel aspect of HCI research that relates to digital technologies and social justice. Reflecting on the Bad Client and Aggressor List, we discuss how technologies can interact with justice-oriented service delivery and develop three implications for design."
pn2484,https://doi.org/10.1145/3290605.3300760,Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions,1,Ali Alkhatib,Stanford University,Stanford,United States,false,true,"Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street-level algorithms that draw on historical design patterns for street-level bureaucracies, including mechanisms for self-policing and recourse in the case of error."
pn2484,https://doi.org/10.1145/3290605.3300760,Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions,2,Michael Bernstein,Stanford University,Stanford,United States,false,true,"Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street-level algorithms that draw on historical design patterns for street-level bureaucracies, including mechanisms for self-policing and recourse in the case of error."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,1,Joseph Seering,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,2,Tianmi Fang,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,3,Luca Damasco,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,4,Mianhong Chen,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,5,Likang Sun,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn2216,https://doi.org/10.1145/3290605.3300836,Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors,6,Geoff Kaufman,Carnegie Mellon University,Pittsburgh,United States,false,false,"Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically ""embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,1,Pei-Yi Kuo,University of Michigan,Hsinchu City,Taiwan Roc,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,2,Rajiv Saran,University of Michigan,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,3,Marissa Argentina,National Kidney Foundation,New York,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,4,Michael Heung,University of Michigan,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,5,Jennifer Bragg-Gresham,University of Michigan,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,6,Dinesh Chatoth,Fresenius Medical Care North America,Waltham,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,7,Brenda Gillespie,University of Michigan,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,8,Sarah Krein,University of Michigan Medical School,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,9,Rebecca Wingard,Fresenius Medical Care North America,Waltham,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,10,Kai Zheng,"University of California, Irvine",Irvine,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn6849,https://doi.org/10.1145/3290605.3300872,Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory,11,Tiffany Veinot,University of Michigan,Ann Arbor,United States,false,false,"Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (""IDH""). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion."
pn3467,https://doi.org/10.1145/3290605.3300777,Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work,1,Leah Kulp,Drexel University,Philadelphia,United States,false,false,"This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work."
pn3467,https://doi.org/10.1145/3290605.3300777,Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work,2,Aleksandra Sarcevic,Drexel University,Philadelphia,United States,false,false,"This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work."
pn3467,https://doi.org/10.1145/3290605.3300777,Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work,3,Megan Cheng,Children's National Medical Center,Washington,United States,false,false,"This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work."
pn3467,https://doi.org/10.1145/3290605.3300777,Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work,4,Yinan Zheng,Children's National Medical Center,Washington,United States,false,false,"This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work."
pn3467,https://doi.org/10.1145/3290605.3300777,Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work,5,Randall Burd,Children's National Medical Center,Washington,United States,false,false,"This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,1,Tobias Grundgeiger,Julius-Maximilians-University,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,2,Stephan Huber,Julius-Maximilians-University,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,3,Daniel Reinhardt,Julius-Maximilians-University,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,4,Andreas Steinisch,University Hospital of Würzburg,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,5,Oliver Happel,University Hospital of Würzburg,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn5501,https://doi.org/10.1145/3290605.3300884,Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams,6,Thomas Wurmb,University Hospital of Würzburg,Würzburg,Germany,true,false,"Cognitive aids – artefacts that support a user in the completion of a task at the time – have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,1,Carrie Cai,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,2,Emily Reif,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,3,Narayan Hegde,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,4,Jason Hipp,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,5,Been Kim,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,6,Daniel Smilkov,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,7,Martin Wattenberg,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,8,Fernanda Viegas,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,9,Greg Corrado,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,10,Martin Stumpe,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn9808,https://doi.org/10.1145/3290605.3300234,Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making,11,Michael Terry,Google Brain,Mountain View,United States,true,false,"Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making."
pn1035,https://doi.org/10.1145/3290605.3300452,Patient Perspectives on Self-Management Technologies for Chronic Fatigue Syndrome,1,Tabby Davies,University of Bath,Bath,United Kingdom,false,false,"Chronic Fatigue Syndrome (CFS) is a debilitating medical condition that is characterized by a range of physical, cognitive and social impairments. This paper investigates CFS patients' perspectives on the potential for technological support for self-management of their symptoms. We report findings from three studies in which people living with CFS 1) prioritized symptoms that they would like technologies to address, 2) articulated their current approaches to self-management alongside challenges they face, and 3) reflected on their experiences with three commercial smartphone apps related to symptom management. We contribute an understanding of the specific needs of the ME/CFS population and the ways in which they currently engage in self-management using technology. The paper ends by describing five high-level design recommendations for ME/CFS self-management technologies."
pn1035,https://doi.org/10.1145/3290605.3300452,Patient Perspectives on Self-Management Technologies for Chronic Fatigue Syndrome,2,Simon Jones,University of Bath,Bath,United Kingdom,false,false,"Chronic Fatigue Syndrome (CFS) is a debilitating medical condition that is characterized by a range of physical, cognitive and social impairments. This paper investigates CFS patients' perspectives on the potential for technological support for self-management of their symptoms. We report findings from three studies in which people living with CFS 1) prioritized symptoms that they would like technologies to address, 2) articulated their current approaches to self-management alongside challenges they face, and 3) reflected on their experiences with three commercial smartphone apps related to symptom management. We contribute an understanding of the specific needs of the ME/CFS population and the ways in which they currently engage in self-management using technology. The paper ends by describing five high-level design recommendations for ME/CFS self-management technologies."
pn1035,https://doi.org/10.1145/3290605.3300452,Patient Perspectives on Self-Management Technologies for Chronic Fatigue Syndrome,3,Ryan Kelly,The University of Melbourne,Melbourne,Australia,false,false,"Chronic Fatigue Syndrome (CFS) is a debilitating medical condition that is characterized by a range of physical, cognitive and social impairments. This paper investigates CFS patients' perspectives on the potential for technological support for self-management of their symptoms. We report findings from three studies in which people living with CFS 1) prioritized symptoms that they would like technologies to address, 2) articulated their current approaches to self-management alongside challenges they face, and 3) reflected on their experiences with three commercial smartphone apps related to symptom management. We contribute an understanding of the specific needs of the ME/CFS population and the ways in which they currently engage in self-management using technology. The paper ends by describing five high-level design recommendations for ME/CFS self-management technologies."
pn5633,https://doi.org/10.1145/3290605.3300895,"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK",1,Eleanor Burgess,Northwestern University,Chicago,United States,false,false,"People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey – recognizing need, seeking, interpreting, and using information – to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools."
pn5633,https://doi.org/10.1145/3290605.3300895,"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK",2,Madhu Reddy,Northwestern University,Evanston,United States,false,false,"People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey – recognizing need, seeking, interpreting, and using information – to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools."
pn5633,https://doi.org/10.1145/3290605.3300895,"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK",3,Andrew Davenport,Royal Free Hospital,London,United Kingdom,false,false,"People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey – recognizing need, seeking, interpreting, and using information – to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools."
pn5633,https://doi.org/10.1145/3290605.3300895,"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK",4,Paul Laboi,York Teaching Hospital NHS Foundation Trust,York,United Kingdom,false,false,"People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey – recognizing need, seeking, interpreting, and using information – to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools."
pn5633,https://doi.org/10.1145/3290605.3300895,"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK",5,Ann Blandford,University College London,London,United Kingdom,false,false,"People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey – recognizing need, seeking, interpreting, and using information – to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,1,Andrew Berry,University of Washington,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,2,Catherine Lim,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,3,Tad Hirsch,Northeastern University,Boston,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,4,Andrea Hartzler,University of Washington,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,5,Linda Kiel,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,6,Zoë Bermet,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn1089,https://doi.org/10.1145/3290605.3300700,Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers,7,James Ralston,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,1,Catherine Lim,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,2,Andrew Berry,University of Washington,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,3,Andrea Hartzler,University of Washington,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,4,Tad Hirsch,Northeastern University,Boston,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,5,David Carrell,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,6,Zoë Bermet,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn8281,https://doi.org/10.1145/3290605.3300885,Facilitating Self-reflection about Values and Self-care Among Individuals with Chronic Conditions,7,James Ralston,Kaiser Permanente Washington Health Research Institute,Seattle,United States,false,false,"Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC."
pn3930,https://doi.org/10.1145/3290605.3300408,Ethical Mediation in UX Practice,1,Colin Gray,Purdue University,West Lafayette,United States,false,false,"HCI scholars have become increasingly interested in describing the complex nature of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical and value-laden relationship between designers and design outcomes. However, little research describes the ethical engagement of UX practitioners as a form of design complexity, including the multiple mediating factors that impact ethical awareness and decision-making. In this paper, we use a practice-led approach to describe ethical complexity, presenting three varied cases of UX practitioners based onin situ observations and interviews. In each case, we describe salient factors relating to ethical mediation, including organizational practices, self-driven ethical principles, and unique characteristics of specific projects the practitioner is engaged in. Using the concept of mediation from activity theory, we provide a rich account of practitioners' ethical decision making. We propose future work on ethical awareness and design education based on the concept of ethical mediation."
pn3930,https://doi.org/10.1145/3290605.3300408,Ethical Mediation in UX Practice,2,Shruthi Chivukula,Purdue University,West Lafayette,United States,false,false,"HCI scholars have become increasingly interested in describing the complex nature of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical and value-laden relationship between designers and design outcomes. However, little research describes the ethical engagement of UX practitioners as a form of design complexity, including the multiple mediating factors that impact ethical awareness and decision-making. In this paper, we use a practice-led approach to describe ethical complexity, presenting three varied cases of UX practitioners based onin situ observations and interviews. In each case, we describe salient factors relating to ethical mediation, including organizational practices, self-driven ethical principles, and unique characteristics of specific projects the practitioner is engaged in. Using the concept of mediation from activity theory, we provide a rich account of practitioners' ethical decision making. We propose future work on ethical awareness and design education based on the concept of ethical mediation."
pn7122,https://doi.org/10.1145/3290605.3300859,An Exploration of Bitcoin Mining Practices: Miners' Trust Challenges and Motivations,1,Irni Eliana Khairuddin,Universiti Teknologi MARA,Shah Alam,Malaysia,false,false,"Bitcoin blockchain technology is a distributed ledger of nodes authorizing transactions between anonymous parties. Its key actors are miners using computational power to solve mathematical problems for validating transactions. By sharing blockchain's characteristics, mining is a decentralized, transparent and unregulated practice, less explored in HCI, so we know little about miners' motivations and experiences, and how these may impact on different dimensions of trust. This paper reports on interviews with 20 bitcoin miners about their practices and trust challenges. Findings contribute to HCI theories by extending the exploration of blockchain's characteristics relevant to trust with the competitiveness dimension underpinning the social organization of mining. We discuss the risks of collaborative mining due to centralization and dishonest administrators, and conclude with design implications highlighting the need for tools monitoring the distribution of rewards in collaborative mining, tools tracking data centers' authorization and reputation, and tools supporting the development of decentralized pools."
pn7122,https://doi.org/10.1145/3290605.3300859,An Exploration of Bitcoin Mining Practices: Miners' Trust Challenges and Motivations,2,Corina Sas,Lancaster University,Lancaster,United Kingdom,false,false,"Bitcoin blockchain technology is a distributed ledger of nodes authorizing transactions between anonymous parties. Its key actors are miners using computational power to solve mathematical problems for validating transactions. By sharing blockchain's characteristics, mining is a decentralized, transparent and unregulated practice, less explored in HCI, so we know little about miners' motivations and experiences, and how these may impact on different dimensions of trust. This paper reports on interviews with 20 bitcoin miners about their practices and trust challenges. Findings contribute to HCI theories by extending the exploration of blockchain's characteristics relevant to trust with the competitiveness dimension underpinning the social organization of mining. We discuss the risks of collaborative mining due to centralization and dishonest administrators, and conclude with design implications highlighting the need for tools monitoring the distribution of rewards in collaborative mining, tools tracking data centers' authorization and reputation, and tools supporting the development of decentralized pools."
pn8774,https://doi.org/10.1145/3290605.3300307,Analyzing Value Discovery in Design Decisions Through Ethicography,1,Shruthi Chivukula,Purdue University,West Lafayette,United States,true,false,"HCI scholarship is increasingly concerned with the ethical impact of socio-technical systems. Current theoretically driven approaches that engage with ethics generally prescribe only abstract approaches by which designers might consider values in the design process. However, there is little guidance on methods that promote value discovery, which might lead to more specific examples of relevant values in specific design contexts. In this paper, we elaborate a method for value discovery, identifying how values impact the designer's decision making. We demonstrate the use of this method, called Ethicography, in describing value discovery and use throughout the design process. We present analysis of design activity by user experience (UX) design students in two lab protocol conditions, describing specific human values that designers considered for each task, and visualizing the interplay of these values. We identify opportunities for further research, using the Ethicograph method to illustrate value discovery and translation into design solutions."
pn8774,https://doi.org/10.1145/3290605.3300307,Analyzing Value Discovery in Design Decisions Through Ethicography,2,Colin Gray,Purdue University,West Lafayette,United States,true,false,"HCI scholarship is increasingly concerned with the ethical impact of socio-technical systems. Current theoretically driven approaches that engage with ethics generally prescribe only abstract approaches by which designers might consider values in the design process. However, there is little guidance on methods that promote value discovery, which might lead to more specific examples of relevant values in specific design contexts. In this paper, we elaborate a method for value discovery, identifying how values impact the designer's decision making. We demonstrate the use of this method, called Ethicography, in describing value discovery and use throughout the design process. We present analysis of design activity by user experience (UX) design students in two lab protocol conditions, describing specific human values that designers considered for each task, and visualizing the interplay of these values. We identify opportunities for further research, using the Ethicograph method to illustrate value discovery and translation into design solutions."
pn8774,https://doi.org/10.1145/3290605.3300307,Analyzing Value Discovery in Design Decisions Through Ethicography,3,Jason Brier,Purdue University,West Lafayette,United States,true,false,"HCI scholarship is increasingly concerned with the ethical impact of socio-technical systems. Current theoretically driven approaches that engage with ethics generally prescribe only abstract approaches by which designers might consider values in the design process. However, there is little guidance on methods that promote value discovery, which might lead to more specific examples of relevant values in specific design contexts. In this paper, we elaborate a method for value discovery, identifying how values impact the designer's decision making. We demonstrate the use of this method, called Ethicography, in describing value discovery and use throughout the design process. We present analysis of design activity by user experience (UX) design students in two lab protocol conditions, describing specific human values that designers considered for each task, and visualizing the interplay of these values. We identify opportunities for further research, using the Ethicograph method to illustrate value discovery and translation into design solutions."
pn5261,https://doi.org/10.1145/3290605.3300617,"Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation",1,Larissa Pschetz,Edinburgh University,Edinburgh,United Kingdom,true,false,"Technologies such as blockchains, smart contracts and programmable batteries facilitate emerging models of energy distribution, trade and consumption, and generate a considerable number of opportunities for energy markets. However, these developments complicate relationships between stakeholders, disrupting traditional notions of value, control and ownership. Discussing these issues with the public is particularly challenging as energy consumption habits often obscure the competing values and interests that shape stakeholders' relationships. To make such difficult discussions more approachable and examine the missing relational aspect of autonomous energy systems, we combined the design of speculative hairdryers with performance and deliberation. This integrated method of inquiry makes visible the competing values and interests, eliciting people's wishes to negotiate these terms. We argue that the complexity of mediated energy distribution and its convoluted stakeholder relationships requires more sophisticated methods of inquiry to engage people in debates concerning distributed energy systems."
pn5261,https://doi.org/10.1145/3290605.3300617,"Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation",2,Kruakae Pothong,University College London,London,United Kingdom,true,false,"Technologies such as blockchains, smart contracts and programmable batteries facilitate emerging models of energy distribution, trade and consumption, and generate a considerable number of opportunities for energy markets. However, these developments complicate relationships between stakeholders, disrupting traditional notions of value, control and ownership. Discussing these issues with the public is particularly challenging as energy consumption habits often obscure the competing values and interests that shape stakeholders' relationships. To make such difficult discussions more approachable and examine the missing relational aspect of autonomous energy systems, we combined the design of speculative hairdryers with performance and deliberation. This integrated method of inquiry makes visible the competing values and interests, eliciting people's wishes to negotiate these terms. We argue that the complexity of mediated energy distribution and its convoluted stakeholder relationships requires more sophisticated methods of inquiry to engage people in debates concerning distributed energy systems."
pn5261,https://doi.org/10.1145/3290605.3300617,"Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation",3,Chris Speed,Edinburgh University,Edinburgh,United Kingdom,true,false,"Technologies such as blockchains, smart contracts and programmable batteries facilitate emerging models of energy distribution, trade and consumption, and generate a considerable number of opportunities for energy markets. However, these developments complicate relationships between stakeholders, disrupting traditional notions of value, control and ownership. Discussing these issues with the public is particularly challenging as energy consumption habits often obscure the competing values and interests that shape stakeholders' relationships. To make such difficult discussions more approachable and examine the missing relational aspect of autonomous energy systems, we combined the design of speculative hairdryers with performance and deliberation. This integrated method of inquiry makes visible the competing values and interests, eliciting people's wishes to negotiate these terms. We argue that the complexity of mediated energy distribution and its convoluted stakeholder relationships requires more sophisticated methods of inquiry to engage people in debates concerning distributed energy systems."
pn9253,https://doi.org/10.1145/3290605.3300893,"Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models",1,Subramanian Chidambaram,Purdue University,West Lafayette,United States,false,false,"Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication."
pn9253,https://doi.org/10.1145/3290605.3300893,"Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models",2,Yunbo Zhang,Rochester Institute of Technology,Rochester,United States,false,false,"Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication."
pn9253,https://doi.org/10.1145/3290605.3300893,"Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models",3,Venkatraghavan Sundararajan,Purdue university,West Lafayette,United States,false,false,"Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication."
pn9253,https://doi.org/10.1145/3290605.3300893,"Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models",4,Niklas Elmqvist,"University of Maryland, College Park",College Park,United States,false,false,"Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication."
pn9253,https://doi.org/10.1145/3290605.3300893,"Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models",5,Karthik Ramani,Purdue University,West Lafayette,United States,false,false,"Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,1,Patrick Baudisch,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,2,Arthur Silber,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,3,Yannis Kommana,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,4,Milan Gruner,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,5,Ludwig Wall,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,6,Kevin Reuss,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,7,Lukas Heilmann,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,8,Robert Kovacs,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,9,Daniel Rechlitz,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn4184,https://doi.org/10.1145/3290605.3300796,Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects,10,Thijs Roumen,Hasso Plattner Institute,Potsdam,Germany,false,false,"We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint ""boxel""—a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7."
pn8506,https://doi.org/10.1145/3290605.3300414,Digital Fabrication of Soft Actuated Objects by Machine Knitting,1,Lea Albaugh,Carnegie Mellon University,Pittsburgh,United States,false,false,"With recent interest in shape-changing interfaces, material-driven design, wearable technologies, and soft robotics, digital fabrication of soft actuatable material is increasingly in demand. Much of this research focuses on elastomers or non-stretchy air bladders. Computationally-controlled machine knitting offers an alternative fabrication technology which can rapidly produce soft textile objects that have a very different character: breathable, lightweight, and pleasant to the touch. These machines are well established and optimized for the mass production of garments, but compared to other digital fabrication techniques such as CNC machining or 3D printing, they have received much less attention as general purpose fabrication devices. In this work, we explore new ways to employ machine knitting for the creation of actuated soft objects. We describe the basic operation of this type of machine, then show new techniques for knitting tendon-based actuation into objects. We explore a series of design strategies for integrating tendons with shaping and anisotropic texture design. Finally, we investigate different knit material properties, including considerations for motor control and sensing."
pn8506,https://doi.org/10.1145/3290605.3300414,Digital Fabrication of Soft Actuated Objects by Machine Knitting,2,Scott Hudson,Carnegie Mellon University,Pittsburgh,United States,false,false,"With recent interest in shape-changing interfaces, material-driven design, wearable technologies, and soft robotics, digital fabrication of soft actuatable material is increasingly in demand. Much of this research focuses on elastomers or non-stretchy air bladders. Computationally-controlled machine knitting offers an alternative fabrication technology which can rapidly produce soft textile objects that have a very different character: breathable, lightweight, and pleasant to the touch. These machines are well established and optimized for the mass production of garments, but compared to other digital fabrication techniques such as CNC machining or 3D printing, they have received much less attention as general purpose fabrication devices. In this work, we explore new ways to employ machine knitting for the creation of actuated soft objects. We describe the basic operation of this type of machine, then show new techniques for knitting tendon-based actuation into objects. We explore a series of design strategies for integrating tendons with shaping and anisotropic texture design. Finally, we investigate different knit material properties, including considerations for motor control and sensing."
pn8506,https://doi.org/10.1145/3290605.3300414,Digital Fabrication of Soft Actuated Objects by Machine Knitting,3,Lining Yao,Carnegie Mellon University,Pittsburgh,United States,false,false,"With recent interest in shape-changing interfaces, material-driven design, wearable technologies, and soft robotics, digital fabrication of soft actuatable material is increasingly in demand. Much of this research focuses on elastomers or non-stretchy air bladders. Computationally-controlled machine knitting offers an alternative fabrication technology which can rapidly produce soft textile objects that have a very different character: breathable, lightweight, and pleasant to the touch. These machines are well established and optimized for the mass production of garments, but compared to other digital fabrication techniques such as CNC machining or 3D printing, they have received much less attention as general purpose fabrication devices. In this work, we explore new ways to employ machine knitting for the creation of actuated soft objects. We describe the basic operation of this type of machine, then show new techniques for knitting tendon-based actuation into objects. We explore a series of design strategies for integrating tendons with shaping and anisotropic texture design. Finally, we investigate different knit material properties, including considerations for motor control and sensing."
pn4270,https://doi.org/10.1145/3290605.3300877,Understanding Metamaterial Mechanisms,1,Alexandra Ion,Hasso Plattner Institute,Potsdam,Germany,false,false,"In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements."
pn4270,https://doi.org/10.1145/3290605.3300877,Understanding Metamaterial Mechanisms,2,David Lindlbauer,Technische Universität Berlin,Berlin,Germany,false,false,"In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements."
pn4270,https://doi.org/10.1145/3290605.3300877,Understanding Metamaterial Mechanisms,3,Philipp Herholz,Technische Universität Berlin,Berlin,Germany,false,false,"In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements."
pn4270,https://doi.org/10.1145/3290605.3300877,Understanding Metamaterial Mechanisms,4,Marc Alexa,Technische Universität Berlin,Berlin,Germany,false,false,"In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements."
pn4270,https://doi.org/10.1145/3290605.3300877,Understanding Metamaterial Mechanisms,5,Patrick Baudisch,"Hasso Plattner Institute, University of Potsdam,",Potsdam,Germany,false,false,"In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements."
pn9250,https://doi.org/10.1145/3290605.3300931,How to Design Voice Based Navigation for How-To Videos,1,Minsuk Chang,KAIST,Daejeon,Republic Of Korea,false,false,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents."
pn9250,https://doi.org/10.1145/3290605.3300931,How to Design Voice Based Navigation for How-To Videos,2,Anh Truong,Adobe Research,San Francisco,United States,false,false,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents."
pn9250,https://doi.org/10.1145/3290605.3300931,How to Design Voice Based Navigation for How-To Videos,3,Oliver Wang,Adobe Research,Seattle,United States,false,false,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents."
pn9250,https://doi.org/10.1145/3290605.3300931,How to Design Voice Based Navigation for How-To Videos,4,Maneesh Agrawala,Stanford University,Stanford,United States,false,false,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents."
pn9250,https://doi.org/10.1145/3290605.3300931,How to Design Voice Based Navigation for How-To Videos,5,Juho Kim,KAIST,Daejeon,Republic Of Korea,false,false,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents."
pn9357,https://doi.org/10.1145/3290605.3300311,B-Script: Transcript-based B-roll Video Editing with Recommendations,1,Bernd Huber,Harvard University,Cambridge,United States,false,false,"In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided."
pn9357,https://doi.org/10.1145/3290605.3300311,B-Script: Transcript-based B-roll Video Editing with Recommendations,2,Hijung Shin,Adobe Research,Cambridge,United States,false,false,"In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided."
pn9357,https://doi.org/10.1145/3290605.3300311,B-Script: Transcript-based B-roll Video Editing with Recommendations,3,Bryan Russell,Adobe Research,San Francisco,United States,false,false,"In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided."
pn9357,https://doi.org/10.1145/3290605.3300311,B-Script: Transcript-based B-roll Video Editing with Recommendations,4,Oliver Wang,Adobe Research,Seattle,United States,false,false,"In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided."
pn9357,https://doi.org/10.1145/3290605.3300311,B-Script: Transcript-based B-roll Video Editing with Recommendations,5,Gautham Mysore,Adobe Research,San Francisco,United States,false,false,"In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided."
pn1028,https://doi.org/10.1145/3290605.3300514,TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality,1,Balasaravanan Thoravi Kumaravel,"University of California, Berkeley",Berkeley,United States,false,false,"Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may suffice for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user's VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR."
pn1028,https://doi.org/10.1145/3290605.3300514,TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality,2,Cuong Nguyen,Adobe Research,San Francisco,United States,false,false,"Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may suffice for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user's VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR."
pn1028,https://doi.org/10.1145/3290605.3300514,TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality,3,Stephen Diverdi,Adobe Research,San Francisco,United States,false,false,"Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may suffice for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user's VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR."
pn1028,https://doi.org/10.1145/3290605.3300514,TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality,4,Björn Hartmann,"University of California, Berkeley",Berkeley,United States,false,false,"Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may suffice for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user's VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR."
pn9295,https://doi.org/10.1145/3290605.3300852,Interactive Body-Driven Graphics for Augmented Video Performance,1,Nazmus Saquib,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present a system that augments live presentation videos with interactive graphics to create a powerful and expressive storytelling environment. Using our system, the presenter interacts with the graphical elements in real-time with gestures and postures, thus leveraging our innate, everyday skills to enhance our communication capabilities with the audience. However, crafting such an interactive and expressive performance typically requires programming, or highly-specialized tools tailored for experts. Our core contribution is a flexible, direct manipulation UI which enables amateurs and experts to craft such presentations beforehand by mapping a variety of body movements to a wide range of graphical manipulations. By simplifying the mapping between gestures, postures, and their corresponding output effects, our UI enables users to craft customized, rich interactions with the graphical elements. Our user study demonstrates the potential usage and unique affordance of this mixed-reality medium for storytelling and presentation across a range of application domains."
pn9295,https://doi.org/10.1145/3290605.3300852,Interactive Body-Driven Graphics for Augmented Video Performance,2,Rubaiat Habib Kazi,Adobe Research,Toronto,Canada,false,false,"We present a system that augments live presentation videos with interactive graphics to create a powerful and expressive storytelling environment. Using our system, the presenter interacts with the graphical elements in real-time with gestures and postures, thus leveraging our innate, everyday skills to enhance our communication capabilities with the audience. However, crafting such an interactive and expressive performance typically requires programming, or highly-specialized tools tailored for experts. Our core contribution is a flexible, direct manipulation UI which enables amateurs and experts to craft such presentations beforehand by mapping a variety of body movements to a wide range of graphical manipulations. By simplifying the mapping between gestures, postures, and their corresponding output effects, our UI enables users to craft customized, rich interactions with the graphical elements. Our user study demonstrates the potential usage and unique affordance of this mixed-reality medium for storytelling and presentation across a range of application domains."
pn9295,https://doi.org/10.1145/3290605.3300852,Interactive Body-Driven Graphics for Augmented Video Performance,3,Li-Yi Wei,Adobe Research,San Jose,United States,false,false,"We present a system that augments live presentation videos with interactive graphics to create a powerful and expressive storytelling environment. Using our system, the presenter interacts with the graphical elements in real-time with gestures and postures, thus leveraging our innate, everyday skills to enhance our communication capabilities with the audience. However, crafting such an interactive and expressive performance typically requires programming, or highly-specialized tools tailored for experts. Our core contribution is a flexible, direct manipulation UI which enables amateurs and experts to craft such presentations beforehand by mapping a variety of body movements to a wide range of graphical manipulations. By simplifying the mapping between gestures, postures, and their corresponding output effects, our UI enables users to craft customized, rich interactions with the graphical elements. Our user study demonstrates the potential usage and unique affordance of this mixed-reality medium for storytelling and presentation across a range of application domains."
pn9295,https://doi.org/10.1145/3290605.3300852,Interactive Body-Driven Graphics for Augmented Video Performance,4,Wilmot Li,Adobe,Seattle,United States,false,false,"We present a system that augments live presentation videos with interactive graphics to create a powerful and expressive storytelling environment. Using our system, the presenter interacts with the graphical elements in real-time with gestures and postures, thus leveraging our innate, everyday skills to enhance our communication capabilities with the audience. However, crafting such an interactive and expressive performance typically requires programming, or highly-specialized tools tailored for experts. Our core contribution is a flexible, direct manipulation UI which enables amateurs and experts to craft such presentations beforehand by mapping a variety of body movements to a wide range of graphical manipulations. By simplifying the mapping between gestures, postures, and their corresponding output effects, our UI enables users to craft customized, rich interactions with the graphical elements. Our user study demonstrates the potential usage and unique affordance of this mixed-reality medium for storytelling and presentation across a range of application domains."
pn4210,https://doi.org/10.1145/3290605.3300883,Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community,1,Maria Tomprou,Carnegie Mellon University,Usa,United States,false,false,"Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange."
pn4210,https://doi.org/10.1145/3290605.3300883,Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community,2,Laura Dabbish,Carnegie Mellon University,Pittsburgh,United States,false,false,"Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange."
pn4210,https://doi.org/10.1145/3290605.3300883,Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community,3,Robert Kraut,Carnegie Mellon University,Pittsburgh,United States,false,false,"Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange."
pn4210,https://doi.org/10.1145/3290605.3300883,Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community,4,Fannie Liu,Carnegie Mellon University,Pittsburgh,United States,false,false,"Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange."
pn2912,https://doi.org/10.1145/3290605.3300367,"What Happens After Disclosing Stigmatized Experiences on Identified Social Media: Individual, Dyadic, and Social/Network Outcomes",1,Nazanin Andalibi,University of Michigan,Ann Arbor,United States,true,false,"Disclosing stigmatized experiences or identity facets on identified social media (e.g., Facebook) can be risky, inhibited, yet beneficial for the discloser. I investigate such disclosures' outcomes when they do happen on identified social media as perceived by the individuals who perform them. I draw on interviews with women who have experienced pregnancy loss and are social media users in the U.S. I document outcomes at the social/network, individual, and dyad levels. I highlight the powerful role of connecting with others with a similar experience within networks of known ties, how disclosures lead to relationship changes, how disclosers take on new social roles as mentors and support sources, and how helpful connections following disclosures originate from various kinds of ties via diverse communication channels. I emphasize reciprocal disclosures as an outcome contributing to further outcomes (e.g., destigmatizing pregnancy loss). I provide design implications related to facilitating being a support source and mentor, helpful reciprocal disclosures, and finding similar others within networks of known ties."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,1,Erin Beneteau,University of Washington,Seattle,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,2,Olivia Richards,Pennsylvania State University,University Park,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,3,Mingrui Zhang,University of Washington,Seattle,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,4,Julie Kientz,University of Washington,Seattle,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,5,Jason Yip,University of Washington,Seattle,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn4063,https://doi.org/10.1145/3290605.3300473,Communication Breakdowns Between Families and Alexa,6,Alexis Hiniker,University of Washington,Seattle,United States,false,false,"We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns."
pn1756,https://doi.org/10.1145/3290605.3300501,Nurturing Constructive Disagreement - Agonistic Design with Neurodiverse Children,1,Christopher Frauenberger,TU Wien,Vienna,Austria,false,false,"Participatory design (PD) with heterogeneous groups poses particular challenges, requiring spaces in which different agendas or visions can be negotiated. In this paper we report on our PD work with two groups of neurodiverse children to design technologies that support co-located, social play. The heterogeneity in the groups in terms of abilities, conceptions of play, motivations to be involved and individual preferences has challenged us to think of the design process and its outcomes as spaces for continuous negotiation. Drawing on the notion of agonistic PD, we sought not to necessarily reconcile all views, but foster constructive disagreement as a resource for and possible outcome of design. Using our project work as a case study, we report on controversies, big and small, and how they manifested themselves in the processes and outcomes. Reflecting on our experiences, we discuss possible implications on the notion of democratising technology innovation."
pn1756,https://doi.org/10.1145/3290605.3300501,Nurturing Constructive Disagreement - Agonistic Design with Neurodiverse Children,2,Katta Spiel,TU Wien,Vienna,Austria,false,false,"Participatory design (PD) with heterogeneous groups poses particular challenges, requiring spaces in which different agendas or visions can be negotiated. In this paper we report on our PD work with two groups of neurodiverse children to design technologies that support co-located, social play. The heterogeneity in the groups in terms of abilities, conceptions of play, motivations to be involved and individual preferences has challenged us to think of the design process and its outcomes as spaces for continuous negotiation. Drawing on the notion of agonistic PD, we sought not to necessarily reconcile all views, but foster constructive disagreement as a resource for and possible outcome of design. Using our project work as a case study, we report on controversies, big and small, and how they manifested themselves in the processes and outcomes. Reflecting on our experiences, we discuss possible implications on the notion of democratising technology innovation."
pn1756,https://doi.org/10.1145/3290605.3300501,Nurturing Constructive Disagreement - Agonistic Design with Neurodiverse Children,3,Laura Scheepmaker,TU Wien,Vienna,Austria,false,false,"Participatory design (PD) with heterogeneous groups poses particular challenges, requiring spaces in which different agendas or visions can be negotiated. In this paper we report on our PD work with two groups of neurodiverse children to design technologies that support co-located, social play. The heterogeneity in the groups in terms of abilities, conceptions of play, motivations to be involved and individual preferences has challenged us to think of the design process and its outcomes as spaces for continuous negotiation. Drawing on the notion of agonistic PD, we sought not to necessarily reconcile all views, but foster constructive disagreement as a resource for and possible outcome of design. Using our project work as a case study, we report on controversies, big and small, and how they manifested themselves in the processes and outcomes. Reflecting on our experiences, we discuss possible implications on the notion of democratising technology innovation."
pn1756,https://doi.org/10.1145/3290605.3300501,Nurturing Constructive Disagreement - Agonistic Design with Neurodiverse Children,4,Irene Posch,TU Wien,Vienna,Austria,false,false,"Participatory design (PD) with heterogeneous groups poses particular challenges, requiring spaces in which different agendas or visions can be negotiated. In this paper we report on our PD work with two groups of neurodiverse children to design technologies that support co-located, social play. The heterogeneity in the groups in terms of abilities, conceptions of play, motivations to be involved and individual preferences has challenged us to think of the design process and its outcomes as spaces for continuous negotiation. Drawing on the notion of agonistic PD, we sought not to necessarily reconcile all views, but foster constructive disagreement as a resource for and possible outcome of design. Using our project work as a case study, we report on controversies, big and small, and how they manifested themselves in the processes and outcomes. Reflecting on our experiences, we discuss possible implications on the notion of democratising technology innovation."
pn8015,https://doi.org/10.1145/3290605.3300621,Crowdworker Economics in the Gig Economy,1,Jason Jacques,University of Cambridge,Cambridge,United Kingdom,false,false,"The nature of work is changing. As labor increasingly trends to casual work in the emerging gig economy, understanding the broader economic context is crucial to effective engagement with a contingent workforce. Crowdsourcing represents an early manifestation of this fluid, laisser-faire, on-demand workforce. This work analyzes the results of four large-scale surveys of US-based Amazon Mechanical Turk workers recorded over a six-year period, providing comparable measures to national statistics. Our results show that despite unemployment far higher than national levels, crowdworkers are seeing positive shifts in employment status and household income. Our most recent surveys indicate a trend away from full-time-equivalent crowdwork, coupled with a reduction in estimated poverty levels to below national figures. These trends are indicative of an increasingly flexible workforce, able to maximize their opportunities in a rapidly changing national labor market, which may have material impacts on existing models of crowdworker behavior."
pn8015,https://doi.org/10.1145/3290605.3300621,Crowdworker Economics in the Gig Economy,2,Per Ola Kristensson,University of Cambridge,Cambridge,United Kingdom,false,false,"The nature of work is changing. As labor increasingly trends to casual work in the emerging gig economy, understanding the broader economic context is crucial to effective engagement with a contingent workforce. Crowdsourcing represents an early manifestation of this fluid, laisser-faire, on-demand workforce. This work analyzes the results of four large-scale surveys of US-based Amazon Mechanical Turk workers recorded over a six-year period, providing comparable measures to national statistics. Our results show that despite unemployment far higher than national levels, crowdworkers are seeing positive shifts in employment status and household income. Our most recent surveys indicate a trend away from full-time-equivalent crowdwork, coupled with a reduction in estimated poverty levels to below national figures. These trends are indicative of an increasingly flexible workforce, able to maximize their opportunities in a rapidly changing national labor market, which may have material impacts on existing models of crowdworker behavior."
pn1120,https://doi.org/10.1145/3290605.3300522,Crowdsourcing Multi-label Audio Annotation Tasks with Citizen Scientists,1,Mark Cartwright,New York University,New York,United States,false,false,"Annotating rich audio data is an essential aspect of training and evaluating machine listening systems. We approach this task in the context of temporally-complex urban soundscapes, which require multiple labels to identify overlapping sound sources. Typically this work is crowdsourced, and previous studies have shown that workers can quickly label audio with binary annotation for single classes. However, this approach can be difficult to scale when multiple passes with different focus classes are required to annotate data with multiple labels. In citizen science, where tasks are often image-based, annotation efforts typically label multiple classes simultaneously in a single pass. This paper describes our data collection on the Zooniverse citizen science platform, comparing the efficiencies of different audio annotation strategies. We compared multiple-pass binary annotation, single-pass multi-label annotation, and a hybrid approach: hierarchical multi-pass multi-label annotation. We discuss our findings, which support using multi-label annotation, with reference to volunteer citizen scientists' motivations."
pn1120,https://doi.org/10.1145/3290605.3300522,Crowdsourcing Multi-label Audio Annotation Tasks with Citizen Scientists,2,Graham Dove,New York University,New York,United States,false,false,"Annotating rich audio data is an essential aspect of training and evaluating machine listening systems. We approach this task in the context of temporally-complex urban soundscapes, which require multiple labels to identify overlapping sound sources. Typically this work is crowdsourced, and previous studies have shown that workers can quickly label audio with binary annotation for single classes. However, this approach can be difficult to scale when multiple passes with different focus classes are required to annotate data with multiple labels. In citizen science, where tasks are often image-based, annotation efforts typically label multiple classes simultaneously in a single pass. This paper describes our data collection on the Zooniverse citizen science platform, comparing the efficiencies of different audio annotation strategies. We compared multiple-pass binary annotation, single-pass multi-label annotation, and a hybrid approach: hierarchical multi-pass multi-label annotation. We discuss our findings, which support using multi-label annotation, with reference to volunteer citizen scientists' motivations."
pn1120,https://doi.org/10.1145/3290605.3300522,Crowdsourcing Multi-label Audio Annotation Tasks with Citizen Scientists,3,Ana Elisa Méndez Méndez,New York University,New York,United States,false,false,"Annotating rich audio data is an essential aspect of training and evaluating machine listening systems. We approach this task in the context of temporally-complex urban soundscapes, which require multiple labels to identify overlapping sound sources. Typically this work is crowdsourced, and previous studies have shown that workers can quickly label audio with binary annotation for single classes. However, this approach can be difficult to scale when multiple passes with different focus classes are required to annotate data with multiple labels. In citizen science, where tasks are often image-based, annotation efforts typically label multiple classes simultaneously in a single pass. This paper describes our data collection on the Zooniverse citizen science platform, comparing the efficiencies of different audio annotation strategies. We compared multiple-pass binary annotation, single-pass multi-label annotation, and a hybrid approach: hierarchical multi-pass multi-label annotation. We discuss our findings, which support using multi-label annotation, with reference to volunteer citizen scientists' motivations."
pn1120,https://doi.org/10.1145/3290605.3300522,Crowdsourcing Multi-label Audio Annotation Tasks with Citizen Scientists,4,Juan Bello,New York University,New York,United States,false,false,"Annotating rich audio data is an essential aspect of training and evaluating machine listening systems. We approach this task in the context of temporally-complex urban soundscapes, which require multiple labels to identify overlapping sound sources. Typically this work is crowdsourced, and previous studies have shown that workers can quickly label audio with binary annotation for single classes. However, this approach can be difficult to scale when multiple passes with different focus classes are required to annotate data with multiple labels. In citizen science, where tasks are often image-based, annotation efforts typically label multiple classes simultaneously in a single pass. This paper describes our data collection on the Zooniverse citizen science platform, comparing the efficiencies of different audio annotation strategies. We compared multiple-pass binary annotation, single-pass multi-label annotation, and a hybrid approach: hierarchical multi-pass multi-label annotation. We discuss our findings, which support using multi-label annotation, with reference to volunteer citizen scientists' motivations."
pn1120,https://doi.org/10.1145/3290605.3300522,Crowdsourcing Multi-label Audio Annotation Tasks with Citizen Scientists,5,Oded Nov,New York University,New York,United States,false,false,"Annotating rich audio data is an essential aspect of training and evaluating machine listening systems. We approach this task in the context of temporally-complex urban soundscapes, which require multiple labels to identify overlapping sound sources. Typically this work is crowdsourced, and previous studies have shown that workers can quickly label audio with binary annotation for single classes. However, this approach can be difficult to scale when multiple passes with different focus classes are required to annotate data with multiple labels. In citizen science, where tasks are often image-based, annotation efforts typically label multiple classes simultaneously in a single pass. This paper describes our data collection on the Zooniverse citizen science platform, comparing the efficiencies of different audio annotation strategies. We compared multiple-pass binary annotation, single-pass multi-label annotation, and a hybrid approach: hierarchical multi-pass multi-label annotation. We discuss our findings, which support using multi-label annotation, with reference to volunteer citizen scientists' motivations."
pn3759,https://doi.org/10.1145/3290605.3300366,Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan,1,Anita Chen,Pennsylvania State University,State College,United States,false,false,"Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the ""gig'' of ride-sharing."
pn3759,https://doi.org/10.1145/3290605.3300366,Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan,2,Chien-Wen Yuan,Fu Jen University,New Taipei City,Taiwan Roc,false,false,"Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the ""gig'' of ride-sharing."
pn3759,https://doi.org/10.1145/3290605.3300366,Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan,3,Ning Ma,Pennsylvania State University,State College,United States,false,false,"Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the ""gig'' of ride-sharing."
pn3759,https://doi.org/10.1145/3290605.3300366,Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan,4,Chi-Yang Hsu,Pennsylvania State University,State College,United States,false,false,"Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the ""gig'' of ride-sharing."
pn3759,https://doi.org/10.1145/3290605.3300366,Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan,5,Benjamin Hanrahan,Pennsylvania State University,State College,United States,false,false,"Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the ""gig'' of ride-sharing."
pn6888,https://doi.org/10.1145/3290605.3300622,Why Do You Need This? Selective Disclosure of Data Among Citizen Scientists,1,Anna Rudnicka,University College London,London,United Kingdom,false,false,"Recent scandals involving data from participatory research have contributed to broader public concern about online privacy. Such concerns might make people more reluctant to participate in research that asks them to volunteer personal data, compromising many researchers' data collection. We tested several motivational messages that encouraged participation in a citizen science project. We measured people's willingness to disclose personal information. While participants were less likely to share sensitive data than neutral data, disclosure behaviour was not affected by attitudes to privacy. Importantly, we found that citizen scientists who were exposed to a motivational message that emphasised 'learning' were more likely to share sensitive information than those presented with other types of motivational cues. Our results suggest that priming individuals with motivational messages can increase their willingness to contribute personal data to a project, even if the request pertains to sensitive information."
pn6888,https://doi.org/10.1145/3290605.3300622,Why Do You Need This? Selective Disclosure of Data Among Citizen Scientists,2,Anna Cox,University College London,London,United Kingdom,false,false,"Recent scandals involving data from participatory research have contributed to broader public concern about online privacy. Such concerns might make people more reluctant to participate in research that asks them to volunteer personal data, compromising many researchers' data collection. We tested several motivational messages that encouraged participation in a citizen science project. We measured people's willingness to disclose personal information. While participants were less likely to share sensitive data than neutral data, disclosure behaviour was not affected by attitudes to privacy. Importantly, we found that citizen scientists who were exposed to a motivational message that emphasised 'learning' were more likely to share sensitive information than those presented with other types of motivational cues. Our results suggest that priming individuals with motivational messages can increase their willingness to contribute personal data to a project, even if the request pertains to sensitive information."
pn6888,https://doi.org/10.1145/3290605.3300622,Why Do You Need This? Selective Disclosure of Data Among Citizen Scientists,3,Sandy Gould,University of Birmingham,Birmingham,United Kingdom,false,false,"Recent scandals involving data from participatory research have contributed to broader public concern about online privacy. Such concerns might make people more reluctant to participate in research that asks them to volunteer personal data, compromising many researchers' data collection. We tested several motivational messages that encouraged participation in a citizen science project. We measured people's willingness to disclose personal information. While participants were less likely to share sensitive data than neutral data, disclosure behaviour was not affected by attitudes to privacy. Importantly, we found that citizen scientists who were exposed to a motivational message that emphasised 'learning' were more likely to share sensitive information than those presented with other types of motivational cues. Our results suggest that priming individuals with motivational messages can increase their willingness to contribute personal data to a project, even if the request pertains to sensitive information."
pn5349,https://doi.org/10.1145/3290605.3300345,(Re-)Framing Menopause Experiences for HCI and Design,1,Jeffrey Bardzell,Indiana University,Bloomington,United States,false,false,"Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design."
pn5349,https://doi.org/10.1145/3290605.3300345,(Re-)Framing Menopause Experiences for HCI and Design,2,Shaowen Bardzell,Indiana University,Bloomington,United States,false,false,"Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design."
pn5349,https://doi.org/10.1145/3290605.3300345,(Re-)Framing Menopause Experiences for HCI and Design,3,Amanda Lazar,"University of Maryland, College Park",College Park,United States,false,false,"Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design."
pn5349,https://doi.org/10.1145/3290605.3300345,(Re-)Framing Menopause Experiences for HCI and Design,4,Norman Su,Indiana University,Bloomington,United States,false,false,"Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design."
pn4549,https://doi.org/10.1145/3290605.3300710,Parting the Red Sea: Sociotechnical Systems and Lived Experiences of Menopause,1,Amanda Lazar,"University of Maryland, College Park",College Park,United States,false,false,"Menopause is a major life change affecting roughly half of the population, resulting in physiological, emotional, and social changes. To understand experiences with menopause holistically, we conducted a study of a subreddit forum. The project was informed by feminist social science methodologies, which center knowledge production on women's lived experiences. Our central finding is that the lived experience of menopause is social: menopause is less about bodily experiences by themselves and more about how experiences with the body become meaningful over time in the social context. We find that gendered marginalization shapes diverse social relationships, leading to widespread feelings of alienation and negative transformation — often expressed in semantically dense figurative language. Research and design can accordingly address menopause not only as a women's health concern, but also as a matter of facilitating social support and a social justice issue."
pn4549,https://doi.org/10.1145/3290605.3300710,Parting the Red Sea: Sociotechnical Systems and Lived Experiences of Menopause,2,Norman Su,Indiana University,Bloomington,United States,false,false,"Menopause is a major life change affecting roughly half of the population, resulting in physiological, emotional, and social changes. To understand experiences with menopause holistically, we conducted a study of a subreddit forum. The project was informed by feminist social science methodologies, which center knowledge production on women's lived experiences. Our central finding is that the lived experience of menopause is social: menopause is less about bodily experiences by themselves and more about how experiences with the body become meaningful over time in the social context. We find that gendered marginalization shapes diverse social relationships, leading to widespread feelings of alienation and negative transformation — often expressed in semantically dense figurative language. Research and design can accordingly address menopause not only as a women's health concern, but also as a matter of facilitating social support and a social justice issue."
pn4549,https://doi.org/10.1145/3290605.3300710,Parting the Red Sea: Sociotechnical Systems and Lived Experiences of Menopause,3,Jeffrey Bardzell,Indiana University,Bloomington,United States,false,false,"Menopause is a major life change affecting roughly half of the population, resulting in physiological, emotional, and social changes. To understand experiences with menopause holistically, we conducted a study of a subreddit forum. The project was informed by feminist social science methodologies, which center knowledge production on women's lived experiences. Our central finding is that the lived experience of menopause is social: menopause is less about bodily experiences by themselves and more about how experiences with the body become meaningful over time in the social context. We find that gendered marginalization shapes diverse social relationships, leading to widespread feelings of alienation and negative transformation — often expressed in semantically dense figurative language. Research and design can accordingly address menopause not only as a women's health concern, but also as a matter of facilitating social support and a social justice issue."
pn4549,https://doi.org/10.1145/3290605.3300710,Parting the Red Sea: Sociotechnical Systems and Lived Experiences of Menopause,4,Shaowen Bardzell,Indiana University,Bloomington,United States,false,false,"Menopause is a major life change affecting roughly half of the population, resulting in physiological, emotional, and social changes. To understand experiences with menopause holistically, we conducted a study of a subreddit forum. The project was informed by feminist social science methodologies, which center knowledge production on women's lived experiences. Our central finding is that the lived experience of menopause is social: menopause is less about bodily experiences by themselves and more about how experiences with the body become meaningful over time in the social context. We find that gendered marginalization shapes diverse social relationships, leading to widespread feelings of alienation and negative transformation — often expressed in semantically dense figurative language. Research and design can accordingly address menopause not only as a women's health concern, but also as a matter of facilitating social support and a social justice issue."
pn8732,https://doi.org/10.1145/3290605.3300881,"""Notjustgirls"": Exploring Male-related Eating Disordered Content across Social Media Platforms",1,Jessica Pater,Parkview Research Center,Atlanta,United States,false,false,"Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research."
pn8732,https://doi.org/10.1145/3290605.3300881,"""Notjustgirls"": Exploring Male-related Eating Disordered Content across Social Media Platforms",2,Lauren Reining,Parkview Research Center,Fort Wayne,United States,false,false,"Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research."
pn8732,https://doi.org/10.1145/3290605.3300881,"""Notjustgirls"": Exploring Male-related Eating Disordered Content across Social Media Platforms",3,Andrew Miller,Indiana University Purdue University Indianapolis (IUPUI),Indianapolis,United States,false,false,"Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research."
pn8732,https://doi.org/10.1145/3290605.3300881,"""Notjustgirls"": Exploring Male-related Eating Disordered Content across Social Media Platforms",4,Tammy Toscos,Parkview Research Center,Fort Wayne,United States,false,false,"Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research."
pn8732,https://doi.org/10.1145/3290605.3300881,"""Notjustgirls"": Exploring Male-related Eating Disordered Content across Social Media Platforms",5,Elizabeth Mynatt,Georgia Institute of Technology,Atlanta,United States,false,false,"Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research."
pn3308,https://doi.org/10.1145/3290605.3300704,Psychologically Inclusive Design: Cues Impact Women's Participation in STEM Education,1,René Kizilcec,Cornell University,Ithaca,United States,false,false,"Visual and verbal cues can reinforce barriers to access for women in science, technology, engineering, and math (STEM) disciplines. Psychologically inclusive design is an evidence-based approach to reduce psychological barriers by strategically placing content and design cues in the environment. Two large field experiments provide estimates of the behavioral impact of psychologically inclusive cues on women's and men's enrollment behaviors in an online learning environment. First, a gender-inclusive photo and statement in an online advertisement for a STEM course increased the click-through rate among women but not men by 26% (N=209,000). Second, an inclusivity statement with a gender-inclusive course image to the enrollment page raised the proportion of women enrolling in a STEM course by up to 18% (N=63,000). These findings contribute evidence of the behavioral impact of psychologically inclusive design to the literature and yield practical implications for the presentation of STEM opportunities."
pn3308,https://doi.org/10.1145/3290605.3300704,Psychologically Inclusive Design: Cues Impact Women's Participation in STEM Education,2,Andrew Saltarelli,Stanford University,Stanford,United States,false,false,"Visual and verbal cues can reinforce barriers to access for women in science, technology, engineering, and math (STEM) disciplines. Psychologically inclusive design is an evidence-based approach to reduce psychological barriers by strategically placing content and design cues in the environment. Two large field experiments provide estimates of the behavioral impact of psychologically inclusive cues on women's and men's enrollment behaviors in an online learning environment. First, a gender-inclusive photo and statement in an online advertisement for a STEM course increased the click-through rate among women but not men by 26% (N=209,000). Second, an inclusivity statement with a gender-inclusive course image to the enrollment page raised the proportion of women enrolling in a STEM course by up to 18% (N=63,000). These findings contribute evidence of the behavioral impact of psychologically inclusive design to the literature and yield practical implications for the presentation of STEM opportunities."
pn7729,https://doi.org/10.1145/3290605.3300462,Neighborhood Perception in Bar Charts,1,Mingqian Zhao,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"In this paper, we report three user experiments that investigate in how far the perception of a bar in a bar chart changes based on the height of its neighboring bars. We hypothesized that the perception of the very same bar, for instance, might differ when it is surrounded by the top highest vs. the top lowest bars. Our results show that such neighborhood effects exist: a target bar surrounded by high neighbor bars, is perceived to be lower as the same bar surrounded with low neighbors. Yet, the effect size of this neighborhood effect is small compared to other data-inherent effects: the judgment accuracy largely depends on the target bar rank, number of data items, and other data characteristics of the dataset. Based on the findings, we discuss design implications for perceptually optimizing bar charts."
pn7729,https://doi.org/10.1145/3290605.3300462,Neighborhood Perception in Bar Charts,2,Huamin Qu,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"In this paper, we report three user experiments that investigate in how far the perception of a bar in a bar chart changes based on the height of its neighboring bars. We hypothesized that the perception of the very same bar, for instance, might differ when it is surrounded by the top highest vs. the top lowest bars. Our results show that such neighborhood effects exist: a target bar surrounded by high neighbor bars, is perceived to be lower as the same bar surrounded with low neighbors. Yet, the effect size of this neighborhood effect is small compared to other data-inherent effects: the judgment accuracy largely depends on the target bar rank, number of data items, and other data characteristics of the dataset. Based on the findings, we discuss design implications for perceptually optimizing bar charts."
pn7729,https://doi.org/10.1145/3290605.3300462,Neighborhood Perception in Bar Charts,3,Michael Sedlmair,University of Stuttgart,Stuttgart,Germany,false,false,"In this paper, we report three user experiments that investigate in how far the perception of a bar in a bar chart changes based on the height of its neighboring bars. We hypothesized that the perception of the very same bar, for instance, might differ when it is surrounded by the top highest vs. the top lowest bars. Our results show that such neighborhood effects exist: a target bar surrounded by high neighbor bars, is perceived to be lower as the same bar surrounded with low neighbors. Yet, the effect size of this neighborhood effect is small compared to other data-inherent effects: the judgment accuracy largely depends on the target bar rank, number of data items, and other data characteristics of the dataset. Based on the findings, we discuss design implications for perceptually optimizing bar charts."
pn4239,https://doi.org/10.1145/3290605.3300422,Ranked-List Visualization: A Graphical Perception Study,1,Pranathi Mylavarapu,"University of Maryland, College Park",College Park,United States,false,false,"Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value."
pn4239,https://doi.org/10.1145/3290605.3300422,Ranked-List Visualization: A Graphical Perception Study,2,Adil Yalcin,"Keshif, LLC.",Alexandria,United States,false,false,"Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value."
pn4239,https://doi.org/10.1145/3290605.3300422,Ranked-List Visualization: A Graphical Perception Study,3,Xan Gregg,"SAS Institute, Inc.",Cary,United States,false,false,"Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value."
pn4239,https://doi.org/10.1145/3290605.3300422,Ranked-List Visualization: A Graphical Perception Study,4,Niklas Elmqvist,"University of Maryland, College Park",College Park,United States,false,false,"Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value."
pn6049,https://doi.org/10.1145/3290605.3300771,Saliency Deficit and Motion Outlier Detection in Animated Scatterplots,1,Rafael Veras,University of Ontario Institute of Technology,Oshawa,Canada,true,false,"We report the results of a crowdsourced experiment that measured the accuracy of motion outlier detection in multivariate, animated scatterplots. The targets were outliers either in speed or direction of motion, and were presented with varying levels of saliency in dimensions that are irrelevant to the task of motion outlier detection (e.g., color, size, position). We found that participants had trouble finding the outlier when it lacked irrelevant salient features and that visual channels contribute unevenly to the odds of an outlier being correctly detected. Direction of motion contributes the most to accurate detection of speed outliers, and position contributes the most to accurate detection of direction outliers. We introduce the concept of saliency deficit in which item importance in the data space is not reflected in the visualization due to a lack of saliency. We conclude that motion outlier detection is not well supported in multivariate animated scatterplots."
pn6049,https://doi.org/10.1145/3290605.3300771,Saliency Deficit and Motion Outlier Detection in Animated Scatterplots,2,Christopher Collins,University of Ontario Institute of Technology,Oshawa,Canada,true,false,"We report the results of a crowdsourced experiment that measured the accuracy of motion outlier detection in multivariate, animated scatterplots. The targets were outliers either in speed or direction of motion, and were presented with varying levels of saliency in dimensions that are irrelevant to the task of motion outlier detection (e.g., color, size, position). We found that participants had trouble finding the outlier when it lacked irrelevant salient features and that visual channels contribute unevenly to the odds of an outlier being correctly detected. Direction of motion contributes the most to accurate detection of speed outliers, and position contributes the most to accurate detection of direction outliers. We introduce the concept of saliency deficit in which item importance in the data space is not reflected in the visualization due to a lack of saliency. We conclude that motion outlier detection is not well supported in multivariate animated scatterplots."
pn8350,https://doi.org/10.1145/3290605.3300899,"Measuring the Separability of Shape, Size, and Color in Scatterplots",1,Stephen Smart,University of Colorado Boulder,Boulder,United States,false,false,"Scatterplots commonly use multiple visual channels to encode multivariate datasets. Such visualizations often use size, shape, and color as these dimensions are considered separable--dimensions represented by one channel do not significantly interfere with viewers' abilities to perceive data in another. However, recent work shows the size of marks significantly impacts color difference perceptions, leading to broader questions about the separability of these channels. In this paper, we present a series of crowdsourced experiments measuring how mark shape, size, and color influence data interpretation in multiclass scatterplots. Our results indicate that mark shape significantly influences color and size perception, and that separability among these channels functions asymmetrically: shape more strongly influences size and color perceptions in scatterplots than size and color influence shape. Models constructed from the resulting data can help designers anticipate viewer perceptions to build more effective visualizations."
pn8350,https://doi.org/10.1145/3290605.3300899,"Measuring the Separability of Shape, Size, and Color in Scatterplots",2,Danielle Szafir,University of Colorado Boulder,Boulder,United States,false,false,"Scatterplots commonly use multiple visual channels to encode multivariate datasets. Such visualizations often use size, shape, and color as these dimensions are considered separable--dimensions represented by one channel do not significantly interfere with viewers' abilities to perceive data in another. However, recent work shows the size of marks significantly impacts color difference perceptions, leading to broader questions about the separability of these channels. In this paper, we present a series of crowdsourced experiments measuring how mark shape, size, and color influence data interpretation in multiclass scatterplots. Our results indicate that mark shape significantly influences color and size perception, and that separability among these channels functions asymmetrically: shape more strongly influences size and color perceptions in scatterplots than size and color influence shape. Models constructed from the resulting data can help designers anticipate viewer perceptions to build more effective visualizations."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,1,Niels Van Berkel,The University of Melbourne,Melbourne,Australia,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,2,Jorge Goncalves,The University of Melbourne,Melbourne,Australia,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,3,Peter Koval,The University of Melbourne,Melbourne,Australia,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,4,Simo Hosio,University of Oulu,Oulu,Finland,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,5,Tilman Dingler,University of Melbourne,Melbourne,Australia,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,6,Denzil Ferreira,University of Oulu,Oulu,Finland,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn7120,https://doi.org/10.1145/3290605.3300281,Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports,7,Vassilis Kostakos,University of Melbourne,Melbourne,Australia,false,false,"Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies."
pn4075,https://doi.org/10.1145/3290605.3300419,Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance,1,Ashley Colley,University of Lapland,Rovaniemi,Finland,false,false,"Sliders are one of the most fundamental components used in touchscreen user interfaces (UIs). When entering data using a slider, errors occur due e.g. to visual perception, resulting in inputs not matching what is intended by the user. However, it is unclear if the errors occur uniformly across the full range of the slider or if there are systematic offsets. We conducted a study to assess the errors occurring when entering values with horizontal and vertical sliders as well as two common visual styles. Our results reveal significant effects of slider orientation and style on the precision of the entered values. Furthermore, we identify systematic offsets that depend on the visual style and the target value. As the errors are partially systematic, they can be compensated to improve users' precision. Our findings provide UI designers with data to optimize user experiences in the wide variety of application areas where slider based touchscreen input is used."
pn4075,https://doi.org/10.1145/3290605.3300419,Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance,2,Sven Mayer,University of Stuttgart,Stuttgart,Germany,false,false,"Sliders are one of the most fundamental components used in touchscreen user interfaces (UIs). When entering data using a slider, errors occur due e.g. to visual perception, resulting in inputs not matching what is intended by the user. However, it is unclear if the errors occur uniformly across the full range of the slider or if there are systematic offsets. We conducted a study to assess the errors occurring when entering values with horizontal and vertical sliders as well as two common visual styles. Our results reveal significant effects of slider orientation and style on the precision of the entered values. Furthermore, we identify systematic offsets that depend on the visual style and the target value. As the errors are partially systematic, they can be compensated to improve users' precision. Our findings provide UI designers with data to optimize user experiences in the wide variety of application areas where slider based touchscreen input is used."
pn4075,https://doi.org/10.1145/3290605.3300419,Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance,3,Niels Henze,University of Regensburg,Regensburg,Germany,false,false,"Sliders are one of the most fundamental components used in touchscreen user interfaces (UIs). When entering data using a slider, errors occur due e.g. to visual perception, resulting in inputs not matching what is intended by the user. However, it is unclear if the errors occur uniformly across the full range of the slider or if there are systematic offsets. We conducted a study to assess the errors occurring when entering values with horizontal and vertical sliders as well as two common visual styles. Our results reveal significant effects of slider orientation and style on the precision of the entered values. Furthermore, we identify systematic offsets that depend on the visual style and the target value. As the errors are partially systematic, they can be compensated to improve users' precision. Our findings provide UI designers with data to optimize user experiences in the wide variety of application areas where slider based touchscreen input is used."
pn6724,https://doi.org/10.1145/3290605.3300927,LocknType: Lockout Task Intervention for Discouraging Smartphone App Use,1,Jaejeung Kim,KAIST,Daejeon,Republic Of Korea,false,false,"Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors."
pn6724,https://doi.org/10.1145/3290605.3300927,LocknType: Lockout Task Intervention for Discouraging Smartphone App Use,2,Joonyoung Park,KAIST,Daejeon,Republic Of Korea,false,false,"Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors."
pn6724,https://doi.org/10.1145/3290605.3300927,LocknType: Lockout Task Intervention for Discouraging Smartphone App Use,3,Hyunsoo Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors."
pn6724,https://doi.org/10.1145/3290605.3300927,LocknType: Lockout Task Intervention for Discouraging Smartphone App Use,4,Minsam Ko,Hanyang University,Seoul,Republic Of Korea,false,false,"Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors."
pn6724,https://doi.org/10.1145/3290605.3300927,LocknType: Lockout Task Intervention for Discouraging Smartphone App Use,5,Uichin Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors."
pn4339,https://doi.org/10.1145/3290605.3300255,Diagnosing and Coping with Mode Errors in Korean-English Dual-language Keyboard,1,Sangyoon Lee,KAIST,Daejeon,Republic Of Korea,false,false,"In countries where languages with non-Latin characters are prevalent, people use a keyboard with two language modes namely, the native language and English, and often experience mode errors. To diagnose the mode error problem, we conducted a field study and observed that 78% of the mode errors occurred immediately after application switching. We implemented four methods (Auto-switch, Preview, Smart-toggle, and Preview & Smart-toggle) based on three strategies to deal with the mode error problem and conducted field studies to verify their effectiveness. In the studies considering Korean-English dual input, Auto-switch was ineffective. On the contrary, Preview significantly reduced the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering from mode errors. In Preview & Smart-toggle, Preview reduced mode errors and Smart-toggle handled 86.2% of the mode errors that slipped past Preview. These results suggest that Preview & Smart-toggle is a promising method for preventing mode errors for the Korean-English dual-input environment."
pn4339,https://doi.org/10.1145/3290605.3300255,Diagnosing and Coping with Mode Errors in Korean-English Dual-language Keyboard,2,Jaeyeon Lee,KAIST,Daejeon,Republic Of Korea,false,false,"In countries where languages with non-Latin characters are prevalent, people use a keyboard with two language modes namely, the native language and English, and often experience mode errors. To diagnose the mode error problem, we conducted a field study and observed that 78% of the mode errors occurred immediately after application switching. We implemented four methods (Auto-switch, Preview, Smart-toggle, and Preview & Smart-toggle) based on three strategies to deal with the mode error problem and conducted field studies to verify their effectiveness. In the studies considering Korean-English dual input, Auto-switch was ineffective. On the contrary, Preview significantly reduced the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering from mode errors. In Preview & Smart-toggle, Preview reduced mode errors and Smart-toggle handled 86.2% of the mode errors that slipped past Preview. These results suggest that Preview & Smart-toggle is a promising method for preventing mode errors for the Korean-English dual-input environment."
pn4339,https://doi.org/10.1145/3290605.3300255,Diagnosing and Coping with Mode Errors in Korean-English Dual-language Keyboard,3,Geehyuk Lee,KAIST,Daejeon,Republic Of Korea,false,false,"In countries where languages with non-Latin characters are prevalent, people use a keyboard with two language modes namely, the native language and English, and often experience mode errors. To diagnose the mode error problem, we conducted a field study and observed that 78% of the mode errors occurred immediately after application switching. We implemented four methods (Auto-switch, Preview, Smart-toggle, and Preview & Smart-toggle) based on three strategies to deal with the mode error problem and conducted field studies to verify their effectiveness. In the studies considering Korean-English dual input, Auto-switch was ineffective. On the contrary, Preview significantly reduced the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering from mode errors. In Preview & Smart-toggle, Preview reduced mode errors and Smart-toggle handled 86.2% of the mode errors that slipped past Preview. These results suggest that Preview & Smart-toggle is a promising method for preventing mode errors for the Korean-English dual-input environment."
pn6303,https://doi.org/10.1145/3290605.3300930,Sensory Alignment in Immersive Entertainment,1,Joe Marshall,University of Nottingham,Nottingham,United Kingdom,false,false,"When we use digital systems to stimulate the senses, we typically stimulate only a subset of users' senses, leaving other senses stimulated by the physical world. This creates potential for misalignment between senses, where digital and physical stimulation give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments, and underlying sensory science research relating to how senses work when given conflicting signals. Using this knowledge we present a design dimension of sensory alignment, and show how this dimension presents opportunities for a range of creative strategies ranging from full alignment of sensory stimulation, up to extreme conflict between senses."
pn6303,https://doi.org/10.1145/3290605.3300930,Sensory Alignment in Immersive Entertainment,2,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"When we use digital systems to stimulate the senses, we typically stimulate only a subset of users' senses, leaving other senses stimulated by the physical world. This creates potential for misalignment between senses, where digital and physical stimulation give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments, and underlying sensory science research relating to how senses work when given conflicting signals. Using this knowledge we present a design dimension of sensory alignment, and show how this dimension presents opportunities for a range of creative strategies ranging from full alignment of sensory stimulation, up to extreme conflict between senses."
pn6303,https://doi.org/10.1145/3290605.3300930,Sensory Alignment in Immersive Entertainment,3,Richard Byrne,RMIT University,Melbourne,Australia,false,false,"When we use digital systems to stimulate the senses, we typically stimulate only a subset of users' senses, leaving other senses stimulated by the physical world. This creates potential for misalignment between senses, where digital and physical stimulation give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments, and underlying sensory science research relating to how senses work when given conflicting signals. Using this knowledge we present a design dimension of sensory alignment, and show how this dimension presents opportunities for a range of creative strategies ranging from full alignment of sensory stimulation, up to extreme conflict between senses."
pn6303,https://doi.org/10.1145/3290605.3300930,Sensory Alignment in Immersive Entertainment,4,Paul Tennent,University of Nottingham,Nottingham,United Kingdom,false,false,"When we use digital systems to stimulate the senses, we typically stimulate only a subset of users' senses, leaving other senses stimulated by the physical world. This creates potential for misalignment between senses, where digital and physical stimulation give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments, and underlying sensory science research relating to how senses work when given conflicting signals. Using this knowledge we present a design dimension of sensory alignment, and show how this dimension presents opportunities for a range of creative strategies ranging from full alignment of sensory stimulation, up to extreme conflict between senses."
pn1377,https://doi.org/10.1145/3290605.3300455,A Framework for the Experience of Meaning in Human-Computer Interaction,1,Elisa Mekler,University of Basel,Basel,Switzerland,false,true,"The view of quality in human-computer interaction continuously develops, having in past decades included consistency, transparency, usability, and positive emotions. Recently, meaning is receiving increased interest in the user experience literature and in industry, referring to the end, purpose or significance of interaction with computers. However, the notion of meaning remains elusive and a bewildering number of senses are in use. We present a framework of meaning in interaction, based on a synthesis of psychological meaning research. The framework outlines five distinct senses of the experience of meaning: connectedness, purpose, coherence, resonance, and significance. We illustrate the usefulness of the framework by analyzing a selection of recent papers at the CHI conference and by raising a series of open research questions about the interplay of meaning, user experience, reflection, and well-being."
pn1377,https://doi.org/10.1145/3290605.3300455,A Framework for the Experience of Meaning in Human-Computer Interaction,2,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,false,true,"The view of quality in human-computer interaction continuously develops, having in past decades included consistency, transparency, usability, and positive emotions. Recently, meaning is receiving increased interest in the user experience literature and in industry, referring to the end, purpose or significance of interaction with computers. However, the notion of meaning remains elusive and a bewildering number of senses are in use. We present a framework of meaning in interaction, based on a synthesis of psychological meaning research. The framework outlines five distinct senses of the experience of meaning: connectedness, purpose, coherence, resonance, and significance. We illustrate the usefulness of the framework by analyzing a selection of recent papers at the CHI conference and by raising a series of open research questions about the interplay of meaning, user experience, reflection, and well-being."
pn5926,https://doi.org/10.1145/3290605.3300753,Understanding the Impact of Information Representation on Willingness to Share Information,1,Stefan Schneegass,University of Duisburg-Essen,Essen,Germany,false,false,"Since the release of the first activity tracker, there has been a steady increase in the number of sensors embedded in wearable devices and with it in the amount and diversity of information that can be derived from these sensors. This development leads to novel privacy threats for users. In a web survey with 248 participants, we explored whether users' willingness to share private data is dependent on how the data is requested by an application. Specifically, requests can be formulated as access to sensor data or as access to information derived from the sensor data (e.g., accelerometer vs. sleep quality). We show that non-expert users lack an understanding of how the two representation levels relate to each other. The results suggest that the willingness to share sensor data over derived information is governed by whether the derived information has positive or negative connotations (e.g., training intensity vs. life expectancy). Using the results of the survey, we derive implications for supporting users in protecting their private data collected via wearable sensors."
pn5926,https://doi.org/10.1145/3290605.3300753,Understanding the Impact of Information Representation on Willingness to Share Information,2,Romina Poguntke,University of Stuttgart,Stuttgart,Germany,false,false,"Since the release of the first activity tracker, there has been a steady increase in the number of sensors embedded in wearable devices and with it in the amount and diversity of information that can be derived from these sensors. This development leads to novel privacy threats for users. In a web survey with 248 participants, we explored whether users' willingness to share private data is dependent on how the data is requested by an application. Specifically, requests can be formulated as access to sensor data or as access to information derived from the sensor data (e.g., accelerometer vs. sleep quality). We show that non-expert users lack an understanding of how the two representation levels relate to each other. The results suggest that the willingness to share sensor data over derived information is governed by whether the derived information has positive or negative connotations (e.g., training intensity vs. life expectancy). Using the results of the survey, we derive implications for supporting users in protecting their private data collected via wearable sensors."
pn5926,https://doi.org/10.1145/3290605.3300753,Understanding the Impact of Information Representation on Willingness to Share Information,3,Tonja Machulla,LMU Munich,Munich,Germany,false,false,"Since the release of the first activity tracker, there has been a steady increase in the number of sensors embedded in wearable devices and with it in the amount and diversity of information that can be derived from these sensors. This development leads to novel privacy threats for users. In a web survey with 248 participants, we explored whether users' willingness to share private data is dependent on how the data is requested by an application. Specifically, requests can be formulated as access to sensor data or as access to information derived from the sensor data (e.g., accelerometer vs. sleep quality). We show that non-expert users lack an understanding of how the two representation levels relate to each other. The results suggest that the willingness to share sensor data over derived information is governed by whether the derived information has positive or negative connotations (e.g., training intensity vs. life expectancy). Using the results of the survey, we derive implications for supporting users in protecting their private data collected via wearable sensors."
pn4674,https://doi.org/10.1145/3290605.3300908,Making Sense of Human-Food Interaction,1,Ferran Altarriba Bertran,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI."
pn4674,https://doi.org/10.1145/3290605.3300908,Making Sense of Human-Food Interaction,2,Samvid Jhaveri,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI."
pn4674,https://doi.org/10.1145/3290605.3300908,Making Sense of Human-Food Interaction,3,Rosa Lutz,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI."
pn4674,https://doi.org/10.1145/3290605.3300908,Making Sense of Human-Food Interaction,4,Katherine Isbister,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI."
pn4674,https://doi.org/10.1145/3290605.3300908,Making Sense of Human-Food Interaction,5,Danielle Wilde,University of Southern Denmark,Kolding,Denmark,false,false,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI."
pn2143,https://doi.org/10.1145/3290605.3300853,Augmenting Couples' Communication with Lifelines: Shared Timelines of Mixed Contextual Information,1,Carla Griggio,INRIA,Paris,France,false,false,"Couples exhibit special communication practices, but apps rarely offer couple-specific functionality. Research shows that sharing streams of contextual information (e.g. location, motion) helps couples coordinate and feel more connected. Most studies explored a single, ephemeral stream; we study how couples' communication changes when sharing multiple, persistent streams. We designed Lifelines, a mobile-app technology probe that visualizes up to six streams on a shared timeline: closeness to home, battery level, steps, media playing, texts and calls. A month-long study with nine couples showed that partners interpreted information mostly from individual streams, but also combined them for more nuanced interpretations. Persistent streams allowed missing data to become meaningful and provided new ways of understanding each other. Unexpected patterns from any stream can trigger calls and texts, whereas seeing expected data can replace direct communication, which may improve or disrupt established communication practices. We conclude with design implications for mediating awareness within couples."
pn2143,https://doi.org/10.1145/3290605.3300853,Augmenting Couples' Communication with Lifelines: Shared Timelines of Mixed Contextual Information,2,Midas Nouwens,Aarhus University,Aarhus,Denmark,false,false,"Couples exhibit special communication practices, but apps rarely offer couple-specific functionality. Research shows that sharing streams of contextual information (e.g. location, motion) helps couples coordinate and feel more connected. Most studies explored a single, ephemeral stream; we study how couples' communication changes when sharing multiple, persistent streams. We designed Lifelines, a mobile-app technology probe that visualizes up to six streams on a shared timeline: closeness to home, battery level, steps, media playing, texts and calls. A month-long study with nine couples showed that partners interpreted information mostly from individual streams, but also combined them for more nuanced interpretations. Persistent streams allowed missing data to become meaningful and provided new ways of understanding each other. Unexpected patterns from any stream can trigger calls and texts, whereas seeing expected data can replace direct communication, which may improve or disrupt established communication practices. We conclude with design implications for mediating awareness within couples."
pn2143,https://doi.org/10.1145/3290605.3300853,Augmenting Couples' Communication with Lifelines: Shared Timelines of Mixed Contextual Information,3,Joanna Mcgrenere,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Couples exhibit special communication practices, but apps rarely offer couple-specific functionality. Research shows that sharing streams of contextual information (e.g. location, motion) helps couples coordinate and feel more connected. Most studies explored a single, ephemeral stream; we study how couples' communication changes when sharing multiple, persistent streams. We designed Lifelines, a mobile-app technology probe that visualizes up to six streams on a shared timeline: closeness to home, battery level, steps, media playing, texts and calls. A month-long study with nine couples showed that partners interpreted information mostly from individual streams, but also combined them for more nuanced interpretations. Persistent streams allowed missing data to become meaningful and provided new ways of understanding each other. Unexpected patterns from any stream can trigger calls and texts, whereas seeing expected data can replace direct communication, which may improve or disrupt established communication practices. We conclude with design implications for mediating awareness within couples."
pn2143,https://doi.org/10.1145/3290605.3300853,Augmenting Couples' Communication with Lifelines: Shared Timelines of Mixed Contextual Information,4,Wendy Mackay,INRIA,Paris,France,false,false,"Couples exhibit special communication practices, but apps rarely offer couple-specific functionality. Research shows that sharing streams of contextual information (e.g. location, motion) helps couples coordinate and feel more connected. Most studies explored a single, ephemeral stream; we study how couples' communication changes when sharing multiple, persistent streams. We designed Lifelines, a mobile-app technology probe that visualizes up to six streams on a shared timeline: closeness to home, battery level, steps, media playing, texts and calls. A month-long study with nine couples showed that partners interpreted information mostly from individual streams, but also combined them for more nuanced interpretations. Persistent streams allowed missing data to become meaningful and provided new ways of understanding each other. Unexpected patterns from any stream can trigger calls and texts, whereas seeing expected data can replace direct communication, which may improve or disrupt established communication practices. We conclude with design implications for mediating awareness within couples."
pn2704,https://doi.org/10.1145/3290605.3300844,"Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues",1,Max Curran,"University of California, Berkeley",Berkeley,United States,false,false,"Digitally sharing our experiences engages a process of empathy shaped by available informational cues. Biosensory data is one informative cue, but the relationship to empathy is underexplored. In this study, we investigate this process by showing a video of a ""target'' person's visual perspective watching a virtual reality film to sixty ""observers''. We vary information available to observers via three experimental conditions: a baseline unmodified video, video with narrative text, or with a graph of electrodermal activity (EDA) of the target. Compared to baseline, narrative text increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively, observers describe their empathic processes as using their own feelings supplemented with the information presented depending on the interpretability of that information. Both narration and EDA prompted observers to reconsider assumptions about another's experience. Our findings lead to a discussion of digitally-mediated empathy with implications for associated research and product development."
pn2704,https://doi.org/10.1145/3290605.3300844,"Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues",2,Jeremy Gordon,"University of California, Berkeley",Berkeley,United States,false,false,"Digitally sharing our experiences engages a process of empathy shaped by available informational cues. Biosensory data is one informative cue, but the relationship to empathy is underexplored. In this study, we investigate this process by showing a video of a ""target'' person's visual perspective watching a virtual reality film to sixty ""observers''. We vary information available to observers via three experimental conditions: a baseline unmodified video, video with narrative text, or with a graph of electrodermal activity (EDA) of the target. Compared to baseline, narrative text increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively, observers describe their empathic processes as using their own feelings supplemented with the information presented depending on the interpretability of that information. Both narration and EDA prompted observers to reconsider assumptions about another's experience. Our findings lead to a discussion of digitally-mediated empathy with implications for associated research and product development."
pn2704,https://doi.org/10.1145/3290605.3300844,"Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues",3,Lily Lin,"University of California, Berkeley",Berkeley,United States,false,false,"Digitally sharing our experiences engages a process of empathy shaped by available informational cues. Biosensory data is one informative cue, but the relationship to empathy is underexplored. In this study, we investigate this process by showing a video of a ""target'' person's visual perspective watching a virtual reality film to sixty ""observers''. We vary information available to observers via three experimental conditions: a baseline unmodified video, video with narrative text, or with a graph of electrodermal activity (EDA) of the target. Compared to baseline, narrative text increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively, observers describe their empathic processes as using their own feelings supplemented with the information presented depending on the interpretability of that information. Both narration and EDA prompted observers to reconsider assumptions about another's experience. Our findings lead to a discussion of digitally-mediated empathy with implications for associated research and product development."
pn2704,https://doi.org/10.1145/3290605.3300844,"Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues",4,Priyashri Sridhar,Singapore University of Technology and Design,Singapore,Singapore,false,false,"Digitally sharing our experiences engages a process of empathy shaped by available informational cues. Biosensory data is one informative cue, but the relationship to empathy is underexplored. In this study, we investigate this process by showing a video of a ""target'' person's visual perspective watching a virtual reality film to sixty ""observers''. We vary information available to observers via three experimental conditions: a baseline unmodified video, video with narrative text, or with a graph of electrodermal activity (EDA) of the target. Compared to baseline, narrative text increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively, observers describe their empathic processes as using their own feelings supplemented with the information presented depending on the interpretability of that information. Both narration and EDA prompted observers to reconsider assumptions about another's experience. Our findings lead to a discussion of digitally-mediated empathy with implications for associated research and product development."
pn2704,https://doi.org/10.1145/3290605.3300844,"Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues",5,John Chuang,"University of California, Berkeley",Berkeley,United States,false,false,"Digitally sharing our experiences engages a process of empathy shaped by available informational cues. Biosensory data is one informative cue, but the relationship to empathy is underexplored. In this study, we investigate this process by showing a video of a ""target'' person's visual perspective watching a virtual reality film to sixty ""observers''. We vary information available to observers via three experimental conditions: a baseline unmodified video, video with narrative text, or with a graph of electrodermal activity (EDA) of the target. Compared to baseline, narrative text increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively, observers describe their empathic processes as using their own feelings supplemented with the information presented depending on the interpretability of that information. Both narration and EDA prompted observers to reconsider assumptions about another's experience. Our findings lead to a discussion of digitally-mediated empathy with implications for associated research and product development."
pn7505,https://doi.org/10.1145/3290605.3300665,Reveal: Investigating Proactive Location-Based Reminiscing with Personal Digital Photo Repositories,1,David Mcgookin,Aalto University,Helsinki,Finland,true,false,"Recording experiences and memories is an important role for digital photography, with smartphone cameras leading to individuals taking increasing numbers of pictures of everyday experiences. Increasingly, these are automatically stored in personal, cloud-backed, photo repositories. However, such experiences can be forgotten quickly, with images 'lost' within the user's library, loosing their role in supporting reminiscing. We investigate how users might be provoked to view these images and the benefits they bring through the development and evaluation of a proactive, location-based reminiscing tool, called Reveal. We outline how a location-based approach allowed participants to reflect more widely on their photo practice, and the potential of such reminiscing tools to support effective management and curation of individual's increasingly large personal photo collections."
pn3358,https://doi.org/10.1145/3290605.3300252,Emotional Utility and Recall of the Facebook News Feed,1,Pawarat Nontasil,University of Bath,Bath,United Kingdom,true,false,"We report a laboratory study (N=53) in which participants browsed their own Facebook news feeds for 10-15 minutes, choosing exactly when to quit, and later rated the overall emotional utility of the episode before attempting to recall threads. Finally, the emotional utility of each encountered thread was rated while looking over a recording of the interaction. We report that Facebook browsing was, overall, an emotionally positive experience; that recall of threads exhibited classic primacy and recency serial order effects; that recalled threads were both more positive and more valenced (less neutral) on average, than forgotten threads; and that overall emotional valence judgments were predicted, statistically, by the peak and end thread judgments. We find no evidence that local quit decisions were driven by the emotional utility of threads. In the light of these findings, we discuss the suggestion that emotional utility might partly explain the attractiveness of reading the news feed, and that an emotional memory bias might further increase the attractiveness of the newsfeed in prospect."
pn3358,https://doi.org/10.1145/3290605.3300252,Emotional Utility and Recall of the Facebook News Feed,2,Stephen Payne,University of Bath,Bath,United Kingdom,true,false,"We report a laboratory study (N=53) in which participants browsed their own Facebook news feeds for 10-15 minutes, choosing exactly when to quit, and later rated the overall emotional utility of the episode before attempting to recall threads. Finally, the emotional utility of each encountered thread was rated while looking over a recording of the interaction. We report that Facebook browsing was, overall, an emotionally positive experience; that recall of threads exhibited classic primacy and recency serial order effects; that recalled threads were both more positive and more valenced (less neutral) on average, than forgotten threads; and that overall emotional valence judgments were predicted, statistically, by the peak and end thread judgments. We find no evidence that local quit decisions were driven by the emotional utility of threads. In the light of these findings, we discuss the suggestion that emotional utility might partly explain the attractiveness of reading the news feed, and that an emotional memory bias might further increase the attractiveness of the newsfeed in prospect."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,1,Yuanyuan Feng,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,2,Katie Li,Pomona College,Claremont,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,3,Azin Semsar,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,4,Hannah Mcgowan,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,5,Jacqueline Mun,Vassar College,Poughkeepsie,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,6,H. Zahiri,Anne Arundel Medical Center,Annapolis,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,7,Ivan George,Johns Hopkins University,Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,8,Adrian Park,Anne Arundel Medical Center,Annapolis,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,9,Andrea Kleinsmith,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn3025,https://doi.org/10.1145/3290605.3300841,Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training,10,Helena Mentis,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks."
pn5714,https://doi.org/10.1145/3290605.3300357,An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis,1,Florian Güldenpfennig,New Design University and Technische Universität Wien,St. Pölten/Vienna,Austria,false,false,"In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy."
pn5714,https://doi.org/10.1145/3290605.3300357,An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis,2,Peter Mayer,Technische Universität Wien,Vienna,Austria,false,false,"In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy."
pn5714,https://doi.org/10.1145/3290605.3300357,An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis,3,Paul Panek,Technische Universität Wien,Vienna,Austria,false,false,"In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy."
pn5714,https://doi.org/10.1145/3290605.3300357,An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis,4,Geraldine Fitzpatrick,Technische Universität Wien,Vienna,Austria,false,false,"In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy."
pn7672,https://doi.org/10.1145/3290605.3300421,Exploring the Opportunities for Technologies to Enhance Quality of Life with People who have Experienced Vision Loss,1,Rachel Bartlett,University of Iowa,Iowa City,United States,false,false,"Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one's place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one's living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind."
pn7672,https://doi.org/10.1145/3290605.3300421,Exploring the Opportunities for Technologies to Enhance Quality of Life with People who have Experienced Vision Loss,2,Yi Xuan Khoo,University of Iowa,Iowa City,United States,false,false,"Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one's place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one's living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind."
pn7672,https://doi.org/10.1145/3290605.3300421,Exploring the Opportunities for Technologies to Enhance Quality of Life with People who have Experienced Vision Loss,3,Juan Pablo Hourcade,University of Iowa,Iowa City,United States,false,false,"Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one's place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one's living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind."
pn7672,https://doi.org/10.1145/3290605.3300421,Exploring the Opportunities for Technologies to Enhance Quality of Life with People who have Experienced Vision Loss,4,Kyle Rector,University of Iowa,Iowa City,United States,false,false,"Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one's place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one's living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind."
pn7788,https://doi.org/10.1145/3290605.3300574,"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities",1,Diyi Yang,Carnegie Mellon University,Pittsburgh,United States,true,false,"Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts."
pn7788,https://doi.org/10.1145/3290605.3300574,"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities",2,Robert Kraut,Carnegie Mellon University,Pittsburgh,United States,true,false,"Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts."
pn7788,https://doi.org/10.1145/3290605.3300574,"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities",3,Tenbroeck Smith,"American Cancer Society, Inc.",Atlanta,United States,true,false,"Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts."
pn7788,https://doi.org/10.1145/3290605.3300574,"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities",4,Elijah Mayfield,Carnegie Mellon University,Pittsburgh,United States,true,false,"Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts."
pn7788,https://doi.org/10.1145/3290605.3300574,"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities",5,Dan Jurafsky,Stanford University,Stanford,United States,true,false,"Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,1,Sarah Foley,University College Cork,Cork,Ireland,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,2,Daniel Welsh,Newcastle University,Newcastel Upon Tyne,United Kingdom,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,3,Nadia Pantidi,University College Cork,Cork,Ireland,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,4,Kellie Morrissey,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,5,Thomas Nappey,Newcastle University,Newcastle Upon Tyne,United Kingdom,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn2907,https://doi.org/10.1145/3290605.3300634,Printer Pals: Experience-Centered Design to Support Agency for People with Dementia,6,John Mccarthy,University College Cork,Cork,Ireland,true,false,"Whereas there have been significant improvements in the quality of care provided for people with dementia, limited attention to the importance for people with dementia being enabled to make positive social contributions within care home contexts can restrict their sense of agency. In this paper we describe the design and deployment of 'Printer Pals' a receipt-based print media device, which encourages social contribution and agency within a care home environment. The design followed a two-year ethnography, from which the need for highlighting participation and supporting agency for residents within the care home became clear. The residents use of Printer Pals mediated participation in a number of different ways, such as engaging with the technology itself, offering shared experiences and participating in co-constructive and meaningful ways, each of which is discussed. We conclude with a series of design consideration to support agentic and caring interactions through inclusive design practices."
pn6475,https://doi.org/10.1145/3290605.3300530,Towards Enabling Blind People to Independently Write on Printed Forms,1,Shirin Feiz,Stony Brook University,Stony Brook,United States,false,false,"Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%."
pn6475,https://doi.org/10.1145/3290605.3300530,Towards Enabling Blind People to Independently Write on Printed Forms,2,Syed Masum Billah,Stony Brook University,Stony Brook,United States,false,false,"Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%."
pn6475,https://doi.org/10.1145/3290605.3300530,Towards Enabling Blind People to Independently Write on Printed Forms,3,Vikas Ashok,Stony Brook University,Stony Brook,United States,false,false,"Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%."
pn6475,https://doi.org/10.1145/3290605.3300530,Towards Enabling Blind People to Independently Write on Printed Forms,4,Roy Shilkrot,Stony Brook University,Stony Brook,United States,false,false,"Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%."
pn6475,https://doi.org/10.1145/3290605.3300530,Towards Enabling Blind People to Independently Write on Printed Forms,5,Iv Ramakrishnan,Stony Brook University,Stony Brook,United States,false,false,"Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,1,Ahtsham Manzoor,Lahore University of Management Sciences,Lahore,Pakistan,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,2,Safa Arooj,Lahore University of Management Sciences,Lahore,Pakistan,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,3,Shaban Zulfiqar,Lahore University of Management Sciences,Lahore,Pakistan,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,4,Murayyiam Parvez,Lahore University of Management Sciences,Lahore,Pakistan,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,5,Suleman Shahid,Lahore University of Management Sciences,Vienna,Austria,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn9893,https://doi.org/10.1145/3290605.3300734,ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation,6,Asim Karim,Lahore University of Management Sciences,Lahore,Pakistan,false,false,"Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP."
pn1724,https://doi.org/10.1145/3290605.3300746,Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia,1,Shaomei Wu,Facebook,Menlo Park,United States,false,false,"People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet."
pn1724,https://doi.org/10.1145/3290605.3300746,Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia,2,Lindsay Reynolds,Facebook,Menlo Park,United States,false,false,"People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet."
pn1724,https://doi.org/10.1145/3290605.3300746,Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia,3,Xian Li,Facebook,Menlo Park,United States,false,false,"People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet."
pn1724,https://doi.org/10.1145/3290605.3300746,Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia,4,Francisco Guzman,Facebook,Menlo Park,United States,false,false,"People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet."
pn6720,https://doi.org/10.1145/3290605.3300873,Preemptive Action: Accelerating Human Reaction using Electrical Muscle Stimulation Without Compromising Agency,1,Shunichi Kasahara,Sony CSL,Tokyo,Japan,false,false,"We enable preemptive force-feedback systems to speed up human reaction time without fully compromising the user's sense of agency. Typically these interfaces actuate by means of electrical muscle stimulation (EMS) or mechanical actuators; they preemptively move the user to perform a task, such as to improve movement performance (e.g., EMS-assisted drumming). Unfortunately, when using preemptive force-feedback users do not feel in control and loose their sense of agency. We address this by actuating the user's body, using EMS, within a particular time window (160 ms after visual stimulus), which we found to speed up reaction time by 80 ms in our first study. With this preemptive timing, when the user and system move congruently, the user feels that they initiated the motion, yet their reaction time is faster than usual. As our second study demonstrated, this particular timing significantly increased agency when compared to the current practice in EMS-based devices. We conclude by illustrating, using examples from the HCI literature, how to leverage our findings to provide more agency to automated haptic interfaces."
pn6720,https://doi.org/10.1145/3290605.3300873,Preemptive Action: Accelerating Human Reaction using Electrical Muscle Stimulation Without Compromising Agency,2,Jun Nishida,University of Chicago,Chicago,United States,false,false,"We enable preemptive force-feedback systems to speed up human reaction time without fully compromising the user's sense of agency. Typically these interfaces actuate by means of electrical muscle stimulation (EMS) or mechanical actuators; they preemptively move the user to perform a task, such as to improve movement performance (e.g., EMS-assisted drumming). Unfortunately, when using preemptive force-feedback users do not feel in control and loose their sense of agency. We address this by actuating the user's body, using EMS, within a particular time window (160 ms after visual stimulus), which we found to speed up reaction time by 80 ms in our first study. With this preemptive timing, when the user and system move congruently, the user feels that they initiated the motion, yet their reaction time is faster than usual. As our second study demonstrated, this particular timing significantly increased agency when compared to the current practice in EMS-based devices. We conclude by illustrating, using examples from the HCI literature, how to leverage our findings to provide more agency to automated haptic interfaces."
pn6720,https://doi.org/10.1145/3290605.3300873,Preemptive Action: Accelerating Human Reaction using Electrical Muscle Stimulation Without Compromising Agency,3,Pedro Lopes,University of Chicago,Chicago,United States,false,false,"We enable preemptive force-feedback systems to speed up human reaction time without fully compromising the user's sense of agency. Typically these interfaces actuate by means of electrical muscle stimulation (EMS) or mechanical actuators; they preemptively move the user to perform a task, such as to improve movement performance (e.g., EMS-assisted drumming). Unfortunately, when using preemptive force-feedback users do not feel in control and loose their sense of agency. We address this by actuating the user's body, using EMS, within a particular time window (160 ms after visual stimulus), which we found to speed up reaction time by 80 ms in our first study. With this preemptive timing, when the user and system move congruently, the user feels that they initiated the motion, yet their reaction time is faster than usual. As our second study demonstrated, this particular timing significantly increased agency when compared to the current practice in EMS-based devices. We conclude by illustrating, using examples from the HCI literature, how to leverage our findings to provide more agency to automated haptic interfaces."
pn8302,https://doi.org/10.1145/3290605.3300556,ChewIt. An Intraoral Interface for Discreet Interactions,1,Pablo Gallego Cascón,The University of Auckland,Auckland,New Zealand,true,false,"Sensing interfaces relying on head or facial gestures provide effective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt -- a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could use to interact with such an intraoral interface."
pn8302,https://doi.org/10.1145/3290605.3300556,ChewIt. An Intraoral Interface for Discreet Interactions,2,Denys Matthies,Auckland Bioengineering Institute,Auckland,New Zealand,true,false,"Sensing interfaces relying on head or facial gestures provide effective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt -- a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could use to interact with such an intraoral interface."
pn8302,https://doi.org/10.1145/3290605.3300556,ChewIt. An Intraoral Interface for Discreet Interactions,3,Sachith Muthukumarana,The University of Auckland,Auckland,New Zealand,true,false,"Sensing interfaces relying on head or facial gestures provide effective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt -- a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could use to interact with such an intraoral interface."
pn8302,https://doi.org/10.1145/3290605.3300556,ChewIt. An Intraoral Interface for Discreet Interactions,4,Suranga Nanayakkara,"Auckland Bioengineering Institute, The University of Auckland",Auckland,New Zealand,true,false,"Sensing interfaces relying on head or facial gestures provide effective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt -- a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could use to interact with such an intraoral interface."
pn9084,https://doi.org/10.1145/3290605.3300505,Clench Interface: Novel Biting Input Techniques,1,Xuhai Xu,University of Washington,Seattle,United States,false,false,"People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users' ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users' eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities."
pn9084,https://doi.org/10.1145/3290605.3300505,Clench Interface: Novel Biting Input Techniques,2,Chun Yu,Tsinghua University,Beijing,China,false,false,"People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users' ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users' eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities."
pn9084,https://doi.org/10.1145/3290605.3300505,Clench Interface: Novel Biting Input Techniques,3,Anind Dey,University of Washington,Seattle,United States,false,false,"People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users' ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users' eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities."
pn9084,https://doi.org/10.1145/3290605.3300505,Clench Interface: Novel Biting Input Techniques,4,Jennifer Mankoff,University of Washington,Seattle,United States,false,false,"People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users' ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users' eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities."
pn1166,https://doi.org/10.1145/3290605.3300506,Interferi: Gesture Sensing using On-Body Acoustic Interferometry,1,Yasha Iravantchi,Carnegie Mellon University,Pittsburgh,United States,true,false,"Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications."
pn1166,https://doi.org/10.1145/3290605.3300506,Interferi: Gesture Sensing using On-Body Acoustic Interferometry,2,Yang Zhang,Carnegie Mellon University,Pittsburgh,United States,true,false,"Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications."
pn1166,https://doi.org/10.1145/3290605.3300506,Interferi: Gesture Sensing using On-Body Acoustic Interferometry,3,Evi Bernitsas,Carnegie Mellon University,Pittsburgh,United States,true,false,"Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications."
pn1166,https://doi.org/10.1145/3290605.3300506,Interferi: Gesture Sensing using On-Body Acoustic Interferometry,4,Mayank Goel,Carnegie Mellon University,Pittsburgh,United States,true,false,"Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications."
pn1166,https://doi.org/10.1145/3290605.3300506,Interferi: Gesture Sensing using On-Body Acoustic Interferometry,5,Chris Harrison,Carnegie Mellon University,Pittsburgh,United States,true,false,"Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications."
pn1067,https://doi.org/10.1145/3290605.3300669,Spaces and Traces: Implications of Smart Technology in Public Housing,1,Sandjar Kozubaev,Georgia Institute of Technology,Atlanta,United States,false,false,"Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies."
pn1067,https://doi.org/10.1145/3290605.3300669,Spaces and Traces: Implications of Smart Technology in Public Housing,2,Fernando Rochaix,Georgia Statue University,Atlanta,United States,false,false,"Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies."
pn1067,https://doi.org/10.1145/3290605.3300669,Spaces and Traces: Implications of Smart Technology in Public Housing,3,Carl Disalvo,Georgia Institute of Technology,Atlanta,United States,false,false,"Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies."
pn1067,https://doi.org/10.1145/3290605.3300669,Spaces and Traces: Implications of Smart Technology in Public Housing,4,Christopher Le Dantec,Georgia Institute of Technology,Atlatna,United States,false,false,"Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,1,William Gaver,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,2,Andy Boucher,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,3,Michail Vanis,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,4,Andy Sheen,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,5,Dean Brown,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,6,Liliana Ovalle,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,7,Naho Matsuda,"Goldsmiths, University of London",London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,8,Amina Abbas-Nazari,Royal College of Art,London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn5470,https://doi.org/10.1145/3290605.3300532,My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design,9,Robert Phillips,Royal College of Art,London,United Kingdom,false,false,"My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels."
pn8454,https://doi.org/10.1145/3290605.3300910,Life-Affirming Biosensing in Public: Sounding Heartbeats on a Red Bench,1,Noura Howell,"University of California, Berkeley",Berkeley,United States,false,false,"""Smart city"" narratives promise IoT data-driven innovations leveraging biosensing technologies. We argue this overlooks a potential benefit of city living: affirmation. We designed the Heart Sounds Bench, which amplifies the heart sounds of those sitting on it, as well as recording and playing back the heart sounds of previous sitters. We outline our design intent to invite rest, reflection, and recognition of others' lives in public space. We share results from a study with 19 participants. Participants expressed feeling connected to a shared life energy including others and the environment, and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate the concept of life-affirmation in terms of recognition of others' lives, feeling connection, and respecting untranslatable differences with opacity, as a way of helping ""smart city"" designs embrace a multiplicity of desires."
pn8454,https://doi.org/10.1145/3290605.3300910,Life-Affirming Biosensing in Public: Sounding Heartbeats on a Red Bench,2,Greg Niemeyer,"University of California, Berkeley",Berkeley,United States,false,false,"""Smart city"" narratives promise IoT data-driven innovations leveraging biosensing technologies. We argue this overlooks a potential benefit of city living: affirmation. We designed the Heart Sounds Bench, which amplifies the heart sounds of those sitting on it, as well as recording and playing back the heart sounds of previous sitters. We outline our design intent to invite rest, reflection, and recognition of others' lives in public space. We share results from a study with 19 participants. Participants expressed feeling connected to a shared life energy including others and the environment, and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate the concept of life-affirmation in terms of recognition of others' lives, feeling connection, and respecting untranslatable differences with opacity, as a way of helping ""smart city"" designs embrace a multiplicity of desires."
pn8454,https://doi.org/10.1145/3290605.3300910,Life-Affirming Biosensing in Public: Sounding Heartbeats on a Red Bench,3,Kimiko Ryokai,"University of California, Berkeley",Berkeley,United States,false,false,"""Smart city"" narratives promise IoT data-driven innovations leveraging biosensing technologies. We argue this overlooks a potential benefit of city living: affirmation. We designed the Heart Sounds Bench, which amplifies the heart sounds of those sitting on it, as well as recording and playing back the heart sounds of previous sitters. We outline our design intent to invite rest, reflection, and recognition of others' lives in public space. We share results from a study with 19 participants. Participants expressed feeling connected to a shared life energy including others and the environment, and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate the concept of life-affirmation in terms of recognition of others' lives, feeling connection, and respecting untranslatable differences with opacity, as a way of helping ""smart city"" designs embrace a multiplicity of desires."
pn6422,https://doi.org/10.1145/3290605.3300571,City Explorer: The Design and Evaluation of a Location-Based Community Information System,1,Carolyn Pang,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes."
pn6422,https://doi.org/10.1145/3290605.3300571,City Explorer: The Design and Evaluation of a Location-Based Community Information System,2,Rui Pan,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes."
pn6422,https://doi.org/10.1145/3290605.3300571,City Explorer: The Design and Evaluation of a Location-Based Community Information System,3,Carman Neustaedter,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes."
pn6422,https://doi.org/10.1145/3290605.3300571,City Explorer: The Design and Evaluation of a Location-Based Community Information System,4,Kate Hennessy,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes."
pn6370,https://doi.org/10.1145/3290605.3300508,"""Beautiful Seams"": Strategic Revelations and Concealments",1,Sarah Inman,University of Washington,Seattle,United States,true,false,"This paper tracks a debate that occurred, first, within the field of Ubiquitous Computing but quickly spread to CHI and beyond, in which design scholars argued that seamlessness had long been an implicit and privileged design virtue, often at the expense of seamfulness. Seamless design emphasizes clarity, simplicity, ease of use, and consistency to facilitate technological interaction. Seamful design emphasizes configurability, user appropriation, and revelation of complexity, ambiguity or inconsistency. Here we review these literatures together and argue that, rather than rival approaches, seamful and seamless design are complements, each emphasizing different aspects of downstream user agency. Ultimately, we situate this debate within the larger, perennial discussion about the strategic revelation and concealment of human and technological operations, and therein the role of design."
pn6370,https://doi.org/10.1145/3290605.3300508,"""Beautiful Seams"": Strategic Revelations and Concealments",2,David Ribes,University of Washington,Seattle,United States,true,false,"This paper tracks a debate that occurred, first, within the field of Ubiquitous Computing but quickly spread to CHI and beyond, in which design scholars argued that seamlessness had long been an implicit and privileged design virtue, often at the expense of seamfulness. Seamless design emphasizes clarity, simplicity, ease of use, and consistency to facilitate technological interaction. Seamful design emphasizes configurability, user appropriation, and revelation of complexity, ambiguity or inconsistency. Here we review these literatures together and argue that, rather than rival approaches, seamful and seamless design are complements, each emphasizing different aspects of downstream user agency. Ultimately, we situate this debate within the larger, perennial discussion about the strategic revelation and concealment of human and technological operations, and therein the role of design."
pn6133,https://doi.org/10.1145/3290605.3300716,Designing for the Infrastructure of the Supply Chain of Malay Handwoven Songket in Terengganu,1,Min Zhang,Lancaster University,Lancaster,United Kingdom,true,false,"The growing HCI interest in developing contexts and cultural craft practices is ripe to focus on their under-explored homegrown sociotechnical infrastructures. This paper explores the creative infrastructural actions embedded within the practices of songket's supply chain in Terengganu, Malaysia. We report on contextual interviews with 92 participants including preparation workers, weavers, designers, merchants, and customers. Findings indicate that increased creative infrastructural actions are reflected in these actors' resourcefulness for mobilizing information, materials, and equipment, and for making creative artifacts through new technologies weaved within traditional practices. We propose two novel approaches to design in this craft-based infrastructure. First, we explore designing for the social layer of infrastructure and its mutually advantageous exploitative relationships rooted in culture and traditions. Second, we suggest designing for roaming value-creation artifacts, which blend physical and digital materializations of songket textile design. Developed through a collaborative and asynchronous process, we argue that these artifacts represent less-explored vehicles for value co-creation, and that sociotechnical infrastructures as emerging sites of innovation could benefit from HCI research."
pn6133,https://doi.org/10.1145/3290605.3300716,Designing for the Infrastructure of the Supply Chain of Malay Handwoven Songket in Terengganu,2,Corina Sas,Lancaster University,Lancaster,United Kingdom,true,false,"The growing HCI interest in developing contexts and cultural craft practices is ripe to focus on their under-explored homegrown sociotechnical infrastructures. This paper explores the creative infrastructural actions embedded within the practices of songket's supply chain in Terengganu, Malaysia. We report on contextual interviews with 92 participants including preparation workers, weavers, designers, merchants, and customers. Findings indicate that increased creative infrastructural actions are reflected in these actors' resourcefulness for mobilizing information, materials, and equipment, and for making creative artifacts through new technologies weaved within traditional practices. We propose two novel approaches to design in this craft-based infrastructure. First, we explore designing for the social layer of infrastructure and its mutually advantageous exploitative relationships rooted in culture and traditions. Second, we suggest designing for roaming value-creation artifacts, which blend physical and digital materializations of songket textile design. Developed through a collaborative and asynchronous process, we argue that these artifacts represent less-explored vehicles for value co-creation, and that sociotechnical infrastructures as emerging sites of innovation could benefit from HCI research."
pn6133,https://doi.org/10.1145/3290605.3300716,Designing for the Infrastructure of the Supply Chain of Malay Handwoven Songket in Terengganu,3,Zoe Lambert,Lancaster University,Lancaster,United Kingdom,true,false,"The growing HCI interest in developing contexts and cultural craft practices is ripe to focus on their under-explored homegrown sociotechnical infrastructures. This paper explores the creative infrastructural actions embedded within the practices of songket's supply chain in Terengganu, Malaysia. We report on contextual interviews with 92 participants including preparation workers, weavers, designers, merchants, and customers. Findings indicate that increased creative infrastructural actions are reflected in these actors' resourcefulness for mobilizing information, materials, and equipment, and for making creative artifacts through new technologies weaved within traditional practices. We propose two novel approaches to design in this craft-based infrastructure. First, we explore designing for the social layer of infrastructure and its mutually advantageous exploitative relationships rooted in culture and traditions. Second, we suggest designing for roaming value-creation artifacts, which blend physical and digital materializations of songket textile design. Developed through a collaborative and asynchronous process, we argue that these artifacts represent less-explored vehicles for value co-creation, and that sociotechnical infrastructures as emerging sites of innovation could benefit from HCI research."
pn6133,https://doi.org/10.1145/3290605.3300716,Designing for the Infrastructure of the Supply Chain of Malay Handwoven Songket in Terengganu,4,Masitah Ahmad,Universiti Teknologi MARA,Shah Alam,Malaysia,true,false,"The growing HCI interest in developing contexts and cultural craft practices is ripe to focus on their under-explored homegrown sociotechnical infrastructures. This paper explores the creative infrastructural actions embedded within the practices of songket's supply chain in Terengganu, Malaysia. We report on contextual interviews with 92 participants including preparation workers, weavers, designers, merchants, and customers. Findings indicate that increased creative infrastructural actions are reflected in these actors' resourcefulness for mobilizing information, materials, and equipment, and for making creative artifacts through new technologies weaved within traditional practices. We propose two novel approaches to design in this craft-based infrastructure. First, we explore designing for the social layer of infrastructure and its mutually advantageous exploitative relationships rooted in culture and traditions. Second, we suggest designing for roaming value-creation artifacts, which blend physical and digital materializations of songket textile design. Developed through a collaborative and asynchronous process, we argue that these artifacts represent less-explored vehicles for value co-creation, and that sociotechnical infrastructures as emerging sites of innovation could benefit from HCI research."
pn5455,https://doi.org/10.1145/3290605.3300656,A-line: 4D Printing Morphing Linear Composite Structures,1,Guanyun Wang,Carnegie Mellon University,Pittsburgh,United States,false,false,"This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures."
pn5455,https://doi.org/10.1145/3290605.3300656,A-line: 4D Printing Morphing Linear Composite Structures,2,Ye Tao,Zhejiang Univeristy,Hangzhou,China,false,false,"This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures."
pn5455,https://doi.org/10.1145/3290605.3300656,A-line: 4D Printing Morphing Linear Composite Structures,3,Ozguc Bertug Capunaman,Carnegie Mellon University,Pittsburgh,United States,false,false,"This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures."
pn5455,https://doi.org/10.1145/3290605.3300656,A-line: 4D Printing Morphing Linear Composite Structures,4,Humphrey Yang,Carnegie Mellon University,Pittsburgh,United States,false,false,"This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures."
pn5455,https://doi.org/10.1145/3290605.3300656,A-line: 4D Printing Morphing Linear Composite Structures,5,Lining Yao,Carnegie Mellon University,Pittsburgh,United States,false,false,"This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",1,Eric Markvicka,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",2,Guanyun Wang,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",3,Yi-Chin Lee,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",4,Gierad Laput,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",5,Carmel Majidi,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn9939,https://doi.org/10.1145/3290605.3300862,"ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages",6,Lining Yao,Carnegie Mellon University,Pittsburgh,United States,false,false,"Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail— including our fabrication parameters and its operational limits—which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics—one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,1,Ernst Kruijff,Simon Fraser University,Sankt Augustin,Germany,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,2,Saugata Biswas,Bonn-Rhein-Sieg University of Applied Sciences,Sankt Augustin,Germany,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,3,Christina Trepkowski,Institute of Visual Computing,Sankt Augustin,Germany,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,4,Jens Maiero,Institue of Visual Computing,Sankt Augustin,Germany,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,5,George Ghinea,Brunel University London,London,United Kingdom,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn3932,https://doi.org/10.1145/3290605.3300373,Multilayer Haptic Feedback for Pen-Based Tablet Interaction,6,Wolfgang Stuerzlinger,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance."
pn2288,https://doi.org/10.1145/3290605.3300470,Magnetact: Magnetic-sheet-based Haptic Interfaces for Touch Devices,1,Kentaro Yasu,Nippon Telegraph and Telephone Corporation,Atsugi,Japan,false,false,"We describe a method for rapid prototyping of haptic interfaces for touch devices. A sheet-like touch interface is constructed from magnetic rubber sheets and conductive materials. The magnetic sheet is thin, and the capacitive sensor of the touch device can still detect the user's finger above the sheet because of the rubber's dielectric nature. Furthermore, tactile feedback can be customized with ease by using our magnetizing toolkit to change the magnetic patterns. Using the magnetizing toolkit, we investigated the appropriate size and thickness of haptic interfaces and demonstrated several interfaces such as buttons, sliders, switches, and dials. Our method is an easy and convenient way to customize the size, shape, and haptic feedback of a wide variety of interfaces."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,1,Shan-Yuan Teng,National Taiwan University,Taipei,Taiwan Roc,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,2,Da-Yuan Huang,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,3,Chi Wang,National Taiwan University of Science and Technology,Taipei,Taiwan Roc,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,4,Jun Gong,Dartmouth College,Hanover,United States,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,5,Teddy Seyed,University of Calgary,Calgary,Canada,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,6,Xing-Dong Yang,Dartmouth College,Hanover,United States,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn2217,https://doi.org/10.1145/3290605.3300902,Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair,7,Bing-Yu Chen,National Taiwan University,Taipei,Taiwan Roc,false,false,"We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs."
pn4452,https://doi.org/10.1145/3290605.3300401,HaptiVec: Presenting Haptic Feedback Vectors in Handheld Controllers using Embedded Tactile Pin Arrays,1,Daniel Chen,Shanghai Jiao Tong University,Shanghai,China,false,false,"HaptiVec is a new haptic feedback paradigm for handheld controllers which allows users to feel directional haptic pressure vectors on their fingers and hands while interacting with virtual environments. We embed a 3 by 5 tactile pin array (with an average pin spacing of 25 mm) into the handles of two custom VR type controllers. By presenting directional pressure vectors in eight cardinal directions (N, NE, E, SE, S, SW, W, NW) to users without prior training, they were able to distinguish the correct direction with an accuracy of at least 79%. We illustrate two applications where our device enhances virtual experiences over traditional vibrotactile feedback. In the first application, through the classic first-person shooter Doom, we demonstrate that users can receive directional pressure feedback corresponding to the direction of incident enemy projectiles. In the second application, we demonstrate how our controller can create a more immersive experience by allowing the user to feel their virtual climate by randomizing the directional vectors and presenting the user with ""haptic rain"" which adapts with the intensity of the rainfall."
pn4452,https://doi.org/10.1145/3290605.3300401,HaptiVec: Presenting Haptic Feedback Vectors in Handheld Controllers using Embedded Tactile Pin Arrays,2,Jean-Baptiste Chossat,Shanghai Jiao Tong University,Shanghai,China,false,false,"HaptiVec is a new haptic feedback paradigm for handheld controllers which allows users to feel directional haptic pressure vectors on their fingers and hands while interacting with virtual environments. We embed a 3 by 5 tactile pin array (with an average pin spacing of 25 mm) into the handles of two custom VR type controllers. By presenting directional pressure vectors in eight cardinal directions (N, NE, E, SE, S, SW, W, NW) to users without prior training, they were able to distinguish the correct direction with an accuracy of at least 79%. We illustrate two applications where our device enhances virtual experiences over traditional vibrotactile feedback. In the first application, through the classic first-person shooter Doom, we demonstrate that users can receive directional pressure feedback corresponding to the direction of incident enemy projectiles. In the second application, we demonstrate how our controller can create a more immersive experience by allowing the user to feel their virtual climate by randomizing the directional vectors and presenting the user with ""haptic rain"" which adapts with the intensity of the rainfall."
pn4452,https://doi.org/10.1145/3290605.3300401,HaptiVec: Presenting Haptic Feedback Vectors in Handheld Controllers using Embedded Tactile Pin Arrays,3,Peter Shull,Shanghai Jiao Tong University,Shanghai,China,false,false,"HaptiVec is a new haptic feedback paradigm for handheld controllers which allows users to feel directional haptic pressure vectors on their fingers and hands while interacting with virtual environments. We embed a 3 by 5 tactile pin array (with an average pin spacing of 25 mm) into the handles of two custom VR type controllers. By presenting directional pressure vectors in eight cardinal directions (N, NE, E, SE, S, SW, W, NW) to users without prior training, they were able to distinguish the correct direction with an accuracy of at least 79%. We illustrate two applications where our device enhances virtual experiences over traditional vibrotactile feedback. In the first application, through the classic first-person shooter Doom, we demonstrate that users can receive directional pressure feedback corresponding to the direction of incident enemy projectiles. In the second application, we demonstrate how our controller can create a more immersive experience by allowing the user to feel their virtual climate by randomizing the directional vectors and presenting the user with ""haptic rain"" which adapts with the intensity of the rainfall."
pn6026,https://doi.org/10.1145/3290605.3300628,Affinity Lens: Data-Assisted Affinity Diagramming with Augmented Reality,1,Hariharan Subramonyam,University of Michigan,Ann Arbor,United States,false,true,"Despite the availability of software to support Affinity Diagramming (AD), practitioners still largely favor physical sticky-notes. Physical notes are easy to set-up, can be moved around in space and offer flexibility when clustering un-structured data. However, when working with mixed data sources such as surveys, designers often trade off the physicality of notes for analytical power. We propose AffinityLens, a mobile-based augmented reality (AR) application for Data-Assisted Affinity Diagramming (DAAD). Our application provides just-in-time quantitative insights overlaid on physical notes. Affinity Lens uses several different types of AR overlays (called lenses) to help users find specific notes, cluster information, and summarize insights from clusters. Through a formative study of AD users, we developed design principles for data-assisted AD and an initial collection of lenses. Based on our prototype, we find that Affinity Lens supports easy switching between qualitative and quantitative 'views' of data, without surrendering the lightweight benefits of existing AD practice."
pn6026,https://doi.org/10.1145/3290605.3300628,Affinity Lens: Data-Assisted Affinity Diagramming with Augmented Reality,2,Steven Drucker,Microsoft Research,Redmond,United States,false,true,"Despite the availability of software to support Affinity Diagramming (AD), practitioners still largely favor physical sticky-notes. Physical notes are easy to set-up, can be moved around in space and offer flexibility when clustering un-structured data. However, when working with mixed data sources such as surveys, designers often trade off the physicality of notes for analytical power. We propose AffinityLens, a mobile-based augmented reality (AR) application for Data-Assisted Affinity Diagramming (DAAD). Our application provides just-in-time quantitative insights overlaid on physical notes. Affinity Lens uses several different types of AR overlays (called lenses) to help users find specific notes, cluster information, and summarize insights from clusters. Through a formative study of AD users, we developed design principles for data-assisted AD and an initial collection of lenses. Based on our prototype, we find that Affinity Lens supports easy switching between qualitative and quantitative 'views' of data, without surrendering the lightweight benefits of existing AD practice."
pn6026,https://doi.org/10.1145/3290605.3300628,Affinity Lens: Data-Assisted Affinity Diagramming with Augmented Reality,3,Eytan Adar,University of Michigan,Ann Arbor,United States,false,true,"Despite the availability of software to support Affinity Diagramming (AD), practitioners still largely favor physical sticky-notes. Physical notes are easy to set-up, can be moved around in space and offer flexibility when clustering un-structured data. However, when working with mixed data sources such as surveys, designers often trade off the physicality of notes for analytical power. We propose AffinityLens, a mobile-based augmented reality (AR) application for Data-Assisted Affinity Diagramming (DAAD). Our application provides just-in-time quantitative insights overlaid on physical notes. Affinity Lens uses several different types of AR overlays (called lenses) to help users find specific notes, cluster information, and summarize insights from clusters. Through a formative study of AD users, we developed design principles for data-assisted AD and an initial collection of lenses. Based on our prototype, we find that Affinity Lens supports easy switching between qualitative and quantitative 'views' of data, without surrendering the lightweight benefits of existing AD practice."
pn3093,https://doi.org/10.1145/3290605.3300917,HoloDoc: Enabling Mixed Reality Workspaces that Harness Physical and Digital Content,1,Zhen Li,University of Toronto,Toronto,Canada,false,false,"Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles."
pn3093,https://doi.org/10.1145/3290605.3300917,HoloDoc: Enabling Mixed Reality Workspaces that Harness Physical and Digital Content,2,Michelle Annett,MishMashMakers,Newmarket,Canada,false,false,"Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles."
pn3093,https://doi.org/10.1145/3290605.3300917,HoloDoc: Enabling Mixed Reality Workspaces that Harness Physical and Digital Content,3,Ken Hinckley,Microsoft Research,Redmond,United States,false,false,"Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles."
pn3093,https://doi.org/10.1145/3290605.3300917,HoloDoc: Enabling Mixed Reality Workspaces that Harness Physical and Digital Content,4,Karan Singh,University of Toronto,Toronto,Canada,false,false,"Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles."
pn3093,https://doi.org/10.1145/3290605.3300917,HoloDoc: Enabling Mixed Reality Workspaces that Harness Physical and Digital Content,5,Daniel Wigdor,University of Toronto,Toronto,Canada,false,false,"Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,1,Thammathip Piumsomboon,University of Canterbury,Christchurch,New Zealand,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,2,Gun Lee,University of South Australia,Adelaide,Australia,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,3,Andrew Irlitti,University of South Australia,Adelaide,Australia,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,4,Barrett Ens,Monash University,Melbourne,Australia,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,5,Bruce Thomas,University of South Australia,Mawson Lakes,Australia,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn9029,https://doi.org/10.1145/3290605.3300458,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,6,Mark Billinghurst,University of South Australia,Mawson Lakes,Australia,false,false,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction."
pn1591,https://doi.org/10.1145/3290605.3300674,DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays,1,Wenge Xu,Xi'an Jiaotong-Liverpool University,Suzhou,China,false,false,"We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches—Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions."
pn1591,https://doi.org/10.1145/3290605.3300674,DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays,2,Hai-Ning Liang,Xi'an Jiaotong-Liverpool University,Suzhou,China,false,false,"We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches—Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions."
pn1591,https://doi.org/10.1145/3290605.3300674,DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays,3,Yuxuan Zhao,Xi'an Jiaotong-Liverpool University,Suzhou,China,false,false,"We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches—Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions."
pn1591,https://doi.org/10.1145/3290605.3300674,DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays,4,Difeng Yu,Xi'an Jiaotong-Liverpool University,Suzhou,China,false,false,"We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches—Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions."
pn1591,https://doi.org/10.1145/3290605.3300674,DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays,5,Diego Monteiro,Xi'an Jiaotong-Liverpool University,Suzhou,China,false,false,"We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches—Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions."
pn7871,https://doi.org/10.1145/3290605.3300649,Monotasking or Multitasking: Designing for Crowdworkers' Preferences,1,Laura Lascau,University College London,London,United Kingdom,false,false,"Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences."
pn7871,https://doi.org/10.1145/3290605.3300649,Monotasking or Multitasking: Designing for Crowdworkers' Preferences,2,Sandy Gould,University of Birmingham,Birmingham,United Kingdom,false,false,"Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences."
pn7871,https://doi.org/10.1145/3290605.3300649,Monotasking or Multitasking: Designing for Crowdworkers' Preferences,3,Anna Cox,University College London,London,United Kingdom,false,false,"Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences."
pn7871,https://doi.org/10.1145/3290605.3300649,Monotasking or Multitasking: Designing for Crowdworkers' Preferences,4,Elizaveta Karmannaya,University College London,London,United Kingdom,false,false,"Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences."
pn7871,https://doi.org/10.1145/3290605.3300649,Monotasking or Multitasking: Designing for Crowdworkers' Preferences,5,Duncan Brumby,University College London,London,United Kingdom,false,false,"Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences."
pn9208,https://doi.org/10.1145/3290605.3300761,"Cicero: Multi-Turn, Contextual Argumentation for Accurate Crowdsourcing",1,Quanze Chen,University of Washington,Seattle,United States,false,false,"Traditional approaches for ensuring high quality crowdwork have failed to achieve high-accuracy on difficult problems. Aggregating redundant answers often fails on the hardest problems when the majority is confused. Argumentation has been shown to be effective in mitigating these drawbacks. However, existing argumentation systems only support limited interactions and show workers general justifications, not context-specific arguments targeted to their reasoning. This paper presents Cicero, a new workflow that improves crowd accuracy on difficult tasks by engaging workers in multi-turn, contextual discussions through real-time, synchronous argumentation. Our experiments show that compared to previous argumentation systems which only improve the average individual worker accuracy by 6.8 percentage points on the Relation Extraction domain, our workflow achieves 16.7 percentage point improvement. Furthermore, previous argumentation approaches don't apply to tasks with many possible answers; in contrast, Cicero works well in these cases, raising accuracy from 66.7% to 98.8% on the Codenames domain."
pn9208,https://doi.org/10.1145/3290605.3300761,"Cicero: Multi-Turn, Contextual Argumentation for Accurate Crowdsourcing",2,Jonathan Bragg,University of Washington,Seattle,United States,false,false,"Traditional approaches for ensuring high quality crowdwork have failed to achieve high-accuracy on difficult problems. Aggregating redundant answers often fails on the hardest problems when the majority is confused. Argumentation has been shown to be effective in mitigating these drawbacks. However, existing argumentation systems only support limited interactions and show workers general justifications, not context-specific arguments targeted to their reasoning. This paper presents Cicero, a new workflow that improves crowd accuracy on difficult tasks by engaging workers in multi-turn, contextual discussions through real-time, synchronous argumentation. Our experiments show that compared to previous argumentation systems which only improve the average individual worker accuracy by 6.8 percentage points on the Relation Extraction domain, our workflow achieves 16.7 percentage point improvement. Furthermore, previous argumentation approaches don't apply to tasks with many possible answers; in contrast, Cicero works well in these cases, raising accuracy from 66.7% to 98.8% on the Codenames domain."
pn9208,https://doi.org/10.1145/3290605.3300761,"Cicero: Multi-Turn, Contextual Argumentation for Accurate Crowdsourcing",3,Lydia Chilton,Columbia University,New York,United States,false,false,"Traditional approaches for ensuring high quality crowdwork have failed to achieve high-accuracy on difficult problems. Aggregating redundant answers often fails on the hardest problems when the majority is confused. Argumentation has been shown to be effective in mitigating these drawbacks. However, existing argumentation systems only support limited interactions and show workers general justifications, not context-specific arguments targeted to their reasoning. This paper presents Cicero, a new workflow that improves crowd accuracy on difficult tasks by engaging workers in multi-turn, contextual discussions through real-time, synchronous argumentation. Our experiments show that compared to previous argumentation systems which only improve the average individual worker accuracy by 6.8 percentage points on the Relation Extraction domain, our workflow achieves 16.7 percentage point improvement. Furthermore, previous argumentation approaches don't apply to tasks with many possible answers; in contrast, Cicero works well in these cases, raising accuracy from 66.7% to 98.8% on the Codenames domain."
pn9208,https://doi.org/10.1145/3290605.3300761,"Cicero: Multi-Turn, Contextual Argumentation for Accurate Crowdsourcing",4,Dan Weld,University of Washington,Seattle,United States,false,false,"Traditional approaches for ensuring high quality crowdwork have failed to achieve high-accuracy on difficult problems. Aggregating redundant answers often fails on the hardest problems when the majority is confused. Argumentation has been shown to be effective in mitigating these drawbacks. However, existing argumentation systems only support limited interactions and show workers general justifications, not context-specific arguments targeted to their reasoning. This paper presents Cicero, a new workflow that improves crowd accuracy on difficult tasks by engaging workers in multi-turn, contextual discussions through real-time, synchronous argumentation. Our experiments show that compared to previous argumentation systems which only improve the average individual worker accuracy by 6.8 percentage points on the Relation Extraction domain, our workflow achieves 16.7 percentage point improvement. Furthermore, previous argumentation approaches don't apply to tasks with many possible answers; in contrast, Cicero works well in these cases, raising accuracy from 66.7% to 98.8% on the Codenames domain."
pn2367,https://doi.org/10.1145/3290605.3300773,Rehumanized Crowdsourcing: A Labeling Framework Addressing Bias and Ethics in Machine Learning,1,Natã Barbosa,Syracuse University,Syracuse,United States,false,false,"The increased use of machine learning in recent years led to large volumes of data being manually labeled via crowdsourcing microtasks completed by humans. This brought about dehumanization effects, namely, when task requesters overlook the humans behind the task, leading to issues of ethics (e.g., unfair payment) and amplification of human biases, which are transferred into training data and affect machine learning in the real world. We propose a framework that allocates microtasks considering human factors of workers such as demographics and compensation. We deployed our framework to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting 160,345 human judgments. By routing microtasks to workers based on demographics and appropriate pay, our framework mitigates biases in the contributor sample and increases the hourly pay given to contributors. We discuss potential extensions and how it can promote transparency in crowdsourcing."
pn2367,https://doi.org/10.1145/3290605.3300773,Rehumanized Crowdsourcing: A Labeling Framework Addressing Bias and Ethics in Machine Learning,2,Monchu Chen,"Figure Eight Technologies, INC.",San Francisco,United States,false,false,"The increased use of machine learning in recent years led to large volumes of data being manually labeled via crowdsourcing microtasks completed by humans. This brought about dehumanization effects, namely, when task requesters overlook the humans behind the task, leading to issues of ethics (e.g., unfair payment) and amplification of human biases, which are transferred into training data and affect machine learning in the real world. We propose a framework that allocates microtasks considering human factors of workers such as demographics and compensation. We deployed our framework to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting 160,345 human judgments. By routing microtasks to workers based on demographics and appropriate pay, our framework mitigates biases in the contributor sample and increases the hourly pay given to contributors. We discuss potential extensions and how it can promote transparency in crowdsourcing."
pn8580,https://doi.org/10.1145/3290605.3300793,The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias,1,Maitraye Das,Northwestern University,Evanston,United States,false,false,"Millions of people worldwide contribute content to peer production repositories that serve human information needs and provide vital world knowledge to prominent artificial intelligence systems. Yet, extreme gender participation disparities exist in which men significantly outnumber women. A central concern has been that due to self-focus bias, these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate findings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute different types of content and do so about different places. However, the character of these differences confound simple narratives about self-focus bias: we find that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men."
pn8580,https://doi.org/10.1145/3290605.3300793,The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias,2,Brent Hecht,Northwestern University,Evanston,United States,false,false,"Millions of people worldwide contribute content to peer production repositories that serve human information needs and provide vital world knowledge to prominent artificial intelligence systems. Yet, extreme gender participation disparities exist in which men significantly outnumber women. A central concern has been that due to self-focus bias, these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate findings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute different types of content and do so about different places. However, the character of these differences confound simple narratives about self-focus bias: we find that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men."
pn8580,https://doi.org/10.1145/3290605.3300793,The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias,3,Darren Gergle,Northwestern University,Evanston,United States,false,false,"Millions of people worldwide contribute content to peer production repositories that serve human information needs and provide vital world knowledge to prominent artificial intelligence systems. Yet, extreme gender participation disparities exist in which men significantly outnumber women. A central concern has been that due to self-focus bias, these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate findings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute different types of content and do so about different places. However, the character of these differences confound simple narratives about self-focus bias: we find that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men."
pn9462,https://doi.org/10.1145/3290605.3300922,Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men,1,Mark Warner,University College London,London,United Kingdom,false,false,"HIV status disclosure fields in online sex-social applications (""apps"") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields."
pn9462,https://doi.org/10.1145/3290605.3300922,Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men,2,Juan Maestre,Indiana University,Bloomington,United States,false,false,"HIV status disclosure fields in online sex-social applications (""apps"") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields."
pn9462,https://doi.org/10.1145/3290605.3300922,Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men,3,Jo Gibbs,University College London,London,United Kingdom,false,false,"HIV status disclosure fields in online sex-social applications (""apps"") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields."
pn9462,https://doi.org/10.1145/3290605.3300922,Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men,4,Chia-Fang Chung,Indiana University,Bloomington,United States,false,false,"HIV status disclosure fields in online sex-social applications (""apps"") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields."
pn9462,https://doi.org/10.1145/3290605.3300922,Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men,5,Ann Blandford,University College London,London,United Kingdom,false,false,"HIV status disclosure fields in online sex-social applications (""apps"") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields."
pn5313,https://doi.org/10.1145/3290605.3300692,"Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI",1,Jacob Abbott,Indiana University,Bloomington,United States,true,false,"When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants."
pn5313,https://doi.org/10.1145/3290605.3300692,"Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI",2,Haley Macleod,Indiana University,Bloomington,United States,true,false,"When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants."
pn5313,https://doi.org/10.1145/3290605.3300692,"Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI",3,Novia Nurain,Indiana University,Bloomington,United States,true,false,"When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants."
pn5313,https://doi.org/10.1145/3290605.3300692,"Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI",4,Gustave Ekobe,Indiana University,Bloomington,United States,true,false,"When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants."
pn5313,https://doi.org/10.1145/3290605.3300692,"Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI",5,Sameer Patil,Indiana University,Bloomington,United States,true,false,"When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants."
pn3279,https://doi.org/10.1145/3290605.3300829,"Emotion and Experience in Negotiating HIV-Related Digital Resources: ""It's not just a runny nose!""",1,Aneesha Singh,University College London,London,United Kingdom,false,false,"While digital technologies are increasingly being used to provide support and diagnoses remotely, it is unclear whether they offer adequate emotional support and appropriate messages in navigating complex, stigmatised and sensitive conditions that can have a momentous impact on people's lives. In this paper, we investigate how and why people access existing HIV resources, and their experiences of using these resources through a survey with 197 respondents and an interview and think-aloud study with 28 participants. Our findings indicate that many HIV-related resources do not address the anxiety-provoking reasons for access, reinforce stigma and neglect to provide important information and emotional support. We finally discuss potential ways of addressing these issues in the current environment where more sexual health services are being delivered online."
pn3279,https://doi.org/10.1145/3290605.3300829,"Emotion and Experience in Negotiating HIV-Related Digital Resources: ""It's not just a runny nose!""",2,Jo Gibbs,University College London,London,United Kingdom,false,false,"While digital technologies are increasingly being used to provide support and diagnoses remotely, it is unclear whether they offer adequate emotional support and appropriate messages in navigating complex, stigmatised and sensitive conditions that can have a momentous impact on people's lives. In this paper, we investigate how and why people access existing HIV resources, and their experiences of using these resources through a survey with 197 respondents and an interview and think-aloud study with 28 participants. Our findings indicate that many HIV-related resources do not address the anxiety-provoking reasons for access, reinforce stigma and neglect to provide important information and emotional support. We finally discuss potential ways of addressing these issues in the current environment where more sexual health services are being delivered online."
pn3279,https://doi.org/10.1145/3290605.3300829,"Emotion and Experience in Negotiating HIV-Related Digital Resources: ""It's not just a runny nose!""",3,Ann Blandford,University College London,London,United Kingdom,false,false,"While digital technologies are increasingly being used to provide support and diagnoses remotely, it is unclear whether they offer adequate emotional support and appropriate messages in navigating complex, stigmatised and sensitive conditions that can have a momentous impact on people's lives. In this paper, we investigate how and why people access existing HIV resources, and their experiences of using these resources through a survey with 197 respondents and an interview and think-aloud study with 28 participants. Our findings indicate that many HIV-related resources do not address the anxiety-provoking reasons for access, reinforce stigma and neglect to provide important information and emotional support. We finally discuss potential ways of addressing these issues in the current environment where more sexual health services are being delivered online."
pn4555,https://doi.org/10.1145/3290605.3300359,"""This Girl is on Fire"" Sensemaking in an Online Health Community for Vulvodynia",1,Alyson Young,Indiana University-Purdue University Indianapolis,Indianapolis,United States,true,false,"Online health communities (OHCs) allow people living with a shared diagnosis or medical condition to connect with peers for social support and advice. OHCs have been well studied in conditions like diabetes and cancer, but less is known about their role in enigmatic diseases with unknown or complex causal mechanisms. In this paper, we study one such condition: Vulvodynia, a chronic pain syndrome of the vulvar region. Through observations of and interviews with members of a vulvodynia Facebook group, we found that while the interaction types are broadly similar to those found in other OHCs, the women spent more time seeking basic information and building individualized management plans. They also encounter significant emotional and interpersonal challenges, which they discuss with each other. We use this study to extend the field's understanding of OHCs, and to propose implications for the design of self-tracking tools to support sensemaking in enigmatic conditions."
pn4555,https://doi.org/10.1145/3290605.3300359,"""This Girl is on Fire"" Sensemaking in an Online Health Community for Vulvodynia",2,Andrew Miller,Indiana University-Purdue University Indianapolis,Indianapolis,United States,true,false,"Online health communities (OHCs) allow people living with a shared diagnosis or medical condition to connect with peers for social support and advice. OHCs have been well studied in conditions like diabetes and cancer, but less is known about their role in enigmatic diseases with unknown or complex causal mechanisms. In this paper, we study one such condition: Vulvodynia, a chronic pain syndrome of the vulvar region. Through observations of and interviews with members of a vulvodynia Facebook group, we found that while the interaction types are broadly similar to those found in other OHCs, the women spent more time seeking basic information and building individualized management plans. They also encounter significant emotional and interpersonal challenges, which they discuss with each other. We use this study to extend the field's understanding of OHCs, and to propose implications for the design of self-tracking tools to support sensemaking in enigmatic conditions."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,1,Yi-Hao Peng,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,2,Muh-Tarng Lin,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,3,Yi Chen,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,4,Tzuchuan Chen,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,5,Pin Sung Ku,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,6,Paul Taele,Texas A&M University,College Station,United States,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,7,Chin Guan Lim,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn1402,https://doi.org/10.1145/3290605.3300913,PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings based on Individual User's Touchscreen Interaction,8,Mike Chen,National Taiwan University,Taipei,Taiwan Roc,false,false,"Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032)."
pn4195,https://doi.org/10.1145/3290605.3300257,Cluster Touch: Improving Touch Accuracy on Smartphones for People with Motor and Situational Impairments,1,Martez Mott,University of Washington,Seattle,United States,false,false,"We present Cluster Touch, a combined user-independent and user-specific touch offset model that improves the accuracy of touch input on smartphones for people with motor impairments, and for people experiencing situational impairments while walking. Cluster Touch combines touch examples from multiple users to create a shared user-independent touch model, which is then updated with touch examples provided by an individual user to make it user-specific. Owing to this combination, Cluster Touch allows people to quickly improve the accuracy of their smartphones by providing only 20 touch examples. In a user study with 12 people with motor impairments and 12 people without motor impairments, but who were walking, Cluster Touch improved touch accuracy by 14.65% for the former group and 6.81% for the latter group over the native touch sensor. Furthermore, in an offline analysis of existing mobile interfaces, Cluster Touch improved touch accuracy by 8.21% and 4.84% over the native touch sensor for the two user groups, respectively."
pn4195,https://doi.org/10.1145/3290605.3300257,Cluster Touch: Improving Touch Accuracy on Smartphones for People with Motor and Situational Impairments,2,Jacob Wobbrock,University of Washington,Seattle,United States,false,false,"We present Cluster Touch, a combined user-independent and user-specific touch offset model that improves the accuracy of touch input on smartphones for people with motor impairments, and for people experiencing situational impairments while walking. Cluster Touch combines touch examples from multiple users to create a shared user-independent touch model, which is then updated with touch examples provided by an individual user to make it user-specific. Owing to this combination, Cluster Touch allows people to quickly improve the accuracy of their smartphones by providing only 20 touch examples. In a user study with 12 people with motor impairments and 12 people without motor impairments, but who were walking, Cluster Touch improved touch accuracy by 14.65% for the former group and 6.81% for the latter group over the native touch sensor. Furthermore, in an offline analysis of existing mobile interfaces, Cluster Touch improved touch accuracy by 8.21% and 4.84% over the native touch sensor for the two user groups, respectively."
pn1548,https://doi.org/10.1145/3290605.3300606,Accessible Gesture Typing for Non-Visual Text Entry on Smartphones,1,Syed Masum Billah,Stony Brook University,Stony Brook,United States,false,false,"Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry."
pn1548,https://doi.org/10.1145/3290605.3300606,Accessible Gesture Typing for Non-Visual Text Entry on Smartphones,2,Yu-Jung Ko,Stony Brook University,Stony Brook,United States,false,false,"Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry."
pn1548,https://doi.org/10.1145/3290605.3300606,Accessible Gesture Typing for Non-Visual Text Entry on Smartphones,3,Vikas Ashok,Stony Brook University,Stony Brook,United States,false,false,"Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry."
pn1548,https://doi.org/10.1145/3290605.3300606,Accessible Gesture Typing for Non-Visual Text Entry on Smartphones,4,Xiaojun Bi,Stony Brook University,Stony Brook,United States,false,false,"Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry."
pn1548,https://doi.org/10.1145/3290605.3300606,Accessible Gesture Typing for Non-Visual Text Entry on Smartphones,5,Iv Ramakrishnan,Stony Brook University,Stony Brook,United States,false,false,"Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry."
pn7908,https://doi.org/10.1145/3290605.3300445,Stroke-Gesture Input for People with Motor Impairments: Empirical Results & Research Roadmap,1,Radu-Daniel Vatavu,University Ştefan cel Mare of Suceava,Suceava,Romania,false,false,"We examine the articulation characteristics of stroke-gestures produced by people with upper body motor impairments on touchscreens as well as the accuracy rates of popular classification techniques, such as the $-family, to recognize those gestures. Our results on a dataset of 9,681 gestures collected from 70 participants reveal that stroke-gestures produced by people with motor impairments are recognized less accurately than the same gesture types produced by people without impairments, yet still accurately enough (93.0%) for practical purposes; are similar in terms of geometrical criteria to the gestures produced by people without impairments; but take considerably more time to produce (3.4s vs. 1.7s) and exhibit lower consistency (-49.7%). We outline a research roadmap for accessible gesture input on touchscreens for users with upper body motor impairments, and we make our large gesture dataset publicly available in the community."
pn7908,https://doi.org/10.1145/3290605.3300445,Stroke-Gesture Input for People with Motor Impairments: Empirical Results & Research Roadmap,2,Ovidiu-Ciprian Ungurean,University Ştefan cel Mare of Suceava,Suceava,Romania,false,false,"We examine the articulation characteristics of stroke-gestures produced by people with upper body motor impairments on touchscreens as well as the accuracy rates of popular classification techniques, such as the $-family, to recognize those gestures. Our results on a dataset of 9,681 gestures collected from 70 participants reveal that stroke-gestures produced by people with motor impairments are recognized less accurately than the same gesture types produced by people without impairments, yet still accurately enough (93.0%) for practical purposes; are similar in terms of geometrical criteria to the gestures produced by people without impairments; but take considerably more time to produce (3.4s vs. 1.7s) and exhibit lower consistency (-49.7%). We outline a research roadmap for accessible gesture input on touchscreens for users with upper body motor impairments, and we make our large gesture dataset publicly available in the community."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,1,Will Brackenbury,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,2,Abhimanyu Deora,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,3,Jillian Ritchey,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,4,Jason Vallee,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,5,Weijia He,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,6,Guan Wang,Brown University,Providence,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,7,Michael Littman,Brown University,Providence,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8594,https://doi.org/10.1145/3290605.3300782,How Users Interpret Bugs in Trigger-Action Programming,8,Blase Ur,University of Chicago,Chicago,United States,false,false,"Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,1,Jacob Kittley-Davies,University of Southampton,Southampton,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,2,Ahmed Alqaraawi,University College London,London,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,3,Rayoung Yang,University College London,London,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,4,Enrico Costanza,University College London,London,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,5,Alex Rogers,University of Oxford,Oxford,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn8677,https://doi.org/10.1145/3290605.3300273,Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study,6,Sebastian Stein,University of Southampton,Southampton,United Kingdom,false,false,"Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,1,Saleema Amershi,Microsoft,Seattle,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,2,Dan Weld,University of Washington,Seattle,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,3,Mihaela Vorvoreanu,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,4,Adam Fourney,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,5,Besmira Nushi,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,6,Penny Collisson,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,7,Jina Suh,Microsoft,Remond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,8,Shamsi Iqbal,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,9,Paul Bennett,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,10,Kori Inkpen,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,11,Jaime Teevan,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,12,Ruth Kikin-Gil,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn6832,https://doi.org/10.1145/3290605.3300233,Guidelines for Human-AI Interaction,13,Eric Horvitz,Microsoft,Redmond,United States,true,false,"Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles."
pn9900,https://doi.org/10.1145/3290605.3300271,Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services,1,Anna Brown,"College of Creative Arts, Massey University",Wellington,New Zealand,true,false,"Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications."
pn9900,https://doi.org/10.1145/3290605.3300271,Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services,2,Alexandra Chouldechova,Carnegie Mellon University,Pittsburgh,United States,true,false,"Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications."
pn9900,https://doi.org/10.1145/3290605.3300271,Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services,3,Emily Putnam-Hornstein,University of Southern California,Los Angeles,United States,true,false,"Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications."
pn9900,https://doi.org/10.1145/3290605.3300271,Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services,4,Andrew Tobin,"College of Creative Arts, Massey University",Wellington,New Zealand,true,false,"Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications."
pn9900,https://doi.org/10.1145/3290605.3300271,Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services,5,Rhema Vaithianathan,Auckland University of Technology,Auckland,New Zealand,true,false,"Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications."
pn4829,https://doi.org/10.1145/3290605.3300603,"Touchscreen Haptic Augmentation Effects on Tapping, Drag and Drop, and Path Following",1,Mitchell Gordon,Stanford University,Stanford,United States,false,false,"We study the effects of haptic augmentation on tapping, path following, and drag & drop tasks based on a recent flagship smartphone with refined touch sensing and haptic actuator technologies. Results show actuated haptic confirmation on tapping targets was subjectively appreciated by some users but did not improve tapping speed or accuracy. For drag & drop, a clear performance improvement was measured when haptic feedback is applied to target boundary crossing, particularly when the targets are small. For path following tasks, virtual haptic feedback improved accuracy at a reduced speed in a sitting condition. Stronger results were achieved in a physical haptic mock-up. Overall, we found actuated touchscreen haptic feedback particularly effective when the touched object was visually interfered by the finger. Participants subjective experience of haptic feedback in all tasks tended to be more positive than their time or accuracy performance suggests. We compare and discuss these findings with previous results on early generations of devices. The work provides an empirical foundation to product design and future research of touch input and haptic systems."
pn4829,https://doi.org/10.1145/3290605.3300603,"Touchscreen Haptic Augmentation Effects on Tapping, Drag and Drop, and Path Following",2,Shumin Zhai,Google,Mountain View,United States,false,false,"We study the effects of haptic augmentation on tapping, path following, and drag & drop tasks based on a recent flagship smartphone with refined touch sensing and haptic actuator technologies. Results show actuated haptic confirmation on tapping targets was subjectively appreciated by some users but did not improve tapping speed or accuracy. For drag & drop, a clear performance improvement was measured when haptic feedback is applied to target boundary crossing, particularly when the targets are small. For path following tasks, virtual haptic feedback improved accuracy at a reduced speed in a sitting condition. Stronger results were achieved in a physical haptic mock-up. Overall, we found actuated touchscreen haptic feedback particularly effective when the touched object was visually interfered by the finger. Participants subjective experience of haptic feedback in all tasks tended to be more positive than their time or accuracy performance suggests. We compare and discuss these findings with previous results on early generations of devices. The work provides an empirical foundation to product design and future research of touch input and haptic systems."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,1,Sven Mayer,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,2,Valentin Schwind,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,3,Huy Viet Le,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,4,Dominik Weber,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,5,Jonas Vogelsang,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,6,Johannes Wolf,University of Stuttgart,Stuttgart,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn6763,https://doi.org/10.1145/3290605.3300928,Effect of Orientation on Unistroke Touch Gestures,7,Niels Henze,University of Regensburg,Regensburg,Germany,false,false,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures."
pn9349,https://doi.org/10.1145/3290605.3300476,An Evaluation of Touch Input at the Edge of a Table,1,Nikhita Joshi,University of Waterloo,Waterloo,Canada,false,false,"Tables, desks, and counters are often nearby, motivating their use as interactive surfaces. However, they are typically cluttered. As an alternative, we explore touch input along the 'edge' of table-like surfaces. The performance of tapping, crossing, and dragging is tested along the two ridges and front face of a table edge. Results show top ridge movement time is comparable to the top face when tapping or dragging. When crossing, both ridges are at least 11% faster than the top face. Effective width analysis is used to model performance and provide recommended target sizes. Based on observed user behaviour, variations of top and bottom ridge crossing are explored in a second study, and design recommendations with example applications are provided."
pn9349,https://doi.org/10.1145/3290605.3300476,An Evaluation of Touch Input at the Edge of a Table,2,Daniel Vogel,University of Waterloo,Waterloo,Canada,false,false,"Tables, desks, and counters are often nearby, motivating their use as interactive surfaces. However, they are typically cluttered. As an alternative, we explore touch input along the 'edge' of table-like surfaces. The performance of tapping, crossing, and dragging is tested along the two ridges and front face of a table edge. Results show top ridge movement time is comparable to the top face when tapping or dragging. When crossing, both ridges are at least 11% faster than the top face. Effective width analysis is used to model performance and provide recommended target sizes. Based on observed user behaviour, variations of top and bottom ridge crossing are explored in a second study, and design recommendations with example applications are provided."
pn1004,https://doi.org/10.1145/3290605.3300350,Modeling Fully and Partially Constrained Lasso Movements in a Grid of Icons,1,Shota Yamanaka,Yahoo Japan Corporation,Tokyo,Japan,false,false,"Lassoing objects is a basic function in illustration software and presentation tools. Yet, for many common object arrangements lassoing is sometimes time-consuming to perform and requires precise pen operation. In this work, we studied lassoing movements in a grid of objects similar to icons. We propose a quantitative model to predict the time to lasso such objects depending on the margins between icons, their sizes, and layout, which all affect the number of stopping and crossing movements. Results of two experiments showed that our models predict fully and partially constrained movements with high accuracy. We also analyzed the speed profiles and pen stroke trajectories and identified deeper insights into user behaviors, such as that an unconstrained area can induce higher movement speeds even in preceding path segments."
pn1004,https://doi.org/10.1145/3290605.3300350,Modeling Fully and Partially Constrained Lasso Movements in a Grid of Icons,2,Wolfgang Stuerzlinger,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Lassoing objects is a basic function in illustration software and presentation tools. Yet, for many common object arrangements lassoing is sometimes time-consuming to perform and requires precise pen operation. In this work, we studied lassoing movements in a grid of objects similar to icons. We propose a quantitative model to predict the time to lasso such objects depending on the margins between icons, their sizes, and layout, which all affect the number of stopping and crossing movements. Results of two experiments showed that our models predict fully and partially constrained movements with high accuracy. We also analyzed the speed profiles and pen stroke trajectories and identified deeper insights into user behaviors, such as that an unconstrained area can induce higher movement speeds even in preceding path segments."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,1,Pooja Desai,Columbia University Teachers College,New York,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,2,Elliot Mitchell,Columbia University Medical Center,New York,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,3,Maria Hwang,Fashion Institute of Technology,New York,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,4,Matthew Levine,California Institute of Technology,Pasadena,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,5,David Albers,University of Colorado Medicine; Columbia University Medical Center,Aurora; New York,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn8346,https://doi.org/10.1145/3290605.3300600,Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,6,Lena Mamykina,Columbia University Medical Center,New York,United States,false,false,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health."
pn1541,https://doi.org/10.1145/3290605.3300391,Communicating Uncertainty in Fertility Prognosis,1,Hanna Schneider,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects."
pn1541,https://doi.org/10.1145/3290605.3300391,Communicating Uncertainty in Fertility Prognosis,2,Julia Wayrauther,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects."
pn1541,https://doi.org/10.1145/3290605.3300391,Communicating Uncertainty in Fertility Prognosis,3,Mariam Hassib,Bundeswehr University Munich,Munich,Germany,false,false,"Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects."
pn1541,https://doi.org/10.1145/3290605.3300391,Communicating Uncertainty in Fertility Prognosis,4,Andreas Butz,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects."
pn8868,https://doi.org/10.1145/3290605.3300933,A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App,1,Ana-Maria Salai,Heriot-Watt University,Edinburgh,United Kingdom,false,false,"Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population. Even though it is a treatable condition, people often do not seek treatment. In this paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical professionals and 21 end-users) an OAB mobile health application that aims to increase adherence to self-managed treatment. Our results support previous research that visualizing progress, setting goals, receiving reminders and feedback increases use. We discovered that games could be used successfully as a distraction technique for urge suppression. Contrary to the current research direction, automatically calculated features could be a detriment to app interaction. Regarding evaluation, we found that designers may not want to rely only on questionnaires when assessing the success of a game and its emotional impact on users."
pn8868,https://doi.org/10.1145/3290605.3300933,A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App,2,Lynne Baillie,Heriot-Watt University,Edinburgh,United Kingdom,false,false,"Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population. Even though it is a treatable condition, people often do not seek treatment. In this paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical professionals and 21 end-users) an OAB mobile health application that aims to increase adherence to self-managed treatment. Our results support previous research that visualizing progress, setting goals, receiving reminders and feedback increases use. We discovered that games could be used successfully as a distraction technique for urge suppression. Contrary to the current research direction, automatically calculated features could be a detriment to app interaction. Regarding evaluation, we found that designers may not want to rely only on questionnaires when assessing the success of a game and its emotional impact on users."
pn7691,https://doi.org/10.1145/3290605.3300349,"""My blood sugar is higher on the weekends"": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology",1,Shriti Raj,University of Michigan,Ann Arbor,United States,true,false,"Tools for self-care of chronic conditions often do not fit the contexts in which self-care happens because the influence of context on self-care practices is unclear. We conducted a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand how context affects self-care. We observed different contextual settings, which we call contextual frames, in which diabetes self-management varied depending on certain factors - physical activity, food, emotional state, insulin, people, and attitudes. The relative prevalence of these factors across contextual frames impacts self-care necessitating different types of support. We show that contextual frames, as phenomenological abstractions of context, can help designers of context-aware systems systematically explore and model the relation of context with behavior and with technology supporting behavior. Lastly, considering contextual frames as sensitizing concepts, we provide design direction for using context in technology design."
pn7691,https://doi.org/10.1145/3290605.3300349,"""My blood sugar is higher on the weekends"": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology",2,Kelsey Toporski,University of Michigan,Ann Arbor,United States,true,false,"Tools for self-care of chronic conditions often do not fit the contexts in which self-care happens because the influence of context on self-care practices is unclear. We conducted a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand how context affects self-care. We observed different contextual settings, which we call contextual frames, in which diabetes self-management varied depending on certain factors - physical activity, food, emotional state, insulin, people, and attitudes. The relative prevalence of these factors across contextual frames impacts self-care necessitating different types of support. We show that contextual frames, as phenomenological abstractions of context, can help designers of context-aware systems systematically explore and model the relation of context with behavior and with technology supporting behavior. Lastly, considering contextual frames as sensitizing concepts, we provide design direction for using context in technology design."
pn7691,https://doi.org/10.1145/3290605.3300349,"""My blood sugar is higher on the weekends"": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology",3,Ashley Garrity,University of Michigan,Ann Arbor,United States,true,false,"Tools for self-care of chronic conditions often do not fit the contexts in which self-care happens because the influence of context on self-care practices is unclear. We conducted a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand how context affects self-care. We observed different contextual settings, which we call contextual frames, in which diabetes self-management varied depending on certain factors - physical activity, food, emotional state, insulin, people, and attitudes. The relative prevalence of these factors across contextual frames impacts self-care necessitating different types of support. We show that contextual frames, as phenomenological abstractions of context, can help designers of context-aware systems systematically explore and model the relation of context with behavior and with technology supporting behavior. Lastly, considering contextual frames as sensitizing concepts, we provide design direction for using context in technology design."
pn7691,https://doi.org/10.1145/3290605.3300349,"""My blood sugar is higher on the weekends"": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology",4,Joyce Lee,University of Michigan,Ann Arbor,United States,true,false,"Tools for self-care of chronic conditions often do not fit the contexts in which self-care happens because the influence of context on self-care practices is unclear. We conducted a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand how context affects self-care. We observed different contextual settings, which we call contextual frames, in which diabetes self-management varied depending on certain factors - physical activity, food, emotional state, insulin, people, and attitudes. The relative prevalence of these factors across contextual frames impacts self-care necessitating different types of support. We show that contextual frames, as phenomenological abstractions of context, can help designers of context-aware systems systematically explore and model the relation of context with behavior and with technology supporting behavior. Lastly, considering contextual frames as sensitizing concepts, we provide design direction for using context in technology design."
pn7691,https://doi.org/10.1145/3290605.3300349,"""My blood sugar is higher on the weekends"": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology",5,Mark Newman,University of Michigan,Ann Arbor,United States,true,false,"Tools for self-care of chronic conditions often do not fit the contexts in which self-care happens because the influence of context on self-care practices is unclear. We conducted a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand how context affects self-care. We observed different contextual settings, which we call contextual frames, in which diabetes self-management varied depending on certain factors - physical activity, food, emotional state, insulin, people, and attitudes. The relative prevalence of these factors across contextual frames impacts self-care necessitating different types of support. We show that contextual frames, as phenomenological abstractions of context, can help designers of context-aware systems systematically explore and model the relation of context with behavior and with technology supporting behavior. Lastly, considering contextual frames as sensitizing concepts, we provide design direction for using context in technology design."
pn2102,https://doi.org/10.1145/3290605.3300588,The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,1,Aloha Ambe,Queensland University of Technology,Brisbane,Australia,false,false,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand."
pn2102,https://doi.org/10.1145/3290605.3300588,The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,2,Margot Brereton,Queensland University of Technology,Brisbane,Australia,false,false,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand."
pn2102,https://doi.org/10.1145/3290605.3300588,The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,3,Alessandro Soro,Queensland University of Technology,Brisbane,Australia,false,false,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand."
pn2102,https://doi.org/10.1145/3290605.3300588,The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,4,Laurie Buys,Queensland University of Technology,Brisbane,Australia,false,false,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand."
pn2102,https://doi.org/10.1145/3290605.3300588,The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,5,Paul Roe,Queensland University of Technology,Brisbane,Australia,false,false,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand."
pn9386,https://doi.org/10.1145/3290605.3300652,HawkEye – Deploying a Design Fiction Probe,1,Renee Noortman,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies."
pn9386,https://doi.org/10.1145/3290605.3300652,HawkEye – Deploying a Design Fiction Probe,2,Britta Schulte,University College London,London,United Kingdom,false,false,"This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies."
pn9386,https://doi.org/10.1145/3290605.3300652,HawkEye – Deploying a Design Fiction Probe,3,Paul Marshall,University of Bristol,Bristol,United Kingdom,false,false,"This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies."
pn9386,https://doi.org/10.1145/3290605.3300652,HawkEye – Deploying a Design Fiction Probe,4,Saskia Bakker,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies."
pn9386,https://doi.org/10.1145/3290605.3300652,HawkEye – Deploying a Design Fiction Probe,5,Anna Cox,University College London,London,United Kingdom,false,false,"This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies."
pn9626,https://doi.org/10.1145/3290605.3300275,Smart Home Security Cameras and Shifting Lines of Creepiness: A Design-Led Inquiry,1,James Pierce,California College of the Arts,San Francisco/Berkeley,United States,false,false,"Through a design-led inquiry focused on smart home security cameras, this research develops three key concepts for research and design pertaining to new and emerging digital consumer technologies. Digital leakage names the propensity for digital information to be shared, stolen, and misused in ways unbeknownst or even harmful to those to whom the data pertains or belongs. Hole-and-corner applications are those functions connected to users' data, devices, and interactions yet concealed from or downplayed to them, often because they are non-beneficial or harmful to them. Foot-in-the-door devices are product and services with functional offerings and affordances that work to normalize and integrate a technology, thus laying groundwork for future adoption of features that might have earlier been rejected as unacceptable or unnecessary. Developed and illustrated through a set of design studies and explorations, this paper shows how these concepts may be used analytically to investigate issues such as privacy and security, anticipatorily to speculate about the future of technology development and use, and generatively to synthesize design concepts and solutions."
pn1280,https://doi.org/10.1145/3290605.3300666,"'What is Fair Shipping, Anyway? ' Using Design Fiction to Raise Ethical Awareness in an Industrial Context",1,Yiying Wu,Aalto University,Helsinki,Finland,false,false,"The HCI community cares for the human and social aspects of technologies. Ethical discussion on the social implications of new technologies often happen among researchers, but it is important to raise this discussion also in the industry that designs and implements new systems. In this paper, we introduce a case in which design fiction was used as an ethical discussion tool among company partners. We report the process of creating and prototyping a fictional world embedded with conflicting values that aimed to shift the focus from industrial merits towards societal values and raise discussion among participants. Moreover, we examine the challenges and propose suggestions in crafting critiques and friction to the industrial context. Our findings suggest why and how one should use design fiction as a means to raise ethical awareness in a technology- and profit-focused context, to support further activities on developing more humane technological futures."
pn1280,https://doi.org/10.1145/3290605.3300666,"'What is Fair Shipping, Anyway? ' Using Design Fiction to Raise Ethical Awareness in an Industrial Context",2,Sus Lyckvi,Chalmers University of Technology,Gothenburg,Sweden,false,false,"The HCI community cares for the human and social aspects of technologies. Ethical discussion on the social implications of new technologies often happen among researchers, but it is important to raise this discussion also in the industry that designs and implements new systems. In this paper, we introduce a case in which design fiction was used as an ethical discussion tool among company partners. We report the process of creating and prototyping a fictional world embedded with conflicting values that aimed to shift the focus from industrial merits towards societal values and raise discussion among participants. Moreover, we examine the challenges and propose suggestions in crafting critiques and friction to the industrial context. Our findings suggest why and how one should use design fiction as a means to raise ethical awareness in a technology- and profit-focused context, to support further activities on developing more humane technological futures."
pn1280,https://doi.org/10.1145/3290605.3300666,"'What is Fair Shipping, Anyway? ' Using Design Fiction to Raise Ethical Awareness in an Industrial Context",3,Virpi Roto,Aalto University,Helsinki,Finland,false,false,"The HCI community cares for the human and social aspects of technologies. Ethical discussion on the social implications of new technologies often happen among researchers, but it is important to raise this discussion also in the industry that designs and implements new systems. In this paper, we introduce a case in which design fiction was used as an ethical discussion tool among company partners. We report the process of creating and prototyping a fictional world embedded with conflicting values that aimed to shift the focus from industrial merits towards societal values and raise discussion among participants. Moreover, we examine the challenges and propose suggestions in crafting critiques and friction to the industrial context. Our findings suggest why and how one should use design fiction as a means to raise ethical awareness in a technology- and profit-focused context, to support further activities on developing more humane technological futures."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,1,Xi Wang,Technische Universität Berlin,Berlin,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,2,Andreas Ley,Technische Universität Berlin,Berlin,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,3,Sebastian Koch,Technische Universität Berlin,Berlin,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,4,David Lindlbauer,Technische Universität Berlin,Berlin,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,5,James Hays,Georgia Institute of Technology,Atlanta,United States,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,6,Kenneth Holmqvist,Universität Regensburg,Regensburg,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn5491,https://doi.org/10.1145/3290605.3300839,The Mental Image Revealed by Gaze Tracking,7,Marc Alexa,Technische Universität Berlin,Berlin,Germany,false,false,"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario."
pn7924,https://doi.org/10.1145/3290605.3300765,An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach,1,Immo Schuetz,Facebook Reality Labs,Redmond,United States,true,false,"Eye gaze as an input method has been studied since the 1990s, to varied results: some studies found gaze to be more efficient than traditional input methods like a mouse, others far behind. Comparisons are often backed up by Fitts' Law without explicitly acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired model, we here show that a Fitts'-like distribution of movement times can arise due to the execution of secondary saccades, especially when targets are small. Study participants selected circular targets using gaze. Seven different target sizes and two saccade distances were used. We then determined performance across target sizes for different sampling windows (""dwell times"") and predicted an optimal dwell time range. Best performance was achieved for large targets reachable by a single saccade. Our findings highlight that Fitts' Law, while a suitable approximation in some cases, is an incomplete description of gaze interaction dynamics."
pn7924,https://doi.org/10.1145/3290605.3300765,An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach,2,T. Scott Murdison,Facebook Reality Labs,Redmond,United States,true,false,"Eye gaze as an input method has been studied since the 1990s, to varied results: some studies found gaze to be more efficient than traditional input methods like a mouse, others far behind. Comparisons are often backed up by Fitts' Law without explicitly acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired model, we here show that a Fitts'-like distribution of movement times can arise due to the execution of secondary saccades, especially when targets are small. Study participants selected circular targets using gaze. Seven different target sizes and two saccade distances were used. We then determined performance across target sizes for different sampling windows (""dwell times"") and predicted an optimal dwell time range. Best performance was achieved for large targets reachable by a single saccade. Our findings highlight that Fitts' Law, while a suitable approximation in some cases, is an incomplete description of gaze interaction dynamics."
pn7924,https://doi.org/10.1145/3290605.3300765,An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach,3,Kevin Mackenzie,Facebook Reality Labs,Redmond,United States,true,false,"Eye gaze as an input method has been studied since the 1990s, to varied results: some studies found gaze to be more efficient than traditional input methods like a mouse, others far behind. Comparisons are often backed up by Fitts' Law without explicitly acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired model, we here show that a Fitts'-like distribution of movement times can arise due to the execution of secondary saccades, especially when targets are small. Study participants selected circular targets using gaze. Seven different target sizes and two saccade distances were used. We then determined performance across target sizes for different sampling windows (""dwell times"") and predicted an optimal dwell time range. Best performance was achieved for large targets reachable by a single saccade. Our findings highlight that Fitts' Law, while a suitable approximation in some cases, is an incomplete description of gaze interaction dynamics."
pn7924,https://doi.org/10.1145/3290605.3300765,An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach,4,Marina Zannoli,Facebook Reality Labs,Redmond,United States,true,false,"Eye gaze as an input method has been studied since the 1990s, to varied results: some studies found gaze to be more efficient than traditional input methods like a mouse, others far behind. Comparisons are often backed up by Fitts' Law without explicitly acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired model, we here show that a Fitts'-like distribution of movement times can arise due to the execution of secondary saccades, especially when targets are small. Study participants selected circular targets using gaze. Seven different target sizes and two saccade distances were used. We then determined performance across target sizes for different sampling windows (""dwell times"") and predicted an optimal dwell time range. Best performance was achieved for large targets reachable by a single saccade. Our findings highlight that Fitts' Law, while a suitable approximation in some cases, is an incomplete description of gaze interaction dynamics."
pn3091,https://doi.org/10.1145/3290605.3300306,CodeGazer: Making Code Navigation Easy and Natural With Gaze Input,1,Asma Shakil,Media Design School,Auckland,New Zealand,false,false,"Navigating source code, an activity common in software development, is time consuming and in need of improvement. We present CodeGazer, a prototype for source code navigation using eye gaze for common navigation functions. These functions include actions such as ""Go to Definition'' and ""Find All Usages'' of an identifier, navigate to files and methods, move back and forth between visited points in code and scrolling. We present user study results showing that many users liked and even preferred the gaze-based navigation, in particular the ""Go to Definition'' function. Gaze-based navigation is also holding up well in completion time when compared to traditional methods. We discuss how eye gaze can be integrated into traditional mouse & keyboard applications in order to make ""look up'' tasks more natural."
pn3091,https://doi.org/10.1145/3290605.3300306,CodeGazer: Making Code Navigation Easy and Natural With Gaze Input,2,Christof Lutteroth,University of Bath,Bath,United Kingdom,false,false,"Navigating source code, an activity common in software development, is time consuming and in need of improvement. We present CodeGazer, a prototype for source code navigation using eye gaze for common navigation functions. These functions include actions such as ""Go to Definition'' and ""Find All Usages'' of an identifier, navigate to files and methods, move back and forth between visited points in code and scrolling. We present user study results showing that many users liked and even preferred the gaze-based navigation, in particular the ""Go to Definition'' function. Gaze-based navigation is also holding up well in completion time when compared to traditional methods. We discuss how eye gaze can be integrated into traditional mouse & keyboard applications in order to make ""look up'' tasks more natural."
pn3091,https://doi.org/10.1145/3290605.3300306,CodeGazer: Making Code Navigation Easy and Natural With Gaze Input,3,Gerald Weber,University of Auckland,Auckland,New Zealand,false,false,"Navigating source code, an activity common in software development, is time consuming and in need of improvement. We present CodeGazer, a prototype for source code navigation using eye gaze for common navigation functions. These functions include actions such as ""Go to Definition'' and ""Find All Usages'' of an identifier, navigate to files and methods, move back and forth between visited points in code and scrolling. We present user study results showing that many users liked and even preferred the gaze-based navigation, in particular the ""Go to Definition'' function. Gaze-based navigation is also holding up well in completion time when compared to traditional methods. We discuss how eye gaze can be integrated into traditional mouse & keyboard applications in order to make ""look up'' tasks more natural."
pn2514,https://doi.org/10.1145/3290605.3300433,ReType: Quick Text Editing with Keyboard and Gaze,1,Shyamli Sindhwani,University of Auckland,Auckland,New Zealand,false,true,"When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new 'patching' metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users."
pn2514,https://doi.org/10.1145/3290605.3300433,ReType: Quick Text Editing with Keyboard and Gaze,2,Christof Lutteroth,University of Bath,Bath,United Kingdom,false,true,"When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new 'patching' metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users."
pn2514,https://doi.org/10.1145/3290605.3300433,ReType: Quick Text Editing with Keyboard and Gaze,3,Gerald Weber,University of Auckland,Auckland,New Zealand,false,true,"When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new 'patching' metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users."
pn3272,https://doi.org/10.1145/3290605.3300477,Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation,1,Filip Škola,"Faculty of Informatics, Masaryk University",Brno,Czech Rep,false,false,"Virtual reality (VR) can be immersive to such a degree that users sometimes report feeling tactile sensations based on visualization of the touch, without any actual physical contact. This effect is not only interesting for studies of human perception, but can also be leveraged to improve the quality of VR by evoking tactile sensations without usage of specialized equipment. The aim of this paper is to study brain processing of the illusory touch and its enhancement for purposes of exploitation in VR scene design. To amplify the illusory touch, transcranial direct current stimulation (tDCS) was used. Participants attended two sessions with blinded stimulation and interacted with a virtual ball using tracked hands in VR. The effects were studied using electroencephalography (EEG), that allowed us to examine stimulation-induced changes in processing of the illusory touch in the brain, as well as to identify its neural correlates. Results confirm enhanced processing of the illusory touch after the stimulation, and some of these changes were correlated to subjective rating of its magnitude."
pn3272,https://doi.org/10.1145/3290605.3300477,Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation,2,Fotis Liarokapis,"Faculty of Informatics, Masaryk University",Brno,Czech Rep,false,false,"Virtual reality (VR) can be immersive to such a degree that users sometimes report feeling tactile sensations based on visualization of the touch, without any actual physical contact. This effect is not only interesting for studies of human perception, but can also be leveraged to improve the quality of VR by evoking tactile sensations without usage of specialized equipment. The aim of this paper is to study brain processing of the illusory touch and its enhancement for purposes of exploitation in VR scene design. To amplify the illusory touch, transcranial direct current stimulation (tDCS) was used. Participants attended two sessions with blinded stimulation and interacted with a virtual ball using tracked hands in VR. The effects were studied using electroencephalography (EEG), that allowed us to examine stimulation-induced changes in processing of the illusory touch in the brain, as well as to identify its neural correlates. Results confirm enhanced processing of the illusory touch after the stimulation, and some of these changes were correlated to subjective rating of its magnitude."
pn3611,https://doi.org/10.1145/3290605.3300743,To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis,1,Yi-Chen Lee,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations."
pn3611,https://doi.org/10.1145/3290605.3300743,To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis,2,Fu-Yin Cherng,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations."
pn3611,https://doi.org/10.1145/3290605.3300743,To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis,3,Jung-Tai King,National Chaio Tung Univerity,Hsinchu,Taiwan Roc,false,false,"Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations."
pn3611,https://doi.org/10.1145/3290605.3300743,To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis,4,Wen-Chieh Lin,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,1,Lukas Gehrke,Technical University of Berlin,Berlin,Germany,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,2,Sezen Akman,Technical University of Berlin,Berlin,Germany,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,3,Pedro Lopes,University of Chicago,Chicago,United States,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,4,Albert Chen,University of Chicago,Chicago,United States,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,5,Avinash Singh,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,6,Hsiang-Ting Chen,University of Technology Sydney,Sydney,Australia,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,7,Chin-Teng Lin,University of Technology Sydney,Ultimo,Australia,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn4956,https://doi.org/10.1145/3290605.3300657,Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials,8,Klaus Gramann,"University of California, San Diego",Berlin,Germany,false,false,"Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.<br>Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.<br>We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion."
pn2220,https://doi.org/10.1145/3290605.3300639,Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-scale Online Studies,1,Fu-Yin Cherng,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters – melody (simple, complex), pitch (high, low), and tempo (fast, slow) – influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters."
pn2220,https://doi.org/10.1145/3290605.3300639,Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-scale Online Studies,2,Yi-Chen Lee,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters – melody (simple, complex), pitch (high, low), and tempo (fast, slow) – influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters."
pn2220,https://doi.org/10.1145/3290605.3300639,Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-scale Online Studies,3,Jung-Tai King,National Chaio Tung Univerity,Hsinchu,Taiwan Roc,false,false,"Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters – melody (simple, complex), pitch (high, low), and tempo (fast, slow) – influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters."
pn2220,https://doi.org/10.1145/3290605.3300639,Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-scale Online Studies,4,Wen-Chieh Lin,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters – melody (simple, complex), pitch (high, low), and tempo (fast, slow) – influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters."
pn9157,https://doi.org/10.1145/3290605.3300712,Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp,1,Anthony Poon,Cornell University,New York,United States,false,false,"We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom."
pn9157,https://doi.org/10.1145/3290605.3300712,Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp,2,Sarah Giroux,Cornell University,Ithaca,United States,false,false,"We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom."
pn9157,https://doi.org/10.1145/3290605.3300712,Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp,3,Parfait Eloundou-Enyegue,Cornell University,Ithaca,United States,false,false,"We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom."
pn9157,https://doi.org/10.1145/3290605.3300712,Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp,4,Francois Guimbretiere,Cornell University,Ithaca,United States,false,false,"We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom."
pn9157,https://doi.org/10.1145/3290605.3300712,Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp,5,Nicola Dell,Cornell Tech,New York,United States,false,false,"We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,1,Agha Ali Raza,Information Technology University,Lahore,Pakistan,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,2,Zain Tariq,Information Technology University,Lahore,Pakistan,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,3,Shan Randhawa,Information Technology University,Lahore,Pakistan,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,4,Bilal Saleem,Information Technology University,Lahore,Pakistan,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,5,Awais Athar,European Bioinformatics Institute (EMBL-EBI),Cambridge,United Kingdom,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,6,Umar Saif,Information Technology University,Lahore,Pakistan,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn9773,https://doi.org/10.1145/3290605.3300642,Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations,7,Roni Rosenfeld,Carnegie Mellon University,Pittsburgh,United States,false,false,"Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind."
pn7623,https://doi.org/10.1145/3290605.3300548,Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations,1,Laton Vermette,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion."
pn7623,https://doi.org/10.1145/3290605.3300548,Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations,2,Joanna Mcgrenere,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion."
pn7623,https://doi.org/10.1145/3290605.3300548,Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations,3,Colin Birge,Microsoft Corporation,Burnaby/Surrey/Vancouver,Canada,false,false,"Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion."
pn7623,https://doi.org/10.1145/3290605.3300548,Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations,4,Adam Kelly,Microsoft Corporation,Burnaby/Surrey/Vancouver,Canada,false,false,"Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion."
pn7623,https://doi.org/10.1145/3290605.3300548,Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations,5,Parmit Chilana,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion."
pn8712,https://doi.org/10.1145/3290605.3300427,Designing Interactive 3D Printed Models with Teachers of the Visually Impaired,1,Lei Shi,Cornell University,Ithaca,United States,false,false,"Students with visual impairments struggle to learn various concepts in the academic curriculum because diagrams, images, and other visual are not accessible to them. To address this, researchers have design interactive 3D printed models (I3Ms) that provide audio descriptions when a user touches components of a model. In prior work, I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines produce effective I3M designs. To address this gap, we conducted two studies with Teachers of the Visually Impaired (TVIs). First, we led two design workshops with 35 TVIs, who modified sample models and added interactive elements to them. Second, we worked with three TVIs to design three I3Ms in an iterative instructional design process. At the end of this process, the TVIs used the I3Ms we designed to teach their students. We conclude that I3Ms should (1) have effective tactile features (e.g., distinctive patterns between components), (2) contain both auditory and visual content (e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview before details)."
pn8712,https://doi.org/10.1145/3290605.3300427,Designing Interactive 3D Printed Models with Teachers of the Visually Impaired,2,Holly Lawson,Portland State University,Portland,United States,false,false,"Students with visual impairments struggle to learn various concepts in the academic curriculum because diagrams, images, and other visual are not accessible to them. To address this, researchers have design interactive 3D printed models (I3Ms) that provide audio descriptions when a user touches components of a model. In prior work, I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines produce effective I3M designs. To address this gap, we conducted two studies with Teachers of the Visually Impaired (TVIs). First, we led two design workshops with 35 TVIs, who modified sample models and added interactive elements to them. Second, we worked with three TVIs to design three I3Ms in an iterative instructional design process. At the end of this process, the TVIs used the I3Ms we designed to teach their students. We conclude that I3Ms should (1) have effective tactile features (e.g., distinctive patterns between components), (2) contain both auditory and visual content (e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview before details)."
pn8712,https://doi.org/10.1145/3290605.3300427,Designing Interactive 3D Printed Models with Teachers of the Visually Impaired,3,Zhuohao Zhang,Zhejiang University,Hangzhou,China,false,false,"Students with visual impairments struggle to learn various concepts in the academic curriculum because diagrams, images, and other visual are not accessible to them. To address this, researchers have design interactive 3D printed models (I3Ms) that provide audio descriptions when a user touches components of a model. In prior work, I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines produce effective I3M designs. To address this gap, we conducted two studies with Teachers of the Visually Impaired (TVIs). First, we led two design workshops with 35 TVIs, who modified sample models and added interactive elements to them. Second, we worked with three TVIs to design three I3Ms in an iterative instructional design process. At the end of this process, the TVIs used the I3Ms we designed to teach their students. We conclude that I3Ms should (1) have effective tactile features (e.g., distinctive patterns between components), (2) contain both auditory and visual content (e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview before details)."
pn8712,https://doi.org/10.1145/3290605.3300427,Designing Interactive 3D Printed Models with Teachers of the Visually Impaired,4,Shiri Azenkot,Cornell University,New York,United States,false,false,"Students with visual impairments struggle to learn various concepts in the academic curriculum because diagrams, images, and other visual are not accessible to them. To address this, researchers have design interactive 3D printed models (I3Ms) that provide audio descriptions when a user touches components of a model. In prior work, I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines produce effective I3M designs. To address this gap, we conducted two studies with Teachers of the Visually Impaired (TVIs). First, we led two design workshops with 35 TVIs, who modified sample models and added interactive elements to them. Second, we worked with three TVIs to design three I3Ms in an iterative instructional design process. At the end of this process, the TVIs used the I3Ms we designed to teach their students. We conclude that I3Ms should (1) have effective tactile features (e.g., distinctive patterns between components), (2) contain both auditory and visual content (e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview before details)."
pn2322,https://doi.org/10.1145/3290605.3300376,SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks,1,Naoki Kimura,The University of Tokyo,Bunkyo-Ku,Japan,true,false,"The availability of digital devices operated by voice is expanding rapidly. However, the applications of voice interfaces are still restricted. For example, speaking in public places becomes an annoyance to the surrounding people, and secret information should not be uttered. Environmental noise may reduce the accuracy of speech recognition. To address these limitations, a system to detect a user's unvoiced utterance is proposed. From internal information observed by an ultrasonic imaging sensor attached to the underside of the jaw, our proposed system recognizes the utterance contents without the user's uttering voice. Our proposed deep neural network model is used to obtain acoustic features from a sequence of ultrasound images. We confirmed that audio signals generated by our system can control the existing smart speakers. We also observed that a user can adjust their oral movement to learn and improve the accuracy of their voice recognition."
pn2322,https://doi.org/10.1145/3290605.3300376,SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks,2,Michinari Kono,The University of Tokyo,Bunkyo-Ku,Japan,true,false,"The availability of digital devices operated by voice is expanding rapidly. However, the applications of voice interfaces are still restricted. For example, speaking in public places becomes an annoyance to the surrounding people, and secret information should not be uttered. Environmental noise may reduce the accuracy of speech recognition. To address these limitations, a system to detect a user's unvoiced utterance is proposed. From internal information observed by an ultrasonic imaging sensor attached to the underside of the jaw, our proposed system recognizes the utterance contents without the user's uttering voice. Our proposed deep neural network model is used to obtain acoustic features from a sequence of ultrasound images. We confirmed that audio signals generated by our system can control the existing smart speakers. We also observed that a user can adjust their oral movement to learn and improve the accuracy of their voice recognition."
pn2322,https://doi.org/10.1145/3290605.3300376,SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks,3,Jun Rekimoto,The University of Tokyo,Bunkyo-Ku,Japan,true,false,"The availability of digital devices operated by voice is expanding rapidly. However, the applications of voice interfaces are still restricted. For example, speaking in public places becomes an annoyance to the surrounding people, and secret information should not be uttered. Environmental noise may reduce the accuracy of speech recognition. To address these limitations, a system to detect a user's unvoiced utterance is proposed. From internal information observed by an ultrasonic imaging sensor attached to the underside of the jaw, our proposed system recognizes the utterance contents without the user's uttering voice. Our proposed deep neural network model is used to obtain acoustic features from a sequence of ultrasound images. We confirmed that audio signals generated by our system can control the existing smart speakers. We also observed that a user can adjust their oral movement to learn and improve the accuracy of their voice recognition."
pn8684,https://doi.org/10.1145/3290605.3300539,VoiceAssist: Guiding Users to High-Quality Voice Recordings,1,Prem Seetharaman,Northwestern University,Evanston,United States,false,false,"Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback."
pn8684,https://doi.org/10.1145/3290605.3300539,VoiceAssist: Guiding Users to High-Quality Voice Recordings,2,Gautham Mysore,Adobe Research,San Francisco,United States,false,false,"Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback."
pn8684,https://doi.org/10.1145/3290605.3300539,VoiceAssist: Guiding Users to High-Quality Voice Recordings,3,Bryan Pardo,Northwestern University,Evanston,United States,false,false,"Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback."
pn8684,https://doi.org/10.1145/3290605.3300539,VoiceAssist: Guiding Users to High-Quality Voice Recordings,4,Paris Smaragdis,University of Illinois at Urbana Champaign,Urbana,United States,false,false,"Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback."
pn8684,https://doi.org/10.1145/3290605.3300539,VoiceAssist: Guiding Users to High-Quality Voice Recordings,5,Celso Gomes,Adobe Research,Seattle,United States,false,false,"Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback."
pn5310,https://doi.org/10.1145/3290605.3300562,Vocal Shortcuts for Creative Experts,1,Yea-Seul Kim,University of Washington,Seattle,United States,false,false,"Vocal shortcuts, short spoken phrases to control interfaces, have the potential to reduce cognitive and physical costs of interactions. They may benefit expert users of creative applications (e.g., designers, illustrators) by helping them maintain creative focus. To aid the design of vocal shortcuts and gather use cases and design guidelines for speech interaction, we interviewed ten creative experts. Based on our findings, we built VoiceCuts, a prototype implementation of vocal shortcuts in the context of an existing creative application. In contrast to other speech interfaces, VoiceCuts targets experts' unique needs by handling short and partial commands and leverages document model and application context to disambiguate user utterances. We report on the viability and limitations of our approach based on feedback from creative experts."
pn5310,https://doi.org/10.1145/3290605.3300562,Vocal Shortcuts for Creative Experts,2,Mira Dontcheva,Adobe Research,Seattle,United States,false,false,"Vocal shortcuts, short spoken phrases to control interfaces, have the potential to reduce cognitive and physical costs of interactions. They may benefit expert users of creative applications (e.g., designers, illustrators) by helping them maintain creative focus. To aid the design of vocal shortcuts and gather use cases and design guidelines for speech interaction, we interviewed ten creative experts. Based on our findings, we built VoiceCuts, a prototype implementation of vocal shortcuts in the context of an existing creative application. In contrast to other speech interfaces, VoiceCuts targets experts' unique needs by handling short and partial commands and leverages document model and application context to disambiguate user utterances. We report on the viability and limitations of our approach based on feedback from creative experts."
pn5310,https://doi.org/10.1145/3290605.3300562,Vocal Shortcuts for Creative Experts,3,Eytan Adar,University of Michigan,Ann Arbor,United States,false,false,"Vocal shortcuts, short spoken phrases to control interfaces, have the potential to reduce cognitive and physical costs of interactions. They may benefit expert users of creative applications (e.g., designers, illustrators) by helping them maintain creative focus. To aid the design of vocal shortcuts and gather use cases and design guidelines for speech interaction, we interviewed ten creative experts. Based on our findings, we built VoiceCuts, a prototype implementation of vocal shortcuts in the context of an existing creative application. In contrast to other speech interfaces, VoiceCuts targets experts' unique needs by handling short and partial commands and leverages document model and application context to disambiguate user utterances. We report on the viability and limitations of our approach based on feedback from creative experts."
pn5310,https://doi.org/10.1145/3290605.3300562,Vocal Shortcuts for Creative Experts,4,Jessica Hullman,Northwestern University,Evanston,United States,false,false,"Vocal shortcuts, short spoken phrases to control interfaces, have the potential to reduce cognitive and physical costs of interactions. They may benefit expert users of creative applications (e.g., designers, illustrators) by helping them maintain creative focus. To aid the design of vocal shortcuts and gather use cases and design guidelines for speech interaction, we interviewed ten creative experts. Based on our findings, we built VoiceCuts, a prototype implementation of vocal shortcuts in the context of an existing creative application. In contrast to other speech interfaces, VoiceCuts targets experts' unique needs by handling short and partial commands and leverages document model and application context to disambiguate user utterances. We report on the viability and limitations of our approach based on feedback from creative experts."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,1,Gianluca Memoli,University of Sussex,Brighton,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,2,Letizia Chisari,University of Sussex,Brighton,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,3,Jonathan Eccles,University of Sussex,Brighton,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,4,Mihai Caleap,University of Bristol,Bristol,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,5,Bruce Drinkwater,University of Bristol,Bristol,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn2765,https://doi.org/10.1145/3290605.3300713,VARI-SOUND: A Varifocal Lens for Sound,6,Sriram Subramanian,University of Sussex,Brighton,United Kingdom,false,false,"Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key acoustic devices, like a ""collimator"", to transform a standard computer speaker into an acoustic ""spotlight""; and a ""magnifying glass"", to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology."
pn8308,https://doi.org/10.1145/3290605.3300766,MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi,1,Sheng Tan,Florida State University,Tallahassee,United States,false,false,"This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios."
pn8308,https://doi.org/10.1145/3290605.3300766,MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi,2,Linghan Zhang,Florida State University,Tallahassee,United States,false,false,"This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios."
pn8308,https://doi.org/10.1145/3290605.3300766,MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi,3,Zi Wang,Florida State University,Tallahassee,United States,false,false,"This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios."
pn8308,https://doi.org/10.1145/3290605.3300766,MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi,4,Jie Yang,Florida State University,Tallahassee,United States,false,false,"This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios."
pn8810,https://doi.org/10.1145/3290605.3300559,"SurfaceSight: A New Spin on Touch, User, and Object Sensing for IoT Experiences",1,Gierad Laput,Carnegie Mellon University,Pittsburgh,United States,false,false,"IoT appliances are gaining consumer traction, from smart thermostats to smart speakers. These devices generally have limited user interfaces, most often small buttons and touchscreens, or rely on voice control. Further, these devices know little about their surroundings – unaware of objects, people and activities happening around them. Consequently, interactions with these ""smart"" devices can be cumbersome and limited. We describe SurfaceSight, an approach that enriches IoT experiences with rich touch and object sensing, offering a complementary input channel and increased contextual awareness. For sensing, we incorporate LIDAR into the base of IoT devices, providing an expansive, ad hoc plane of sensing just above the surface on which devices rest. We can recognize and track a wide array of objects, including finger input and hand gestures. We can also track people and estimate which way they are facing. We evaluate the accuracy of these new capabilities and illustrate how they can be used to power novel and contextually-aware interactive experiences."
pn8810,https://doi.org/10.1145/3290605.3300559,"SurfaceSight: A New Spin on Touch, User, and Object Sensing for IoT Experiences",2,Chris Harrison,Carnegie Mellon University,Pittsburgh,United States,false,false,"IoT appliances are gaining consumer traction, from smart thermostats to smart speakers. These devices generally have limited user interfaces, most often small buttons and touchscreens, or rely on voice control. Further, these devices know little about their surroundings – unaware of objects, people and activities happening around them. Consequently, interactions with these ""smart"" devices can be cumbersome and limited. We describe SurfaceSight, an approach that enriches IoT experiences with rich touch and object sensing, offering a complementary input channel and increased contextual awareness. For sensing, we incorporate LIDAR into the base of IoT devices, providing an expansive, ad hoc plane of sensing just above the surface on which devices rest. We can recognize and track a wide array of objects, including finger input and hand gestures. We can also track people and estimate which way they are facing. We evaluate the accuracy of these new capabilities and illustrate how they can be used to power novel and contextually-aware interactive experiences."
pn5945,https://doi.org/10.1145/3290605.3300778,Enabling Identification and Behavioral Sensing in Homes using Radio Reflections,1,Chen-Yu Hsu,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction."
pn5945,https://doi.org/10.1145/3290605.3300778,Enabling Identification and Behavioral Sensing in Homes using Radio Reflections,2,Rumen Hristov,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction."
pn5945,https://doi.org/10.1145/3290605.3300778,Enabling Identification and Behavioral Sensing in Homes using Radio Reflections,3,Guang-He Lee,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction."
pn5945,https://doi.org/10.1145/3290605.3300778,Enabling Identification and Behavioral Sensing in Homes using Radio Reflections,4,Mingmin Zhao,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction."
pn5945,https://doi.org/10.1145/3290605.3300778,Enabling Identification and Behavioral Sensing in Homes using Radio Reflections,5,Dina Katabi,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction."
pn2294,https://doi.org/10.1145/3290605.3300248,MilliSonic: Pushing the Limits of Acoustic Motion Tracking,1,Anran Wang,University of Washington,Seattle,United States,false,false,"Recent years have seen interest in device tracking and localization using acoustic signals. State-of-the-art acoustic motion tracking systems however do not achieve millimeter accuracy and require large separation between microphones and speakers, and as a result, do not meet the requirements for many VR/AR applications. Further, tracking multiple concurrent acoustic transmissions from VR devices today requires sacrificing accuracy or frame rate. We present MilliSonic, a novel system that pushes the limits of acoustic based motion tracking. Our core contribution is a novel localization algorithm that can provably achieve sub-millimeter 1D tracking accuracy in the presence of multipath, while using only a single beacon with a small 4-microphone array.Further, MilliSonic enables concurrent tracking of up to four smartphones without reducing frame rate or accuracy. Our evaluation shows that MilliSonic achieves 0.7mm median 1D accuracy and a 2.6mm median 3D accuracy for smartphones, which is 5x more accurate than state-of-the-art systems. MilliSonic enables two previously infeasible interaction applications: a) 3D tracking of VR headsets using the smartphone as a beacon and b) fine-grained 3D tracking for the Google Cardboard VR system using a small microphone array."
pn2294,https://doi.org/10.1145/3290605.3300248,MilliSonic: Pushing the Limits of Acoustic Motion Tracking,2,Shyamnath Gollakota,University of Washington,Seattle,United States,false,false,"Recent years have seen interest in device tracking and localization using acoustic signals. State-of-the-art acoustic motion tracking systems however do not achieve millimeter accuracy and require large separation between microphones and speakers, and as a result, do not meet the requirements for many VR/AR applications. Further, tracking multiple concurrent acoustic transmissions from VR devices today requires sacrificing accuracy or frame rate. We present MilliSonic, a novel system that pushes the limits of acoustic based motion tracking. Our core contribution is a novel localization algorithm that can provably achieve sub-millimeter 1D tracking accuracy in the presence of multipath, while using only a single beacon with a small 4-microphone array.Further, MilliSonic enables concurrent tracking of up to four smartphones without reducing frame rate or accuracy. Our evaluation shows that MilliSonic achieves 0.7mm median 1D accuracy and a 2.6mm median 3D accuracy for smartphones, which is 5x more accurate than state-of-the-art systems. MilliSonic enables two previously infeasible interaction applications: a) 3D tracking of VR headsets using the smartphone as a beacon and b) fine-grained 3D tracking for the Google Cardboard VR system using a small microphone array."
pn5074,https://doi.org/10.1145/3290605.3300879,Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-scarce Areas,1,Tawanna Dillahunt,University of Michigan,Ann Arbor,United States,false,true,"Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services' potential to provide healthy-food access and influence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group's 1-month use of an online grocery delivery service, and a control group's 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are affordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster affordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups."
pn5074,https://doi.org/10.1145/3290605.3300879,Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-scarce Areas,2,Sylvia Simioni,University of Michigan,Ann Arbor,United States,false,true,"Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services' potential to provide healthy-food access and influence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group's 1-month use of an online grocery delivery service, and a control group's 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are affordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster affordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups."
pn5074,https://doi.org/10.1145/3290605.3300879,Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-scarce Areas,3,Xuecong Xu,University of Michigan,Ann Arbor,United States,false,true,"Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services' potential to provide healthy-food access and influence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group's 1-month use of an online grocery delivery service, and a control group's 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are affordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster affordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",1,Xianghua Ding,Fudan University,Shanghai,China,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",2,Yanqi Jiang,Fudan University,Shanghai,China,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",3,Xiankang Qin,Fudan University,Shanghai,China,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",4,Yunan Chen,"University of California, Irvine",Irvine,United States,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",5,Wenqiang Zhang,Fudan University,Shanghai,China,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn6038,https://doi.org/10.1145/3290605.3300435,"Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",6,Lizhe Qi,Fudan University,Shanghai,China,false,false,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices."
pn3806,https://doi.org/10.1145/3290605.3300616,The Race Towards Digital Wellbeing: Issues and Opportunities,1,Alberto Monge Roffarello,Politecnico di Torino,Torino,Italy,false,false,"As smartphone use increases dramatically, so do studies about technology overuse. Many different mobile apps for breaking ""smartphone addiction"" and achieving ""digital wellbeing"" are available. However, it is still not clear whether and how such solutions work. Which functionality do they have? Are they effective and appreciated? Do they have a relevant impact on users' behavior? To answer these questions, (i) we reviewed the features of 42 digital wellbeing apps, (ii) we performed a thematic analysis on 1,128 user reviews of such apps, and (iii) we conducted a 3-week-long in-the-wild study of Socialize, an app that includes the most common digital wellbeing features, with 38 participants. We discovered that digital wellbeing apps are appreciated and useful for some specific situations. However, they do not promote the formation of new habits and they are perceived as not restrictive enough, thus not effectively helping users to change their behavior with smartphones."
pn3806,https://doi.org/10.1145/3290605.3300616,The Race Towards Digital Wellbeing: Issues and Opportunities,2,Luigi De Russis,Politecnico di Torino,Torino,Italy,false,false,"As smartphone use increases dramatically, so do studies about technology overuse. Many different mobile apps for breaking ""smartphone addiction"" and achieving ""digital wellbeing"" are available. However, it is still not clear whether and how such solutions work. Which functionality do they have? Are they effective and appreciated? Do they have a relevant impact on users' behavior? To answer these questions, (i) we reviewed the features of 42 digital wellbeing apps, (ii) we performed a thematic analysis on 1,128 user reviews of such apps, and (iii) we conducted a 3-week-long in-the-wild study of Socialize, an app that includes the most common digital wellbeing features, with 38 participants. We discovered that digital wellbeing apps are appreciated and useful for some specific situations. However, they do not promote the formation of new habits and they are perceived as not restrictive enough, thus not effectively helping users to change their behavior with smartphones."
pn1528,https://doi.org/10.1145/3290605.3300900,Beyond Behavior: The Coach's Perspective on Technology in Health Coaching,1,Heleen Rutjes,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Rapid innovations in electronic healthcare and behavior tracking systems are challenging health coaches (dietitians, personal trainers, etc.) to rethink their traditional roles and healthcare practices. At the same time, many current e-coaching systems have been developed without explicitly incorporating the healthcare professionals' perspective into the design process. In the current paper, we present three consecutive qualitative studies, starting from the health coach's perspective on successful coaching, progressively zooming in on the potential role and impact of technology as part of the coaching process. Our main finding is that coaches are concerned that introducing technology in the coaching process puts too much emphasis on behavioral information, lowering the attention for the client's lived experience, while understanding those experiences is key for successful coaching. We summarize our insights in a multi-channel communication model and draw implications for the design of supporting technology in health coaching."
pn1528,https://doi.org/10.1145/3290605.3300900,Beyond Behavior: The Coach's Perspective on Technology in Health Coaching,2,Martijn Willemsen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Rapid innovations in electronic healthcare and behavior tracking systems are challenging health coaches (dietitians, personal trainers, etc.) to rethink their traditional roles and healthcare practices. At the same time, many current e-coaching systems have been developed without explicitly incorporating the healthcare professionals' perspective into the design process. In the current paper, we present three consecutive qualitative studies, starting from the health coach's perspective on successful coaching, progressively zooming in on the potential role and impact of technology as part of the coaching process. Our main finding is that coaches are concerned that introducing technology in the coaching process puts too much emphasis on behavioral information, lowering the attention for the client's lived experience, while understanding those experiences is key for successful coaching. We summarize our insights in a multi-channel communication model and draw implications for the design of supporting technology in health coaching."
pn1528,https://doi.org/10.1145/3290605.3300900,Beyond Behavior: The Coach's Perspective on Technology in Health Coaching,3,Wijnand Ijsselsteijn,Technical university of Eindhoven,Eindhoven,Netherlands,false,false,"Rapid innovations in electronic healthcare and behavior tracking systems are challenging health coaches (dietitians, personal trainers, etc.) to rethink their traditional roles and healthcare practices. At the same time, many current e-coaching systems have been developed without explicitly incorporating the healthcare professionals' perspective into the design process. In the current paper, we present three consecutive qualitative studies, starting from the health coach's perspective on successful coaching, progressively zooming in on the potential role and impact of technology as part of the coaching process. Our main finding is that coaches are concerned that introducing technology in the coaching process puts too much emphasis on behavioral information, lowering the attention for the client's lived experience, while understanding those experiences is key for successful coaching. We summarize our insights in a multi-channel communication model and draw implications for the design of supporting technology in health coaching."
pn4262,https://doi.org/10.1145/3290605.3300295,Increasing the Transparency of Research Papers with Explorable Multiverse Analyses,1,Pierre Dragicevic,INRIA,Paris,France,false,true,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers."
pn4262,https://doi.org/10.1145/3290605.3300295,Increasing the Transparency of Research Papers with Explorable Multiverse Analyses,2,Yvonne Jansen,CNRS – Sorbonne Université,Paris,France,false,true,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers."
pn4262,https://doi.org/10.1145/3290605.3300295,Increasing the Transparency of Research Papers with Explorable Multiverse Analyses,3,Abhraneel Sarma,University of Michigan,Ann Arbor,United States,false,true,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers."
pn4262,https://doi.org/10.1145/3290605.3300295,Increasing the Transparency of Research Papers with Explorable Multiverse Analyses,4,Matthew Kay,University of Michigan,Ann Arbor,United States,false,true,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers."
pn4262,https://doi.org/10.1145/3290605.3300295,Increasing the Transparency of Research Papers with Explorable Multiverse Analyses,5,Fanny Chevalier,University of Toronto,Toronto,Canada,false,true,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",1,Frederik Brudy,University College London,London,United Kingdom,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",2,Christian Holz,Microsoft Research,Redmond,United States,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",3,Roman Rädle,Aarhus University,Aarhus,Denmark,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",4,Chi-Jui Wu,Lancaster University,Lancaster,United Kingdom,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",5,Steven Houben,Lancaster University,Lancaster,United Kingdom,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",6,Clemens Klokmose,Aarhus University,Aarhus,Denmark,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn9054,https://doi.org/10.1145/3290605.3300792,"Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices",7,Nicolai Marquardt,University College London,London,United Kingdom,false,false,"Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research."
pn3382,https://doi.org/10.1145/3290605.3300592,Anchoring Effects and Troublesome Asymmetric Transfer in Subjective Ratings,1,Andy Cockburn,University of Canterbury,Christchurch,New Zealand,false,false,"Within-subjects experiments are prone to asymmetric transfer, which confounds results interpretation. While HCI researchers routinely test asymmetric transfer in objective data, doing so for subjective data is rare. Yet literature suggests that anchoring effects should make subjective measures particularly susceptible to asymmetric transfer. We report on four analyses of NASA-TLX data from four previously published HCI papers, with four main findings. First, asymmetric transfer is common, occurring in 42% of tests analysed. Second, the data conforms to predictions of anchoring effects. Third, the magnitude of the anchor's effect correlates with the magnitude of the difference between the interface ratings -- that is, the anchor's 'pull' correlates with the anchoring stimulus. Fourth, several of the previously published findings are changed when data are reanalysed using between-subjects treatment. We urge caution when analysing within-subjects subjective measures and recommend that researchers test for and report the occurrence of asymmetric transfer."
pn3382,https://doi.org/10.1145/3290605.3300592,Anchoring Effects and Troublesome Asymmetric Transfer in Subjective Ratings,2,Carl Gutwin,University of Saskatchewan,Saskatoon,Canada,false,false,"Within-subjects experiments are prone to asymmetric transfer, which confounds results interpretation. While HCI researchers routinely test asymmetric transfer in objective data, doing so for subjective data is rare. Yet literature suggests that anchoring effects should make subjective measures particularly susceptible to asymmetric transfer. We report on four analyses of NASA-TLX data from four previously published HCI papers, with four main findings. First, asymmetric transfer is common, occurring in 42% of tests analysed. Second, the data conforms to predictions of anchoring effects. Third, the magnitude of the anchor's effect correlates with the magnitude of the difference between the interface ratings -- that is, the anchor's 'pull' correlates with the anchoring stimulus. Fourth, several of the previously published findings are changed when data are reanalysed using between-subjects treatment. We urge caution when analysing within-subjects subjective measures and recommend that researchers test for and report the occurrence of asymmetric transfer."
pn2772,https://doi.org/10.1145/3290605.3300447,Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design,1,Alexander Eiselmayer,University of Zurich,Zurich,Switzerland,false,true,"Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2's benefits and limitations, as well as directions for future research."
pn2772,https://doi.org/10.1145/3290605.3300447,Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design,2,Chat Wacharamanotham,University of Zurich,Zurich,Switzerland,false,true,"Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2's benefits and limitations, as well as directions for future research."
pn2772,https://doi.org/10.1145/3290605.3300447,Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design,3,Michel Beaudouin-Lafon,INRIA,Paris,France,false,true,"Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2's benefits and limitations, as well as directions for future research."
pn2772,https://doi.org/10.1145/3290605.3300447,Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design,4,Wendy Mackay,INRIA,Paris,France,false,true,"Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2's benefits and limitations, as well as directions for future research."
pn2731,https://doi.org/10.1145/3290605.3300718,"Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces",1,Nur Al-Huda Hamdan,RWTH Aachen University,Aachen,Germany,true,false,"We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor."
pn2731,https://doi.org/10.1145/3290605.3300718,"Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces",2,Adrian Wagner,RWTH Aachen University,Aachen,Germany,true,false,"We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor."
pn2731,https://doi.org/10.1145/3290605.3300718,"Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces",3,Simon Voelker,RWTH Aachen University,Aachen,Germany,true,false,"We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor."
pn2731,https://doi.org/10.1145/3290605.3300718,"Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces",4,Jürgen Steimle,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,true,false,"We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor."
pn2731,https://doi.org/10.1145/3290605.3300718,"Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces",5,Jan Borchers,RWTH Aachen University,Aachen,Germany,true,false,"We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor."
pn2853,https://doi.org/10.1145/3290605.3300638,Magnetips: Combining Fingertip Tracking and Haptic Feedback for Around-Device Interaction,1,Jess Mcintosh,University of Copenhagen,Copenhagen,Denmark,false,false,"Around-device interaction methods expand the available interaction space for mobile devices; however, there is currently no way to simultaneously track a user's input and provide haptic feedback at the tracked point away from the device. We present Magnetips, a simple, mobile solution for around-device tracking and mid-air haptic feedback. Magnetips combines magnetic tracking and electromagnetic feedback that works regardless of visual occlusion, through most common materials, and at a size that allows for integration with mobile devices. We demonstrate: (1) high-frequency around-device tracking and haptic feedback; (2) the accuracy and range of our tracking solution which corrects for the effects of geomagnetism, necessary for enabling mobile use; and (3) guidelines for maximising strength of haptic feedback, given a desired tracking frequency. We present technical and usability evaluations of our prototype, and demonstrate four example applications of its use."
pn2853,https://doi.org/10.1145/3290605.3300638,Magnetips: Combining Fingertip Tracking and Haptic Feedback for Around-Device Interaction,2,Paul Strohmeier,University of Copenhagen,Copenhagen,Denmark,false,false,"Around-device interaction methods expand the available interaction space for mobile devices; however, there is currently no way to simultaneously track a user's input and provide haptic feedback at the tracked point away from the device. We present Magnetips, a simple, mobile solution for around-device tracking and mid-air haptic feedback. Magnetips combines magnetic tracking and electromagnetic feedback that works regardless of visual occlusion, through most common materials, and at a size that allows for integration with mobile devices. We demonstrate: (1) high-frequency around-device tracking and haptic feedback; (2) the accuracy and range of our tracking solution which corrects for the effects of geomagnetism, necessary for enabling mobile use; and (3) guidelines for maximising strength of haptic feedback, given a desired tracking frequency. We present technical and usability evaluations of our prototype, and demonstrate four example applications of its use."
pn2853,https://doi.org/10.1145/3290605.3300638,Magnetips: Combining Fingertip Tracking and Haptic Feedback for Around-Device Interaction,3,Jarrod Knibbe,Monash University,Melbourne,Australia,false,false,"Around-device interaction methods expand the available interaction space for mobile devices; however, there is currently no way to simultaneously track a user's input and provide haptic feedback at the tracked point away from the device. We present Magnetips, a simple, mobile solution for around-device tracking and mid-air haptic feedback. Magnetips combines magnetic tracking and electromagnetic feedback that works regardless of visual occlusion, through most common materials, and at a size that allows for integration with mobile devices. We demonstrate: (1) high-frequency around-device tracking and haptic feedback; (2) the accuracy and range of our tracking solution which corrects for the effects of geomagnetism, necessary for enabling mobile use; and (3) guidelines for maximising strength of haptic feedback, given a desired tracking frequency. We present technical and usability evaluations of our prototype, and demonstrate four example applications of its use."
pn2853,https://doi.org/10.1145/3290605.3300638,Magnetips: Combining Fingertip Tracking and Haptic Feedback for Around-Device Interaction,4,Sebastian Boring,University of Copenhagen,Copenhagen,Denmark,false,false,"Around-device interaction methods expand the available interaction space for mobile devices; however, there is currently no way to simultaneously track a user's input and provide haptic feedback at the tracked point away from the device. We present Magnetips, a simple, mobile solution for around-device tracking and mid-air haptic feedback. Magnetips combines magnetic tracking and electromagnetic feedback that works regardless of visual occlusion, through most common materials, and at a size that allows for integration with mobile devices. We demonstrate: (1) high-frequency around-device tracking and haptic feedback; (2) the accuracy and range of our tracking solution which corrects for the effects of geomagnetism, necessary for enabling mobile use; and (3) guidelines for maximising strength of haptic feedback, given a desired tracking frequency. We present technical and usability evaluations of our prototype, and demonstrate four example applications of its use."
pn2853,https://doi.org/10.1145/3290605.3300638,Magnetips: Combining Fingertip Tracking and Haptic Feedback for Around-Device Interaction,5,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,false,false,"Around-device interaction methods expand the available interaction space for mobile devices; however, there is currently no way to simultaneously track a user's input and provide haptic feedback at the tracked point away from the device. We present Magnetips, a simple, mobile solution for around-device tracking and mid-air haptic feedback. Magnetips combines magnetic tracking and electromagnetic feedback that works regardless of visual occlusion, through most common materials, and at a size that allows for integration with mobile devices. We demonstrate: (1) high-frequency around-device tracking and haptic feedback; (2) the accuracy and range of our tracking solution which corrects for the effects of geomagnetism, necessary for enabling mobile use; and (3) guidelines for maximising strength of haptic feedback, given a desired tracking frequency. We present technical and usability evaluations of our prototype, and demonstrate four example applications of its use."
pn6428,https://doi.org/10.1145/3290605.3300871,Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback,1,Alix Goguey,Swansea University,Swansea,United Kingdom,false,false,"Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios."
pn6428,https://doi.org/10.1145/3290605.3300871,Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback,2,Deepak Sahoo,Swansea University,Swansea,United Kingdom,false,false,"Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios."
pn6428,https://doi.org/10.1145/3290605.3300871,Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback,3,Simon Robinson,Swansea University,Swansea,United Kingdom,false,false,"Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios."
pn6428,https://doi.org/10.1145/3290605.3300871,Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback,4,Jennifer Pearson,Swansea University,Swansea,United Kingdom,false,false,"Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios."
pn6428,https://doi.org/10.1145/3290605.3300871,Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback,5,Matt Jones,Swansea University,Swansea,United Kingdom,false,false,"Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios."
pn5678,https://doi.org/10.1145/3290605.3300715,Leveraging Distal Vibrotactile Feedback for Target Acquisition,1,Jay Henderson,University of Waterloo,Waterloo,Canada,false,false,"Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available."
pn5678,https://doi.org/10.1145/3290605.3300715,Leveraging Distal Vibrotactile Feedback for Target Acquisition,2,Jeff Avery,University of Waterloo,Waterloo,Canada,false,false,"Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available."
pn5678,https://doi.org/10.1145/3290605.3300715,Leveraging Distal Vibrotactile Feedback for Target Acquisition,3,Laurent Grisoni,University of Lille,Villeneuve D'ascq,France,false,false,"Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available."
pn5678,https://doi.org/10.1145/3290605.3300715,Leveraging Distal Vibrotactile Feedback for Target Acquisition,4,Edward Lank,INRIA,Waterloo,Canada,false,false,"Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available."
pn5383,https://doi.org/10.1145/3290605.3300348,More than the Sum of Makers: The Complex Dynamics of Diverse Practices at Maker Faire,1,Janis Meissner,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Human Computer Interaction has developed great interest in the Maker Movement. Previous work has explored it from various perspectives, focusing either on its potentials or issues. As these are however only fragmented portrayals, this paper aims to take a broader perspective and interconnect some of the fragments. We conducted a qualitative study in the context of two Maker Faires to gain a better understanding of the complex dynamics that makers operate in. We captured the voices of different stakeholders and explored how their respective agendas relate to each other. The findings illustrate how the event is co-created at the nexus of different technological, social and economic interests while leaving space for diverse practices. The paper contributes a first focused analysis of Maker Faire, probes it as a site for research and discusses how holistic perspectives on the Maker Movement could create new research opportunities."
pn5383,https://doi.org/10.1145/3290605.3300348,More than the Sum of Makers: The Complex Dynamics of Diverse Practices at Maker Faire,2,Pradthana Jarusriboonchai,University of Lapland,Rovaniemi,Finland,false,false,"Human Computer Interaction has developed great interest in the Maker Movement. Previous work has explored it from various perspectives, focusing either on its potentials or issues. As these are however only fragmented portrayals, this paper aims to take a broader perspective and interconnect some of the fragments. We conducted a qualitative study in the context of two Maker Faires to gain a better understanding of the complex dynamics that makers operate in. We captured the voices of different stakeholders and explored how their respective agendas relate to each other. The findings illustrate how the event is co-created at the nexus of different technological, social and economic interests while leaving space for diverse practices. The paper contributes a first focused analysis of Maker Faire, probes it as a site for research and discusses how holistic perspectives on the Maker Movement could create new research opportunities."
pn5383,https://doi.org/10.1145/3290605.3300348,More than the Sum of Makers: The Complex Dynamics of Diverse Practices at Maker Faire,3,Janice Mclaughlin,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Human Computer Interaction has developed great interest in the Maker Movement. Previous work has explored it from various perspectives, focusing either on its potentials or issues. As these are however only fragmented portrayals, this paper aims to take a broader perspective and interconnect some of the fragments. We conducted a qualitative study in the context of two Maker Faires to gain a better understanding of the complex dynamics that makers operate in. We captured the voices of different stakeholders and explored how their respective agendas relate to each other. The findings illustrate how the event is co-created at the nexus of different technological, social and economic interests while leaving space for diverse practices. The paper contributes a first focused analysis of Maker Faire, probes it as a site for research and discusses how holistic perspectives on the Maker Movement could create new research opportunities."
pn5383,https://doi.org/10.1145/3290605.3300348,More than the Sum of Makers: The Complex Dynamics of Diverse Practices at Maker Faire,4,Peter Wright,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Human Computer Interaction has developed great interest in the Maker Movement. Previous work has explored it from various perspectives, focusing either on its potentials or issues. As these are however only fragmented portrayals, this paper aims to take a broader perspective and interconnect some of the fragments. We conducted a qualitative study in the context of two Maker Faires to gain a better understanding of the complex dynamics that makers operate in. We captured the voices of different stakeholders and explored how their respective agendas relate to each other. The findings illustrate how the event is co-created at the nexus of different technological, social and economic interests while leaving space for diverse practices. The paper contributes a first focused analysis of Maker Faire, probes it as a site for research and discusses how holistic perspectives on the Maker Movement could create new research opportunities."
pn5738,https://doi.org/10.1145/3290605.3300696,"Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home",1,Kelly Widdicks,Lancaster University,Lancaster,United Kingdom,false,false,"Internet use and online services underpin everyday life, and the resultant energy demand is almost entirely hidden, yet significant and growing: it is anticipated to reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse gas emissions of transportation by 2040. Driving this growth, real-time video streaming ('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants in 9 households, we reveal the online activity of domestic watching and provide a detailed exploration of video-on-demand activities. We identify new ways in which watching is transitioning in more rather than less data demanding directions; and explore the role HCI may play in reducing this growing data demand. We further highlight implications for key HCI and societal stakeholders (policy makers, service providers, network engineers) to tackle this important issue."
pn5738,https://doi.org/10.1145/3290605.3300696,"Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home",2,Mike Hazas,Lancaster University,Lancaster,United Kingdom,false,false,"Internet use and online services underpin everyday life, and the resultant energy demand is almost entirely hidden, yet significant and growing: it is anticipated to reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse gas emissions of transportation by 2040. Driving this growth, real-time video streaming ('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants in 9 households, we reveal the online activity of domestic watching and provide a detailed exploration of video-on-demand activities. We identify new ways in which watching is transitioning in more rather than less data demanding directions; and explore the role HCI may play in reducing this growing data demand. We further highlight implications for key HCI and societal stakeholders (policy makers, service providers, network engineers) to tackle this important issue."
pn5738,https://doi.org/10.1145/3290605.3300696,"Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home",3,Oliver Bates,Lancaster University,Lancaster,United Kingdom,false,false,"Internet use and online services underpin everyday life, and the resultant energy demand is almost entirely hidden, yet significant and growing: it is anticipated to reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse gas emissions of transportation by 2040. Driving this growth, real-time video streaming ('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants in 9 households, we reveal the online activity of domestic watching and provide a detailed exploration of video-on-demand activities. We identify new ways in which watching is transitioning in more rather than less data demanding directions; and explore the role HCI may play in reducing this growing data demand. We further highlight implications for key HCI and societal stakeholders (policy makers, service providers, network engineers) to tackle this important issue."
pn5738,https://doi.org/10.1145/3290605.3300696,"Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home",4,Adrian Friday,Lancaster University,Lancaster,United Kingdom,false,false,"Internet use and online services underpin everyday life, and the resultant energy demand is almost entirely hidden, yet significant and growing: it is anticipated to reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse gas emissions of transportation by 2040. Driving this growth, real-time video streaming ('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants in 9 households, we reveal the online activity of domestic watching and provide a detailed exploration of video-on-demand activities. We identify new ways in which watching is transitioning in more rather than less data demanding directions; and explore the role HCI may play in reducing this growing data demand. We further highlight implications for key HCI and societal stakeholders (policy makers, service providers, network engineers) to tackle this important issue."
pn5278,https://doi.org/10.1145/3290605.3300459,"""I feel it is my responsibility to stream"": Streaming and Engaging with Intangible Cultural Heritage through Livestreaming",1,Zhicong Lu,University of Toronto,Toronto,Canada,false,true,"Globalization has led to the destruction of many cultural practices, expressions, and knowledge found within local communities. These practices, defined by UNESCO as Intangible Cultural Heritage (ICH), have been identified, promoted, and safeguarded by nations, academia, organizations and local communities to varying degrees. Despite such efforts, many practices are still in danger of being lost or forgotten forever. With the increased popularity of livestreaming in China, some streamers have begun to use livestreaming to showcase and promote ICH activities. To better understand the practices, opportunities, and challenges inherent in sharing and safeguarding ICH through livestreaming, we interviewed 10 streamers and 8 viewers from China. Through our qualitative investigation, we found that ICH streamers had altruistic motivations and engaged with viewers using multiple modalities beyond livestreams. We also found that livestreaming encouraged real-time interaction and sociality, while non-live curated videos attracted attention from a broader audience and assisted in the archiving of knowledge."
pn5278,https://doi.org/10.1145/3290605.3300459,"""I feel it is my responsibility to stream"": Streaming and Engaging with Intangible Cultural Heritage through Livestreaming",2,Michelle Annett,MishMashMakers,Toronto,Canada,false,true,"Globalization has led to the destruction of many cultural practices, expressions, and knowledge found within local communities. These practices, defined by UNESCO as Intangible Cultural Heritage (ICH), have been identified, promoted, and safeguarded by nations, academia, organizations and local communities to varying degrees. Despite such efforts, many practices are still in danger of being lost or forgotten forever. With the increased popularity of livestreaming in China, some streamers have begun to use livestreaming to showcase and promote ICH activities. To better understand the practices, opportunities, and challenges inherent in sharing and safeguarding ICH through livestreaming, we interviewed 10 streamers and 8 viewers from China. Through our qualitative investigation, we found that ICH streamers had altruistic motivations and engaged with viewers using multiple modalities beyond livestreams. We also found that livestreaming encouraged real-time interaction and sociality, while non-live curated videos attracted attention from a broader audience and assisted in the archiving of knowledge."
pn5278,https://doi.org/10.1145/3290605.3300459,"""I feel it is my responsibility to stream"": Streaming and Engaging with Intangible Cultural Heritage through Livestreaming",3,Mingming Fan,University of Toronto,Toronto,Canada,false,true,"Globalization has led to the destruction of many cultural practices, expressions, and knowledge found within local communities. These practices, defined by UNESCO as Intangible Cultural Heritage (ICH), have been identified, promoted, and safeguarded by nations, academia, organizations and local communities to varying degrees. Despite such efforts, many practices are still in danger of being lost or forgotten forever. With the increased popularity of livestreaming in China, some streamers have begun to use livestreaming to showcase and promote ICH activities. To better understand the practices, opportunities, and challenges inherent in sharing and safeguarding ICH through livestreaming, we interviewed 10 streamers and 8 viewers from China. Through our qualitative investigation, we found that ICH streamers had altruistic motivations and engaged with viewers using multiple modalities beyond livestreams. We also found that livestreaming encouraged real-time interaction and sociality, while non-live curated videos attracted attention from a broader audience and assisted in the archiving of knowledge."
pn5278,https://doi.org/10.1145/3290605.3300459,"""I feel it is my responsibility to stream"": Streaming and Engaging with Intangible Cultural Heritage through Livestreaming",4,Daniel Wigdor,University of Toronto,Toronto,Canada,false,true,"Globalization has led to the destruction of many cultural practices, expressions, and knowledge found within local communities. These practices, defined by UNESCO as Intangible Cultural Heritage (ICH), have been identified, promoted, and safeguarded by nations, academia, organizations and local communities to varying degrees. Despite such efforts, many practices are still in danger of being lost or forgotten forever. With the increased popularity of livestreaming in China, some streamers have begun to use livestreaming to showcase and promote ICH activities. To better understand the practices, opportunities, and challenges inherent in sharing and safeguarding ICH through livestreaming, we interviewed 10 streamers and 8 viewers from China. Through our qualitative investigation, we found that ICH streamers had altruistic motivations and engaged with viewers using multiple modalities beyond livestreams. We also found that livestreaming encouraged real-time interaction and sociality, while non-live curated videos attracted attention from a broader audience and assisted in the archiving of knowledge."
pn2656,https://doi.org/10.1145/3290605.3300491,Understanding Mass-Market Mobile TV Behaviors in the Streaming Era,1,Frank Bentley,Yahoo,Sunnyvale,United States,false,false,"Despite claims of Mobile TV's mainstream arrival in 2010, it took until 2017 for watching professionally-produced television content on mobile phones to truly become a mass-market phenomenon in America, with half of all TV content expected to be watched on mobile phones by 2020. But what professionally produced content are people watching on their phones and when are they watching it? Are there any clusters of behavior that emerge in the broader population when it comes to watching TV on the phone? We set out to answer these questions through two surveys deployed to representative samples of online Americans. We discuss our findings on the mass-market arrival of mobile TV viewing and differences from how the HCI community has previously envisioned mobile video. We conclude with implications for the design of future mobile TV systems."
pn2656,https://doi.org/10.1145/3290605.3300491,Understanding Mass-Market Mobile TV Behaviors in the Streaming Era,2,Danielle Lottridge,Yahoo,Sunnyvale,United States,false,false,"Despite claims of Mobile TV's mainstream arrival in 2010, it took until 2017 for watching professionally-produced television content on mobile phones to truly become a mass-market phenomenon in America, with half of all TV content expected to be watched on mobile phones by 2020. But what professionally produced content are people watching on their phones and when are they watching it? Are there any clusters of behavior that emerge in the broader population when it comes to watching TV on the phone? We set out to answer these questions through two surveys deployed to representative samples of online Americans. We discuss our findings on the mass-market arrival of mobile TV viewing and differences from how the HCI community has previously envisioned mobile video. We conclude with implications for the design of future mobile TV systems."
pn7608,https://doi.org/10.1145/3290605.3300590,Using Presence Questionnaires in Virtual Reality,1,Valentin Schwind,University of Stuttgart,Stuttgart,Germany,false,false,"Virtual Reality (VR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of VR is creating presence, the experience of 'being' or 'acting', when physically situated in another place. Measuring presence is vital for VR research and development. It is typically repeatedly assessed through questionnaires completed after leaving a VR scene. Requiring participants to leave and re-enter the VR costs time and can cause disorientation. In this paper, we investigate the effect of completing presence questionnaires directly in VR. Thirty-six participants experienced two immersion levels and filled three standardized presence questionnaires in the real world or VR. We found no effect on the questionnaires' mean scores; however, we found that the variance of those measures significantly depends on the realism of the virtual scene and if the subjects had left the VR. The results indicate that, besides reducing a study's duration and reducing disorientation, completing questionnaires in VR does not change the measured presence but can increase the consistency of the variance."
pn7608,https://doi.org/10.1145/3290605.3300590,Using Presence Questionnaires in Virtual Reality,2,Pascal Knierim,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Virtual Reality (VR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of VR is creating presence, the experience of 'being' or 'acting', when physically situated in another place. Measuring presence is vital for VR research and development. It is typically repeatedly assessed through questionnaires completed after leaving a VR scene. Requiring participants to leave and re-enter the VR costs time and can cause disorientation. In this paper, we investigate the effect of completing presence questionnaires directly in VR. Thirty-six participants experienced two immersion levels and filled three standardized presence questionnaires in the real world or VR. We found no effect on the questionnaires' mean scores; however, we found that the variance of those measures significantly depends on the realism of the virtual scene and if the subjects had left the VR. The results indicate that, besides reducing a study's duration and reducing disorientation, completing questionnaires in VR does not change the measured presence but can increase the consistency of the variance."
pn7608,https://doi.org/10.1145/3290605.3300590,Using Presence Questionnaires in Virtual Reality,3,Nico Haas,University of Stuttgart,Stuttgart,Germany,false,false,"Virtual Reality (VR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of VR is creating presence, the experience of 'being' or 'acting', when physically situated in another place. Measuring presence is vital for VR research and development. It is typically repeatedly assessed through questionnaires completed after leaving a VR scene. Requiring participants to leave and re-enter the VR costs time and can cause disorientation. In this paper, we investigate the effect of completing presence questionnaires directly in VR. Thirty-six participants experienced two immersion levels and filled three standardized presence questionnaires in the real world or VR. We found no effect on the questionnaires' mean scores; however, we found that the variance of those measures significantly depends on the realism of the virtual scene and if the subjects had left the VR. The results indicate that, besides reducing a study's duration and reducing disorientation, completing questionnaires in VR does not change the measured presence but can increase the consistency of the variance."
pn7608,https://doi.org/10.1145/3290605.3300590,Using Presence Questionnaires in Virtual Reality,4,Niels Henze,University of Regensburg,Regensburg,Germany,false,false,"Virtual Reality (VR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of VR is creating presence, the experience of 'being' or 'acting', when physically situated in another place. Measuring presence is vital for VR research and development. It is typically repeatedly assessed through questionnaires completed after leaving a VR scene. Requiring participants to leave and re-enter the VR costs time and can cause disorientation. In this paper, we investigate the effect of completing presence questionnaires directly in VR. Thirty-six participants experienced two immersion levels and filled three standardized presence questionnaires in the real world or VR. We found no effect on the questionnaires' mean scores; however, we found that the variance of those measures significantly depends on the realism of the virtual scene and if the subjects had left the VR. The results indicate that, besides reducing a study's duration and reducing disorientation, completing questionnaires in VR does not change the measured presence but can increase the consistency of the variance."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,1,Florian Müller,TU Darmsatdt,Darmstadt,Germany,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,2,Joshua Mcmanus,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,3,Sebastian Günther,TU Darmstadt,Darmstadt,Germany,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,4,Martin Schmitz,TU Darmstadt,Darmstadt,Germany,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,5,Max Mühlhäuser,TU Darmstadt,Darmstadt,Germany,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn7329,https://doi.org/10.1145/3290605.3300707,Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays,6,Markus Funk,TU Darmstadt,Darmstadt,Germany,true,false,"From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,1,Seungwon Kim,University of South Australia,Mawson Lakes,Australia,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,2,Gun Lee,University of South Australia,Adelaide,Australia,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,3,Weidong Huang,Swinburne University of Technology,Melbourne,Australia,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,4,Hayun Kim,KAIST,Daejeon,Republic Of Korea,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,5,Woontack Woo,KAIST,Daejeon,Republic Of Korea,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn4857,https://doi.org/10.1145/3290605.3300403,Evaluating the Combination of Visual Communication Cues for HMD-based Mixed Reality Remote Collaboration,6,Mark Billinghurst,University of South Australia,Mawson Lakes,Australia,false,false,"Many researchers have studied various visual communication cues (e.g. pointer, sketching, and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks. However, the effect of combining them has not been so well explored. We studied the effect of these cues in four combinations: hand only, hand + pointer, hand + sketch, and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami. The study results showed that the participants completed the task significantly faster and felt a significantly higher level of usability when the sketch cue is added to the hand gesture cue, but not with adding the pointer cue. Participants also preferred the combinations including hand and sketch cues over the other combinations. However, using additional cues (pointer or sketch) increased the perceived mental effort and did not improve the feeling of co-presence. We discuss the implications of these results and future research directions."
pn7651,https://doi.org/10.1145/3290605.3300737,"Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts",1,Alexandra Voit,VIS,Stuttgart,Germany,false,false,"Empirical studies are a cornerstone of HCI research. Technical progress constantly enables new study methods. Online surveys, for example, make it possible to collect feedback from remote users. Progress in augmented and virtual reality enables to collect feedback with early designs. In-situ studies enable researchers to gather feedback in natural environments. While these methods have unique advantages and disadvantages, it is unclear if and how using a specific method affects the results. Therefore, we conducted a study with 60 participants comparing five different methods (online, virtual reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of smart artifacts. We asked participants to assess four different smart artifacts using standardized questionnaires. We show that the method significantly affects the study result and discuss implications for HCI research. Finally, we highlight further directions to overcome the effect of the used methods."
pn7651,https://doi.org/10.1145/3290605.3300737,"Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts",2,Sven Mayer,University of Stuttgart,Stuttgart,Germany,false,false,"Empirical studies are a cornerstone of HCI research. Technical progress constantly enables new study methods. Online surveys, for example, make it possible to collect feedback from remote users. Progress in augmented and virtual reality enables to collect feedback with early designs. In-situ studies enable researchers to gather feedback in natural environments. While these methods have unique advantages and disadvantages, it is unclear if and how using a specific method affects the results. Therefore, we conducted a study with 60 participants comparing five different methods (online, virtual reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of smart artifacts. We asked participants to assess four different smart artifacts using standardized questionnaires. We show that the method significantly affects the study result and discuss implications for HCI research. Finally, we highlight further directions to overcome the effect of the used methods."
pn7651,https://doi.org/10.1145/3290605.3300737,"Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts",3,Valentin Schwind,University of Stuttgart,Stuttgart,Germany,false,false,"Empirical studies are a cornerstone of HCI research. Technical progress constantly enables new study methods. Online surveys, for example, make it possible to collect feedback from remote users. Progress in augmented and virtual reality enables to collect feedback with early designs. In-situ studies enable researchers to gather feedback in natural environments. While these methods have unique advantages and disadvantages, it is unclear if and how using a specific method affects the results. Therefore, we conducted a study with 60 participants comparing five different methods (online, virtual reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of smart artifacts. We asked participants to assess four different smart artifacts using standardized questionnaires. We show that the method significantly affects the study result and discuss implications for HCI research. Finally, we highlight further directions to overcome the effect of the used methods."
pn7651,https://doi.org/10.1145/3290605.3300737,"Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts",4,Niels Henze,University of Regensburg,Regensburg,Germany,false,false,"Empirical studies are a cornerstone of HCI research. Technical progress constantly enables new study methods. Online surveys, for example, make it possible to collect feedback from remote users. Progress in augmented and virtual reality enables to collect feedback with early designs. In-situ studies enable researchers to gather feedback in natural environments. While these methods have unique advantages and disadvantages, it is unclear if and how using a specific method affects the results. Therefore, we conducted a study with 60 participants comparing five different methods (online, virtual reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of smart artifacts. We asked participants to assess four different smart artifacts using standardized questionnaires. We show that the method significantly affects the study result and discuss implications for HCI research. Finally, we highlight further directions to overcome the effect of the used methods."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",1,Nithya Sambasivan,Google,San Francisco,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",2,Amna Batool,Information Technology University,Lahore,Pakistan,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",3,Nova Ahmed,North South University,Dhaka,Bangladesh,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",4,Tara Matthews,Independent Researcher,San Jose,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",5,Kurt Thomas,Google,Mountain View,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",6,Laura Sanely Gaytán-Lugo,Universidad de Colima,Colima,Mexico,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",7,David Nemer,University of Kentucky,Lexington,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",8,Elie Bursztein,Google,Mountain View,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",9,Elizabeth Churchill,Google,Mountain View,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn8460,https://doi.org/10.1145/3290605.3300232,"""They Don't Leave Us Alone Anywhere We Go"": Gender and Digital Abuse in South Asia",10,Sunny Consolvo,Google,Mountain View,United States,false,true,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia."
pn5990,https://doi.org/10.1145/3290605.3300302,"Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums",1,Aditya Vashistha,University of Washington,Seattle,United States,false,false,"HCI4D researchers and practitioners have leveraged voice forums to enable people with literacy, socioeconomic, and connectivity barriers to access, report, and share information. Although voice forums have received impassioned usage from low-income, low-literate, rural, tribal, and disabled communities in diverse HCI4D contexts, the participation of women in these services is almost non-existent. In this paper, we investigate the reasons for the low participation of women in social media voice forums by examining the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and men. Our mixed-methods approach spanning content analysis of audio posts, quantitative analysis of interactions between users, and qualitative interviews with users indicate gender inequity due to deep-rooted patriarchal values. We found that women on these forums faced systemic discrimination and encountered abusive content, flirts, threats, and harassment. We discuss design recommendations to create social media voice forums that foster gender equity in use of these services."
pn5990,https://doi.org/10.1145/3290605.3300302,"Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums",2,Abhinav Garg,University of Washington,Seattle,United States,false,false,"HCI4D researchers and practitioners have leveraged voice forums to enable people with literacy, socioeconomic, and connectivity barriers to access, report, and share information. Although voice forums have received impassioned usage from low-income, low-literate, rural, tribal, and disabled communities in diverse HCI4D contexts, the participation of women in these services is almost non-existent. In this paper, we investigate the reasons for the low participation of women in social media voice forums by examining the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and men. Our mixed-methods approach spanning content analysis of audio posts, quantitative analysis of interactions between users, and qualitative interviews with users indicate gender inequity due to deep-rooted patriarchal values. We found that women on these forums faced systemic discrimination and encountered abusive content, flirts, threats, and harassment. We discuss design recommendations to create social media voice forums that foster gender equity in use of these services."
pn5990,https://doi.org/10.1145/3290605.3300302,"Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums",3,Richard Anderson,University of Washington,Seattle,United States,false,false,"HCI4D researchers and practitioners have leveraged voice forums to enable people with literacy, socioeconomic, and connectivity barriers to access, report, and share information. Although voice forums have received impassioned usage from low-income, low-literate, rural, tribal, and disabled communities in diverse HCI4D contexts, the participation of women in these services is almost non-existent. In this paper, we investigate the reasons for the low participation of women in social media voice forums by examining the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and men. Our mixed-methods approach spanning content analysis of audio posts, quantitative analysis of interactions between users, and qualitative interviews with users indicate gender inequity due to deep-rooted patriarchal values. We found that women on these forums faced systemic discrimination and encountered abusive content, flirts, threats, and harassment. We discuss design recommendations to create social media voice forums that foster gender equity in use of these services."
pn5990,https://doi.org/10.1145/3290605.3300302,"Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums",4,Agha Ali Raza,Information Technology University,Lahore,Pakistan,false,false,"HCI4D researchers and practitioners have leveraged voice forums to enable people with literacy, socioeconomic, and connectivity barriers to access, report, and share information. Although voice forums have received impassioned usage from low-income, low-literate, rural, tribal, and disabled communities in diverse HCI4D contexts, the participation of women in these services is almost non-existent. In this paper, we investigate the reasons for the low participation of women in social media voice forums by examining the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and men. Our mixed-methods approach spanning content analysis of audio posts, quantitative analysis of interactions between users, and qualitative interviews with users indicate gender inequity due to deep-rooted patriarchal values. We found that women on these forums faced systemic discrimination and encountered abusive content, flirts, threats, and harassment. We discuss design recommendations to create social media voice forums that foster gender equity in use of these services."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,1,Mihaela Vorvoreanu,Microsoft Research,Redmond,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,2,Lingyi Zhang,Purdue University,West Lafayette,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,3,Yun-Han Huang,Purdue University,West Lafayette,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,4,Claudia Hilderbrand,Oregon State University,Corvallis,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,5,Zoe Steine-Hanson,Oregon State University,Corvallis,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn6706,https://doi.org/10.1145/3290605.3300283,From Gender Biases to Gender-Inclusive Design: An Empirical Investigation,6,Margaret Burnett,Oregon State University,Corvallis,United States,false,false,"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared."
pn7265,https://doi.org/10.1145/3290605.3300875,"Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters",1,Yolande Strengers,Monash University,Melbourne,Australia,false,true,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households' experiences in relation to three concepts central to Intel's ambient computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'. We find that protection is a form of caregiving; productivity provides 'small conveniences', energy savings and multi-tasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased 'digital housekeeping'. We conclude by suggesting how HCI designers can and should respond to these gendered challenges."
pn7265,https://doi.org/10.1145/3290605.3300875,"Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters",2,Jenny Kennedy,RMIT University,Melbourne,Australia,false,true,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households' experiences in relation to three concepts central to Intel's ambient computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'. We find that protection is a form of caregiving; productivity provides 'small conveniences', energy savings and multi-tasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased 'digital housekeeping'. We conclude by suggesting how HCI designers can and should respond to these gendered challenges."
pn7265,https://doi.org/10.1145/3290605.3300875,"Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters",3,Larissa Nicholls,RMIT University,Melbourne,Australia,false,true,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households' experiences in relation to three concepts central to Intel's ambient computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'. We find that protection is a form of caregiving; productivity provides 'small conveniences', energy savings and multi-tasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased 'digital housekeeping'. We conclude by suggesting how HCI designers can and should respond to these gendered challenges."
pn7265,https://doi.org/10.1145/3290605.3300875,"Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters",4,Paula Arcari,RMIT University,Melbourne,Australia,false,true,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households' experiences in relation to three concepts central to Intel's ambient computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'. We find that protection is a form of caregiving; productivity provides 'small conveniences', energy savings and multi-tasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased 'digital housekeeping'. We conclude by suggesting how HCI designers can and should respond to these gendered challenges."
pn7265,https://doi.org/10.1145/3290605.3300875,"Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters",5,Mel Gregg,Intel Corporation,Portland,United States,false,true,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households' experiences in relation to three concepts central to Intel's ambient computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'. We find that protection is a form of caregiving; productivity provides 'small conveniences', energy savings and multi-tasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased 'digital housekeeping'. We conclude by suggesting how HCI designers can and should respond to these gendered challenges."
pn8624,https://doi.org/10.1145/3290605.3300598,An Analytic Model for Time Efficient Personal Hierarchies,1,William Delamare,Kochi University of Technology,Kochi,Japan,true,false,"Hierarchy structures such as file systems are widespread interfaces for item retrieval and selection tasks. Some hierarchies can be modified by end-users, such as application launchers on smartphones or pictures in a file folder. These modifiable hierarchies cannot benefit from an optimization made beforehand as their content, unknown during the design process, is constantly evolving. We hence propose an analytic model which designers can integrate in their system to recommend a range of local structure modifications (e.g., creating new folders) to end-users. Proposing a range of modifications gives flexibility to end-users regarding their own meaningful grouping and labeling choices to follow a recommendation. A first experiment confirms that the recommendations built on our model can lead to modified hierarchies resulting in faster theoretical selection times. A second experiment confirms that the theoretical selection times fit empirical selection times in different hierarchy visual layouts: linear, radial, and grid."
pn8624,https://doi.org/10.1145/3290605.3300598,An Analytic Model for Time Efficient Personal Hierarchies,2,Ali Neshati,University of Manitoba,Winnipeg,Canada,true,false,"Hierarchy structures such as file systems are widespread interfaces for item retrieval and selection tasks. Some hierarchies can be modified by end-users, such as application launchers on smartphones or pictures in a file folder. These modifiable hierarchies cannot benefit from an optimization made beforehand as their content, unknown during the design process, is constantly evolving. We hence propose an analytic model which designers can integrate in their system to recommend a range of local structure modifications (e.g., creating new folders) to end-users. Proposing a range of modifications gives flexibility to end-users regarding their own meaningful grouping and labeling choices to follow a recommendation. A first experiment confirms that the recommendations built on our model can lead to modified hierarchies resulting in faster theoretical selection times. A second experiment confirms that the theoretical selection times fit empirical selection times in different hierarchy visual layouts: linear, radial, and grid."
pn8624,https://doi.org/10.1145/3290605.3300598,An Analytic Model for Time Efficient Personal Hierarchies,3,Pourang Irani,University of Manitoba,Winnipeg,Canada,true,false,"Hierarchy structures such as file systems are widespread interfaces for item retrieval and selection tasks. Some hierarchies can be modified by end-users, such as application launchers on smartphones or pictures in a file folder. These modifiable hierarchies cannot benefit from an optimization made beforehand as their content, unknown during the design process, is constantly evolving. We hence propose an analytic model which designers can integrate in their system to recommend a range of local structure modifications (e.g., creating new folders) to end-users. Proposing a range of modifications gives flexibility to end-users regarding their own meaningful grouping and labeling choices to follow a recommendation. A first experiment confirms that the recommendations built on our model can lead to modified hierarchies resulting in faster theoretical selection times. A second experiment confirms that the theoretical selection times fit empirical selection times in different hierarchy visual layouts: linear, radial, and grid."
pn8624,https://doi.org/10.1145/3290605.3300598,An Analytic Model for Time Efficient Personal Hierarchies,4,Xiangshi Ren,Kochi University of Technology,Kochi,Japan,true,false,"Hierarchy structures such as file systems are widespread interfaces for item retrieval and selection tasks. Some hierarchies can be modified by end-users, such as application launchers on smartphones or pictures in a file folder. These modifiable hierarchies cannot benefit from an optimization made beforehand as their content, unknown during the design process, is constantly evolving. We hence propose an analytic model which designers can integrate in their system to recommend a range of local structure modifications (e.g., creating new folders) to end-users. Proposing a range of modifications gives flexibility to end-users regarding their own meaningful grouping and labeling choices to follow a recommendation. A first experiment confirms that the recommendations built on our model can lead to modified hierarchies resulting in faster theoretical selection times. A second experiment confirms that the theoretical selection times fit empirical selection times in different hierarchy visual layouts: linear, radial, and grid."
pn2018,https://doi.org/10.1145/3290605.3300866,Text Entry Throughput: Towards Unifying Speed and Accuracy in a Single Performance Metric,1,Mingrui Zhang,University of Washington,Seattle,United States,false,false,"Human-computer input performance inherently involves speed-accuracy tradeoffs---the faster users act, the more inaccurate those actions are. Therefore, comparing speeds and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate technique perform better or worse overall than a slow but accurate one? For pointing, speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman 1957, Welford 1968), but to date, no similar metric has been established for text entry. In this paper, we introduce a text entry method-independent throughput metric based on Shannon information theory (1948). To explore the practical usability of the metric, we conducted an experiment in which 16 participants typed with a laptop keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results show that as a performance metric, text entry throughput remains relatively stable under different speed-accuracy conditions. We also evaluated a smartphone keyboard with 12 participants, finding that throughput varied least compared to other text entry metrics. This work allows researchers to characterize text entry performance with a single unified measure of input efficiency."
pn2018,https://doi.org/10.1145/3290605.3300866,Text Entry Throughput: Towards Unifying Speed and Accuracy in a Single Performance Metric,2,Shumin Zhai,Google,Mountain View,United States,false,false,"Human-computer input performance inherently involves speed-accuracy tradeoffs---the faster users act, the more inaccurate those actions are. Therefore, comparing speeds and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate technique perform better or worse overall than a slow but accurate one? For pointing, speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman 1957, Welford 1968), but to date, no similar metric has been established for text entry. In this paper, we introduce a text entry method-independent throughput metric based on Shannon information theory (1948). To explore the practical usability of the metric, we conducted an experiment in which 16 participants typed with a laptop keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results show that as a performance metric, text entry throughput remains relatively stable under different speed-accuracy conditions. We also evaluated a smartphone keyboard with 12 participants, finding that throughput varied least compared to other text entry metrics. This work allows researchers to characterize text entry performance with a single unified measure of input efficiency."
pn2018,https://doi.org/10.1145/3290605.3300866,Text Entry Throughput: Towards Unifying Speed and Accuracy in a Single Performance Metric,3,Jacob Wobbrock,University of Washington,Seattle,United States,false,false,"Human-computer input performance inherently involves speed-accuracy tradeoffs---the faster users act, the more inaccurate those actions are. Therefore, comparing speeds and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate technique perform better or worse overall than a slow but accurate one? For pointing, speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman 1957, Welford 1968), but to date, no similar metric has been established for text entry. In this paper, we introduce a text entry method-independent throughput metric based on Shannon information theory (1948). To explore the practical usability of the metric, we conducted an experiment in which 16 participants typed with a laptop keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results show that as a performance metric, text entry throughput remains relatively stable under different speed-accuracy conditions. We also evaluated a smartphone keyboard with 12 participants, finding that throughput varied least compared to other text entry metrics. This work allows researchers to characterize text entry performance with a single unified measure of input efficiency."
pn1006,https://doi.org/10.1145/3290605.3300800,Steering Performance with Error-accepting Delays,1,Shota Yamanaka,Yahoo Japan Corporation,Tokyo,Japan,true,false,"In steering law tasks, deviating from the path is immediately considered an error operation. However, in navigating a hierarchical menu item, which is a representative application of the law, a deviation within a short duration is sometimes permitted. We tested the validity of the steering law model with various durations of such error-accepting delays and found that it showed high fits for each delay condition (R!(2) > 0.96) but poor fits if the delay values were not separated (R!(2) = 0.58). Because the average movement speed linearly increased as the delay increased, we refined the model by taking the delay into account, and the fitness was significantly improved (R!(2) = 0.97). Our model will help GUI designers estimate the average operational time on the basis of the menu item length, width, and error-accepting delay."
pn1771,https://doi.org/10.1145/3290605.3300443,Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs,1,Ziming Wu,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"Designers strive to make their mobile apps stand out in a competitive market by creating a distinctive brand personality. However, it is unclear whether users can form a consistent impression of brand personality by looking at a few user interface (UI) screenshots in the app store, and if this process can be modeled computationally. To bridge this gap, we first collect crowd assessment on brand personalities depicted by the UIs of 318 applications, and statistically confirm that users can reach substantial agreement. To further model how users process mobile UI visually, we compute UI descriptors including Color, Organization, and Texture at both element and page levels. We feed these descriptors to a computational model, achieving a high accuracy of predicting perceived brand personality (MSE = 0.035 and R!2 = 0.78). This work could benefit designers by highlighting contributing visual factors to brand personality creation and providing quick, low-cost design feedback."
pn1771,https://doi.org/10.1145/3290605.3300443,Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs,2,Taewook Kim,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"Designers strive to make their mobile apps stand out in a competitive market by creating a distinctive brand personality. However, it is unclear whether users can form a consistent impression of brand personality by looking at a few user interface (UI) screenshots in the app store, and if this process can be modeled computationally. To bridge this gap, we first collect crowd assessment on brand personalities depicted by the UIs of 318 applications, and statistically confirm that users can reach substantial agreement. To further model how users process mobile UI visually, we compute UI descriptors including Color, Organization, and Texture at both element and page levels. We feed these descriptors to a computational model, achieving a high accuracy of predicting perceived brand personality (MSE = 0.035 and R!2 = 0.78). This work could benefit designers by highlighting contributing visual factors to brand personality creation and providing quick, low-cost design feedback."
pn1771,https://doi.org/10.1145/3290605.3300443,Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs,3,Quan Li,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"Designers strive to make their mobile apps stand out in a competitive market by creating a distinctive brand personality. However, it is unclear whether users can form a consistent impression of brand personality by looking at a few user interface (UI) screenshots in the app store, and if this process can be modeled computationally. To bridge this gap, we first collect crowd assessment on brand personalities depicted by the UIs of 318 applications, and statistically confirm that users can reach substantial agreement. To further model how users process mobile UI visually, we compute UI descriptors including Color, Organization, and Texture at both element and page levels. We feed these descriptors to a computational model, achieving a high accuracy of predicting perceived brand personality (MSE = 0.035 and R!2 = 0.78). This work could benefit designers by highlighting contributing visual factors to brand personality creation and providing quick, low-cost design feedback."
pn1771,https://doi.org/10.1145/3290605.3300443,Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs,4,Xiaojuan Ma,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"Designers strive to make their mobile apps stand out in a competitive market by creating a distinctive brand personality. However, it is unclear whether users can form a consistent impression of brand personality by looking at a few user interface (UI) screenshots in the app store, and if this process can be modeled computationally. To bridge this gap, we first collect crowd assessment on brand personalities depicted by the UIs of 318 applications, and statistically confirm that users can reach substantial agreement. To further model how users process mobile UI visually, we compute UI descriptors including Color, Organization, and Texture at both element and page levels. We feed these descriptors to a computational model, achieving a high accuracy of predicting perceived brand personality (MSE = 0.035 and R!2 = 0.78). This work could benefit designers by highlighting contributing visual factors to brand personality creation and providing quick, low-cost design feedback."
pn7491,https://doi.org/10.1145/3290605.3300542,Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use,1,Jonathan Tran,University of Washington,Seattle,United States,false,false,"Many smartphone users engage in compulsive and habitual phone checking they find frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phone-use demonstration, and a sketching exercise with 39 smartphone users (ages 14-64) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defined as transcending the current instance of use. Participants said they periodically reflect on their compulsive use and delete apps that drive compulsive checking without providing sufficient meaning. We use these findings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users' definition of meaningfulness rather than creating lock-out mechanisms to help them police their own use."
pn7491,https://doi.org/10.1145/3290605.3300542,Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use,2,Katie Yang,University of Washington,Seattle,United States,false,false,"Many smartphone users engage in compulsive and habitual phone checking they find frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phone-use demonstration, and a sketching exercise with 39 smartphone users (ages 14-64) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defined as transcending the current instance of use. Participants said they periodically reflect on their compulsive use and delete apps that drive compulsive checking without providing sufficient meaning. We use these findings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users' definition of meaningfulness rather than creating lock-out mechanisms to help them police their own use."
pn7491,https://doi.org/10.1145/3290605.3300542,Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use,3,Katie Davis,University of Washington,Seattle,United States,false,false,"Many smartphone users engage in compulsive and habitual phone checking they find frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phone-use demonstration, and a sketching exercise with 39 smartphone users (ages 14-64) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defined as transcending the current instance of use. Participants said they periodically reflect on their compulsive use and delete apps that drive compulsive checking without providing sufficient meaning. We use these findings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users' definition of meaningfulness rather than creating lock-out mechanisms to help them police their own use."
pn7491,https://doi.org/10.1145/3290605.3300542,Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use,4,Alexis Hiniker,University of Washington,Seattle,United States,false,false,"Many smartphone users engage in compulsive and habitual phone checking they find frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phone-use demonstration, and a sketching exercise with 39 smartphone users (ages 14-64) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defined as transcending the current instance of use. Participants said they periodically reflect on their compulsive use and delete apps that drive compulsive checking without providing sufficient meaning. We use these findings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users' definition of meaningfulness rather than creating lock-out mechanisms to help them police their own use."
pn4841,https://doi.org/10.1145/3290605.3300429,Understanding Perceptions of Problematic Facebook Use: When People Experience Negative Life Impact and a Lack of Control,1,Justin Cheng,Facebook,Menlo Park,United States,false,false,"While many people use social network sites to connect with friends and family, some feel that their use is problematic, seriously affecting their sleep, work, or life. Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use with behavioral and demographic data, we examined Facebook activities associated with problematic use as well as the kinds of people most likely to experience it. People who feel their use is problematic are more likely to be younger, male, and going through a major life event such as a breakup. They spend more time on the platform, particularly at night, and spend proportionally more time looking at profiles and less time browsing their News Feeds. They also message their friends more frequently. While they are more likely to respond to notifications, they are also more likely to deactivate their accounts, perhaps in an effort to better manage their time. Further, they are more likely to have seen content about social media or phone addiction. Notably, people reporting problematic use rate the site as more valuable to them, highlighting the complex relationship between technology use and well-being. A better understanding of problematic Facebook use can inform the design of context-appropriate and supportive tools to help people become more in control."
pn4841,https://doi.org/10.1145/3290605.3300429,Understanding Perceptions of Problematic Facebook Use: When People Experience Negative Life Impact and a Lack of Control,2,Moira Burke,Facebook,Menlo Park,United States,false,false,"While many people use social network sites to connect with friends and family, some feel that their use is problematic, seriously affecting their sleep, work, or life. Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use with behavioral and demographic data, we examined Facebook activities associated with problematic use as well as the kinds of people most likely to experience it. People who feel their use is problematic are more likely to be younger, male, and going through a major life event such as a breakup. They spend more time on the platform, particularly at night, and spend proportionally more time looking at profiles and less time browsing their News Feeds. They also message their friends more frequently. While they are more likely to respond to notifications, they are also more likely to deactivate their accounts, perhaps in an effort to better manage their time. Further, they are more likely to have seen content about social media or phone addiction. Notably, people reporting problematic use rate the site as more valuable to them, highlighting the complex relationship between technology use and well-being. A better understanding of problematic Facebook use can inform the design of context-appropriate and supportive tools to help people become more in control."
pn4841,https://doi.org/10.1145/3290605.3300429,Understanding Perceptions of Problematic Facebook Use: When People Experience Negative Life Impact and a Lack of Control,3,Elena Davis,Facebook,Menlo Park,United States,false,false,"While many people use social network sites to connect with friends and family, some feel that their use is problematic, seriously affecting their sleep, work, or life. Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use with behavioral and demographic data, we examined Facebook activities associated with problematic use as well as the kinds of people most likely to experience it. People who feel their use is problematic are more likely to be younger, male, and going through a major life event such as a breakup. They spend more time on the platform, particularly at night, and spend proportionally more time looking at profiles and less time browsing their News Feeds. They also message their friends more frequently. While they are more likely to respond to notifications, they are also more likely to deactivate their accounts, perhaps in an effort to better manage their time. Further, they are more likely to have seen content about social media or phone addiction. Notably, people reporting problematic use rate the site as more valuable to them, highlighting the complex relationship between technology use and well-being. A better understanding of problematic Facebook use can inform the design of context-appropriate and supportive tools to help people become more in control."
pn1157,https://doi.org/10.1145/3290605.3300876,Keeping Rumors in Proportion: Managing Uncertainty in Rumor Systems,1,Peter Krafft,University of Washington,Seattle,United States,false,false,"The study of rumors has garnered wider attention as regulators and researchers turn towards problems of misinformation on social media. One goal has been to discover and implement mechanisms that promote healthy information ecosystems. Classically defined as regarding ambiguous situations, rumors pose the unique difficulty of intrinsic uncertainty around their veracity. Further complicating matters, rumors can serve the public when they do spread valuable true information. To address these challenges, we develop an approach that reifies ""rumor proportions"" as central to the theory of systems for managing rumors. We use this lens to advocate for systems that, rather than aiming to stifle rumors entirely or aiming to stop only false rumors, aim to prevent rumors from growing out of proportion relative to normative benchmark representations of intrinsic uncertainty."
pn1157,https://doi.org/10.1145/3290605.3300876,Keeping Rumors in Proportion: Managing Uncertainty in Rumor Systems,2,Emma Spiro,University of Washington,Seattle,United States,false,false,"The study of rumors has garnered wider attention as regulators and researchers turn towards problems of misinformation on social media. One goal has been to discover and implement mechanisms that promote healthy information ecosystems. Classically defined as regarding ambiguous situations, rumors pose the unique difficulty of intrinsic uncertainty around their veracity. Further complicating matters, rumors can serve the public when they do spread valuable true information. To address these challenges, we develop an approach that reifies ""rumor proportions"" as central to the theory of systems for managing rumors. We use this lens to advocate for systems that, rather than aiming to stifle rumors entirely or aiming to stop only false rumors, aim to prevent rumors from growing out of proportion relative to normative benchmark representations of intrinsic uncertainty."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,1,Fatema Akbar,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,2,Ayse Bayraktaroglu,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,3,Pradeep Buddharaju,University of Houston,Houston,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,4,Dennis Rodrigo Da Cunha Silva,Texas A&M University,College Station,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,5,Ge Gao,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,6,Ted Grover,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,7,Ricardo Gutierrez-Osuna,Texas A&M University,College Station,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,8,Nathan Jones,University of Houston,Houston,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,9,Gloria Mark,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,10,Ioannis Pavlidis,University of Houston,Houston,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,11,Kevin Storer,"University of California, Irvine",Irvine,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,12,Zelun Wang,Texas A&M University,College Station,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,13,Amanveer Wesley,University of Houston,Houston,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn6909,https://doi.org/10.1145/3290605.3300898,Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging,14,Shaila Zaman,University of Houston,Houston,United States,false,false,"Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress."
pn9847,https://doi.org/10.1145/3290605.3300768,Machine Heuristic: When We Trust Computers More than Humans with Our Personal Information,1,S. Sundar,Pennsylvania State University,University Park,United States,false,false,"In this day and age of identity theft, are we likely to trust machines more than humans for handling our personal information? We answer this question by invoking the concept of ""machine heuristic,"" which is a rule of thumb that machines are more secure and trustworthy than humans. In an experiment (N = 160) that involved making airline reservations, users were more likely to reveal their credit card information to a machine agent than a human agent. We demonstrate that cues on the interface trigger the machine heuristic by showing that those with higher cognitive accessibility of the heuristic (i.e., stronger prior belief in the rule of thumb) were more likely than those with lower accessibility to disclose to a machine, but they did not differ in their disclosure to a human. These findings have implications for design of interface cues conveying machine vs. human sources of our online interactions."
pn9847,https://doi.org/10.1145/3290605.3300768,Machine Heuristic: When We Trust Computers More than Humans with Our Personal Information,2,Jinyoung Kim,Pennsylvania State University,University Park,United States,false,false,"In this day and age of identity theft, are we likely to trust machines more than humans for handling our personal information? We answer this question by invoking the concept of ""machine heuristic,"" which is a rule of thumb that machines are more secure and trustworthy than humans. In an experiment (N = 160) that involved making airline reservations, users were more likely to reveal their credit card information to a machine agent than a human agent. We demonstrate that cues on the interface trigger the machine heuristic by showing that those with higher cognitive accessibility of the heuristic (i.e., stronger prior belief in the rule of thumb) were more likely than those with lower accessibility to disclose to a machine, but they did not differ in their disclosure to a human. These findings have implications for design of interface cues conveying machine vs. human sources of our online interactions."
pn9745,https://doi.org/10.1145/3290605.3300469,AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness,1,Maurice Jakesch,Cornell Tech,New York,United States,false,false,"We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory."
pn9745,https://doi.org/10.1145/3290605.3300469,AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness,2,Megan French,Stanford University,Stanford,United States,false,false,"We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory."
pn9745,https://doi.org/10.1145/3290605.3300469,AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness,3,Xiao Ma,Cornell Tech,New York,United States,false,false,"We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory."
pn9745,https://doi.org/10.1145/3290605.3300469,AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness,4,Jeffrey Hancock,Stanford University,Stanford,United States,false,false,"We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory."
pn9745,https://doi.org/10.1145/3290605.3300469,AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness,5,Mor Naaman,Cornell Tech,New York,United States,false,false,"We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory."
pn7942,https://doi.org/10.1145/3290605.3300750,"Automation Accuracy Is Good, but High Controllability May Be Better",1,Quentin Roy,University of Waterloo,Waterloo,Canada,true,false,"When automating tasks using some form of artificial intelligence, some inaccuracy in the result is virtually unavoidable. In many cases, the user must decide whether to try the automated method again, or fix it themselves using the available user interface. We argue this decision is influenced by both perceived automation accuracy and degree of task ""controllability"" (how easily and to what extent an automated result can be manually modified). This relationship between accuracy and controllability is investigated in a 750-participant crowdsourced experiment using a controlled, gamified task. With high controllability, self-reported satisfaction remained constant even under very low accuracy conditions, and overall, a strong preference was observed for using manual control rather than automation, despite much slower performance and regardless of very poor controllability."
pn7942,https://doi.org/10.1145/3290605.3300750,"Automation Accuracy Is Good, but High Controllability May Be Better",2,Futian Zhang,University of Waterloo,Waterloo,Canada,true,false,"When automating tasks using some form of artificial intelligence, some inaccuracy in the result is virtually unavoidable. In many cases, the user must decide whether to try the automated method again, or fix it themselves using the available user interface. We argue this decision is influenced by both perceived automation accuracy and degree of task ""controllability"" (how easily and to what extent an automated result can be manually modified). This relationship between accuracy and controllability is investigated in a 750-participant crowdsourced experiment using a controlled, gamified task. With high controllability, self-reported satisfaction remained constant even under very low accuracy conditions, and overall, a strong preference was observed for using manual control rather than automation, despite much slower performance and regardless of very poor controllability."
pn7942,https://doi.org/10.1145/3290605.3300750,"Automation Accuracy Is Good, but High Controllability May Be Better",3,Daniel Vogel,University of Waterloo,Waterloo,Canada,true,false,"When automating tasks using some form of artificial intelligence, some inaccuracy in the result is virtually unavoidable. In many cases, the user must decide whether to try the automated method again, or fix it themselves using the available user interface. We argue this decision is influenced by both perceived automation accuracy and degree of task ""controllability"" (how easily and to what extent an automated result can be manually modified). This relationship between accuracy and controllability is investigated in a 750-participant crowdsourced experiment using a controlled, gamified task. With high controllability, self-reported satisfaction remained constant even under very low accuracy conditions, and overall, a strong preference was observed for using manual control rather than automation, despite much slower performance and regardless of very poor controllability."
pn1763,https://doi.org/10.1145/3290605.3300573,Upside and Downside Risk in Online Security for Older Adults with Mild Cognitive Impairment,1,Helena Mentis,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Older adults are rapidly increasing their use of online services such as banking, social media, and email - services that come with subtle and serious security and privacy risks. Older adults with mild cognitive impairment (MCI) are particularly vulnerable to these risks because MCI can reduce their ability to recognize scams such as email phishing, follow recommended password guidelines, and consider the implications of sharing personal information. Older adults with MCI often cope with their impairments with the help of caregivers, including partners, children, and professional health personnel, when using and managing online services. Yet, this too carries security and privacy risks: sharing personal information with caregivers can create issues of agency, autonomy, and even risk embarrassment and information leakage; caregivers also do not always act in their charges' best interest. Through a series of interviews conducted in the US, we identify a spectrum of safeguarding strategies used and consider them through the lens of 'upside and downside risk' where there are tradeoffs between reduced privacy and maintaining older adults' autonomy and access to online services."
pn1763,https://doi.org/10.1145/3290605.3300573,Upside and Downside Risk in Online Security for Older Adults with Mild Cognitive Impairment,2,Galina Madjaroff,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Older adults are rapidly increasing their use of online services such as banking, social media, and email - services that come with subtle and serious security and privacy risks. Older adults with mild cognitive impairment (MCI) are particularly vulnerable to these risks because MCI can reduce their ability to recognize scams such as email phishing, follow recommended password guidelines, and consider the implications of sharing personal information. Older adults with MCI often cope with their impairments with the help of caregivers, including partners, children, and professional health personnel, when using and managing online services. Yet, this too carries security and privacy risks: sharing personal information with caregivers can create issues of agency, autonomy, and even risk embarrassment and information leakage; caregivers also do not always act in their charges' best interest. Through a series of interviews conducted in the US, we identify a spectrum of safeguarding strategies used and consider them through the lens of 'upside and downside risk' where there are tradeoffs between reduced privacy and maintaining older adults' autonomy and access to online services."
pn1763,https://doi.org/10.1145/3290605.3300573,Upside and Downside Risk in Online Security for Older Adults with Mild Cognitive Impairment,3,Aaron Massey,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"Older adults are rapidly increasing their use of online services such as banking, social media, and email - services that come with subtle and serious security and privacy risks. Older adults with mild cognitive impairment (MCI) are particularly vulnerable to these risks because MCI can reduce their ability to recognize scams such as email phishing, follow recommended password guidelines, and consider the implications of sharing personal information. Older adults with MCI often cope with their impairments with the help of caregivers, including partners, children, and professional health personnel, when using and managing online services. Yet, this too carries security and privacy risks: sharing personal information with caregivers can create issues of agency, autonomy, and even risk embarrassment and information leakage; caregivers also do not always act in their charges' best interest. Through a series of interviews conducted in the US, we identify a spectrum of safeguarding strategies used and consider them through the lens of 'upside and downside risk' where there are tradeoffs between reduced privacy and maintaining older adults' autonomy and access to online services."
pn8864,https://doi.org/10.1145/3290605.3300845,"Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity",1,Young-Ho Kim,Seoul National University,Seoul,Republic Of Korea,false,false,"Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity's diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work–ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment–work product, time management, worker's state, attitude toward work, impact & benefit, and compound task–and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities."
pn8864,https://doi.org/10.1145/3290605.3300845,"Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity",2,Eun Kyoung Choe,University of Maryland,College Park,United States,false,false,"Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity's diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work–ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment–work product, time management, worker's state, attitude toward work, impact & benefit, and compound task–and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities."
pn8864,https://doi.org/10.1145/3290605.3300845,"Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity",3,Bongshin Lee,Microsoft Research,Redmond,United States,false,false,"Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity's diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work–ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment–work product, time management, worker's state, attitude toward work, impact & benefit, and compound task–and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities."
pn8864,https://doi.org/10.1145/3290605.3300845,"Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity",4,Jinwook Seo,Seoul National University,Seoul,Republic Of Korea,false,false,"Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity's diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work–ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment–work product, time management, worker's state, attitude toward work, impact & benefit, and compound task–and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities."
pn9880,https://doi.org/10.1145/3290605.3300570,"Beyond ""One-Size-Fits-All"": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources",1,Kimia Kiani,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond ""one-size-fits-all"" help resources towards more structured, personalized, and curated help and learning materials."
pn9880,https://doi.org/10.1145/3290605.3300570,"Beyond ""One-Size-Fits-All"": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources",2,George Cui,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond ""one-size-fits-all"" help resources towards more structured, personalized, and curated help and learning materials."
pn9880,https://doi.org/10.1145/3290605.3300570,"Beyond ""One-Size-Fits-All"": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources",3,Andrea Bunt,University of Manitoba,Winnipeg,Canada,false,false,"For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond ""one-size-fits-all"" help resources towards more structured, personalized, and curated help and learning materials."
pn9880,https://doi.org/10.1145/3290605.3300570,"Beyond ""One-Size-Fits-All"": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources",4,Joanna Mcgrenere,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond ""one-size-fits-all"" help resources towards more structured, personalized, and curated help and learning materials."
pn9880,https://doi.org/10.1145/3290605.3300570,"Beyond ""One-Size-Fits-All"": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources",5,Parmit Chilana,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond ""one-size-fits-all"" help resources towards more structured, personalized, and curated help and learning materials."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,1,Geza Kovacs,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,2,Andrew Gregory,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,3,Zilin Ma,Bucknell University,Lewisburg,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,4,Zhengxuan Wu,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,5,Golrokh Emami,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,6,Jacob Ray,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn3785,https://doi.org/10.1145/3290605.3300560,Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?,7,Michael Bernstein,Stanford University,Stanford,United States,false,false,"Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects."
pn1939,https://doi.org/10.1145/3290605.3300541,PledgeWork: Online Volunteering through Crowdwork,1,Keiko Katsuragawa,University of Waterloo,Waterloo,Canada,true,false,"In this paper, we explore an alternative form of volunteer work, PledgeWork, where individuals, rather than working directly for a charity, make indirect donations by completing tasks provided by a third party task provider. PledgeWork poses novel research questions on issues of user acceptance of on-line volunteerism, on quality and quantity of work performed as a volunteer, and on the benefits low-barrier volunteerism might provide to charities. To evaluate these questions, we conduct a mixed methods study that compares the quality and quantity of work between volunteer workers and paid workers and user attitudes toward PledgeWork, including perceived benefits and drawbacks. We find that PledgeWork can improve the quality of simple tasks and that the vast majority of our participants expressed interest in using our PledgeWork platform to contribute to a charity. Our interview also reveals current problems with volunteering and online donations, thus highlighting additional strengths of PledgeWork."
pn1939,https://doi.org/10.1145/3290605.3300541,PledgeWork: Online Volunteering through Crowdwork,2,Qi Shu,University of Waterloo,Waterloo,Canada,true,false,"In this paper, we explore an alternative form of volunteer work, PledgeWork, where individuals, rather than working directly for a charity, make indirect donations by completing tasks provided by a third party task provider. PledgeWork poses novel research questions on issues of user acceptance of on-line volunteerism, on quality and quantity of work performed as a volunteer, and on the benefits low-barrier volunteerism might provide to charities. To evaluate these questions, we conduct a mixed methods study that compares the quality and quantity of work between volunteer workers and paid workers and user attitudes toward PledgeWork, including perceived benefits and drawbacks. We find that PledgeWork can improve the quality of simple tasks and that the vast majority of our participants expressed interest in using our PledgeWork platform to contribute to a charity. Our interview also reveals current problems with volunteering and online donations, thus highlighting additional strengths of PledgeWork."
pn1939,https://doi.org/10.1145/3290605.3300541,PledgeWork: Online Volunteering through Crowdwork,3,Edward Lank,,Waterloo,Canada,true,false,"In this paper, we explore an alternative form of volunteer work, PledgeWork, where individuals, rather than working directly for a charity, make indirect donations by completing tasks provided by a third party task provider. PledgeWork poses novel research questions on issues of user acceptance of on-line volunteerism, on quality and quantity of work performed as a volunteer, and on the benefits low-barrier volunteerism might provide to charities. To evaluate these questions, we conduct a mixed methods study that compares the quality and quantity of work between volunteer workers and paid workers and user attitudes toward PledgeWork, including perceived benefits and drawbacks. We find that PledgeWork can improve the quality of simple tasks and that the vast majority of our participants expressed interest in using our PledgeWork platform to contribute to a charity. Our interview also reveals current problems with volunteering and online donations, thus highlighting additional strengths of PledgeWork."
pn2481,https://doi.org/10.1145/3290605.3300564,Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work,1,Swathi Jagannath,Drexel University,Philadelphia,United States,false,false,"We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for real-time documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings."
pn2481,https://doi.org/10.1145/3290605.3300564,Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work,2,Aleksandra Sarcevic,Drexel University,Philadelphia,United States,false,false,"We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for real-time documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings."
pn2481,https://doi.org/10.1145/3290605.3300564,Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work,3,Victoria Young,Drexel University,Philadelphia,United States,false,false,"We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for real-time documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings."
pn2481,https://doi.org/10.1145/3290605.3300564,Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work,4,Sage Myers,The Children's Hospital of Philadelphia,Philadelphia,United States,false,false,"We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for real-time documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,1,Ignacio Avellino,"Sorbonne Université, CNRS, ISIR",Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,2,Gilles Bailly,"Sorbonne Université, CNRS, ISIR",Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,3,Geoffroy Canlorbe,Hôpital Pitié Salpêtrière,Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,4,Jeremie Belgihti,Hôpital Pitié Salpêtrière,Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,5,Guillaume Morel,"Sorbonne Université, CNRS, ISIR",Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn7183,https://doi.org/10.1145/3290605.3300813,Impacts of Telemanipulation in Robotic Assisted Surgery,6,Marie-Aude Vitrani,"Sorbonne Université, CNRS, ISIR",Paris,France,false,false,"Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field."
pn8407,https://doi.org/10.1145/3290605.3300865,Electronic Health Records Are More Than a Work Tool: Conflicting Needs of Direct and Indirect Stakeholders,1,Åsa Cajander,Uppsala University,Uppsala,Sweden,false,false,"The involvement of stakeholders is crucial when designing IT in highly complex application domains, such as healthcare. Stakeholder relationships are complex and can include strongly conflicting needs and value tensions. In this case study, we investigate the different perspectives of patients and physicians related to Patient Accessible Electronic Health Records (PAEHR) in Sweden. Generally, the introduction of this service has been heavily criticised by healthcare professionals, but welcomed by patients. The paper presents an innovative study design where themes from interviews with physicians are used as a lens to analyse survey data from patients. The findings highlight the necessity to understand stakeholders' perspectives about other stakeholder groups by contrasting assumptions and expectations of physicians (indirect stakeholders) with experience of use by patients (direct stakeholders), and discusses practical challenges when designing large-scale health information systems."
pn8407,https://doi.org/10.1145/3290605.3300865,Electronic Health Records Are More Than a Work Tool: Conflicting Needs of Direct and Indirect Stakeholders,2,Christiane Grünloh,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"The involvement of stakeholders is crucial when designing IT in highly complex application domains, such as healthcare. Stakeholder relationships are complex and can include strongly conflicting needs and value tensions. In this case study, we investigate the different perspectives of patients and physicians related to Patient Accessible Electronic Health Records (PAEHR) in Sweden. Generally, the introduction of this service has been heavily criticised by healthcare professionals, but welcomed by patients. The paper presents an innovative study design where themes from interviews with physicians are used as a lens to analyse survey data from patients. The findings highlight the necessity to understand stakeholders' perspectives about other stakeholder groups by contrasting assumptions and expectations of physicians (indirect stakeholders) with experience of use by patients (direct stakeholders), and discusses practical challenges when designing large-scale health information systems."
pn7089,https://doi.org/10.1145/3290605.3300353,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,1,Alaa Alahmadi,University of Manchester,Manchester,United Kingdom,false,false,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG."
pn7089,https://doi.org/10.1145/3290605.3300353,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,2,Alan Davies,University of Manchester,Manchester,United Kingdom,false,false,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG."
pn7089,https://doi.org/10.1145/3290605.3300353,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,3,Jennifer Royle,CRUK Manchester Institute,Manchester,United Kingdom,false,false,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG."
pn7089,https://doi.org/10.1145/3290605.3300353,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,4,Markel Vigo,University of Manchester,Manchester,United Kingdom,false,false,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG."
pn7089,https://doi.org/10.1145/3290605.3300353,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,5,Caroline Jay,University of Manchester,Manchester,United Kingdom,false,false,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG."
pn4785,https://doi.org/10.1145/3290605.3300699,Making Well-being: Exploring the Role of Makerspaces in Long Term Care Facilities,1,Kayla Carucci,University of Michigan,Ann Arbor,United States,false,false,"Fourth-age residents in long-term care facilities (LTCF) are known to suffer declines in well-being due to their advanced age and resulting loss of independence. Using an action research approach, we set up a makerspace in a New Jersey LTCF for eight weeks to see whether it could improve well-being for residents. Based on engaged observation over 280 hours and semi-structured interviews with participants, we find that people aged 80-99 years will spend (sometimes significant) time in a makerspace for the purposes of making and companionship; that makerspaces can contribute to both autonomy and well-being for older residents; and participants produced not only decorative art, but novel artifacts that solved real challenges in their daily lives. We situate these findings in the literature on art and activity therapy for fourth-age people, and make recommendations for makerspaces in long-term care facilities."
pn4785,https://doi.org/10.1145/3290605.3300699,Making Well-being: Exploring the Role of Makerspaces in Long Term Care Facilities,2,Kentaro Toyama,University of Michigan,Ann Arbor,United States,false,false,"Fourth-age residents in long-term care facilities (LTCF) are known to suffer declines in well-being due to their advanced age and resulting loss of independence. Using an action research approach, we set up a makerspace in a New Jersey LTCF for eight weeks to see whether it could improve well-being for residents. Based on engaged observation over 280 hours and semi-structured interviews with participants, we find that people aged 80-99 years will spend (sometimes significant) time in a makerspace for the purposes of making and companionship; that makerspaces can contribute to both autonomy and well-being for older residents; and participants produced not only decorative art, but novel artifacts that solved real challenges in their daily lives. We situate these findings in the literature on art and activity therapy for fourth-age people, and make recommendations for makerspaces in long-term care facilities."
pn1315,https://doi.org/10.1145/3290605.3300250,Making Sense of Art: Access for Gallery Visitors with Vision Impairments,1,Leona Holloway,Monash University,Caulfield East,Australia,false,false,"While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders."
pn1315,https://doi.org/10.1145/3290605.3300250,Making Sense of Art: Access for Gallery Visitors with Vision Impairments,2,Kim Marriott,Monash University,Melbourne,Australia,false,false,"While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders."
pn1315,https://doi.org/10.1145/3290605.3300250,Making Sense of Art: Access for Gallery Visitors with Vision Impairments,3,Matthew Butler,Monash University,Melbourne,Australia,false,false,"While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders."
pn1315,https://doi.org/10.1145/3290605.3300250,Making Sense of Art: Access for Gallery Visitors with Vision Impairments,4,Alan Borning,University of Washington,Seattle,United States,false,false,"While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders."
pn1905,https://doi.org/10.1145/3290605.3300518,A Place to Play: The (Dis)Abled Embodied Experience for Autistic Children in Online Spaces,1,Kathryn Ringland,Northwestern University,Chicago,United States,true,false,"Play is the work of children—but access to play is not equal from child to child. Having access to a place to play is a challenge for marginalized children, such as children with disabilities. For autistic children, playing with other children in the physical world may be uncomfortable or even painful. Yet, having practice in the social skills play provides is essential for childhood development. In this ethnographic work, I explore how one community uses the sense of place and the digital embodied experience in a virtual world specifically to give autistic children access to play with their peers. The contribution of this work is twofold. First, I demonstrate how various physical and virtual spaces work together to make play possible. Second, I demonstrate these spaces, though some of them are digital, are no more or less ""real"" than the physical spaces making up a schoolyard or playground."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",1,Megan Hofmann,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",2,Kristin Williams,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",3,Toni Kaplan,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",4,Stephanie Valencia,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",5,Gabriella Han,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",6,Scott Hudson,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",7,Jennifer Mankoff,University of Washington,Seattle,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn3835,https://doi.org/10.1145/3290605.3300544,"""Occupational Therapy is Making"": Clinical Rapid Prototyping and Digital Fabrication",8,Patrick Carrington,Carnegie Mellon University,Pittsburgh,United States,false,true,"Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,1,Jotaro Shigeyama,The University of Tokyo,Tokyo,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,2,Takeru Hashimoto,The University of Tokyo,Tokyo,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,3,Shigeo Yoshida,The University of Tokyo,Tokyo,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,4,Takuji Narumi,The University of Tokyo,Tokyo,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,5,Tomohiro Tanikawa,The University of Tokyo,Tokyo,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn1255,https://doi.org/10.1145/3290605.3300241,Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model,6,Michitaka Hirose,The University of Tokyo,Tokyko,Japan,true,false,"Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment."
pn3526,https://doi.org/10.1145/3290605.3300441,Drag: on - A Virtual Reality Controller Providing Haptic Feedback Based on Drag and Weight Shift,1,André Zenner,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Standard controllers for virtual reality (VR) lack sophisticated means to convey a realistic, kinesthetic impression of size, resistance or inertia. We present the concept and implementation of Drag:on, an ungrounded shape-changing VR controller that provides dynamic passive haptic feedback based on drag, i.e. air resistance, and weight shift. Drag:on leverages the airflow occurring at the controller during interaction. By dynamically adjusting its surface area, the controller changes the drag and rotational inertia felt by the user. In a user study, we found that Drag:on can provide distinguishable levels of haptic feedback. Our prototype increases the haptic realism in VR compared to standard controllers and when rotated or swung improves the perception of virtual resistance. By this, Drag:on provides haptic feedback suitable for rendering different virtual mechanical resistances, virtual gas streams, and virtual objects differing in scale, material and fill state."
pn3526,https://doi.org/10.1145/3290605.3300441,Drag: on - A Virtual Reality Controller Providing Haptic Feedback Based on Drag and Weight Shift,2,Antonio Krüger,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Standard controllers for virtual reality (VR) lack sophisticated means to convey a realistic, kinesthetic impression of size, resistance or inertia. We present the concept and implementation of Drag:on, an ungrounded shape-changing VR controller that provides dynamic passive haptic feedback based on drag, i.e. air resistance, and weight shift. Drag:on leverages the airflow occurring at the controller during interaction. By dynamically adjusting its surface area, the controller changes the drag and rotational inertia felt by the user. In a user study, we found that Drag:on can provide distinguishable levels of haptic feedback. Our prototype increases the haptic realism in VR compared to standard controllers and when rotated or swung improves the perception of virtual resistance. By this, Drag:on provides haptic feedback suitable for rendering different virtual mechanical resistances, virtual gas streams, and virtual objects differing in scale, material and fill state."
pn8664,https://doi.org/10.1145/3290605.3300550,Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio,1,Majed Samad,Facebook Reality Labs,Redmond,United States,false,false,"In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality."
pn8664,https://doi.org/10.1145/3290605.3300550,Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio,2,Elia Gatti,Facebook Reality Labs,Redmond,United States,false,false,"In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality."
pn8664,https://doi.org/10.1145/3290605.3300550,Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio,3,Anne Hermes,Facebook Reality Labs,Redmond,United States,false,false,"In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality."
pn8664,https://doi.org/10.1145/3290605.3300550,Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio,4,Hrvoje Benko,Facebook Reality Labs,Redmond,United States,false,false,"In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality."
pn8664,https://doi.org/10.1145/3290605.3300550,Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio,5,Cesare Parise,Facebook Reality Labs,Redmond,United States,false,false,"In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,1,Joon-Gi Shin,KAIST,Daejeon,Republic Of Korea,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,2,Eiji Onchi,University of Tsukuba,Tsukuba,Japan,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,3,Maria Reyes,KAIST,Daejeon,Republic Of Korea,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,4,Junbong Song,teamVoid,Seoul,Republic Of Korea,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,5,Uichin Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,6,Seung-Hee Lee,University of Tsukuba,Tsukuba,Japan,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn6442,https://doi.org/10.1145/3290605.3300843,Slow Robots for Unobtrusive Posture Correction,7,Daniel Saakes,KAIST,Daejeon,Republic Of Korea,false,false,"Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction.In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction.In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,1,Mehmet Aydin Baytas,Koç University,Istanbul,Turkey,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,2,Damla Çay,Koç University,Istanbul,Turkey,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,3,Yuchong Zhang,Chalmers University of Technology,Gothenburg,Sweden,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,4,Mohammad Obaid,University of New South Wales,Sydney,Australia,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,5,Asim Yantaç,Koç University,Istanbul,Turkey,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2074,https://doi.org/10.1145/3290605.3300480,The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments,6,Morten Fjeld,Chalmers University of Technology,Gothenburg,Sweden,false,false,"The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones."
pn2738,https://doi.org/10.1145/3290605.3300502,An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations,1,Md. Nafiz Hasan Khan,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"In the near future, emergency services within Canada will be supporting new technologies for 9-1-1 call centres and firefighters to learn about an emergency situation. One such technology is drones. To understand the benefits and challenges of using drones within emergency response, we conducted a study with citizens who have called 9-1-1 and firefighters who respond to a range of everyday emergencies. Our results show that drones have numerous benefits to both firefighters and 9-1-1 callers which include context awareness and social support for callers who receive feelings of assurance that help is on the way. Privacy was largely not an issue, though safety issues arose especially for complex uses of drones such as indoor flying. Our results point to opportunities for designing drone systems that help people to develop a sense of trust with emergency response drones, and mitigate privacy and safety concerns with more complex drone systems."
pn2738,https://doi.org/10.1145/3290605.3300502,An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations,2,Carman Neustaedter,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"In the near future, emergency services within Canada will be supporting new technologies for 9-1-1 call centres and firefighters to learn about an emergency situation. One such technology is drones. To understand the benefits and challenges of using drones within emergency response, we conducted a study with citizens who have called 9-1-1 and firefighters who respond to a range of everyday emergencies. Our results show that drones have numerous benefits to both firefighters and 9-1-1 callers which include context awareness and social support for callers who receive feelings of assurance that help is on the way. Privacy was largely not an issue, though safety issues arose especially for complex uses of drones such as indoor flying. Our results point to opportunities for designing drone systems that help people to develop a sense of trust with emergency response drones, and mitigate privacy and safety concerns with more complex drone systems."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,1,Sara Eriksson,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,2,Åsa Unander-Scharin,Luleå University of Technology,Luleå,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,3,Vincent Trichon,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,4,Carl Unander-Scharin,Karlstad University,Stockholm,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,5,Hedvig Kjellström,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn9915,https://doi.org/10.1145/3290605.3300847,Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality,6,Kristina Höök,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Movement-based interactions are gaining traction, requiring a better understanding of how such expressions are shaped by designers. Through an analysis of an artistic process aimed to deliver a commissioned opera where custom-built drones are performing on stage alongside human performers, we observed the importance of achieving anintercorporeal understanding to shape body-based emotional expressivity. Our analysis reveals how the choreographer moves herself to: (1) imitate and feel the affordances and expressivity of the drones' 'otherness' through her own bodily experience; (2) communicate to the engineer of the team how she wants to alter the drones' behaviors to be more expressive; (3) enact and interactively alter her choreography. Through months of intense development and creative work, such an intercorporeal understanding was achieved by carefully crafting the drones' behaviors, but also by the choreographer adjusting her own somatics and expressions. The choreography arose as a result of the expressivity they enabled together."
pn8731,https://doi.org/10.1145/3290605.3300595,ZeRONE: Safety Drone with Blade-Free Propulsion,1,Wataru Yamada,NTT DOCOMO,Yokosuka,Japan,false,false,"We present ZeRONE, a new indoor drone that does not use rotating blades for propulsion. The proposed device is a helium blimp type drone that uses the wind generated by the ultrasonic vibration of piezo elements for propulsion. Compared to normal drones with rotating propellers, the drone is much safer because its only moving parts are the piezo elements whose surfaces vibrate at the order of micrometers. The drone can float for a few weeks and the ultrasonic propulsion system is quiet. We implement a prototype of the drone and evaluate its performance and unique characteristics in experiments. Moreover, application scenarios in which ZeRONE coexists with people are also discussed."
pn8731,https://doi.org/10.1145/3290605.3300595,ZeRONE: Safety Drone with Blade-Free Propulsion,2,Hiroyuki Manabe,NTT DOCOMO,Yokosuka,Japan,false,false,"We present ZeRONE, a new indoor drone that does not use rotating blades for propulsion. The proposed device is a helium blimp type drone that uses the wind generated by the ultrasonic vibration of piezo elements for propulsion. Compared to normal drones with rotating propellers, the drone is much safer because its only moving parts are the piezo elements whose surfaces vibrate at the order of micrometers. The drone can float for a few weeks and the ultrasonic propulsion system is quiet. We implement a prototype of the drone and evaluate its performance and unique characteristics in experiments. Moreover, application scenarios in which ZeRONE coexists with people are also discussed."
pn8731,https://doi.org/10.1145/3290605.3300595,ZeRONE: Safety Drone with Blade-Free Propulsion,3,Daizo Ikeda,NTT DOCOMO,Yokosuka,Japan,false,false,"We present ZeRONE, a new indoor drone that does not use rotating blades for propulsion. The proposed device is a helium blimp type drone that uses the wind generated by the ultrasonic vibration of piezo elements for propulsion. Compared to normal drones with rotating propellers, the drone is much safer because its only moving parts are the piezo elements whose surfaces vibrate at the order of micrometers. The drone can float for a few weeks and the ultrasonic propulsion system is quiet. We implement a prototype of the drone and evaluate its performance and unique characteristics in experiments. Moreover, application scenarios in which ZeRONE coexists with people are also discussed."
pn9126,https://doi.org/10.1145/3290605.3300863,May AI? Design Ideation with Cooperative Contextual Bandits,1,Janin Koch,Aalto University,Helsinki,Finland,false,false,"Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials (""may AI?""); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control."
pn9126,https://doi.org/10.1145/3290605.3300863,May AI? Design Ideation with Cooperative Contextual Bandits,2,Andrés Lucero,Aalto University,Helsinki,Finland,false,false,"Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials (""may AI?""); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control."
pn9126,https://doi.org/10.1145/3290605.3300863,May AI? Design Ideation with Cooperative Contextual Bandits,3,Lena Hegemann,Aalto University,Helsinki,Finland,false,false,"Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials (""may AI?""); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control."
pn9126,https://doi.org/10.1145/3290605.3300863,May AI? Design Ideation with Cooperative Contextual Bandits,4,Antti Oulasvirta,Aalto University,Helsinki,Finland,false,false,"Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials (""may AI?""); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control."
pn4596,https://doi.org/10.1145/3290605.3300831,Designing Theory-Driven User-Centric Explainable AI,1,Danding Wang,National University of Singapore,Singapore,Singapore,false,false,"From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development."
pn4596,https://doi.org/10.1145/3290605.3300831,Designing Theory-Driven User-Centric Explainable AI,2,Qian Yang,Carnegie Mellon University,"Pittsburgh, Pa",United States,false,false,"From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development."
pn4596,https://doi.org/10.1145/3290605.3300831,Designing Theory-Driven User-Centric Explainable AI,3,Ashraf Abdul,National University of Singapore,Singapore,Singapore,false,false,"From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development."
pn4596,https://doi.org/10.1145/3290605.3300831,Designing Theory-Driven User-Centric Explainable AI,4,Brian Lim,National University of Singapore,Singapore,Singapore,false,false,"From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,1,Jon Mccormack,Monash University,Melbourne,Australia,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,2,Toby Gifford,Monash University,Melbourne,Australia,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,3,Patrick Hutchings,Monash University,Melbourne,Australia,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,4,Maria Teresa Llano Rodriguez,"Goldsmiths, University of London",London,United Kingdom,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,5,Matthew Yee-King,"Goldsmiths, University of London",London,United Kingdom,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn1743,https://doi.org/10.1145/3290605.3300268,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,6,Mark D'inverno,"Goldsmiths, University of London",London,United Kingdom,false,false,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement."
pn7897,https://doi.org/10.1145/3290605.3300641,Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI-powered Systems,1,Rafal Kocielnik,University of Washington,Seattle,United States,false,false,"AI technologies have been incorporated into many end-user applications. However, expectations of the capabilities of such systems vary among people. Furthermore, bloated expectations have been identified as negatively affecting perception and acceptance of such systems. Although the intelligibility of ML algorithms has been well studied, there has been little work on methods for setting appropriate expectations before the initial use of an AI-based system. In this work, we use a Scheduling Assistant - an AI system for automated meeting request detection in free-text email - to study the impact of several methods of expectation setting. We explore two versions of this system with the same 50% level of accuracy of the AI component but each designed with a different focus on the types of errors to avoid (avoiding False Positives vs. False Negatives). We show that such different focus can lead to vastly different subjective perceptions of accuracy and acceptance. Further, we design expectation adjustment techniques that prepare users for AI imperfections and result in a significant increase in acceptance."
pn7897,https://doi.org/10.1145/3290605.3300641,Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI-powered Systems,2,Saleema Amershi,Microsoft Research,Seattle,United States,false,false,"AI technologies have been incorporated into many end-user applications. However, expectations of the capabilities of such systems vary among people. Furthermore, bloated expectations have been identified as negatively affecting perception and acceptance of such systems. Although the intelligibility of ML algorithms has been well studied, there has been little work on methods for setting appropriate expectations before the initial use of an AI-based system. In this work, we use a Scheduling Assistant - an AI system for automated meeting request detection in free-text email - to study the impact of several methods of expectation setting. We explore two versions of this system with the same 50% level of accuracy of the AI component but each designed with a different focus on the types of errors to avoid (avoiding False Positives vs. False Negatives). We show that such different focus can lead to vastly different subjective perceptions of accuracy and acceptance. Further, we design expectation adjustment techniques that prepare users for AI imperfections and result in a significant increase in acceptance."
pn7897,https://doi.org/10.1145/3290605.3300641,Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI-powered Systems,3,Paul Bennett,Microsoft Research AI,Redmond,United States,false,false,"AI technologies have been incorporated into many end-user applications. However, expectations of the capabilities of such systems vary among people. Furthermore, bloated expectations have been identified as negatively affecting perception and acceptance of such systems. Although the intelligibility of ML algorithms has been well studied, there has been little work on methods for setting appropriate expectations before the initial use of an AI-based system. In this work, we use a Scheduling Assistant - an AI system for automated meeting request detection in free-text email - to study the impact of several methods of expectation setting. We explore two versions of this system with the same 50% level of accuracy of the AI component but each designed with a different focus on the types of errors to avoid (avoiding False Positives vs. False Negatives). We show that such different focus can lead to vastly different subjective perceptions of accuracy and acceptance. Further, we design expectation adjustment techniques that prepare users for AI imperfections and result in a significant increase in acceptance."
pn9509,https://doi.org/10.1145/3290605.3300388,Virtual Performance Augmentation in an Immersive Jump & Run Exergame,1,Christos Ioannou,University of Bath,Bath,United Kingdom,false,false,"Human performance augmentation through technology has been a recurring theme in science and culture, aiming to increase human capabilities and accessibility. We investigate a related concept: virtual performance augmentation (VPA), using VR to give users the illusion of greater capabilities than they actually have. We propose a method for VPA of running and jumping, based on in place movements, and studied its effects in a VR exergame. We found that in place running and jumping in VR can be used to create a somewhat natural experience and can elicit medium to high physical exertion in an immersive and intrinsically motivating manner. We also found that virtually augmenting running and jumping can increase intrinsic motivation, perceived competence and flow, and may also increase motivation for physical activity in general. We discuss implications of VPA for safety and accessibility, with initial evidence suggesting that VPA may help users with physical impairments enjoy the benefits of exergaming."
pn9509,https://doi.org/10.1145/3290605.3300388,Virtual Performance Augmentation in an Immersive Jump & Run Exergame,2,Patrick Archard,University of Bath,Bath,United Kingdom,false,false,"Human performance augmentation through technology has been a recurring theme in science and culture, aiming to increase human capabilities and accessibility. We investigate a related concept: virtual performance augmentation (VPA), using VR to give users the illusion of greater capabilities than they actually have. We propose a method for VPA of running and jumping, based on in place movements, and studied its effects in a VR exergame. We found that in place running and jumping in VR can be used to create a somewhat natural experience and can elicit medium to high physical exertion in an immersive and intrinsically motivating manner. We also found that virtually augmenting running and jumping can increase intrinsic motivation, perceived competence and flow, and may also increase motivation for physical activity in general. We discuss implications of VPA for safety and accessibility, with initial evidence suggesting that VPA may help users with physical impairments enjoy the benefits of exergaming."
pn9509,https://doi.org/10.1145/3290605.3300388,Virtual Performance Augmentation in an Immersive Jump & Run Exergame,3,Eamonn O'neill,University of Bath,Bath,United Kingdom,false,false,"Human performance augmentation through technology has been a recurring theme in science and culture, aiming to increase human capabilities and accessibility. We investigate a related concept: virtual performance augmentation (VPA), using VR to give users the illusion of greater capabilities than they actually have. We propose a method for VPA of running and jumping, based on in place movements, and studied its effects in a VR exergame. We found that in place running and jumping in VR can be used to create a somewhat natural experience and can elicit medium to high physical exertion in an immersive and intrinsically motivating manner. We also found that virtually augmenting running and jumping can increase intrinsic motivation, perceived competence and flow, and may also increase motivation for physical activity in general. We discuss implications of VPA for safety and accessibility, with initial evidence suggesting that VPA may help users with physical impairments enjoy the benefits of exergaming."
pn9509,https://doi.org/10.1145/3290605.3300388,Virtual Performance Augmentation in an Immersive Jump & Run Exergame,4,Christof Lutteroth,University of Auckland,Bath,United Kingdom,false,false,"Human performance augmentation through technology has been a recurring theme in science and culture, aiming to increase human capabilities and accessibility. We investigate a related concept: virtual performance augmentation (VPA), using VR to give users the illusion of greater capabilities than they actually have. We propose a method for VPA of running and jumping, based on in place movements, and studied its effects in a VR exergame. We found that in place running and jumping in VR can be used to create a somewhat natural experience and can elicit medium to high physical exertion in an immersive and intrinsically motivating manner. We also found that virtually augmenting running and jumping can increase intrinsic motivation, perceived competence and flow, and may also increase motivation for physical activity in general. We discuss implications of VPA for safety and accessibility, with initial evidence suggesting that VPA may help users with physical impairments enjoy the benefits of exergaming."
pn1674,https://doi.org/10.1145/3290605.3300811,Abstract Machines: Overlaying Virtual Worlds on Physical Rides,1,Paul Tennent,University of Nottingham,Nottingham,United Kingdom,false,false,"Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders."
pn1674,https://doi.org/10.1145/3290605.3300811,Abstract Machines: Overlaying Virtual Worlds on Physical Rides,2,Joe Marshall,University of Nottingham,Nottingham,United Kingdom,false,false,"Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders."
pn1674,https://doi.org/10.1145/3290605.3300811,Abstract Machines: Overlaying Virtual Worlds on Physical Rides,3,Patrick Brundell,University of Nottingham,Nottingham,United Kingdom,false,false,"Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders."
pn1674,https://doi.org/10.1145/3290605.3300811,Abstract Machines: Overlaying Virtual Worlds on Physical Rides,4,Brendan Walker,University of Nottingham,Nottingham,United Kingdom,false,false,"Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders."
pn1674,https://doi.org/10.1145/3290605.3300811,Abstract Machines: Overlaying Virtual Worlds on Physical Rides,5,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,1,Florian Mueller,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,2,Zhuying Li,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,3,Richard Byrne,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,4,Yash Mehta,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,5,Peter Arnold,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn7445,https://doi.org/10.1145/3290605.3300868,A 2nd Person Social Perspective on Bodily Play,6,Tuomas Kari,RMIT University,Melbourne,Australia,false,false,"Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological ""lived"" body) and a 3rd person perspective (the material ""fleshy"" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,1,Yongqi Zhang,University of Massachusetts Boston,Boston,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,2,Biao Xie,University of Massachusetts Boston,Boston,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,3,Haikun Huang,University of Massachusetts Boston,Boston,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,4,Elisa Ogawa,University of Massachusetts Boston,Boston,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,5,Tongjian You,University of Massachusetts Boston,Boston,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn8686,https://doi.org/10.1145/3290605.3300784,Pose-Guided Level Design,6,Lap-Fai Yu,George Mason University,Fairfax,United States,true,false,"Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach."
pn9454,https://doi.org/10.1145/3290605.3300246,Airport Accessibility and Navigation Assistance for People with Visual Impairments,1,João Guerreiro,Carnegie Mellon University,Pittsburgh,United States,false,false,"People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports."
pn9454,https://doi.org/10.1145/3290605.3300246,Airport Accessibility and Navigation Assistance for People with Visual Impairments,2,Dragan Ahmetovic,University of Turin\t,Torino,Italy,false,false,"People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports."
pn9454,https://doi.org/10.1145/3290605.3300246,Airport Accessibility and Navigation Assistance for People with Visual Impairments,3,Daisuke Sato,IBM Research - Tokyo,Tokyo,Japan,false,false,"People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports."
pn9454,https://doi.org/10.1145/3290605.3300246,Airport Accessibility and Navigation Assistance for People with Visual Impairments,4,Kris Kitani,Robotics Institute,Pittsburgh,United States,false,false,"People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports."
pn9454,https://doi.org/10.1145/3290605.3300246,Airport Accessibility and Navigation Assistance for People with Visual Impairments,5,Chieko Asakawa,Carnegie Mellon University,Pittsburgh,United States,false,false,"People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,1,Manaswi Saha,University of Washington,Seattle,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,2,Michael Saugstad,University of Washington,Seattle,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,3,Hanuma Teja Maddali,University of Maryland,College Park,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,4,Aileen Zeng,University of Washington,Seattle,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,5,Ryan Holland,Montgomery Blair High School,Silver Spring,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,6,Steven Bower,University of Maryland,College Park,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,7,Aditya Dash,University of Maryland,College Park,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,8,Sage Chen,University of Michigan,Ann Arbor,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,9,Anthony Li,University of Maryland,College Park,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,10,Kotaro Hara,Singapore Management University,Singapore,Singapore,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9161,https://doi.org/10.1145/3290605.3300292,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale,11,Jon Froehlich,University of Washington,Seattle,United States,false,true,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches."
pn9138,https://doi.org/10.1145/3290605.3300759,Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber,1,Sooyeon Lee,Pennsylvania State University,University Park,United States,false,false,"We used content analysis of in-app driver survey responses, customer support tickets, and tweets, and face-to-face interviews of DHH Uber drivers to better understand the DHH driver experience. Here we describe challenges DHH drivers experience and how they address those difficulties via Uber's accessibility features and their own workarounds. We also identify and discuss design and product opportunities to improve the DHH driver experience on Uber."
pn9138,https://doi.org/10.1145/3290605.3300759,Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber,2,Bjorn Hubert-Wallander,"Uber Technologies, Inc.",San Francisco,United States,false,false,"We used content analysis of in-app driver survey responses, customer support tickets, and tweets, and face-to-face interviews of DHH Uber drivers to better understand the DHH driver experience. Here we describe challenges DHH drivers experience and how they address those difficulties via Uber's accessibility features and their own workarounds. We also identify and discuss design and product opportunities to improve the DHH driver experience on Uber."
pn9138,https://doi.org/10.1145/3290605.3300759,Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber,3,Molly Stevens,"Uber Technologies, Inc.",San Francisco,United States,false,false,"We used content analysis of in-app driver survey responses, customer support tickets, and tweets, and face-to-face interviews of DHH Uber drivers to better understand the DHH driver experience. Here we describe challenges DHH drivers experience and how they address those difficulties via Uber's accessibility features and their own workarounds. We also identify and discuss design and product opportunities to improve the DHH driver experience on Uber."
pn9138,https://doi.org/10.1145/3290605.3300759,Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber,4,John Carroll,Pennsylvania State University,University Park,United States,false,false,"We used content analysis of in-app driver survey responses, customer support tickets, and tweets, and face-to-face interviews of DHH Uber drivers to better understand the DHH driver experience. Here we describe challenges DHH drivers experience and how they address those difficulties via Uber's accessibility features and their own workarounds. We also identify and discuss design and product opportunities to improve the DHH driver experience on Uber."
pn5693,https://doi.org/10.1145/3290605.3300425,"Understanding Trust, Transportation, and Accessibility through Ridesharing",1,Robin Brewer,University of Michigan,Ann Arbor,United States,false,false,"Relatively few studies of accessibility and transportation for people with vision impairments have investigated forms of transportation besides public transportation and walking. To develop a more nuanced understanding of this context, we turn to ridesharing, an increasingly used mode of transportation. We interviewed 16 visually-impaired individuals about their active use of ridesharing services like Uber and Lyft. Our findings show that, while people with vision impairments value independence, ridesharing involves building trust across a complex network of stakeholders and technologies. This data is used to start a discussion on how other systems can facilitate trust for people with vision impairments by considering the role of conversation, affordances of system incentives, and increased agency."
pn5693,https://doi.org/10.1145/3290605.3300425,"Understanding Trust, Transportation, and Accessibility through Ridesharing",2,Vaishnav Kameswaran,University of Michigan,Ann Arbor,United States,false,false,"Relatively few studies of accessibility and transportation for people with vision impairments have investigated forms of transportation besides public transportation and walking. To develop a more nuanced understanding of this context, we turn to ridesharing, an increasingly used mode of transportation. We interviewed 16 visually-impaired individuals about their active use of ridesharing services like Uber and Lyft. Our findings show that, while people with vision impairments value independence, ridesharing involves building trust across a complex network of stakeholders and technologies. This data is used to start a discussion on how other systems can facilitate trust for people with vision impairments by considering the role of conversation, affordances of system incentives, and increased agency."
pn4117,https://doi.org/10.1145/3290605.3300809,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,1,Fred Hohman,Georgia Institute of Technology,Atlanta,United States,false,false,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data."
pn4117,https://doi.org/10.1145/3290605.3300809,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,2,Andrew Head,"University of California, Berkeley",Berkeley,United States,false,false,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data."
pn4117,https://doi.org/10.1145/3290605.3300809,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,3,Rich Caruana,Microsoft Research,Redmond,United States,false,false,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data."
pn4117,https://doi.org/10.1145/3290605.3300809,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,4,Robert Deline,Microsoft Research,Redmond,United States,false,false,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data."
pn4117,https://doi.org/10.1145/3290605.3300809,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,5,Steven Drucker,Microsoft Research,Redmond,United States,false,false,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data."
pn9115,https://doi.org/10.1145/3290605.3300358,VizML: A Machine Learning Approach to Visualization Recommendation,1,Kevin Hu,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems."
pn9115,https://doi.org/10.1145/3290605.3300358,VizML: A Machine Learning Approach to Visualization Recommendation,2,Michiel Bakker,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems."
pn9115,https://doi.org/10.1145/3290605.3300358,VizML: A Machine Learning Approach to Visualization Recommendation,3,Stephen Li,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems."
pn9115,https://doi.org/10.1145/3290605.3300358,VizML: A Machine Learning Approach to Visualization Recommendation,4,Tim Kraska,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems."
pn9115,https://doi.org/10.1145/3290605.3300358,VizML: A Machine Learning Approach to Visualization Recommendation,5,César Hidalgo,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,1,Qianwen Wang,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,2,Yao Ming,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,3,Zhihua Jin,Zhejiang University,Hangzhou,China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,4,Qiaomu Shen,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,5,Dongyu Liu,Hong Kong University of Science and Technology,"Kowloon, Hong Kong",China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,6,Micah Smith,Massachusetts Institute of Technology,Cambridge,United States,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,7,Kalyan Veeramachaneni,Massachusetts Institute of Technology,Cambridge,United States,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn3891,https://doi.org/10.1145/3290605.3300911,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,8,Huamin Qu,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,1,Minsuk Choi,Korea University,Seoul,Republic Of Korea,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,2,Cheonbok Park,Korea University,Seoul,Republic Of Korea,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,3,Soyoung Yang,Korea University,Seoul,Republic Of Korea,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,4,Yonggyu Kim,Ajou University,Seoul,Republic Of Korea,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,5,Jaegul Choo,Korea University,Seoul,Republic Of Korea,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn9308,https://doi.org/10.1145/3290605.3300460,AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks,6,Sungsoo Hong,University of Washington,Seattle,United States,false,false,"Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,1,Alix Goguey,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,2,Cameron Steer,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,3,Andrés Lucero,Aalto University,Helsinki,Finland,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,4,Laurence Nigay,Université Grenoble Alpes,Grenoble,France,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,5,Deepak Sahoo,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,6,Céline Coutrix,CNRS,Grenoble,France,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,7,Anne Roudaut,University of Bristol,Bristol,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,8,Sriram Subramanian,University of Sussex,Brighton,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,9,Yutaka Tokuda,University of Sussex,Brighton,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,10,Timothy Neate,City University of London,London,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,11,Jennifer Pearson,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,12,Simon Robinson,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn6184,https://doi.org/10.1145/3290605.3300503,PickCells: A Physically Reconfigurable Cell-composed Touchscreen,13,Matt Jones,Swansea University,Swansea,United Kingdom,false,false,"Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping."
pn1430,https://doi.org/10.1145/3290605.3300456,Sustainabot – Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users,1,Simon Robinson,Swansea University,Swansea,United Kingdom,true,false,"Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot – a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-source mobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future."
pn1430,https://doi.org/10.1145/3290605.3300456,Sustainabot – Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users,2,Jennifer Pearson,Swansea University,Swansea,United Kingdom,true,false,"Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot – a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-source mobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future."
pn1430,https://doi.org/10.1145/3290605.3300456,Sustainabot – Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users,3,Mark Holton,Swansea University,Swansea,United Kingdom,true,false,"Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot – a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-source mobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future."
pn1430,https://doi.org/10.1145/3290605.3300456,Sustainabot – Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users,4,Shashank Ahire,Indian Institute of Technology Bombay,Mumbai,India,true,false,"Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot – a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-source mobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future."
pn1430,https://doi.org/10.1145/3290605.3300456,Sustainabot – Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users,5,Matt Jones,Swansea University,Swansea,United Kingdom,true,false,"Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot – a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-source mobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future."
pn4973,https://doi.org/10.1145/3290605.3300651,Analyzing the Use of Camera Glasses in the Wild,1,Taryn Bipat,University of Washington,Seattle,United States,false,false,"Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors."
pn4973,https://doi.org/10.1145/3290605.3300651,Analyzing the Use of Camera Glasses in the Wild,2,Maarten Bos,Snap Inc.,Santa Monica,United States,false,false,"Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors."
pn4973,https://doi.org/10.1145/3290605.3300651,Analyzing the Use of Camera Glasses in the Wild,3,Rajan Vaish,Snap Inc.,Santa Monica,United States,false,false,"Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors."
pn4973,https://doi.org/10.1145/3290605.3300651,Analyzing the Use of Camera Glasses in the Wild,4,Andrés Monroy-Hernández,Snap Inc.,Seattle,United States,false,false,"Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors."
pn4943,https://doi.org/10.1145/3290605.3300444,Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction,1,Aida Komkaite Komkaite,Aalborg University,Aalborg,Denmark,false,false,"During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this."
pn4943,https://doi.org/10.1145/3290605.3300444,Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction,2,Liga Lavrinovica,Aalborg University,Aalborg,Denmark,false,false,"During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this."
pn4943,https://doi.org/10.1145/3290605.3300444,Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction,3,Maria Vraka,Aalborg University,Aalborg,Denmark,false,false,"During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this."
pn4943,https://doi.org/10.1145/3290605.3300444,Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction,4,Mikael B. Skov,Aalborg University,Aalborg,Denmark,false,false,"During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this."
pn2771,https://doi.org/10.1145/3290605.3300558,The Effects of Interruption Timings on Autonomous Height-Adjustable Desks that Respond to Task Changes,1,Bokyung Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Actuated furniture, such as electric adjustable sit-stand desks, helps users vary their posture and contributes to comfort and health. However, studies found that users rarely initiate height changes. Therefore, in this paper, we look into furniture that adjusts itself to the user's needs. A situated interview study indicated task-changing as an opportune moment for automatic height adjustment. We then performed a Wizard of Oz study to find the best timing for changing desk height to minimize interruption and discomfort. The results are in line with prior work on task interruption in graphical user interfaces and show that the table should change height during a task change. However, results also indicate that until users build trust in the system, they prefer actuation after a task change to experience the impact of the adjustment. Based on the results, we discuss design guidelines for interactive desks with agency."
pn2771,https://doi.org/10.1145/3290605.3300558,The Effects of Interruption Timings on Autonomous Height-Adjustable Desks that Respond to Task Changes,2,Sindy Wu,University of Florida,Gainesville,United States,false,false,"Actuated furniture, such as electric adjustable sit-stand desks, helps users vary their posture and contributes to comfort and health. However, studies found that users rarely initiate height changes. Therefore, in this paper, we look into furniture that adjusts itself to the user's needs. A situated interview study indicated task-changing as an opportune moment for automatic height adjustment. We then performed a Wizard of Oz study to find the best timing for changing desk height to minimize interruption and discomfort. The results are in line with prior work on task interruption in graphical user interfaces and show that the table should change height during a task change. However, results also indicate that until users build trust in the system, they prefer actuation after a task change to experience the impact of the adjustment. Based on the results, we discuss design guidelines for interactive desks with agency."
pn2771,https://doi.org/10.1145/3290605.3300558,The Effects of Interruption Timings on Autonomous Height-Adjustable Desks that Respond to Task Changes,3,Maria Reyes,KAIST,Daejeon,Republic Of Korea,false,false,"Actuated furniture, such as electric adjustable sit-stand desks, helps users vary their posture and contributes to comfort and health. However, studies found that users rarely initiate height changes. Therefore, in this paper, we look into furniture that adjusts itself to the user's needs. A situated interview study indicated task-changing as an opportune moment for automatic height adjustment. We then performed a Wizard of Oz study to find the best timing for changing desk height to minimize interruption and discomfort. The results are in line with prior work on task interruption in graphical user interfaces and show that the table should change height during a task change. However, results also indicate that until users build trust in the system, they prefer actuation after a task change to experience the impact of the adjustment. Based on the results, we discuss design guidelines for interactive desks with agency."
pn2771,https://doi.org/10.1145/3290605.3300558,The Effects of Interruption Timings on Autonomous Height-Adjustable Desks that Respond to Task Changes,4,Daniel Saakes,KAIST,Daejeon,Republic Of Korea,false,false,"Actuated furniture, such as electric adjustable sit-stand desks, helps users vary their posture and contributes to comfort and health. However, studies found that users rarely initiate height changes. Therefore, in this paper, we look into furniture that adjusts itself to the user's needs. A situated interview study indicated task-changing as an opportune moment for automatic height adjustment. We then performed a Wizard of Oz study to find the best timing for changing desk height to minimize interruption and discomfort. The results are in line with prior work on task interruption in graphical user interfaces and show that the table should change height during a task change. However, results also indicate that until users build trust in the system, they prefer actuation after a task change to experience the impact of the adjustment. Based on the results, we discuss design guidelines for interactive desks with agency."
pn1301,https://doi.org/10.1145/3290605.3300808,DreamGigs: Designing a Tool to Empower Low-Resource Job Seekers,1,Tawanna Dillahunt,University of Michigan,Ann Arbor,United States,false,false,"Technology allows us to scale the number of jobs we search for and apply to, train for work, and earn money online. However, these technologies do not benefit all job seekers equally and must be designed to better support the needs of underserved job seekers. Research suggests that underserved job seekers prefer employment technologies that can support them in articulating their skills and experiences and in identifying pathways to achieve their career goals. Therefore, we present the design, implementation, and evaluation of DreamGigs, a tool that identifies the skills job seekers need to reach their dream jobs and presents volunteer and employment opportunities for them to acquire those skills. Our evaluation results show that DreamGigs aids in the process of personal empowerment. We contribute design implications for mitigating aspects of powerlessness that low-resource job seekers experience and discuss ways to promote action-taking in these job seekers."
pn1301,https://doi.org/10.1145/3290605.3300808,DreamGigs: Designing a Tool to Empower Low-Resource Job Seekers,2,Alex Lu,University of Michigan,Ann Arbor,United States,false,false,"Technology allows us to scale the number of jobs we search for and apply to, train for work, and earn money online. However, these technologies do not benefit all job seekers equally and must be designed to better support the needs of underserved job seekers. Research suggests that underserved job seekers prefer employment technologies that can support them in articulating their skills and experiences and in identifying pathways to achieve their career goals. Therefore, we present the design, implementation, and evaluation of DreamGigs, a tool that identifies the skills job seekers need to reach their dream jobs and presents volunteer and employment opportunities for them to acquire those skills. Our evaluation results show that DreamGigs aids in the process of personal empowerment. We contribute design implications for mitigating aspects of powerlessness that low-resource job seekers experience and discuss ways to promote action-taking in these job seekers."
pn3075,https://doi.org/10.1145/3290605.3300640,"Design Considerations for Interactive Office Lighting: Interface Characteristics, Shared and Hybrid Control",1,Thomas Van De Werff,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"The inclusion of IoT in office lighting allows people to have personal lighting control at their workplace. To design lighting control interfaces that fit people's everyday living, we need a better understanding of how people experience lighting interaction in the real world. Still, lighting control is often explored in controlled settings. This work presents a qualitative field study concerning the user experience of two control interfaces for a state-of-the-art lighting system of 400+ luminaires in a real-life office. In ten weeks, 43 people interacted 3937 times. The findings illustrate the effects of using a smartphone for lighting control, how people experience lighting control in shared situations, and issues with automatic system behavior. We define design considerations for interface characteristics, shared control, and hybrid control. The work contributes to making the potential benefits of interactive office lighting a reality."
pn3075,https://doi.org/10.1145/3290605.3300640,"Design Considerations for Interactive Office Lighting: Interface Characteristics, Shared and Hybrid Control",2,Charlotte Van Lotringen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"The inclusion of IoT in office lighting allows people to have personal lighting control at their workplace. To design lighting control interfaces that fit people's everyday living, we need a better understanding of how people experience lighting interaction in the real world. Still, lighting control is often explored in controlled settings. This work presents a qualitative field study concerning the user experience of two control interfaces for a state-of-the-art lighting system of 400+ luminaires in a real-life office. In ten weeks, 43 people interacted 3937 times. The findings illustrate the effects of using a smartphone for lighting control, how people experience lighting control in shared situations, and issues with automatic system behavior. We define design considerations for interface characteristics, shared control, and hybrid control. The work contributes to making the potential benefits of interactive office lighting a reality."
pn3075,https://doi.org/10.1145/3290605.3300640,"Design Considerations for Interactive Office Lighting: Interface Characteristics, Shared and Hybrid Control",3,Harm Van Essen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"The inclusion of IoT in office lighting allows people to have personal lighting control at their workplace. To design lighting control interfaces that fit people's everyday living, we need a better understanding of how people experience lighting interaction in the real world. Still, lighting control is often explored in controlled settings. This work presents a qualitative field study concerning the user experience of two control interfaces for a state-of-the-art lighting system of 400+ luminaires in a real-life office. In ten weeks, 43 people interacted 3937 times. The findings illustrate the effects of using a smartphone for lighting control, how people experience lighting control in shared situations, and issues with automatic system behavior. We define design considerations for interface characteristics, shared control, and hybrid control. The work contributes to making the potential benefits of interactive office lighting a reality."
pn3075,https://doi.org/10.1145/3290605.3300640,"Design Considerations for Interactive Office Lighting: Interface Characteristics, Shared and Hybrid Control",4,Berry Eggen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"The inclusion of IoT in office lighting allows people to have personal lighting control at their workplace. To design lighting control interfaces that fit people's everyday living, we need a better understanding of how people experience lighting interaction in the real world. Still, lighting control is often explored in controlled settings. This work presents a qualitative field study concerning the user experience of two control interfaces for a state-of-the-art lighting system of 400+ luminaires in a real-life office. In ten weeks, 43 people interacted 3937 times. The findings illustrate the effects of using a smartphone for lighting control, how people experience lighting control in shared situations, and issues with automatic system behavior. We define design considerations for interface characteristics, shared control, and hybrid control. The work contributes to making the potential benefits of interactive office lighting a reality."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,1,Manu Chopra,Microsoft Research India,Bangalore,India,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,2,Indrani Medhi Thies,Microsoft Research India,Bangalore,India,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,3,Joyojeet Pal,Microsoft Research India,Bangalore,India,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,4,Colin Scott,Microsoft Research India,Bangalore,India,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,5,William Thies,Microsoft Research India,Cambridge,United States,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn7983,https://doi.org/10.1145/3290605.3300611,Exploring Crowdsourced Work in Low-Resource Settings,6,Vivek Seshadri,Microsoft Research India,Bangalore,India,false,false,"While researchers have studied the benefits and hazards of crowdsourcing for diverse classes of workers, most work has focused on those having high familiarity with both computers and English. We explore whether paid crowdsourcing can be inclusive of individuals in rural India, who are relatively new to digital devices and literate mainly in local languages. We built an Android application to measure the accuracy with which participants can digitize handwritten Marathi/Hindi words. The tasks were based on the real-world need for digitizing handwritten Devanagari script documents. Results from a two-week, mixed-methods study show that participants achieved 96.7% accuracy in digitizing handwritten words on low-end smartphones. A crowdsourcing platform that employs these users performs comparably to a professional transcription firm. Participants showed overwhelming enthusiasm for completing tasks, so much so that we recommend imposing limits to prevent overuse of the application. We discuss the implications of these results for crowdsourcing in low-resource areas."
pn9492,https://doi.org/10.1145/3290605.3300481,Recipes for Programmable Money,1,Chris Elsden,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app – Monzo – with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT 'recipes' shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of 'programmable money' and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy."
pn9492,https://doi.org/10.1145/3290605.3300481,Recipes for Programmable Money,2,Tom Feltwell,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app – Monzo – with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT 'recipes' shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of 'programmable money' and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy."
pn9492,https://doi.org/10.1145/3290605.3300481,Recipes for Programmable Money,3,Shaun Lawson,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app – Monzo – with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT 'recipes' shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of 'programmable money' and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy."
pn9492,https://doi.org/10.1145/3290605.3300481,Recipes for Programmable Money,4,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app – Monzo – with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT 'recipes' shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of 'programmable money' and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy."
pn2311,https://doi.org/10.1145/3290605.3300399,ReCall: Crowdsourcing on Basic Phones to Financially Sustain Voice Forums,1,Aditya Vashistha,University of Washington,Seattle,United States,false,false,"Although voice forums are widely used to enable marginalized communities to produce, consume, and share information, their financial sustainability is a key concern among HCI4D researchers and practitioners. We present ReCall, a crowdsourcing marketplace accessible via phone calls where low-income rural residents vocally transcribe audio files to gain free airtime to participate in voice forums as well as to earn money. We conducted a series of experimental and usability evaluations with 28 low-income people in rural India to examine the effect of phone types, channel types, and review modes on speech transcription performance. We then deployed ReCall for two weeks to 24 low-income rural residents who placed 5,879 phone calls, completed 29,000 micro tasks to yield transcriptions with 85% accuracy, and earned INR 20,500. Our mixed-methods analysis indicates that each minute of crowd work on ReCall gives users eight minutes of free airtime on another voice forum, and thus illustrates a way to address the financial sustainability of voice forums."
pn2311,https://doi.org/10.1145/3290605.3300399,ReCall: Crowdsourcing on Basic Phones to Financially Sustain Voice Forums,2,Abhinav Garg,University of Washington,Seattle,United States,false,false,"Although voice forums are widely used to enable marginalized communities to produce, consume, and share information, their financial sustainability is a key concern among HCI4D researchers and practitioners. We present ReCall, a crowdsourcing marketplace accessible via phone calls where low-income rural residents vocally transcribe audio files to gain free airtime to participate in voice forums as well as to earn money. We conducted a series of experimental and usability evaluations with 28 low-income people in rural India to examine the effect of phone types, channel types, and review modes on speech transcription performance. We then deployed ReCall for two weeks to 24 low-income rural residents who placed 5,879 phone calls, completed 29,000 micro tasks to yield transcriptions with 85% accuracy, and earned INR 20,500. Our mixed-methods analysis indicates that each minute of crowd work on ReCall gives users eight minutes of free airtime on another voice forum, and thus illustrates a way to address the financial sustainability of voice forums."
pn2311,https://doi.org/10.1145/3290605.3300399,ReCall: Crowdsourcing on Basic Phones to Financially Sustain Voice Forums,3,Richard Anderson,University of Washington,Seattle,United States,false,false,"Although voice forums are widely used to enable marginalized communities to produce, consume, and share information, their financial sustainability is a key concern among HCI4D researchers and practitioners. We present ReCall, a crowdsourcing marketplace accessible via phone calls where low-income rural residents vocally transcribe audio files to gain free airtime to participate in voice forums as well as to earn money. We conducted a series of experimental and usability evaluations with 28 low-income people in rural India to examine the effect of phone types, channel types, and review modes on speech transcription performance. We then deployed ReCall for two weeks to 24 low-income rural residents who placed 5,879 phone calls, completed 29,000 micro tasks to yield transcriptions with 85% accuracy, and earned INR 20,500. Our mixed-methods analysis indicates that each minute of crowd work on ReCall gives users eight minutes of free airtime on another voice forum, and thus illustrates a way to address the financial sustainability of voice forums."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,1,Maryam Mustafa,Information Technology University,Lahore,Pakistan,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,2,Noor Mazhar,Information Technology University,Lahore,Pakistan,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,3,Ayesha Asghar,Information Technology University Lahore,Lahore,Pakistan,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,4,Maryem Usmani,Information Technology University,Lahore,Pakistan,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,5,Lubna Razaq,Information Technology University,Lahore,Pakistan,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn4878,https://doi.org/10.1145/3290605.3300490,Digital Financial Needs of Micro-entrepreneur Women in Pakistan: Is Mobile Money The Answer?,6,Richard Anderson,University of Washington,Seattle,United States,false,false,"This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them."
pn5769,https://doi.org/10.1145/3290605.3300620,Follow the Money: Managing Personal Finance Digitally,1,Makayla Lewis,Brunel University London,London,United Kingdom,false,false,"The move towards digital payments and mobile money, and away from physical cash and banking services offers users opportunities to change the ways that they can spend, save and manage their money through a variety of personal financial management services. However, set against ordinary, everyday patterns of spending, saving and other forms of financial transaction, it is not clear how users might interact with, understand, or value financial management services that utilise rich data and connected digital content for their personal use. In order to explore how people might engage with such systems, we conducted a study of financial activity, following people's transactional activity over time, and interviewing them about their practices, understandings, needs, concerns and expectations of current and future financial technologies. Drawing from the everyday activities and practices observed, we identify implications for the design of digitally enabled, personal financial systems."
pn5769,https://doi.org/10.1145/3290605.3300620,Follow the Money: Managing Personal Finance Digitally,2,Mark Perry,Brunel University London,London,United Kingdom,false,false,"The move towards digital payments and mobile money, and away from physical cash and banking services offers users opportunities to change the ways that they can spend, save and manage their money through a variety of personal financial management services. However, set against ordinary, everyday patterns of spending, saving and other forms of financial transaction, it is not clear how users might interact with, understand, or value financial management services that utilise rich data and connected digital content for their personal use. In order to explore how people might engage with such systems, we conducted a study of financial activity, following people's transactional activity over time, and interviewing them about their practices, understandings, needs, concerns and expectations of current and future financial technologies. Drawing from the everyday activities and practices observed, we identify implications for the design of digitally enabled, personal financial systems."
pn7810,https://doi.org/10.1145/3290605.3300783,Evaluating Expert Curation in a Baby Milestone Tracking App,1,Ayelet Ben-Sasson,University of Haifa,Haifa,Israel,false,false,"Early childhood developmental screening is critical for timely detection and intervention. babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive developmental tracking mobile app with over 3,000 children's diaries. Parents write or select short milestone texts, like ""began taking first steps,"" to record their babies' developmental achievements, and receive crowd-based percentiles to evaluate development and catch potential delays.<br>Currently, an expert-based Curated Crowd Intelligence (CCI) process manually groups incoming novel parent-authored milestone texts according to their similarity to existing milestones in the database (for example, starting to walk), or determining that the milestone represents a new developmental concept not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS is mature enough, with a rich enough database of existing milestone texts, to now consider machine learning tools to replace or assist the human curators. Three new studies explore (1) the usefulness of automation, by analyzing the human cost of CCI and how the work is currently broken down; (2) the validity of automation, by testing the inter-rater reliability of curators; and (3) the value of automation, by appraising the ""real world"" clinical value of milestones when assessing child development.<br>We conclude that automation can indeed be appropriate and helpful for a large percentage, though not all, of CCI work. We further establish realistic upper bounds for algorithm performance; confirm that the babyTRACKS milestones dataset is valid for training and testing purposes; and verify that it represents clinically meaningful developmental information."
pn7810,https://doi.org/10.1145/3290605.3300783,Evaluating Expert Curation in a Baby Milestone Tracking App,2,Eli Ben-Sasson,Technion,Haifa,Israel,false,false,"Early childhood developmental screening is critical for timely detection and intervention. babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive developmental tracking mobile app with over 3,000 children's diaries. Parents write or select short milestone texts, like ""began taking first steps,"" to record their babies' developmental achievements, and receive crowd-based percentiles to evaluate development and catch potential delays.<br>Currently, an expert-based Curated Crowd Intelligence (CCI) process manually groups incoming novel parent-authored milestone texts according to their similarity to existing milestones in the database (for example, starting to walk), or determining that the milestone represents a new developmental concept not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS is mature enough, with a rich enough database of existing milestone texts, to now consider machine learning tools to replace or assist the human curators. Three new studies explore (1) the usefulness of automation, by analyzing the human cost of CCI and how the work is currently broken down; (2) the validity of automation, by testing the inter-rater reliability of curators; and (3) the value of automation, by appraising the ""real world"" clinical value of milestones when assessing child development.<br>We conclude that automation can indeed be appropriate and helpful for a large percentage, though not all, of CCI work. We further establish realistic upper bounds for algorithm performance; confirm that the babyTRACKS milestones dataset is valid for training and testing purposes; and verify that it represents clinically meaningful developmental information."
pn7810,https://doi.org/10.1145/3290605.3300783,Evaluating Expert Curation in a Baby Milestone Tracking App,3,Kayla Jacobs,Technion,Haifa,Israel,false,false,"Early childhood developmental screening is critical for timely detection and intervention. babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive developmental tracking mobile app with over 3,000 children's diaries. Parents write or select short milestone texts, like ""began taking first steps,"" to record their babies' developmental achievements, and receive crowd-based percentiles to evaluate development and catch potential delays.<br>Currently, an expert-based Curated Crowd Intelligence (CCI) process manually groups incoming novel parent-authored milestone texts according to their similarity to existing milestones in the database (for example, starting to walk), or determining that the milestone represents a new developmental concept not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS is mature enough, with a rich enough database of existing milestone texts, to now consider machine learning tools to replace or assist the human curators. Three new studies explore (1) the usefulness of automation, by analyzing the human cost of CCI and how the work is currently broken down; (2) the validity of automation, by testing the inter-rater reliability of curators; and (3) the value of automation, by appraising the ""real world"" clinical value of milestones when assessing child development.<br>We conclude that automation can indeed be appropriate and helpful for a large percentage, though not all, of CCI work. We further establish realistic upper bounds for algorithm performance; confirm that the babyTRACKS milestones dataset is valid for training and testing purposes; and verify that it represents clinically meaningful developmental information."
pn7810,https://doi.org/10.1145/3290605.3300783,Evaluating Expert Curation in a Baby Milestone Tracking App,4,Elisheva Argaman,Technion,Haifa,Israel,false,false,"Early childhood developmental screening is critical for timely detection and intervention. babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive developmental tracking mobile app with over 3,000 children's diaries. Parents write or select short milestone texts, like ""began taking first steps,"" to record their babies' developmental achievements, and receive crowd-based percentiles to evaluate development and catch potential delays.<br>Currently, an expert-based Curated Crowd Intelligence (CCI) process manually groups incoming novel parent-authored milestone texts according to their similarity to existing milestones in the database (for example, starting to walk), or determining that the milestone represents a new developmental concept not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS is mature enough, with a rich enough database of existing milestone texts, to now consider machine learning tools to replace or assist the human curators. Three new studies explore (1) the usefulness of automation, by analyzing the human cost of CCI and how the work is currently broken down; (2) the validity of automation, by testing the inter-rater reliability of curators; and (3) the value of automation, by appraising the ""real world"" clinical value of milestones when assessing child development.<br>We conclude that automation can indeed be appropriate and helpful for a large percentage, though not all, of CCI work. We further establish realistic upper bounds for algorithm performance; confirm that the babyTRACKS milestones dataset is valid for training and testing purposes; and verify that it represents clinically meaningful developmental information."
pn7810,https://doi.org/10.1145/3290605.3300783,Evaluating Expert Curation in a Baby Milestone Tracking App,5,Eden Saig,Technion,Haifa,Israel,false,false,"Early childhood developmental screening is critical for timely detection and intervention. babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive developmental tracking mobile app with over 3,000 children's diaries. Parents write or select short milestone texts, like ""began taking first steps,"" to record their babies' developmental achievements, and receive crowd-based percentiles to evaluate development and catch potential delays.<br>Currently, an expert-based Curated Crowd Intelligence (CCI) process manually groups incoming novel parent-authored milestone texts according to their similarity to existing milestones in the database (for example, starting to walk), or determining that the milestone represents a new developmental concept not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS is mature enough, with a rich enough database of existing milestone texts, to now consider machine learning tools to replace or assist the human curators. Three new studies explore (1) the usefulness of automation, by analyzing the human cost of CCI and how the work is currently broken down; (2) the validity of automation, by testing the inter-rater reliability of curators; and (3) the value of automation, by appraising the ""real world"" clinical value of milestones when assessing child development.<br>We conclude that automation can indeed be appropriate and helpful for a large percentage, though not all, of CCI work. We further establish realistic upper bounds for algorithm performance; confirm that the babyTRACKS milestones dataset is valid for training and testing purposes; and verify that it represents clinically meaningful developmental information."
pn6662,https://doi.org/10.1145/3290605.3300891,Breakdowns in Home-School Collaboration for Behavioral Intervention,1,Gabriela Marcu,University of Michigan,Ann Arbor,United States,false,false,"For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, home-school collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children."
pn6662,https://doi.org/10.1145/3290605.3300891,Breakdowns in Home-School Collaboration for Behavioral Intervention,2,Allison Spiller,University of Michigan,Ann Arbor,United States,false,false,"For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, home-school collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children."
pn6662,https://doi.org/10.1145/3290605.3300891,Breakdowns in Home-School Collaboration for Behavioral Intervention,3,Jonathan Arevalo Garay,Drexel University,Philadelphia,United States,false,false,"For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, home-school collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children."
pn6662,https://doi.org/10.1145/3290605.3300891,Breakdowns in Home-School Collaboration for Behavioral Intervention,4,James Connell,Drexel University,Philadelphia,United States,false,false,"For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, home-school collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children."
pn6662,https://doi.org/10.1145/3290605.3300891,Breakdowns in Home-School Collaboration for Behavioral Intervention,5,Laura Pina,University of Washington,Seattle,United States,false,false,"For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, home-school collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children."
pn5259,https://doi.org/10.1145/3290605.3300671,Making Diabetes Education Interactive: Tangible Educational Toys for Children with Type-1 Diabetes,1,Charalampos Kyfonidis,University of Strathclyde,Glasgow,United Kingdom,false,false,"Younger children (under 9 years) with type-1 diabetes are often very passive in the management of their condition and can face difficulties in accessing and understanding basic diabetes related information. This can make transitioning to self-management in later years very challenging. Previous research has mostly focused on educational interventions for older children.<br>To create an educational tool which can support the diabetes educational process of younger children, we conducted a multiphase and multi-stakeholder user-centred design process. The result is an interactive tool that illustrates diabetes concepts in an age-appropriate way with the use of tangible toys. The tool was evaluated inside a paediatric diabetes clinic with clinicians, children and parents and was found to be engaging, acceptable and effective. In addition to providing implications for the design and adoption of educational tools for children in a clinical setting, we discuss the challenges for conducting user-centred design in such a setting."
pn5259,https://doi.org/10.1145/3290605.3300671,Making Diabetes Education Interactive: Tangible Educational Toys for Children with Type-1 Diabetes,2,Marilyn Lennon,University of Strathclyde,Glasgow,United Kingdom,false,false,"Younger children (under 9 years) with type-1 diabetes are often very passive in the management of their condition and can face difficulties in accessing and understanding basic diabetes related information. This can make transitioning to self-management in later years very challenging. Previous research has mostly focused on educational interventions for older children.<br>To create an educational tool which can support the diabetes educational process of younger children, we conducted a multiphase and multi-stakeholder user-centred design process. The result is an interactive tool that illustrates diabetes concepts in an age-appropriate way with the use of tangible toys. The tool was evaluated inside a paediatric diabetes clinic with clinicians, children and parents and was found to be engaging, acceptable and effective. In addition to providing implications for the design and adoption of educational tools for children in a clinical setting, we discuss the challenges for conducting user-centred design in such a setting."
pn8114,https://doi.org/10.1145/3290605.3300266,Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home,1,Alissa Antle,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"About 18% of children in industrialized countries suffer from anxiety. We designed a mobile neurofeedback app, called Mind-Full, based on existing design guidelines. Our goal was for young children in lower socio-economic status schools to improve their ability to self-regulate anxiety by using Mind-Full. In this paper we report on quantitative outcomes from a sixteen-week field evaluation with 20 young children (aged 5 to 8). Our methodological contribution includes using a control group, validated measures of anxiety and stress, and assessing transfer and maintenance. Results from teacher and parent behavioral surveys indicated gains in children's ability to self-regulate anxiety at school and home; a decrease in anxious behaviors at home; and cortisol tests showed variable improvement in physiological stress levels. We contribute to HCI for mental health with evidence that it is viable to use a mobile app in lower socio-economic status schools to improve children's mental health."
pn8114,https://doi.org/10.1145/3290605.3300266,Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home,2,Elgin-Skye Mclaren,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"About 18% of children in industrialized countries suffer from anxiety. We designed a mobile neurofeedback app, called Mind-Full, based on existing design guidelines. Our goal was for young children in lower socio-economic status schools to improve their ability to self-regulate anxiety by using Mind-Full. In this paper we report on quantitative outcomes from a sixteen-week field evaluation with 20 young children (aged 5 to 8). Our methodological contribution includes using a control group, validated measures of anxiety and stress, and assessing transfer and maintenance. Results from teacher and parent behavioral surveys indicated gains in children's ability to self-regulate anxiety at school and home; a decrease in anxious behaviors at home; and cortisol tests showed variable improvement in physiological stress levels. We contribute to HCI for mental health with evidence that it is viable to use a mobile app in lower socio-economic status schools to improve children's mental health."
pn8114,https://doi.org/10.1145/3290605.3300266,Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home,3,Holly Fiedler,Langara College,Burnaby/Surrey/Vancouver,Canada,false,false,"About 18% of children in industrialized countries suffer from anxiety. We designed a mobile neurofeedback app, called Mind-Full, based on existing design guidelines. Our goal was for young children in lower socio-economic status schools to improve their ability to self-regulate anxiety by using Mind-Full. In this paper we report on quantitative outcomes from a sixteen-week field evaluation with 20 young children (aged 5 to 8). Our methodological contribution includes using a control group, validated measures of anxiety and stress, and assessing transfer and maintenance. Results from teacher and parent behavioral surveys indicated gains in children's ability to self-regulate anxiety at school and home; a decrease in anxious behaviors at home; and cortisol tests showed variable improvement in physiological stress levels. We contribute to HCI for mental health with evidence that it is viable to use a mobile app in lower socio-economic status schools to improve children's mental health."
pn8114,https://doi.org/10.1145/3290605.3300266,Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home,4,Naomi Johnson,Social Work Independent Consultant,Toronto,Canada,false,false,"About 18% of children in industrialized countries suffer from anxiety. We designed a mobile neurofeedback app, called Mind-Full, based on existing design guidelines. Our goal was for young children in lower socio-economic status schools to improve their ability to self-regulate anxiety by using Mind-Full. In this paper we report on quantitative outcomes from a sixteen-week field evaluation with 20 young children (aged 5 to 8). Our methodological contribution includes using a control group, validated measures of anxiety and stress, and assessing transfer and maintenance. Results from teacher and parent behavioral surveys indicated gains in children's ability to self-regulate anxiety at school and home; a decrease in anxious behaviors at home; and cortisol tests showed variable improvement in physiological stress levels. We contribute to HCI for mental health with evidence that it is viable to use a mobile app in lower socio-economic status schools to improve children's mental health."
pn7796,https://doi.org/10.1145/3290605.3300395,HotStrokes: Word-Gesture Shortcuts on a Trackpad,1,Wenzhe Cui,Stony Brook University,Stony Brook,United States,false,false,"Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing ""menu and hotkey"" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall."
pn7796,https://doi.org/10.1145/3290605.3300395,HotStrokes: Word-Gesture Shortcuts on a Trackpad,2,Jingjie Zheng,Google,Kitchener,Canada,false,false,"Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing ""menu and hotkey"" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall."
pn7796,https://doi.org/10.1145/3290605.3300395,HotStrokes: Word-Gesture Shortcuts on a Trackpad,3,Blaine Lewis,University of Waterloo,Waterloo,Canada,false,false,"Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing ""menu and hotkey"" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall."
pn7796,https://doi.org/10.1145/3290605.3300395,HotStrokes: Word-Gesture Shortcuts on a Trackpad,4,Daniel Vogel,University of Waterloo,Waterloo,Canada,false,false,"Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing ""menu and hotkey"" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall."
pn7796,https://doi.org/10.1145/3290605.3300395,HotStrokes: Word-Gesture Shortcuts on a Trackpad,5,Xiaojun Bi,Stony Brook University,Stony Brook,United States,false,false,"Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing ""menu and hotkey"" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall."
pn6998,https://doi.org/10.1145/3290605.3300678,i'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control,1,Suwen Zhu,Stony Brook University,Stony Brook,United States,false,false,"Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i'sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i'sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users."
pn6998,https://doi.org/10.1145/3290605.3300678,i'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control,2,Jingjie Zheng,Google,Kitchener,Canada,false,false,"Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i'sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i'sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users."
pn6998,https://doi.org/10.1145/3290605.3300678,i'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control,3,Shumin Zhai,Google,Mountain View,United States,false,false,"Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i'sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i'sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users."
pn6998,https://doi.org/10.1145/3290605.3300678,i'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control,4,Xiaojun Bi,Stony Brook University,Stony Brook,United States,false,false,"Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i'sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i'sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,1,Weinan Shi,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,2,Chun Yu,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,3,Shuyi Fan,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,4,Feng Wang,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,5,Tong Wang,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,6,Xin Yi,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,7,Xiaojun Bi,Stony Brook University,Stony Brook,United States,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn8646,https://doi.org/10.1145/3290605.3300747,VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction,8,Yuanchun Shi,Tsinghua University,Beijing,China,true,false,"Modern touchscreen keyboards are all powered by the word-level auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such benefit because a screen-reader keyboard offers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users' touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,1,Keith Vertanen,Michigan Technological University,Houghton,United States,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,2,Dylan Gaines,Michigan Technological University,Houghton,United States,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,3,Crystal Fletcher,Michigan Technological University,Houghton,United States,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,4,Alex Stanage,Michigan Technological University,Houghton,United States,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,5,Robbie Watling,Michigan Technological University,Houghton,United States,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn6723,https://doi.org/10.1145/3290605.3300821,VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text,6,Per Ola Kristensson,University of Cambridge,Cambridge,United Kingdom,false,false,"Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct."
pn3054,https://doi.org/10.1145/3290605.3300450,ElasticVR: Providing Multilevel Continuously-Changing Resistive Force and Instant Impact Using Elasticity for VR,1,Hsin-Ruey Tsai,National Taiwan University,Taipei,Taiwan Roc,false,false,"Resistive force (e.g., due to object elasticity) and impact (e.g., due to recoil) are common effects in our daily life. However, resistive force continuously changes due to users' movements while impact instantly occurs when an event triggers it. These feedback are still not realistically provided by current VR haptic methods. In this paper, a wearable device, ElasticVR, which consists of an elastic band, servo motors and mechanical brakes, is proposed to provide the continuously-changing resistive force and instantly-occurring impact upon the user's hand to enhance VR realism. By changing two physical properties, length and extension distance, of the elastic band, ElasticVR provides multilevel resistive force with no delay and impact with little delay, respectively, for realistic and versatile VR applications. A force perception study was performed to observe users' force distinguishability of the resistive force and impact, and the prototype was built based on its results. A VR experience study further proves that the resistive force and impact from ElasticVR both outperform those from current approaches in realism. Applications using ElasticVR are also demonstrated."
pn3054,https://doi.org/10.1145/3290605.3300450,ElasticVR: Providing Multilevel Continuously-Changing Resistive Force and Instant Impact Using Elasticity for VR,2,Jun Rekimoto,University of Tokyo,Tokyo,Japan,false,false,"Resistive force (e.g., due to object elasticity) and impact (e.g., due to recoil) are common effects in our daily life. However, resistive force continuously changes due to users' movements while impact instantly occurs when an event triggers it. These feedback are still not realistically provided by current VR haptic methods. In this paper, a wearable device, ElasticVR, which consists of an elastic band, servo motors and mechanical brakes, is proposed to provide the continuously-changing resistive force and instantly-occurring impact upon the user's hand to enhance VR realism. By changing two physical properties, length and extension distance, of the elastic band, ElasticVR provides multilevel resistive force with no delay and impact with little delay, respectively, for realistic and versatile VR applications. A force perception study was performed to observe users' force distinguishability of the resistive force and impact, and the prototype was built based on its results. A VR experience study further proves that the resistive force and impact from ElasticVR both outperform those from current approaches in realism. Applications using ElasticVR are also demonstrated."
pn3054,https://doi.org/10.1145/3290605.3300450,ElasticVR: Providing Multilevel Continuously-Changing Resistive Force and Instant Impact Using Elasticity for VR,3,Bing-Yu Chen,National Taiwan University,Taipei,Taiwan Roc,false,false,"Resistive force (e.g., due to object elasticity) and impact (e.g., due to recoil) are common effects in our daily life. However, resistive force continuously changes due to users' movements while impact instantly occurs when an event triggers it. These feedback are still not realistically provided by current VR haptic methods. In this paper, a wearable device, ElasticVR, which consists of an elastic band, servo motors and mechanical brakes, is proposed to provide the continuously-changing resistive force and instantly-occurring impact upon the user's hand to enhance VR realism. By changing two physical properties, length and extension distance, of the elastic band, ElasticVR provides multilevel resistive force with no delay and impact with little delay, respectively, for realistic and versatile VR applications. A force perception study was performed to observe users' force distinguishability of the resistive force and impact, and the prototype was built based on its results. A VR experience study further proves that the resistive force and impact from ElasticVR both outperform those from current approaches in realism. Applications using ElasticVR are also demonstrated."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,1,Matthias Hoppe,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,2,Jakob Karolus,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,3,Felix Dietz,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,4,Paweł Woźniak,Utrecht University,Utrecht,Netherlands,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,5,Albrecht Schmidt,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn5564,https://doi.org/10.1145/3290605.3300776,VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback,6,Tonja-Katrin Machulla,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds."
pn9723,https://doi.org/10.1145/3290605.3300925,"""When the Elephant Trumps"": A Comparative Study on Spatial Audio for Orientation in 360º Videos",1,Paulo Bala,Madeira Interactive Technologies Institute,Funchal,Portugal,true,false,"Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may fail in locating points of interest. Recent strategies to tackle this research problem have investigated the role of cues, specifically diegetic sound effects. In this paper, we examine the use of sound spatialization for orientation purposes, namely by studying different spatialization conditions (""none"", ""partial"", and ""full"" spatial manipulation) of multitrack soundtracks. We performed a between-subject mixed-methods study with 36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound editing and data collection/analysis. Based on existing literature on orientation cues in 360º and theories on human listening, we discuss situations in which the spatialization was more effective (namely, ""full"" spatial manipulation both when using only music and when combining music and diegetic effects), and how this can be used by creators of 360º videos."
pn9723,https://doi.org/10.1145/3290605.3300925,"""When the Elephant Trumps"": A Comparative Study on Spatial Audio for Orientation in 360º Videos",2,Raul Masu,Madeira Interactive Technologies Institute,Funchal,Portugal,true,false,"Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may fail in locating points of interest. Recent strategies to tackle this research problem have investigated the role of cues, specifically diegetic sound effects. In this paper, we examine the use of sound spatialization for orientation purposes, namely by studying different spatialization conditions (""none"", ""partial"", and ""full"" spatial manipulation) of multitrack soundtracks. We performed a between-subject mixed-methods study with 36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound editing and data collection/analysis. Based on existing literature on orientation cues in 360º and theories on human listening, we discuss situations in which the spatialization was more effective (namely, ""full"" spatial manipulation both when using only music and when combining music and diegetic effects), and how this can be used by creators of 360º videos."
pn9723,https://doi.org/10.1145/3290605.3300925,"""When the Elephant Trumps"": A Comparative Study on Spatial Audio for Orientation in 360º Videos",3,Valentina Nisi,Madeira Interactive Technologies Institute,Funchal,Portugal,true,false,"Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may fail in locating points of interest. Recent strategies to tackle this research problem have investigated the role of cues, specifically diegetic sound effects. In this paper, we examine the use of sound spatialization for orientation purposes, namely by studying different spatialization conditions (""none"", ""partial"", and ""full"" spatial manipulation) of multitrack soundtracks. We performed a between-subject mixed-methods study with 36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound editing and data collection/analysis. Based on existing literature on orientation cues in 360º and theories on human listening, we discuss situations in which the spatialization was more effective (namely, ""full"" spatial manipulation both when using only music and when combining music and diegetic effects), and how this can be used by creators of 360º videos."
pn9723,https://doi.org/10.1145/3290605.3300925,"""When the Elephant Trumps"": A Comparative Study on Spatial Audio for Orientation in 360º Videos",4,Nuno Nunes,Madeira Interactive Technologies Institute,Funchal,Portugal,true,false,"Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may fail in locating points of interest. Recent strategies to tackle this research problem have investigated the role of cues, specifically diegetic sound effects. In this paper, we examine the use of sound spatialization for orientation purposes, namely by studying different spatialization conditions (""none"", ""partial"", and ""full"" spatial manipulation) of multitrack soundtracks. We performed a between-subject mixed-methods study with 36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound editing and data collection/analysis. Based on existing literature on orientation cues in 360º and theories on human listening, we discuss situations in which the spatialization was more effective (namely, ""full"" spatial manipulation both when using only music and when combining music and diegetic effects), and how this can be used by creators of 360º videos."
pn5968,https://doi.org/10.1145/3290605.3300682,"PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-based Interactions",1,Yuqian Sun,The University of Tokyo,Tokyo,Japan,false,false,"We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic."
pn5968,https://doi.org/10.1145/3290605.3300682,"PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-based Interactions",2,Shigeo Yoshida,The University of Tokyo,Tokyo,Japan,false,false,"We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic."
pn5968,https://doi.org/10.1145/3290605.3300682,"PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-based Interactions",3,Takuji Narumi,The University of Tokyo,Tokyo,Japan,false,false,"We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic."
pn5968,https://doi.org/10.1145/3290605.3300682,"PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-based Interactions",4,Michitaka Hirose,The University of Tokyo,Tokyo,Japan,false,false,"We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic."
pn4540,https://doi.org/10.1145/3290605.3300525,3D Pen + 3D Printer: Exploring the Role of Humans and Fabrication Machines in Creative Making,1,Haruki Takahashi,Meiji University,Nakano,Japan,false,false,"The emergence of a 3D pen brings 3D modeling from a screen-based computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3D models using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication."
pn4540,https://doi.org/10.1145/3290605.3300525,3D Pen + 3D Printer: Exploring the Role of Humans and Fabrication Machines in Creative Making,2,Jeeeun Kim,University of Colorado Boulder,Boulder,United States,false,false,"The emergence of a 3D pen brings 3D modeling from a screen-based computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3D models using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication."
pn5684,https://doi.org/10.1145/3290605.3300434,Desktop Electrospinning: A Single Extruder 3D Printer for Producing Rigid Plastic and Electrospun Textiles,1,Michael Rivera,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present a new type of 3D printer that combines rigid plastic printing with melt electrospinning– a technique that uses electrostatic forces to create thin fibers from a molten polymer. Our printer enables custom-shaped textile sheets (similar in feel to wool felt) to be produced alongside rigid plastic using a single material (i.e., PLA) in a single process. We contribute open-source firmware, hardware specifications, and printing parameters to achieve melt electrospinning. Our approach offers new opportunities for fabricating interactive objects and sensors that blend the flexibility, absorbency and softness of produced electrospun textiles with the structure and rigidity of hard plastic for actuation, sensing, and tactile experiences."
pn5684,https://doi.org/10.1145/3290605.3300434,Desktop Electrospinning: A Single Extruder 3D Printer for Producing Rigid Plastic and Electrospun Textiles,2,Scott Hudson,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present a new type of 3D printer that combines rigid plastic printing with melt electrospinning– a technique that uses electrostatic forces to create thin fibers from a molten polymer. Our printer enables custom-shaped textile sheets (similar in feel to wool felt) to be produced alongside rigid plastic using a single material (i.e., PLA) in a single process. We contribute open-source firmware, hardware specifications, and printing parameters to achieve melt electrospinning. Our approach offers new opportunities for fabricating interactive objects and sensors that blend the flexibility, absorbency and softness of produced electrospun textiles with the structure and rigidity of hard plastic for actuation, sensing, and tactile experiences."
pn7012,https://doi.org/10.1145/3290605.3300386,JigFab: Computational Design of Constraints to Facilitate Fabrication with Power Tools,1,Danny Leen,Katholieke Universiteit Leuven,Leuven,Belgium,false,false,"We present JigFab, an integrated end-to-end system that supports casual makers in designing and fabricating constructions with power tools. Starting from a digital version of the construction, JigFab achieves this by generating various types of constraints that configure and physically aid the movement of a power tool. Constraints are generated for every operation and are custom to the work piece. Constraints are laser cut and assembled together with predefined parts to reduce waste. JigFab's constraints are used according to an interactive step-by-step manual. JigFab internalizes all the required domain knowledge for designing and building intricate structures, consisting of various types of finger joints, tenon & mortise joints, grooves, and dowels. Building such structures is normally reserved for artisans or automated with advanced CNC machinery."
pn7012,https://doi.org/10.1145/3290605.3300386,JigFab: Computational Design of Constraints to Facilitate Fabrication with Power Tools,2,Tom Veuskens,Hasselt University,Diepenbeek,Belgium,false,false,"We present JigFab, an integrated end-to-end system that supports casual makers in designing and fabricating constructions with power tools. Starting from a digital version of the construction, JigFab achieves this by generating various types of constraints that configure and physically aid the movement of a power tool. Constraints are generated for every operation and are custom to the work piece. Constraints are laser cut and assembled together with predefined parts to reduce waste. JigFab's constraints are used according to an interactive step-by-step manual. JigFab internalizes all the required domain knowledge for designing and building intricate structures, consisting of various types of finger joints, tenon & mortise joints, grooves, and dowels. Building such structures is normally reserved for artisans or automated with advanced CNC machinery."
pn7012,https://doi.org/10.1145/3290605.3300386,JigFab: Computational Design of Constraints to Facilitate Fabrication with Power Tools,3,Kris Luyten,Hasselt University - tUL - Flanders Make,Diepenbeek,Belgium,false,false,"We present JigFab, an integrated end-to-end system that supports casual makers in designing and fabricating constructions with power tools. Starting from a digital version of the construction, JigFab achieves this by generating various types of constraints that configure and physically aid the movement of a power tool. Constraints are generated for every operation and are custom to the work piece. Constraints are laser cut and assembled together with predefined parts to reduce waste. JigFab's constraints are used according to an interactive step-by-step manual. JigFab internalizes all the required domain knowledge for designing and building intricate structures, consisting of various types of finger joints, tenon & mortise joints, grooves, and dowels. Building such structures is normally reserved for artisans or automated with advanced CNC machinery."
pn7012,https://doi.org/10.1145/3290605.3300386,JigFab: Computational Design of Constraints to Facilitate Fabrication with Power Tools,4,Raf Ramakers,Hasselt University,Hasselt,Belgium,false,false,"We present JigFab, an integrated end-to-end system that supports casual makers in designing and fabricating constructions with power tools. Starting from a digital version of the construction, JigFab achieves this by generating various types of constraints that configure and physically aid the movement of a power tool. Constraints are generated for every operation and are custom to the work piece. Constraints are laser cut and assembled together with predefined parts to reduce waste. JigFab's constraints are used according to an interactive step-by-step manual. JigFab internalizes all the required domain knowledge for designing and building intricate structures, consisting of various types of finger joints, tenon & mortise joints, grooves, and dowels. Building such structures is normally reserved for artisans or automated with advanced CNC machinery."
pn3885,https://doi.org/10.1145/3290605.3300684,"./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects",1,Martin Schmitz,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate."
pn3885,https://doi.org/10.1145/3290605.3300684,"./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects",2,Martin Stitz,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate."
pn3885,https://doi.org/10.1145/3290605.3300684,"./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects",3,Florian Müller,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate."
pn3885,https://doi.org/10.1145/3290605.3300684,"./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects",4,Markus Funk,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate."
pn3885,https://doi.org/10.1145/3290605.3300684,"./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects",5,Max Mühlhäuser,Technische Universität Darmstadt,Darmstadt,Germany,false,false,"Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,1,Ulrik Lyngs,University of Oxford,Oxford,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,2,Kai Lukoff,University of Washington,Seattle,United States,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,3,Petr Slovak,University College London,London,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,4,Reuben Binns,University of Oxford,Oxford,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,5,Adam Slack,University of Oxford,Oxford,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,6,Michael Inzlicht,University of Toronto,Toronto,Canada,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,7,Max Van Kleek,University of Oxford,Oxford,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn8969,https://doi.org/10.1145/3290605.3300361,Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools,8,Nigel Shadbolt,University of Oxford,Oxford,United Kingdom,true,false,"Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools."
pn1601,https://doi.org/10.1145/3290605.3300591,Understanding the Social Acceptability of Mobile Devices using the Stereotype Content Model,1,Valentin Schwind,University of Stuttgart,Stuttgart,Germany,false,false,"Understanding social perception is important for designing mobile devices that are socially acceptable. Previous work not only investigated the social acceptability of mobile devices and interaction techniques but also provided tools to measure social acceptance. However, we lack a robust model that explains the underlying factors that make devices socially acceptable. In this paper, we consider mobile devices as social objects and investigate if the stereotype content model (SCM) can be applied to those devices. Through a study that assesses combinations of mobile devices and group stereotypes, we show that mobile devices have a systematic effect on the stereotypes' warmth and competence. Supported by a second study, which combined mobile devices without a specific stereotypical user, our result suggests that mobile devices are perceived stereotypically by themselves. Our combined results highlight mobile devices as social objects and the importance of considering stereotypes when assessing social acceptance of mobile devices."
pn1601,https://doi.org/10.1145/3290605.3300591,Understanding the Social Acceptability of Mobile Devices using the Stereotype Content Model,2,Niklas Deierlein,University of Hagen,Hagen,Germany,false,false,"Understanding social perception is important for designing mobile devices that are socially acceptable. Previous work not only investigated the social acceptability of mobile devices and interaction techniques but also provided tools to measure social acceptance. However, we lack a robust model that explains the underlying factors that make devices socially acceptable. In this paper, we consider mobile devices as social objects and investigate if the stereotype content model (SCM) can be applied to those devices. Through a study that assesses combinations of mobile devices and group stereotypes, we show that mobile devices have a systematic effect on the stereotypes' warmth and competence. Supported by a second study, which combined mobile devices without a specific stereotypical user, our result suggests that mobile devices are perceived stereotypically by themselves. Our combined results highlight mobile devices as social objects and the importance of considering stereotypes when assessing social acceptance of mobile devices."
pn1601,https://doi.org/10.1145/3290605.3300591,Understanding the Social Acceptability of Mobile Devices using the Stereotype Content Model,3,Romina Poguntke,"VIS, University of Stuttgart",Stuttgart,Germany,false,false,"Understanding social perception is important for designing mobile devices that are socially acceptable. Previous work not only investigated the social acceptability of mobile devices and interaction techniques but also provided tools to measure social acceptance. However, we lack a robust model that explains the underlying factors that make devices socially acceptable. In this paper, we consider mobile devices as social objects and investigate if the stereotype content model (SCM) can be applied to those devices. Through a study that assesses combinations of mobile devices and group stereotypes, we show that mobile devices have a systematic effect on the stereotypes' warmth and competence. Supported by a second study, which combined mobile devices without a specific stereotypical user, our result suggests that mobile devices are perceived stereotypically by themselves. Our combined results highlight mobile devices as social objects and the importance of considering stereotypes when assessing social acceptance of mobile devices."
pn1601,https://doi.org/10.1145/3290605.3300591,Understanding the Social Acceptability of Mobile Devices using the Stereotype Content Model,4,Niels Henze,University of Regensburg,Regensburg,Germany,false,false,"Understanding social perception is important for designing mobile devices that are socially acceptable. Previous work not only investigated the social acceptability of mobile devices and interaction techniques but also provided tools to measure social acceptance. However, we lack a robust model that explains the underlying factors that make devices socially acceptable. In this paper, we consider mobile devices as social objects and investigate if the stereotype content model (SCM) can be applied to those devices. Through a study that assesses combinations of mobile devices and group stereotypes, we show that mobile devices have a systematic effect on the stereotypes' warmth and competence. Supported by a second study, which combined mobile devices without a specific stereotypical user, our result suggests that mobile devices are perceived stereotypically by themselves. Our combined results highlight mobile devices as social objects and the importance of considering stereotypes when assessing social acceptance of mobile devices."
pn7888,https://doi.org/10.1145/3290605.3300733,23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction,1,Ana Caraban,"Instituto Superior Técnico, Persuasive Tech Lab, Madeira-ITI",Funchal,Portugal,false,false,"Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging – the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications."
pn7888,https://doi.org/10.1145/3290605.3300733,23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction,2,Evangelos Karapanos,"Persuasive Tech Lab, Cyprus University of Technology",Limassol,Cyprus,false,false,"Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging – the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications."
pn7888,https://doi.org/10.1145/3290605.3300733,23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction,3,Daniel Gonçalves,"Instituto Superior Técnico, University of Lisbon",Funchal,Portugal,false,false,"Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging – the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications."
pn7888,https://doi.org/10.1145/3290605.3300733,23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction,4,Pedro Campos,"Madeira-ITI, University of Madeira",Funchal,Portugal,false,false,"Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging – the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications."
pn4258,https://doi.org/10.1145/3290605.3300687,A Review & Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities,1,Nada Terzimehi?,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Mindfulness is a term seen with increasing frequency in HCI literature, and yet the term itself is used almost as variously as the number of papers in which it appears. This diversity makes comparing or evaluating HCI approaches around mindfulness or understanding the design space itself a challenging task. We conducted a structured ACM literature search based on the term mindfulness. Our selection process yielded 38 relevant papers, which we analyzed for their definition, motivation, practice, evaluation and technology use around mindfulness. We identify similarities, divergences and areas of interest for each aspect, resulting in a framework composed of four perspectives and seven lines of research. We highlight challenges and opportunities for future HCI research and design."
pn4258,https://doi.org/10.1145/3290605.3300687,A Review & Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities,2,Renate Häuslschmid,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Mindfulness is a term seen with increasing frequency in HCI literature, and yet the term itself is used almost as variously as the number of papers in which it appears. This diversity makes comparing or evaluating HCI approaches around mindfulness or understanding the design space itself a challenging task. We conducted a structured ACM literature search based on the term mindfulness. Our selection process yielded 38 relevant papers, which we analyzed for their definition, motivation, practice, evaluation and technology use around mindfulness. We identify similarities, divergences and areas of interest for each aspect, resulting in a framework composed of four perspectives and seven lines of research. We highlight challenges and opportunities for future HCI research and design."
pn4258,https://doi.org/10.1145/3290605.3300687,A Review & Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities,3,Heinrich Hussmann,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Mindfulness is a term seen with increasing frequency in HCI literature, and yet the term itself is used almost as variously as the number of papers in which it appears. This diversity makes comparing or evaluating HCI approaches around mindfulness or understanding the design space itself a challenging task. We conducted a structured ACM literature search based on the term mindfulness. Our selection process yielded 38 relevant papers, which we analyzed for their definition, motivation, practice, evaluation and technology use around mindfulness. We identify similarities, divergences and areas of interest for each aspect, resulting in a framework composed of four perspectives and seven lines of research. We highlight challenges and opportunities for future HCI research and design."
pn4258,https://doi.org/10.1145/3290605.3300687,A Review & Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities,4,M.C. Schraefel,University of Southampton,Southampton,United Kingdom,false,false,"Mindfulness is a term seen with increasing frequency in HCI literature, and yet the term itself is used almost as variously as the number of papers in which it appears. This diversity makes comparing or evaluating HCI approaches around mindfulness or understanding the design space itself a challenging task. We conducted a structured ACM literature search based on the term mindfulness. Our selection process yielded 38 relevant papers, which we analyzed for their definition, motivation, practice, evaluation and technology use around mindfulness. We identify similarities, divergences and areas of interest for each aspect, resulting in a framework composed of four perspectives and seven lines of research. We highlight challenges and opportunities for future HCI research and design."
pn3507,https://doi.org/10.1145/3290605.3300802,REsCUE: A framework for REal-time feedback on behavioral CUEs using multimodal anomaly detection,1,Riku Arakawa,Tokyo University,Hongo,Japan,false,false,"Executive coaching has been drawing more and more attention for developing corporate managers. While conversing with managers, coach practitioners are also required to understand internal states of coachees through objective observations. In this paper, we present REsCUE, an automated system to aid coach practitioners in detecting unconscious behaviors of their clients. Using an unsupervised anomaly detection algorithm applied to multimodal behavior data such as the subject's posture and gaze, REsCUE notifies behavioral cues for coaches via intuitive and interpretive feedback in real-time. Our evaluation with actual coaching scenes confirms that REsCUE provides the informative cues to understand internal states of coachees. Since REsCUE is based on the unsupervised method and does not assume any prior knowledge, further applications beside executive coaching are conceivable using our framework."
pn3507,https://doi.org/10.1145/3290605.3300802,REsCUE: A framework for REal-time feedback on behavioral CUEs using multimodal anomaly detection,2,Hiromu Yakura,Teambox Inc.,Tokyo,Japan,false,false,"Executive coaching has been drawing more and more attention for developing corporate managers. While conversing with managers, coach practitioners are also required to understand internal states of coachees through objective observations. In this paper, we present REsCUE, an automated system to aid coach practitioners in detecting unconscious behaviors of their clients. Using an unsupervised anomaly detection algorithm applied to multimodal behavior data such as the subject's posture and gaze, REsCUE notifies behavioral cues for coaches via intuitive and interpretive feedback in real-time. Our evaluation with actual coaching scenes confirms that REsCUE provides the informative cues to understand internal states of coachees. Since REsCUE is based on the unsupervised method and does not assume any prior knowledge, further applications beside executive coaching are conceivable using our framework."
pn9632,https://doi.org/10.1145/3290605.3300643,ORC Layout: Adaptive GUI Layout with OR-Constraints,1,Yue Jiang,"University of Maryland, College Park",College Park,United States,false,false,"We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime."
pn9632,https://doi.org/10.1145/3290605.3300643,ORC Layout: Adaptive GUI Layout with OR-Constraints,2,Ruofei Du,"University of Maryland, College Park",San Francisco,United States,false,false,"We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime."
pn9632,https://doi.org/10.1145/3290605.3300643,ORC Layout: Adaptive GUI Layout with OR-Constraints,3,Christof Lutteroth,University of Bath,Bath,United Kingdom,false,false,"We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime."
pn9632,https://doi.org/10.1145/3290605.3300643,ORC Layout: Adaptive GUI Layout with OR-Constraints,4,Wolfgang Stuerzlinger,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime."
pn5594,https://doi.org/10.1145/3290605.3300805,MessageOnTap: A Suggestive Interface to Facilitate Messaging-related Tasks,1,Fanglin Chen,Human-Computer Interaction Institute,Pittsburgh,United States,false,false,"Text messages are sometimes prompts that lead to information related tasks, e.g. checking one's schedule, creating reminders, or sharing content. We introduce MessageOnTap, a suggestive inter-face for smartphones that uses the text in a conversation to suggest task shortcuts that can streamline likely next actions. When activated, MessageOnTap uses word embeddings to rank relevant external apps, and parameterizes associated task shortcuts using key phrases mentioned in the conversation, such as times, persons, or events. MessageOnTap also tailors the auto-complete dictionary based on text in the conversation, to streamline any text input.We first conducted a month-long study of messaging behaviors(N=22) that informed our design. We then conducted a lab study to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that participants can complete tasks 3.1x faster withMessageOnTap than their typical task flow."
pn5594,https://doi.org/10.1145/3290605.3300805,MessageOnTap: A Suggestive Interface to Facilitate Messaging-related Tasks,2,Kewei Xia,Wuhan University,Wuhan,China,false,false,"Text messages are sometimes prompts that lead to information related tasks, e.g. checking one's schedule, creating reminders, or sharing content. We introduce MessageOnTap, a suggestive inter-face for smartphones that uses the text in a conversation to suggest task shortcuts that can streamline likely next actions. When activated, MessageOnTap uses word embeddings to rank relevant external apps, and parameterizes associated task shortcuts using key phrases mentioned in the conversation, such as times, persons, or events. MessageOnTap also tailors the auto-complete dictionary based on text in the conversation, to streamline any text input.We first conducted a month-long study of messaging behaviors(N=22) that informed our design. We then conducted a lab study to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that participants can complete tasks 3.1x faster withMessageOnTap than their typical task flow."
pn5594,https://doi.org/10.1145/3290605.3300805,MessageOnTap: A Suggestive Interface to Facilitate Messaging-related Tasks,3,Karan Dhabalia,Carnegie Mellon University,Pittsburgh,United States,false,false,"Text messages are sometimes prompts that lead to information related tasks, e.g. checking one's schedule, creating reminders, or sharing content. We introduce MessageOnTap, a suggestive inter-face for smartphones that uses the text in a conversation to suggest task shortcuts that can streamline likely next actions. When activated, MessageOnTap uses word embeddings to rank relevant external apps, and parameterizes associated task shortcuts using key phrases mentioned in the conversation, such as times, persons, or events. MessageOnTap also tailors the auto-complete dictionary based on text in the conversation, to streamline any text input.We first conducted a month-long study of messaging behaviors(N=22) that informed our design. We then conducted a lab study to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that participants can complete tasks 3.1x faster withMessageOnTap than their typical task flow."
pn5594,https://doi.org/10.1145/3290605.3300805,MessageOnTap: A Suggestive Interface to Facilitate Messaging-related Tasks,4,Jason Hong,Carnegie Mellon University,Pittsburgh,United States,false,false,"Text messages are sometimes prompts that lead to information related tasks, e.g. checking one's schedule, creating reminders, or sharing content. We introduce MessageOnTap, a suggestive inter-face for smartphones that uses the text in a conversation to suggest task shortcuts that can streamline likely next actions. When activated, MessageOnTap uses word embeddings to rank relevant external apps, and parameterizes associated task shortcuts using key phrases mentioned in the conversation, such as times, persons, or events. MessageOnTap also tailors the auto-complete dictionary based on text in the conversation, to streamline any text input.We first conducted a month-long study of messaging behaviors(N=22) that informed our design. We then conducted a lab study to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that participants can complete tasks 3.1x faster withMessageOnTap than their typical task flow."
pn1172,https://doi.org/10.1145/3290605.3300769,"Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback",1,Aditya Bharadwaj,Virginia Tech,Blacksburg,United States,false,false,"Checklists and guidelines have played an increasingly important role in complex tasks ranging from the cockpit to the operating theater. Their role in creative tasks like design is less explored. In a needfinding study with expert web designers, we identified designers' challenges in adhering to a checklist of design guidelines. We built Critter, which addressed these challenges with three components: Dynamic Checklists that progressively disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate common quality assurance checks, and guideline-specific feedback provided by a reviewer to highlight mistakes as they appear. In an observational study, we found that the more engaged a designer was with Critter, the fewer mistakes they made in following design guidelines. Designers rated the AutoQA and contextual feedback experience highly, and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We additionally found that a majority of designers rated the AutoQA experience as excellent and felt that it increased the quality of their work. Finally, we discuss broader implications for supporting complex creative tasks."
pn1172,https://doi.org/10.1145/3290605.3300769,"Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback",2,Pao Siangliulue,B12,New York,United States,false,false,"Checklists and guidelines have played an increasingly important role in complex tasks ranging from the cockpit to the operating theater. Their role in creative tasks like design is less explored. In a needfinding study with expert web designers, we identified designers' challenges in adhering to a checklist of design guidelines. We built Critter, which addressed these challenges with three components: Dynamic Checklists that progressively disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate common quality assurance checks, and guideline-specific feedback provided by a reviewer to highlight mistakes as they appear. In an observational study, we found that the more engaged a designer was with Critter, the fewer mistakes they made in following design guidelines. Designers rated the AutoQA and contextual feedback experience highly, and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We additionally found that a majority of designers rated the AutoQA experience as excellent and felt that it increased the quality of their work. Finally, we discuss broader implications for supporting complex creative tasks."
pn1172,https://doi.org/10.1145/3290605.3300769,"Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback",3,Adam Marcus,B12,New York,United States,false,false,"Checklists and guidelines have played an increasingly important role in complex tasks ranging from the cockpit to the operating theater. Their role in creative tasks like design is less explored. In a needfinding study with expert web designers, we identified designers' challenges in adhering to a checklist of design guidelines. We built Critter, which addressed these challenges with three components: Dynamic Checklists that progressively disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate common quality assurance checks, and guideline-specific feedback provided by a reviewer to highlight mistakes as they appear. In an observational study, we found that the more engaged a designer was with Critter, the fewer mistakes they made in following design guidelines. Designers rated the AutoQA and contextual feedback experience highly, and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We additionally found that a majority of designers rated the AutoQA experience as excellent and felt that it increased the quality of their work. Finally, we discuss broader implications for supporting complex creative tasks."
pn1172,https://doi.org/10.1145/3290605.3300769,"Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback",4,Kurt Luther,Virginia Tech,Arlington,United States,false,false,"Checklists and guidelines have played an increasingly important role in complex tasks ranging from the cockpit to the operating theater. Their role in creative tasks like design is less explored. In a needfinding study with expert web designers, we identified designers' challenges in adhering to a checklist of design guidelines. We built Critter, which addressed these challenges with three components: Dynamic Checklists that progressively disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate common quality assurance checks, and guideline-specific feedback provided by a reviewer to highlight mistakes as they appear. In an observational study, we found that the more engaged a designer was with Critter, the fewer mistakes they made in following design guidelines. Designers rated the AutoQA and contextual feedback experience highly, and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We additionally found that a majority of designers rated the AutoQA experience as excellent and felt that it increased the quality of their work. Finally, we discuss broader implications for supporting complex creative tasks."
pn3575,https://doi.org/10.1145/3290605.3300413,The Role of Physical Props in VR Climbing Environments,1,Peter Schulz,University of Bremen,Bremen,Germany,false,false,"Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height."
pn3575,https://doi.org/10.1145/3290605.3300413,The Role of Physical Props in VR Climbing Environments,2,Dmitry Alexandrovsky,University of Bremen,Bremen,Germany,false,false,"Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height."
pn3575,https://doi.org/10.1145/3290605.3300413,The Role of Physical Props in VR Climbing Environments,3,Felix Putze,University of Bremen,Bremen,Germany,false,false,"Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height."
pn3575,https://doi.org/10.1145/3290605.3300413,The Role of Physical Props in VR Climbing Environments,4,Rainer Malaka,University of Bremen,Bremen,Germany,false,false,"Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height."
pn3575,https://doi.org/10.1145/3290605.3300413,The Role of Physical Props in VR Climbing Environments,5,Johannes Schöning,University of Bremen,Bremen,Germany,false,false,"Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,1,Dylan Fafard,University of Saskatchewan,Saskatoon,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,2,Ian Stavness,University of Saskatchewan,Saskatoon,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,3,Martin Dechant,University of Saskatchewan,Saskatoon,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,4,Regan Mandryk,University of Saskatchewan,Saskatoon,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,5,Qian Zhou,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn3810,https://doi.org/10.1145/3290605.3300763,FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display,6,Sidney Fels,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual ""crystal ball"" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR."
pn9978,https://doi.org/10.1145/3290605.3300661,Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation,1,Jonas Auda,University of Duisburg-Essen,Essen,Germany,false,false,"Virtual worlds are infinite environments in which the user can move around freely. When shifting from controller-based movement to regular walking as an input, the limitation of the real world also limits the virtual world. Tackling this challenge, we propose the use of electrical muscle stimulation to limit the necessary real-world space to create an unlimited walking experience. We thereby actuate the users' legs in a way that they deviate from their straight route and thus, walk in circles in the real world while still walking straight in the virtual world. We report on a study comparing this approach to vision shift - the state of the art approach - as well as combining both approaches. The results show that particularly combining both approaches yield high potential to create an infinite walking experience."
pn9978,https://doi.org/10.1145/3290605.3300661,Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation,2,Max Pascher,University of Duisburg-Essen,Essen,Germany,false,false,"Virtual worlds are infinite environments in which the user can move around freely. When shifting from controller-based movement to regular walking as an input, the limitation of the real world also limits the virtual world. Tackling this challenge, we propose the use of electrical muscle stimulation to limit the necessary real-world space to create an unlimited walking experience. We thereby actuate the users' legs in a way that they deviate from their straight route and thus, walk in circles in the real world while still walking straight in the virtual world. We report on a study comparing this approach to vision shift - the state of the art approach - as well as combining both approaches. The results show that particularly combining both approaches yield high potential to create an infinite walking experience."
pn9978,https://doi.org/10.1145/3290605.3300661,Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation,3,Stefan Schneegass,Universität Duisburg-Essen,Essen,Germany,false,false,"Virtual worlds are infinite environments in which the user can move around freely. When shifting from controller-based movement to regular walking as an input, the limitation of the real world also limits the virtual world. Tackling this challenge, we propose the use of electrical muscle stimulation to limit the necessary real-world space to create an unlimited walking experience. We thereby actuate the users' legs in a way that they deviate from their straight route and thus, walk in circles in the real world while still walking straight in the virtual world. We report on a study comparing this approach to vision shift - the state of the art approach - as well as combining both approaches. The results show that particularly combining both approaches yield high potential to create an infinite walking experience."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",1,Jatin Arora,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",2,Aryan Saini,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",3,Nirmita Mehra,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",4,Varnit Jain,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",5,Shwetank Shrey,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn1384,https://doi.org/10.1145/3290605.3300286,"VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR",6,Aman Parnami,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community."
pn9343,https://doi.org/10.1145/3290605.3300394,Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences,1,Netta Ofer,The Interdisciplinary Center (IDC) Herzliya,Herzliya,Israel,true,false,"Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences."
pn9343,https://doi.org/10.1145/3290605.3300394,Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences,2,Idan David,The Interdisciplinary Center (IDC) Herzliya,Herzliya,Israel,true,false,"Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences."
pn9343,https://doi.org/10.1145/3290605.3300394,Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences,3,Hadas Erel,The Interdisciplinary Center (IDC) Herzliya,Herzliya,Israel,true,false,"Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences."
pn9343,https://doi.org/10.1145/3290605.3300394,Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences,4,Oren Zuckerman,The Interdisciplinary Center (IDC) Herzliya,Herzliya,Israel,true,false,"Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,1,Arpita Bhattacharya,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,2,Travis Windleharth,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,3,Rio Ishii,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,4,Ivy Acevedo,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,5,Cecilia Aragon,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,6,Julie Kientz,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,7,Jason Yip,University of Washinton,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn6012,https://doi.org/10.1145/3290605.3300817,Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pokémon GO,8,Jin Ha Lee,University of Washington,Seattle,United States,false,false,"Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pokémon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pokémon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions."
pn2281,https://doi.org/10.1145/3290605.3300318,"ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup",1,Anna Lisa Martin-Niedecken,Zurich University of the Arts,Zurich,Switzerland,false,false,"Today's spectrum of playful fitness solutions features systems that are clearly game-first or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently, existing applications and evaluations often lack in focus on attractiveness and effectiveness, which should be addressed on the levels of body, controller, and game scenario following a holistic design approach. To contribute to this topic and as a proof-of-concept, we designed the ExerCube, an adaptive fitness game setup. We evaluated participants' multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube version and compared them with personal training to reveal insights to inform the next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube is on par with personal training. Results further reveal differences in perception of exertion, types and quality of movement, social factors, feedback, and audio experiences. Finally, we derive considerations for future research and development directions in holistic fitness game setups."
pn2281,https://doi.org/10.1145/3290605.3300318,"ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup",2,Katja Rogers,Ulm University,Ulm,Germany,false,false,"Today's spectrum of playful fitness solutions features systems that are clearly game-first or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently, existing applications and evaluations often lack in focus on attractiveness and effectiveness, which should be addressed on the levels of body, controller, and game scenario following a holistic design approach. To contribute to this topic and as a proof-of-concept, we designed the ExerCube, an adaptive fitness game setup. We evaluated participants' multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube version and compared them with personal training to reveal insights to inform the next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube is on par with personal training. Results further reveal differences in perception of exertion, types and quality of movement, social factors, feedback, and audio experiences. Finally, we derive considerations for future research and development directions in holistic fitness game setups."
pn2281,https://doi.org/10.1145/3290605.3300318,"ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup",3,Laia Turmo Vidal,Uppsala University,Uppsala,Sweden,false,false,"Today's spectrum of playful fitness solutions features systems that are clearly game-first or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently, existing applications and evaluations often lack in focus on attractiveness and effectiveness, which should be addressed on the levels of body, controller, and game scenario following a holistic design approach. To contribute to this topic and as a proof-of-concept, we designed the ExerCube, an adaptive fitness game setup. We evaluated participants' multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube version and compared them with personal training to reveal insights to inform the next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube is on par with personal training. Results further reveal differences in perception of exertion, types and quality of movement, social factors, feedback, and audio experiences. Finally, we derive considerations for future research and development directions in holistic fitness game setups."
pn2281,https://doi.org/10.1145/3290605.3300318,"ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup",4,Elisa Mekler,University of Basel,Basel,Switzerland,false,false,"Today's spectrum of playful fitness solutions features systems that are clearly game-first or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently, existing applications and evaluations often lack in focus on attractiveness and effectiveness, which should be addressed on the levels of body, controller, and game scenario following a holistic design approach. To contribute to this topic and as a proof-of-concept, we designed the ExerCube, an adaptive fitness game setup. We evaluated participants' multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube version and compared them with personal training to reveal insights to inform the next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube is on par with personal training. Results further reveal differences in perception of exertion, types and quality of movement, social factors, feedback, and audio experiences. Finally, we derive considerations for future research and development directions in holistic fitness game setups."
pn2281,https://doi.org/10.1145/3290605.3300318,"ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup",5,Elena Márquez Segura,Uppsala University,Uppsala,Sweden,false,false,"Today's spectrum of playful fitness solutions features systems that are clearly game-first or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently, existing applications and evaluations often lack in focus on attractiveness and effectiveness, which should be addressed on the levels of body, controller, and game scenario following a holistic design approach. To contribute to this topic and as a proof-of-concept, we designed the ExerCube, an adaptive fitness game setup. We evaluated participants' multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube version and compared them with personal training to reveal insights to inform the next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube is on par with personal training. Results further reveal differences in perception of exertion, types and quality of movement, social factors, feedback, and audio experiences. Finally, we derive considerations for future research and development directions in holistic fitness game setups."
pn6778,https://doi.org/10.1145/3290605.3300660,Social Play in an Exergame: How the Need to Belong Predicts Adherence,1,Maximus Kaos,Queen's University,Kingston,Canada,false,true,"The general trend in exercise interventions, including those based on exergames, is to see high initial enthusiasm but significantly declining adherence. Social play is considered a core tenet of the design of exercise interventions help foster motivation to play. To determine whether social play aids in adherence to exergames, we analyzed data from a study involving five waves of six-week exergame trials between a single-player and multiplayer group. In this paper, we examine the multiplayer group to determine who might benefit from social play and why. We found that people who primarily engage in group play have superior adherence to people who primarily play alone. People who play alone in a multiplayer exergame have worse adherence than playing a single-player version, which can undo any potential benefit of social play. The primary construct distinguishing group versus alone players is their sense of program belonging. Program belonging is, thus, crucial to multiplayer exergame design."
pn6778,https://doi.org/10.1145/3290605.3300660,Social Play in an Exergame: How the Need to Belong Predicts Adherence,2,Ryan Rhodes,University of Victoria,Victoria,Canada,false,true,"The general trend in exercise interventions, including those based on exergames, is to see high initial enthusiasm but significantly declining adherence. Social play is considered a core tenet of the design of exercise interventions help foster motivation to play. To determine whether social play aids in adherence to exergames, we analyzed data from a study involving five waves of six-week exergame trials between a single-player and multiplayer group. In this paper, we examine the multiplayer group to determine who might benefit from social play and why. We found that people who primarily engage in group play have superior adherence to people who primarily play alone. People who play alone in a multiplayer exergame have worse adherence than playing a single-player version, which can undo any potential benefit of social play. The primary construct distinguishing group versus alone players is their sense of program belonging. Program belonging is, thus, crucial to multiplayer exergame design."
pn6778,https://doi.org/10.1145/3290605.3300660,Social Play in an Exergame: How the Need to Belong Predicts Adherence,3,Perttu Hämäläinen,Aalto University,Helsinki,Finland,false,true,"The general trend in exercise interventions, including those based on exergames, is to see high initial enthusiasm but significantly declining adherence. Social play is considered a core tenet of the design of exercise interventions help foster motivation to play. To determine whether social play aids in adherence to exergames, we analyzed data from a study involving five waves of six-week exergame trials between a single-player and multiplayer group. In this paper, we examine the multiplayer group to determine who might benefit from social play and why. We found that people who primarily engage in group play have superior adherence to people who primarily play alone. People who play alone in a multiplayer exergame have worse adherence than playing a single-player version, which can undo any potential benefit of social play. The primary construct distinguishing group versus alone players is their sense of program belonging. Program belonging is, thus, crucial to multiplayer exergame design."
pn6778,https://doi.org/10.1145/3290605.3300660,Social Play in an Exergame: How the Need to Belong Predicts Adherence,4,T.C. Graham,Queen's University,Kingston,Canada,false,true,"The general trend in exercise interventions, including those based on exergames, is to see high initial enthusiasm but significantly declining adherence. Social play is considered a core tenet of the design of exercise interventions help foster motivation to play. To determine whether social play aids in adherence to exergames, we analyzed data from a study involving five waves of six-week exergame trials between a single-player and multiplayer group. In this paper, we examine the multiplayer group to determine who might benefit from social play and why. We found that people who primarily engage in group play have superior adherence to people who primarily play alone. People who play alone in a multiplayer exergame have worse adherence than playing a single-player version, which can undo any potential benefit of social play. The primary construct distinguishing group versus alone players is their sense of program belonging. Program belonging is, thus, crucial to multiplayer exergame design."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,1,Dimitrios Darzentas,University of Nottingham,Nottingham,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,2,Raphael Velt,Unaffiliated,Nottingham,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,3,Richard Wetzel,Lucerne University of Applied Sciences and Arts,Lucerne,Switzerland,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,4,Peter Craigon,University of Nottingham,Nottingham,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,5,Hanne Wagner,University of Nottingham,Nottingham,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,6,Lachlan Urquhart,Edinburgh University,Edinburgh,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn6567,https://doi.org/10.1145/3290605.3300801,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,7,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations."
pn5985,https://doi.org/10.1145/3290605.3300804,Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience,1,Nathan Semertzidis,RMIT University,Melbourne,Australia,false,false,"Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of ""Inter-Dream"", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep."
pn5985,https://doi.org/10.1145/3290605.3300804,Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience,2,Betty Sargeant,RMIT University,Melbourne,Australia,false,false,"Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of ""Inter-Dream"", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep."
pn5985,https://doi.org/10.1145/3290605.3300804,Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience,3,Justin Dwyer,RMIT University,Melbourne,Australia,false,false,"Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of ""Inter-Dream"", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep."
pn5985,https://doi.org/10.1145/3290605.3300804,Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience,4,Florian Mueller,RMIT University,Melbourne,Australia,false,false,"Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of ""Inter-Dream"", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep."
pn5985,https://doi.org/10.1145/3290605.3300804,Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience,5,Fabio Zambetta,RMIT University,Melbourne,Australia,false,false,"Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of ""Inter-Dream"", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,1,William Odom,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,2,Ron Wakkary,Eindhoven University of Technology,Burnaby/Surrey/Vancouver,Canada,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,3,Jeroen Hol,Eindhoven University of Technology,Eindhoven,Netherlands,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,4,Bram Naus,Eindhoven University of Technology,Eindhoven,Netherlands,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,5,Pepijn Verburg,Eindhoven University of Technology,Eindhoven,Netherlands,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,6,Tal Amram,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn5440,https://doi.org/10.1145/3290605.3300264,Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly,7,Amy Yo Sue Chen,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,true,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner's Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice."
pn2888,https://doi.org/10.1145/3290605.3300905,Adding Proprioceptive Feedback to Virtual Reality Experiences Using Galvanic Vestibular Stimulation,1,Misha Sra,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present a small and lightweight wearable device that enhances virtual reality experiences and reduces cybersickness by means of galvanic vestibular stimulation (GVS). GVS is a specific way to elicit vestibular reflexes that has been used for over a century to study the function of the vestibular system. In addition to GVS, we support physiological sensing by connecting heart rate, electrodermal activity and other sensors to our wearable device using a plug and play mechanism. An accompanying Android app communicates with the device over Bluetooth (BLE) for transmitting the GVS stimulus to the user through electrodes attached behind the ears. Our system supports multiple categories of virtual reality applications with different types of virtual motion such as driving, navigating by flying, teleporting, or riding. We present a user study in which participants (N = 20) experienced significantly lower cybersickness when using our device and rated experiences with GVS-induced haptic feedback as significantly more immersive than a no-GVS baseline."
pn2888,https://doi.org/10.1145/3290605.3300905,Adding Proprioceptive Feedback to Virtual Reality Experiences Using Galvanic Vestibular Stimulation,2,Abhinandan Jain,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present a small and lightweight wearable device that enhances virtual reality experiences and reduces cybersickness by means of galvanic vestibular stimulation (GVS). GVS is a specific way to elicit vestibular reflexes that has been used for over a century to study the function of the vestibular system. In addition to GVS, we support physiological sensing by connecting heart rate, electrodermal activity and other sensors to our wearable device using a plug and play mechanism. An accompanying Android app communicates with the device over Bluetooth (BLE) for transmitting the GVS stimulus to the user through electrodes attached behind the ears. Our system supports multiple categories of virtual reality applications with different types of virtual motion such as driving, navigating by flying, teleporting, or riding. We present a user study in which participants (N = 20) experienced significantly lower cybersickness when using our device and rated experiences with GVS-induced haptic feedback as significantly more immersive than a no-GVS baseline."
pn2888,https://doi.org/10.1145/3290605.3300905,Adding Proprioceptive Feedback to Virtual Reality Experiences Using Galvanic Vestibular Stimulation,3,Pattie Maes,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present a small and lightweight wearable device that enhances virtual reality experiences and reduces cybersickness by means of galvanic vestibular stimulation (GVS). GVS is a specific way to elicit vestibular reflexes that has been used for over a century to study the function of the vestibular system. In addition to GVS, we support physiological sensing by connecting heart rate, electrodermal activity and other sensors to our wearable device using a plug and play mechanism. An accompanying Android app communicates with the device over Bluetooth (BLE) for transmitting the GVS stimulus to the user through electrodes attached behind the ears. Our system supports multiple categories of virtual reality applications with different types of virtual motion such as driving, navigating by flying, teleporting, or riding. We present a user study in which participants (N = 20) experienced significantly lower cybersickness when using our device and rated experiences with GVS-induced haptic feedback as significantly more immersive than a no-GVS baseline."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,1,Markus Funk,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,2,Florian Müller,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,3,Marco Fendrich,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,4,Megan Shene,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,5,Moritz Kolvenbach,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,6,Niclas Dobbertin,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,7,Sebastian Günther,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn8105,https://doi.org/10.1145/3290605.3300377,Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories,8,Max Mühlhäuser,TU Darmstadt,Darmstadt,Germany,false,false,"Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation."
pn4612,https://doi.org/10.1145/3290605.3300644,Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements,1,Katja Rogers,Ulm University,Ulm,Germany,false,false,"High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results."
pn4612,https://doi.org/10.1145/3290605.3300644,Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements,2,Jana Funke,Ulm University,Ulm,Germany,false,false,"High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results."
pn4612,https://doi.org/10.1145/3290605.3300644,Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements,3,Julian Frommel,Ulm University,Ulm,Germany,false,false,"High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results."
pn4612,https://doi.org/10.1145/3290605.3300644,Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements,4,Sven Stamm,Ulm University,Ulm,Germany,false,false,"High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results."
pn4612,https://doi.org/10.1145/3290605.3300644,Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements,5,Michael Weber,Ulm University,Ulm,Germany,false,false,"High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results."
pn7282,https://doi.org/10.1145/3290605.3300553,Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games,1,Po Bhattacharyya,Carnegie Mellon University,Pittsburgh,United States,false,false,"Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay."
pn7282,https://doi.org/10.1145/3290605.3300553,Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games,2,Radha Nath,Carnegie Mellon University,Pittsburgh,United States,false,false,"Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay."
pn7282,https://doi.org/10.1145/3290605.3300553,Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games,3,Yein Jo,Entertainment technology center,Pittsburgh,United States,false,false,"Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay."
pn7282,https://doi.org/10.1145/3290605.3300553,Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games,4,Ketki Jadhav,Carnegie Mellon University,Pittsburgh,United States,false,false,"Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay."
pn7282,https://doi.org/10.1145/3290605.3300553,Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games,5,Jessica Hammer,Carnegie Mellon University,Pittsburgh,United States,false,false,"Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay."
pn1251,https://doi.org/10.1145/3290605.3300846,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,1,Tom Horak,Technische Universität Dresden,Dresden,Germany,false,false,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework."
pn1251,https://doi.org/10.1145/3290605.3300846,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,2,Andreas Mathisen,Aarhus University,Aarhus,Denmark,false,false,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework."
pn1251,https://doi.org/10.1145/3290605.3300846,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,3,Clemens Klokmose,Aarhus University,Aarhus,Denmark,false,false,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework."
pn1251,https://doi.org/10.1145/3290605.3300846,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,4,Raimund Dachselt,Technische Universität Dresden,Dresden,Germany,false,false,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework."
pn1251,https://doi.org/10.1145/3290605.3300846,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,5,Niklas Elmqvist,"University of Maryland, College Park",College Park,United States,false,false,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,1,Hugo Romat,Microsoft Research,Seattle,United States,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,2,Nathalie Henry Riche,Microsoft Research,Redmond,United States,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,3,Ken Hinckley,Microsoft Research,Redmond,United States,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,4,Bongshin Lee,Microsoft Research,Redmond,United States,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,5,Caroline Appert,"Université Paris-Sud, CNRS, Université Paris-Saclay.",Paris,France,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,6,Emmanuel Pietriga,INRIA,Paris,France,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn7761,https://doi.org/10.1145/3290605.3300272,ActiveInk: (Th)Inking with Data,7,Christopher Collins,Microsoft Research,Seattle,United States,true,false,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking."
pn8601,https://doi.org/10.1145/3290605.3300360,Dynamic Network Plaid: A Tool for the Analysis of Dynamic Networks,1,Alexandra Lee,Swansea University,Swansea,United Kingdom,false,false,"Network data that changes over time can be very useful for studying a wide range of important phenomena, from how social network connections change to epidemiology. However, it is challenging to analyze, especially if it has many actors, connections or if the covered timespan is large with rapidly changing links (e.g., months of changes with changes at second resolution). In these analyses one would often like to compare many periods of time to others, without having to look at the full timeline. To support this kind of analysis we designed and implemented a technique and system to visualize this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays and based on user-generated interactive timeslicing on the dynamic graph attributes and on linked provenance-preserving representations. We present the technique, interface and the design/evaluation with a group of public health researchers investigating non-suicidal self-harm picture sharing in Instagram."
pn8601,https://doi.org/10.1145/3290605.3300360,Dynamic Network Plaid: A Tool for the Analysis of Dynamic Networks,2,Daniel Archambault,Swansea University,Swansea,United Kingdom,false,false,"Network data that changes over time can be very useful for studying a wide range of important phenomena, from how social network connections change to epidemiology. However, it is challenging to analyze, especially if it has many actors, connections or if the covered timespan is large with rapidly changing links (e.g., months of changes with changes at second resolution). In these analyses one would often like to compare many periods of time to others, without having to look at the full timeline. To support this kind of analysis we designed and implemented a technique and system to visualize this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays and based on user-generated interactive timeslicing on the dynamic graph attributes and on linked provenance-preserving representations. We present the technique, interface and the design/evaluation with a group of public health researchers investigating non-suicidal self-harm picture sharing in Instagram."
pn8601,https://doi.org/10.1145/3290605.3300360,Dynamic Network Plaid: A Tool for the Analysis of Dynamic Networks,3,Miguel Nacenta,University of St Andrews,St Andrews,United Kingdom,false,false,"Network data that changes over time can be very useful for studying a wide range of important phenomena, from how social network connections change to epidemiology. However, it is challenging to analyze, especially if it has many actors, connections or if the covered timespan is large with rapidly changing links (e.g., months of changes with changes at second resolution). In these analyses one would often like to compare many periods of time to others, without having to look at the full timeline. To support this kind of analysis we designed and implemented a technique and system to visualize this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays and based on user-generated interactive timeslicing on the dynamic graph attributes and on linked provenance-preserving representations. We present the technique, interface and the design/evaluation with a group of public health researchers investigating non-suicidal self-harm picture sharing in Instagram."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,1,Michail Schwab,Northeastern University,Boston,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,2,Sicheng Hao,Northeastern University,Boston,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,3,Olga Vitek,Northeastern University,Boston,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,4,James Tompkin,Brown University,Providence,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,5,Jeff Huang,Brown University,Providence,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn8172,https://doi.org/10.1145/3290605.3300786,Evaluating Pan and Zoom Timelines and Sliders,6,Michelle Borkin,Northeastern University,Boston,United States,false,false,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source."
pn4779,https://doi.org/10.1145/3290605.3300676,Augmented Reality Views for Occluded Interaction,1,Klemen Lilija,University of Copenhagen,Copenhagen,Denmark,false,false,"We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability."
pn4779,https://doi.org/10.1145/3290605.3300676,Augmented Reality Views for Occluded Interaction,2,Henning Pohl,University of Copenhagen,Copenhagen,Denmark,false,false,"We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability."
pn4779,https://doi.org/10.1145/3290605.3300676,Augmented Reality Views for Occluded Interaction,3,Sebastian Boring,University of Copenhagen,Copenhagen,Denmark,false,false,"We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability."
pn4779,https://doi.org/10.1145/3290605.3300676,Augmented Reality Views for Occluded Interaction,4,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,false,false,"We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability."
pn7710,https://doi.org/10.1145/3290605.3300855,A Design Space for Gaze Interaction on Head-mounted Displays,1,Teresa Hirzle,Ulm University,Ulm,Germany,false,false,"Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision."
pn7710,https://doi.org/10.1145/3290605.3300855,A Design Space for Gaze Interaction on Head-mounted Displays,2,Jan Gugenheimer,Ulm University,Ulm,Germany,false,false,"Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision."
pn7710,https://doi.org/10.1145/3290605.3300855,A Design Space for Gaze Interaction on Head-mounted Displays,3,Florian Geiselhart,Ulm University,Ulm,Germany,false,false,"Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision."
pn7710,https://doi.org/10.1145/3290605.3300855,A Design Space for Gaze Interaction on Head-mounted Displays,4,Andreas Bulling,University of Stuttgart,Stuttgart,Germany,false,false,"Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision."
pn7710,https://doi.org/10.1145/3290605.3300855,A Design Space for Gaze Interaction on Head-mounted Displays,5,Enrico Rukzio,University of Ulm,Ulm,Germany,false,false,"Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision."
pn8820,https://doi.org/10.1145/3290605.3300762,Personalising the TV Experience using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation,1,Vinoba Vinayagamoorthy,BBC R&D,London,United Kingdom,false,false,"Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme – one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research."
pn8820,https://doi.org/10.1145/3290605.3300762,Personalising the TV Experience using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation,2,Maxine Glancy,BBC R&D,Salford,United Kingdom,false,false,"Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme – one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research."
pn8820,https://doi.org/10.1145/3290605.3300762,Personalising the TV Experience using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation,3,Christoph Ziegler,IRT,Munich,Germany,false,false,"Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme – one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research."
pn8820,https://doi.org/10.1145/3290605.3300762,Personalising the TV Experience using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation,4,Richard Schäffer,IRT,Munich,Germany,false,false,"Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme – one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,1,Jun Nishida,JSPS,Chicago,United States,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,2,Soichiro Matsuda,University of Tsukuba,Tsukuba,Japan,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,3,Mika Oki,University of Tsukuba,Tsukuba City,Japan,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,4,Hikaru Takatori,University of Tsukuba,Tsukuba,Japan,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,5,Kosuke Sato,University of Tsukuba,Ibaraki,Japan,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn9629,https://doi.org/10.1145/3290605.3300926,Egocentric Smaller-person Experience through a Change in Visual Perspective,6,Kenji Suzuki,University of Tsukuba,Tsukuba,Japan,true,false,"This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment."
pn4601,https://doi.org/10.1145/3290605.3300315,Towards an Effective Digital Literacy Intervention to Assist Returning Citizens with Job Search,1,Ihudiya Ogbonnaya-Ogburu,University of Michigan,Ann Arbor,United States,false,false,"Returning citizens (formerly incarcerated individuals) face great challenges finding employment, and these are exacerbated by the need for digital literacy in modern job search. Through 23 semi-structured interviews and a pilot digital literacy course with returning citizens in the Greater Detroit area, we explore tactics and needs with respect to job search and digital technology. Returning citizens exhibit great diversity, but overall, we find our participants to have striking gaps in digital literacy upon release, even as they are quickly introduced to smartphones by friends and family. They tend to have employable skills and ability to use offline social networks to find opportunities, but have little understanding of formal job search processes, online or offline. They mostly mirror mainstream use of mobile technology, but they have various reasons to avoid social media. These and other findings lead to recommendations for digital literacy programs for returning citizens."
pn4601,https://doi.org/10.1145/3290605.3300315,Towards an Effective Digital Literacy Intervention to Assist Returning Citizens with Job Search,2,Kentaro Toyama,University of Michigan,Ann Arbor,United States,false,false,"Returning citizens (formerly incarcerated individuals) face great challenges finding employment, and these are exacerbated by the need for digital literacy in modern job search. Through 23 semi-structured interviews and a pilot digital literacy course with returning citizens in the Greater Detroit area, we explore tactics and needs with respect to job search and digital technology. Returning citizens exhibit great diversity, but overall, we find our participants to have striking gaps in digital literacy upon release, even as they are quickly introduced to smartphones by friends and family. They tend to have employable skills and ability to use offline social networks to find opportunities, but have little understanding of formal job search processes, online or offline. They mostly mirror mainstream use of mobile technology, but they have various reasons to avoid social media. These and other findings lead to recommendations for digital literacy programs for returning citizens."
pn4601,https://doi.org/10.1145/3290605.3300315,Towards an Effective Digital Literacy Intervention to Assist Returning Citizens with Job Search,3,Tawanna Dillahunt,University of Michigan,Ann Arbor,United States,false,false,"Returning citizens (formerly incarcerated individuals) face great challenges finding employment, and these are exacerbated by the need for digital literacy in modern job search. Through 23 semi-structured interviews and a pilot digital literacy course with returning citizens in the Greater Detroit area, we explore tactics and needs with respect to job search and digital technology. Returning citizens exhibit great diversity, but overall, we find our participants to have striking gaps in digital literacy upon release, even as they are quickly introduced to smartphones by friends and family. They tend to have employable skills and ability to use offline social networks to find opportunities, but have little understanding of formal job search processes, online or offline. They mostly mirror mainstream use of mobile technology, but they have various reasons to avoid social media. These and other findings lead to recommendations for digital literacy programs for returning citizens."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,1,Manya Sleeper,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,2,Tara Matthews,Independent,Pullman,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,3,Kathleen O'leary,Google,Seattle,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,4,Anna Turner,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,5,Jill Woelfer,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,6,Martin Shelton,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,7,Andrew Oplinger,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,8,Andreas Schou,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn9759,https://doi.org/10.1145/3290605.3300319,Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy,9,Sunny Consolvo,Google,Mountain View,United States,false,false,"Addressing digital security and privacy issues can be particularly difficult for users who face challenging circumstances. We performed semi-structured interviews with residents and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15 residents, 3 staff) to explore their digital security and privacy challenges. Based on these interviews, we outline four tough times themes --- challenges experienced by our financially insecure participants that impacted their digital security and privacy --- which included: (1) limited financial resources, (2) limited access to reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress. We provide examples of how each theme impacts digital security and privacy practices and needs. We then use these themes to provide a framework outlining opportunities for technology creators to better support users facing security and privacy challenges related to financial insecurity."
pn3433,https://doi.org/10.1145/3290605.3300586,"Witchcraft and HCI: Morality, Modernity, and Postcolonial Computing in Rural Bangladesh",1,Sharifa Sultana,Cornell University,Ithaca,United States,false,false,"While Human-Computer Interaction (HCI) research on health and well-being is increasingly becoming more aware and inclusive of its social and political dimensions, spiritual practices are still largely overlooked there. For a large number of people around the world, especially in the global south, witchcraft, sorcery, and other occult practices are the primary means of achieving health, wealth, satisfaction, and happiness. Building on an eight-month long ethnography in six villages in Jessore, Bangladesh, this paper explores the knowledge, materials, and politics involved in the local witchcraft practices there. By drawing from a rich body of anthropological work on witchcraft, this paper discusses how those findings contribute to the broader issues in HCI around morality, modernity, and postcolonial computing. This paper concludes by recommending ways for smooth integration of traditional occult practices with HCI through design and policy. We argue for occult practices as an under-appreciated site for HCI to learn how to combat ideological hegemony."
pn3433,https://doi.org/10.1145/3290605.3300586,"Witchcraft and HCI: Morality, Modernity, and Postcolonial Computing in Rural Bangladesh",2,Syed Ishtiaque Ahmed,University of Toronto,Toronto,Canada,false,false,"While Human-Computer Interaction (HCI) research on health and well-being is increasingly becoming more aware and inclusive of its social and political dimensions, spiritual practices are still largely overlooked there. For a large number of people around the world, especially in the global south, witchcraft, sorcery, and other occult practices are the primary means of achieving health, wealth, satisfaction, and happiness. Building on an eight-month long ethnography in six villages in Jessore, Bangladesh, this paper explores the knowledge, materials, and politics involved in the local witchcraft practices there. By drawing from a rich body of anthropological work on witchcraft, this paper discusses how those findings contribute to the broader issues in HCI around morality, modernity, and postcolonial computing. This paper concludes by recommending ways for smooth integration of traditional occult practices with HCI through design and policy. We argue for occult practices as an under-appreciated site for HCI to learn how to combat ideological hegemony."
pn8567,https://doi.org/10.1145/3290605.3300561,Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking,1,Julia Deeb-Swihart,Georgia Institute of Technology,Atlanta,United States,false,false,"In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development."
pn8567,https://doi.org/10.1145/3290605.3300561,Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking,2,Alex Endert,Georgia Institute of Technology,Atlanta,United States,false,false,"In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development."
pn8567,https://doi.org/10.1145/3290605.3300561,Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking,3,Amy Bruckman,Georgia Institute of Technology,Atlanta,United States,false,false,"In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development."
pn3089,https://doi.org/10.1145/3290605.3300536,The Smartphone as a Pacifier and its Consequences: Young adults' smartphone usage in moments of solitude and correlations to self-reflection,1,Sarah Diefenbach,Ludwig Maximilians University Munich,Munich,Germany,false,false,"The smartphone plays a dominant role in everyday life. Among young adults, the average daily usage time is almost four hours. The present study [N=399] examines the specific psychological role of smartphone usage during alone time (e.g. in the subway, waiting, in bed). Particularly, we explore its role in coping with negative emotions in the sense of an ""attachment object"", providing comfort like a pacifier for infants. Results underlined the pacifying role of smartphone usage to cope with negative emotions in moments of alone time. Moreover, particular personality dispositions (e.g., high need to belong, high proneness to boredom) were associated with more extensive self-reported smartphone usage and mediated by the perception of the smartphone as an attachment object. Finally, smartphone usage was negatively correlated to self-insight, possibly substituting intense inner debates or self-realizations during alone time. Implications for HCI research and practice are discussed."
pn3089,https://doi.org/10.1145/3290605.3300536,The Smartphone as a Pacifier and its Consequences: Young adults' smartphone usage in moments of solitude and correlations to self-reflection,2,Kim Borrmann,Ludwig Maximilians University Munich,Munich,Germany,false,false,"The smartphone plays a dominant role in everyday life. Among young adults, the average daily usage time is almost four hours. The present study [N=399] examines the specific psychological role of smartphone usage during alone time (e.g. in the subway, waiting, in bed). Particularly, we explore its role in coping with negative emotions in the sense of an ""attachment object"", providing comfort like a pacifier for infants. Results underlined the pacifying role of smartphone usage to cope with negative emotions in moments of alone time. Moreover, particular personality dispositions (e.g., high need to belong, high proneness to boredom) were associated with more extensive self-reported smartphone usage and mediated by the perception of the smartphone as an attachment object. Finally, smartphone usage was negatively correlated to self-insight, possibly substituting intense inner debates or self-realizations during alone time. Implications for HCI research and practice are discussed."
pn1947,https://doi.org/10.1145/3290605.3300896,Long-Term Value of Social Robots through the Eyes of Expert Users,1,Dmitry Dereshev,Northumbria University at Newcastle,Newcastle Upon Tyne,United Kingdom,false,false,"Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper - a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots."
pn1947,https://doi.org/10.1145/3290605.3300896,Long-Term Value of Social Robots through the Eyes of Expert Users,2,David Kirk,Northumbria University at Newcastle,Newcastle Upon Tyne,United Kingdom,false,false,"Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper - a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots."
pn1947,https://doi.org/10.1145/3290605.3300896,Long-Term Value of Social Robots through the Eyes of Expert Users,3,Kohei Matsumura,Ritsumeikan University,Kyoto,Japan,false,false,"Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper - a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots."
pn1947,https://doi.org/10.1145/3290605.3300896,Long-Term Value of Social Robots through the Eyes of Expert Users,4,Toshiyuki Maeda,Hannan University,Osaka,Japan,false,false,"Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper - a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots."
pn2204,https://doi.org/10.1145/3290605.3300328,Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process,1,Zhenhui Peng,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner."
pn2204,https://doi.org/10.1145/3290605.3300328,Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process,2,Yunhwan Kwon,Dongguk University,Seoul,Republic Of Korea,false,false,"As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner."
pn2204,https://doi.org/10.1145/3290605.3300328,Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process,3,Jiaan Lu,University of Michigan-Shanghai Jiao Tong University Joint Institute,Shanghai,China,false,false,"As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner."
pn2204,https://doi.org/10.1145/3290605.3300328,Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process,4,Ziming Wu,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner."
pn2204,https://doi.org/10.1145/3290605.3300328,Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process,5,Xiaojuan Ma,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,false,false,"As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner."
pn3275,https://doi.org/10.1145/3290605.3300711,Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship,1,Yubo Kou,Florida State University,Tallahassee,United States,false,false,"Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self—the totality of internal qualities such as consciousness and agency—plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault's ethics of ""care of the self,"" which examines how the self is constituted through conscious and reflective work on self-transformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design."
pn3275,https://doi.org/10.1145/3290605.3300711,Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship,2,Xinning Gui,"University of California, Irvine",Irvine,United States,false,false,"Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self—the totality of internal qualities such as consciousness and agency—plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault's ethics of ""care of the self,"" which examines how the self is constituted through conscious and reflective work on self-transformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design."
pn3275,https://doi.org/10.1145/3290605.3300711,Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship,3,Yunan Chen,"University of California, Irvine",Irvine,United States,false,false,"Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self—the totality of internal qualities such as consciousness and agency—plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault's ethics of ""care of the self,"" which examines how the self is constituted through conscious and reflective work on self-transformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design."
pn3275,https://doi.org/10.1145/3290605.3300711,Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship,4,Bonnie Nardi,"University of California, Irvine",Irvine,United States,false,false,"Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self—the totality of internal qualities such as consciousness and agency—plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault's ethics of ""care of the self,"" which examines how the self is constituted through conscious and reflective work on self-transformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design."
pn7249,https://doi.org/10.1145/3290605.3300484,Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns,1,Zahra Ashktorab,IBM Research AI,Yorktown Heights,United States,false,false,"Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy."
pn7249,https://doi.org/10.1145/3290605.3300484,Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns,2,Mohit Jain,IBM Research,Bangalore,India,false,false,"Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy."
pn7249,https://doi.org/10.1145/3290605.3300484,Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns,3,Q. Liao,IBM Research AI,Yorktown Heights,United States,false,false,"Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy."
pn7249,https://doi.org/10.1145/3290605.3300484,Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns,4,Justin Weisz,IBM Research AI,Yorktown Heights,United States,false,false,"Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy."
pn8259,https://doi.org/10.1145/3290605.3300511,Exploring Virtual Agents for Augmented Reality,1,Isaac Wang,University of Florida,Gainesville,United States,false,false,"Prior work has shown that embodiment can benefit virtual agents, such as increasing rapport and conveying non-verbal information. However, it is unclear if users prefer an embodied to a speech-only agent for augmented reality (AR) headsets that are designed to assist users in completing real-world tasks. We conducted a study to examine users' perceptions and behaviors when interacting with virtual agents in AR. We asked 24 adults to wear the Microsoft HoloLens and find objects in a hidden object game while interacting with an agent that would offer assistance. We presented participants with four different agents: voice-only, non-human, full-size embodied, and a miniature embodied agent. Overall, users preferred the miniature embodied agent due to the novelty of his size and reduced uncanniness as opposed to the larger agent. From our results, we draw conclusions about how agent representation matters and derive guidelines on designing agents for AR headsets."
pn8259,https://doi.org/10.1145/3290605.3300511,Exploring Virtual Agents for Augmented Reality,2,Jesse Smith,University of Florida,Gainesville,United States,false,false,"Prior work has shown that embodiment can benefit virtual agents, such as increasing rapport and conveying non-verbal information. However, it is unclear if users prefer an embodied to a speech-only agent for augmented reality (AR) headsets that are designed to assist users in completing real-world tasks. We conducted a study to examine users' perceptions and behaviors when interacting with virtual agents in AR. We asked 24 adults to wear the Microsoft HoloLens and find objects in a hidden object game while interacting with an agent that would offer assistance. We presented participants with four different agents: voice-only, non-human, full-size embodied, and a miniature embodied agent. Overall, users preferred the miniature embodied agent due to the novelty of his size and reduced uncanniness as opposed to the larger agent. From our results, we draw conclusions about how agent representation matters and derive guidelines on designing agents for AR headsets."
pn8259,https://doi.org/10.1145/3290605.3300511,Exploring Virtual Agents for Augmented Reality,3,Jaime Ruiz,University of Florida,Gainesville,United States,false,false,"Prior work has shown that embodiment can benefit virtual agents, such as increasing rapport and conveying non-verbal information. However, it is unclear if users prefer an embodied to a speech-only agent for augmented reality (AR) headsets that are designed to assist users in completing real-world tasks. We conducted a study to examine users' perceptions and behaviors when interacting with virtual agents in AR. We asked 24 adults to wear the Microsoft HoloLens and find objects in a hidden object game while interacting with an agent that would offer assistance. We presented participants with four different agents: voice-only, non-human, full-size embodied, and a miniature embodied agent. Overall, users preferred the miniature embodied agent due to the novelty of his size and reduced uncanniness as opposed to the larger agent. From our results, we draw conclusions about how agent representation matters and derive guidelines on designing agents for AR headsets."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,1,Minha Lee,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,2,Sander Ackermans,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,3,Nena Van As,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,4,Hanwen Chang,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,5,Enzo Lucas,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn5228,https://doi.org/10.1145/3290605.3300932,Caring for Vincent: A Chatbot for Self-Compassion,6,Wijnand Ijsselsteijn,Technical University of Eindhoven,Eindhoven,Netherlands,false,false,"The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,1,Leigh Clark,University College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,2,Nadia Pantidi,University College Cork,Cork,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,3,Orla Cooney,University College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,4,Philip Doyle,Voysis Ltd.,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,5,Diego Garaialde,University College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,6,Justin Edwards,University College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,7,Brendan Spillane,Trinity College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,8,Emer Gilmartin,Trinity College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,9,Christine Murad,University of Toronto,Toronto,Canada,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,10,Cosmin Munteanu,University of Toronto Mississauga,Mississauga,Canada,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,11,Vincent Wade,Trinity College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8785,https://doi.org/10.1145/3290605.3300705,What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents,12,Benjamin Cowan,University College Dublin,Dublin,Ireland,true,false,"Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction."
pn8669,https://doi.org/10.1145/3290605.3300735,Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology,1,Rosella Galindo Esparza,Queen Mary University of London,London,United Kingdom,false,false,"Participatory performance provides methods for exploring social identities and situations in ways that can help people to imagine new ways of being. Digital technologies provide tools that can help people envision these possibilities. We explore this combination through a performance workshop process designed to help stroke survivors imagine new physical and social possibilities by enacting fantasies of ""things they always wanted to do"". This process uses performance methods combined with specially designed real-time movement visualisations to progressively build fantasy narratives that are enacted with and for other workshop participants. Qualitative evaluations suggest this process successfully stimulates participant's embodied imagination and generates a diverse range of fantasies. The interactive and communal aspects of the workshop process appear to be especially important in achieving these effects. This work highlights how the combination of performance methods and interactive tools can bring a rich, prospective and political understanding of people's lived experience to design."
pn8669,https://doi.org/10.1145/3290605.3300735,Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology,2,Patrick Healey,Queen Mary University of London,London,United Kingdom,false,false,"Participatory performance provides methods for exploring social identities and situations in ways that can help people to imagine new ways of being. Digital technologies provide tools that can help people envision these possibilities. We explore this combination through a performance workshop process designed to help stroke survivors imagine new physical and social possibilities by enacting fantasies of ""things they always wanted to do"". This process uses performance methods combined with specially designed real-time movement visualisations to progressively build fantasy narratives that are enacted with and for other workshop participants. Qualitative evaluations suggest this process successfully stimulates participant's embodied imagination and generates a diverse range of fantasies. The interactive and communal aspects of the workshop process appear to be especially important in achieving these effects. This work highlights how the combination of performance methods and interactive tools can bring a rich, prospective and political understanding of people's lived experience to design."
pn8669,https://doi.org/10.1145/3290605.3300735,Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology,3,Lois Weaver,Queen Mary University of London,London,United Kingdom,false,false,"Participatory performance provides methods for exploring social identities and situations in ways that can help people to imagine new ways of being. Digital technologies provide tools that can help people envision these possibilities. We explore this combination through a performance workshop process designed to help stroke survivors imagine new physical and social possibilities by enacting fantasies of ""things they always wanted to do"". This process uses performance methods combined with specially designed real-time movement visualisations to progressively build fantasy narratives that are enacted with and for other workshop participants. Qualitative evaluations suggest this process successfully stimulates participant's embodied imagination and generates a diverse range of fantasies. The interactive and communal aspects of the workshop process appear to be especially important in achieving these effects. This work highlights how the combination of performance methods and interactive tools can bring a rich, prospective and political understanding of people's lived experience to design."
pn8669,https://doi.org/10.1145/3290605.3300735,Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology,4,Matthew Delbridge,Melbourne University,Melbourne,Australia,false,false,"Participatory performance provides methods for exploring social identities and situations in ways that can help people to imagine new ways of being. Digital technologies provide tools that can help people envision these possibilities. We explore this combination through a performance workshop process designed to help stroke survivors imagine new physical and social possibilities by enacting fantasies of ""things they always wanted to do"". This process uses performance methods combined with specially designed real-time movement visualisations to progressively build fantasy narratives that are enacted with and for other workshop participants. Qualitative evaluations suggest this process successfully stimulates participant's embodied imagination and generates a diverse range of fantasies. The interactive and communal aspects of the workshop process appear to be especially important in achieving these effects. This work highlights how the combination of performance methods and interactive tools can bring a rich, prospective and political understanding of people's lived experience to design."
pn3319,https://doi.org/10.1145/3290605.3300612,Using Both Hands: Tangibles for Stroke Rehabilitation in the Home,1,Mikko Kytö,Aalto University,Helsinki,Finland,false,false,"Stroke is one of the most common cause of long-term disability in the world, significantly reducing quality of life through impairing motor functions and cognitive abilities. Whilst rehabilitation exercises can help in the recovery of motor function impairments, stroke survivors rarely exercise enough, leading to far from optimal recovery. In this paper, we investigate how upper limb stroke rehabilitation can be supported using interactive tangible bimanual devices in the home. We customise the rehabilitation activities based on individual rehabilitation requirements and motivation of stroke survivors. Through evaluation with five stroke survivors, we uncovered insight into how tangible stroke rehabilitation systems for the home should be designed. The evaluation revealed the special importance of tailorable form factor and supporting self-awareness and grip exercises in order to increase the independency of stroke survivors to carry out activities of daily living."
pn3319,https://doi.org/10.1145/3290605.3300612,Using Both Hands: Tangibles for Stroke Rehabilitation in the Home,2,Laura Maye,Aalto University,Helsinki,Finland,false,false,"Stroke is one of the most common cause of long-term disability in the world, significantly reducing quality of life through impairing motor functions and cognitive abilities. Whilst rehabilitation exercises can help in the recovery of motor function impairments, stroke survivors rarely exercise enough, leading to far from optimal recovery. In this paper, we investigate how upper limb stroke rehabilitation can be supported using interactive tangible bimanual devices in the home. We customise the rehabilitation activities based on individual rehabilitation requirements and motivation of stroke survivors. Through evaluation with five stroke survivors, we uncovered insight into how tangible stroke rehabilitation systems for the home should be designed. The evaluation revealed the special importance of tailorable form factor and supporting self-awareness and grip exercises in order to increase the independency of stroke survivors to carry out activities of daily living."
pn3319,https://doi.org/10.1145/3290605.3300612,Using Both Hands: Tangibles for Stroke Rehabilitation in the Home,3,David Mcgookin,Aalto University,Helsinki,Finland,false,false,"Stroke is one of the most common cause of long-term disability in the world, significantly reducing quality of life through impairing motor functions and cognitive abilities. Whilst rehabilitation exercises can help in the recovery of motor function impairments, stroke survivors rarely exercise enough, leading to far from optimal recovery. In this paper, we investigate how upper limb stroke rehabilitation can be supported using interactive tangible bimanual devices in the home. We customise the rehabilitation activities based on individual rehabilitation requirements and motivation of stroke survivors. Through evaluation with five stroke survivors, we uncovered insight into how tangible stroke rehabilitation systems for the home should be designed. The evaluation revealed the special importance of tailorable form factor and supporting self-awareness and grip exercises in order to increase the independency of stroke survivors to carry out activities of daily living."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,1,Sonali Mishra,University of Washington,Seattle,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,2,Predrag Klasnja,University of Michigan,Ann Arbor,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,3,John Macduffie Woodburn,Sage Bionetworks,Seattle,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,4,Eric Hekler,University of California San Diego,San Diego,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,5,Larsson Omberg,Sage Bionetworks,Seattle,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,6,Michael Kellen,Sage Bionetworks,Seattle,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn3969,https://doi.org/10.1145/3290605.3300337,Supporting Coping with Parkinson's Disease Through Self Tracking,7,Lara Mangravite,Sage Bionetworks,Seattle,United States,false,false,"Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,1,Feng Tian,Chinese Academy of Sciences,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,2,Xiangmin Fan,Chinese Academy of Sciences,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,3,Junjun Fan,Chinese Academy of Sciences,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,4,Yicheng Zhu,Peking Union Medical College Hospital,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,5,Jing Gao,Chinese Academy of Sciences,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,6,Dakuo Wang,IBM T.J. Watson Research Center,Yorktown Heights,United States,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,7,Xiaojun Bi,Stony Brook University,Stony Brook,United States,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn6014,https://doi.org/10.1145/3290605.3300313,What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions,8,Hongan Wang,Chinese Academy of Sciences,Beijing,China,false,false,"Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions."
pn3740,https://doi.org/10.1145/3290605.3300500,Managing Messes in Computational Notebooks,1,Andrew Head,"University of California, Berkeley",Berkeley,United States,false,true,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning."
pn3740,https://doi.org/10.1145/3290605.3300500,Managing Messes in Computational Notebooks,2,Fred Hohman,Georgia Institute of Technology,Atlanta,United States,false,true,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning."
pn3740,https://doi.org/10.1145/3290605.3300500,Managing Messes in Computational Notebooks,3,Titus Barik,Microsoft,Redmond,United States,false,true,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning."
pn3740,https://doi.org/10.1145/3290605.3300500,Managing Messes in Computational Notebooks,4,Steven Drucker,Microsoft Research,Redmond,United States,false,true,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning."
pn3740,https://doi.org/10.1145/3290605.3300500,Managing Messes in Computational Notebooks,5,Robert Deline,Microsoft Research,Redmond,United States,false,true,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning."
pn4092,https://doi.org/10.1145/3290605.3300322,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,1,Mary Beth Kery,Carnegie Mellon University,Pittsburgh,United States,false,false,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab."
pn4092,https://doi.org/10.1145/3290605.3300322,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,2,Bonnie John,Bloomberg L.P.,New York,United States,false,false,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab."
pn4092,https://doi.org/10.1145/3290605.3300322,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,3,Patrick O'flaherty,Bloomberg L.P.,New York,United States,false,false,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab."
pn4092,https://doi.org/10.1145/3290605.3300322,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,4,Amber Horvath,Carnegie Mellon University,Pittsburgh,United States,false,false,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab."
pn4092,https://doi.org/10.1145/3290605.3300322,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,5,Brad Myers,Carnegie Mellon University,Pittsburgh,United States,false,false,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab."
pn4759,https://doi.org/10.1145/3290605.3300557,The Scale and Structure of Personal File Collections,1,Jesse Dinneen,Victoria University of Wellington,Wellington,New Zealand,false,false,"Although many challenges of managing computer files have been identified in past studies -- and many alternative prototypes made -- the scale and structure of personal file collections remain relatively unknown. We studied 348 such collections, and found they are typically considerably larger in scale (30-190 thousand files) and structure (folder trees twice taller and many times wider) than previously thought, which suggests files and folders are used now more than ever despite advances in Web storage, desktop search, and tagging. Data along many measures within and across collections were log normally distributed, indicating that personal collections resemble imbalanced, group-made collections and confirming the intuition that personal information management behaviour varies greatly. Directions for the generation of test collections and other future research are discussed."
pn4759,https://doi.org/10.1145/3290605.3300557,The Scale and Structure of Personal File Collections,2,Charles-Antoine Julien,McGill University,Montreal,Canada,false,false,"Although many challenges of managing computer files have been identified in past studies -- and many alternative prototypes made -- the scale and structure of personal file collections remain relatively unknown. We studied 348 such collections, and found they are typically considerably larger in scale (30-190 thousand files) and structure (folder trees twice taller and many times wider) than previously thought, which suggests files and folders are used now more than ever despite advances in Web storage, desktop search, and tagging. Data along many measures within and across collections were log normally distributed, indicating that personal collections resemble imbalanced, group-made collections and confirming the intuition that personal information management behaviour varies greatly. Directions for the generation of test collections and other future research are discussed."
pn4759,https://doi.org/10.1145/3290605.3300557,The Scale and Structure of Personal File Collections,3,Ilja Frissen,McGill University,Montreal,Canada,false,false,"Although many challenges of managing computer files have been identified in past studies -- and many alternative prototypes made -- the scale and structure of personal file collections remain relatively unknown. We studied 348 such collections, and found they are typically considerably larger in scale (30-190 thousand files) and structure (folder trees twice taller and many times wider) than previously thought, which suggests files and folders are used now more than ever despite advances in Web storage, desktop search, and tagging. Data along many measures within and across collections were log normally distributed, indicating that personal collections resemble imbalanced, group-made collections and confirming the intuition that personal information management behaviour varies greatly. Directions for the generation of test collections and other future research are discussed."
pn4659,https://doi.org/10.1145/3290605.3300409,Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data,1,Po-Ming Law,Georgia Institute of Technology,Atlanta,United States,false,false,"Asking pairwise comparison questions is common. Yet, we often find ourselves comparing apples and oranges --- the two entities of interest are not readily comparable. To understand how technologies can extend our capabilities to conduct pairwise comparisons during data analysis, we analyzed pairwise comparison questions collected from crowd workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet application that supports comparing two groups of records in a data table. Duo decomposes a pairwise comparison question into rules and showcases sloppy rules, a query technique for specifying pairwise comparisons. We conducted a user study comparing sloppy rules and natural language. The findings suggest that for easier pairwise comparison tasks, the two techniques are comparable in efficiency and preference and that for more difficult pairwise comparison tasks, sloppy rules allow faster specification and are more preferable."
pn4659,https://doi.org/10.1145/3290605.3300409,Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data,2,Subhajit Das,Georgia Institute of Technology,Atlanta,United States,false,false,"Asking pairwise comparison questions is common. Yet, we often find ourselves comparing apples and oranges --- the two entities of interest are not readily comparable. To understand how technologies can extend our capabilities to conduct pairwise comparisons during data analysis, we analyzed pairwise comparison questions collected from crowd workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet application that supports comparing two groups of records in a data table. Duo decomposes a pairwise comparison question into rules and showcases sloppy rules, a query technique for specifying pairwise comparisons. We conducted a user study comparing sloppy rules and natural language. The findings suggest that for easier pairwise comparison tasks, the two techniques are comparable in efficiency and preference and that for more difficult pairwise comparison tasks, sloppy rules allow faster specification and are more preferable."
pn4659,https://doi.org/10.1145/3290605.3300409,Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data,3,Rahul Basole,Georgia Institute of Technology,Atlanta,United States,false,false,"Asking pairwise comparison questions is common. Yet, we often find ourselves comparing apples and oranges --- the two entities of interest are not readily comparable. To understand how technologies can extend our capabilities to conduct pairwise comparisons during data analysis, we analyzed pairwise comparison questions collected from crowd workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet application that supports comparing two groups of records in a data table. Duo decomposes a pairwise comparison question into rules and showcases sloppy rules, a query technique for specifying pairwise comparisons. We conducted a user study comparing sloppy rules and natural language. The findings suggest that for easier pairwise comparison tasks, the two techniques are comparable in efficiency and preference and that for more difficult pairwise comparison tasks, sloppy rules allow faster specification and are more preferable."
pn9280,https://doi.org/10.1145/3290605.3300554,"Instrumenting and Analyzing Fabrication Activities, Users, and Expertise",1,Jun Gong,Autodesk Research,Toronto,Canada,false,false,"The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces."
pn9280,https://doi.org/10.1145/3290605.3300554,"Instrumenting and Analyzing Fabrication Activities, Users, and Expertise",2,Fraser Anderson,Autodesk Research,Toronto,Canada,false,false,"The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces."
pn9280,https://doi.org/10.1145/3290605.3300554,"Instrumenting and Analyzing Fabrication Activities, Users, and Expertise",3,George Fitzmaurice,Autodesk Research,Toronto,Canada,false,false,"The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces."
pn9280,https://doi.org/10.1145/3290605.3300554,"Instrumenting and Analyzing Fabrication Activities, Users, and Expertise",4,Tovi Grossman,Autodesk Research,Toronto,Canada,false,false,"The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,1,Jo-Yu Lo,National Chiao Tung University,Hsinchu,Taiwan Roc,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,2,Da-Yuan Huang,National Chiao Tung University,Hsinchu,Taiwan Roc,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,3,Tzu-Sheng Kuo,National Taiwan University,Taipei,Taiwan Roc,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,4,Chen-Kuo Sun,National Taiwan University of Science and Technology,Taipei,Taiwan Roc,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,5,Jun Gong,Dartmouth College,Hanover,United States,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,6,Teddy Seyed,University of Calgary,Calgary,Canada,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,7,Xing-Dong Yang,Dartmouth College,Hanover,United States,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn5623,https://doi.org/10.1145/3290605.3300633,AutoFritz: Autocomplete for Prototyping Virtual Breadboard Circuits,8,Bing-Yu Chen,National Taiwan University,Taipei,Taiwan Roc,true,false,"We propose autocomplete for the design and development of virtual breadboard circuits using software prototyping tools. With our system, a user inserts a component into the virtual breadboard, and it automatically provides a user with a list of suggested components. These suggestions complete or ex- tend the electronic functionality of the inserted component to save the user's time and reduce circuit error. To demon- strate the effectiveness of autocomplete, we implemented our system on Fritzing, a popular open source breadboard circuit prototyping software, used by novice makers. Our autocomplete suggestions were implemented based upon schematics from datasheets for standard components, as well as how components are used together from over 4000 circuit projects from the Fritzing community. We report the results of a controlled study with 16 participants, evaluating the effectiveness of autocomplete in the creation of virtual breadboard circuits, and conclude by sharing insights and directions for future research."
pn4920,https://doi.org/10.1145/3290605.3300278,Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation,1,Evan Strasnick,Stanford University,Stanford,United States,false,false,"Difficulties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifications. Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user's PCB to our custom testing hardware and to software tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues by instrumenting and testing different classes of boards, as well as by characterizing its technical limitations and by soliciting feedback through a guided exploration with PCB designers."
pn4920,https://doi.org/10.1145/3290605.3300278,Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation,2,Sean Follmer,Stanford University,Stanford,United States,false,false,"Difficulties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifications. Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user's PCB to our custom testing hardware and to software tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues by instrumenting and testing different classes of boards, as well as by characterizing its technical limitations and by soliciting feedback through a guided exploration with PCB designers."
pn4920,https://doi.org/10.1145/3290605.3300278,Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation,3,Maneesh Agrawala,Stanford University,Stanford,United States,false,false,"Difficulties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifications. Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user's PCB to our custom testing hardware and to software tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues by instrumenting and testing different classes of boards, as well as by characterizing its technical limitations and by soliciting feedback through a guided exploration with PCB designers."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,1,Richard Lin,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,2,Rohit Ramesh,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,3,Antonio Iannopollo,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,4,Alberto Sangiovanni Vincentelli,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,5,Prabal Dutta,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,6,Elad Alon,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn8756,https://doi.org/10.1145/3290605.3300513,Beyond Schematic Capture: Meaningful Abstractions for Better Electronics Design Tools,7,Björn Hartmann,"University of California, Berkeley",Berkeley,United States,false,false,"Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain."
pn1609,https://doi.org/10.1145/3290605.3300679,Beyond Tutoring: Opportunities for Intergenerational Mentorship at a Community Level,1,Ye Yuan,University of Minnesota,Minneapolis,United States,true,false,"Community intergenerational mentorship offers an opportunity to address older adults' social isolation while providing valuable one-on-one or small group learning experiences for elementary school students. Current organizations that support this kind of engagement focus on in-person visits that place the burden of logistics and transportation on the older adult. However, as older adults become less independent while aging, coming to schools in person becomes more challenging. We present a qualitative analysis of current intergenerational mentorship practices to understand opportunities for technology to expand access to this experience. We highlight elements critical for building successful mentorship: the importance of relationship building between older adults and children during mentoring activities, the skills mentors acquired to carry out mentoring activities, and support needed from teachers and schools. We contribute a rich description of current intergenerational mentorship practices and provide insights for opportunities for novel HCI technologies in this context."
pn1609,https://doi.org/10.1145/3290605.3300679,Beyond Tutoring: Opportunities for Intergenerational Mentorship at a Community Level,2,Svetlana Yarosh,University of Minnesota,Minneapolis,United States,true,false,"Community intergenerational mentorship offers an opportunity to address older adults' social isolation while providing valuable one-on-one or small group learning experiences for elementary school students. Current organizations that support this kind of engagement focus on in-person visits that place the burden of logistics and transportation on the older adult. However, as older adults become less independent while aging, coming to schools in person becomes more challenging. We present a qualitative analysis of current intergenerational mentorship practices to understand opportunities for technology to expand access to this experience. We highlight elements critical for building successful mentorship: the importance of relationship building between older adults and children during mentoring activities, the skills mentors acquired to carry out mentoring activities, and support needed from teachers and schools. We contribute a rich description of current intergenerational mentorship practices and provide insights for opportunities for novel HCI technologies in this context."
pn2429,https://doi.org/10.1145/3290605.3300572,Dynamics of Visual Attention in Multiparty Collaborative Problem Solving using Multidimensional Recurrence Quantification Analysis,1,Hana Vrzakova,University of Colorado Boulder,Boulder,United States,false,false,"Multiparty collaborative problem solving - an increasingly important context in the 21st century workforce - suffers from a degradation of social and behavioral signals when attempted remotely, resulting in suboptimal outcomes. We investigate teams' multidimensional patterns of visual attention during a collaborative problem-solving task with an eye for leveraging insights to improve collaborative interfaces. Fifty-seven novices (forming 19 triads) engaged in a challenging programming task (Minecraft Hour of Code) using videoconferencing software with screen sharing. To discover patterns of individual-level gaze-UI coupling(coordination of a teammate's attention with respect to changes in the user interface) and team-level gaze-UI regularity (dynamics of teams' collective attention in context with changes in the user interface), we applied cross- and multidimensional recurrence quantification analyses, respectively. Individuals' eye gaze was significantly coupled with the ongoing screen activity whereas teams displayed significant patterns of gaze regularity, suggesting repetitive patterns in teams' attention. These measures predicted expert-coded collaborative processes of constructing shared knowledge and negotiation and coordination (but not maintaining team function) and correlated with task score (r = .425). They also predicted individually assessed subjective perceptions of team performance and the collaboration process, but not individual's learning or team's task scores. We discuss implications of our findings for the design of intelligent collaborative interfaces."
pn2429,https://doi.org/10.1145/3290605.3300572,Dynamics of Visual Attention in Multiparty Collaborative Problem Solving using Multidimensional Recurrence Quantification Analysis,2,Mary Jean Amon,University of Colorado Boulder,Boulder,United States,false,false,"Multiparty collaborative problem solving - an increasingly important context in the 21st century workforce - suffers from a degradation of social and behavioral signals when attempted remotely, resulting in suboptimal outcomes. We investigate teams' multidimensional patterns of visual attention during a collaborative problem-solving task with an eye for leveraging insights to improve collaborative interfaces. Fifty-seven novices (forming 19 triads) engaged in a challenging programming task (Minecraft Hour of Code) using videoconferencing software with screen sharing. To discover patterns of individual-level gaze-UI coupling(coordination of a teammate's attention with respect to changes in the user interface) and team-level gaze-UI regularity (dynamics of teams' collective attention in context with changes in the user interface), we applied cross- and multidimensional recurrence quantification analyses, respectively. Individuals' eye gaze was significantly coupled with the ongoing screen activity whereas teams displayed significant patterns of gaze regularity, suggesting repetitive patterns in teams' attention. These measures predicted expert-coded collaborative processes of constructing shared knowledge and negotiation and coordination (but not maintaining team function) and correlated with task score (r = .425). They also predicted individually assessed subjective perceptions of team performance and the collaboration process, but not individual's learning or team's task scores. We discuss implications of our findings for the design of intelligent collaborative interfaces."
pn2429,https://doi.org/10.1145/3290605.3300572,Dynamics of Visual Attention in Multiparty Collaborative Problem Solving using Multidimensional Recurrence Quantification Analysis,3,Angela Stewart,University of Colorado Boulder,Boulder,United States,false,false,"Multiparty collaborative problem solving - an increasingly important context in the 21st century workforce - suffers from a degradation of social and behavioral signals when attempted remotely, resulting in suboptimal outcomes. We investigate teams' multidimensional patterns of visual attention during a collaborative problem-solving task with an eye for leveraging insights to improve collaborative interfaces. Fifty-seven novices (forming 19 triads) engaged in a challenging programming task (Minecraft Hour of Code) using videoconferencing software with screen sharing. To discover patterns of individual-level gaze-UI coupling(coordination of a teammate's attention with respect to changes in the user interface) and team-level gaze-UI regularity (dynamics of teams' collective attention in context with changes in the user interface), we applied cross- and multidimensional recurrence quantification analyses, respectively. Individuals' eye gaze was significantly coupled with the ongoing screen activity whereas teams displayed significant patterns of gaze regularity, suggesting repetitive patterns in teams' attention. These measures predicted expert-coded collaborative processes of constructing shared knowledge and negotiation and coordination (but not maintaining team function) and correlated with task score (r = .425). They also predicted individually assessed subjective perceptions of team performance and the collaboration process, but not individual's learning or team's task scores. We discuss implications of our findings for the design of intelligent collaborative interfaces."
pn2429,https://doi.org/10.1145/3290605.3300572,Dynamics of Visual Attention in Multiparty Collaborative Problem Solving using Multidimensional Recurrence Quantification Analysis,4,Sidney D'mello,University of Colorado Boulder,Boulder,United States,false,false,"Multiparty collaborative problem solving - an increasingly important context in the 21st century workforce - suffers from a degradation of social and behavioral signals when attempted remotely, resulting in suboptimal outcomes. We investigate teams' multidimensional patterns of visual attention during a collaborative problem-solving task with an eye for leveraging insights to improve collaborative interfaces. Fifty-seven novices (forming 19 triads) engaged in a challenging programming task (Minecraft Hour of Code) using videoconferencing software with screen sharing. To discover patterns of individual-level gaze-UI coupling(coordination of a teammate's attention with respect to changes in the user interface) and team-level gaze-UI regularity (dynamics of teams' collective attention in context with changes in the user interface), we applied cross- and multidimensional recurrence quantification analyses, respectively. Individuals' eye gaze was significantly coupled with the ongoing screen activity whereas teams displayed significant patterns of gaze regularity, suggesting repetitive patterns in teams' attention. These measures predicted expert-coded collaborative processes of constructing shared knowledge and negotiation and coordination (but not maintaining team function) and correlated with task score (r = .425). They also predicted individually assessed subjective perceptions of team performance and the collaboration process, but not individual's learning or team's task scores. We discuss implications of our findings for the design of intelligent collaborative interfaces."
pn3936,https://doi.org/10.1145/3290605.3300269,Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data,1,Vanessa Echeverria,University of Technology Sydney,Sydney,Australia,false,false,"Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard to replicate online. Team members' embodied, multimodal interaction with each other and artefacts has been studied by researchers, but due to its complexity, has remained opaque to automated analysis. However, the ready availability of sensors makes it increasingly affordable to instrument work spaces to study teamwork and groupwork. The possibility of visualising key aspects of a collaboration has huge potential for both academic and professional learning, but a frontline challenge is the enrichment of quantitative data streams with the qualitative insights needed to make sense of them. In response, we introduce the concept of collaboration translucence, an approach to make visible selected features of group activity. This is grounded both theoretically (in the physical, epistemic, social and affective dimensions of group activity), and contextually (using domain-specific concepts). We illustrate the approach from the automated analysis of healthcare simulations to train nurses, generating four visual proxies that fuse multimodal data into higher order patterns."
pn3936,https://doi.org/10.1145/3290605.3300269,Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data,2,Roberto Martinez-Maldonado,University of Technology Sydney,Sydney,Australia,false,false,"Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard to replicate online. Team members' embodied, multimodal interaction with each other and artefacts has been studied by researchers, but due to its complexity, has remained opaque to automated analysis. However, the ready availability of sensors makes it increasingly affordable to instrument work spaces to study teamwork and groupwork. The possibility of visualising key aspects of a collaboration has huge potential for both academic and professional learning, but a frontline challenge is the enrichment of quantitative data streams with the qualitative insights needed to make sense of them. In response, we introduce the concept of collaboration translucence, an approach to make visible selected features of group activity. This is grounded both theoretically (in the physical, epistemic, social and affective dimensions of group activity), and contextually (using domain-specific concepts). We illustrate the approach from the automated analysis of healthcare simulations to train nurses, generating four visual proxies that fuse multimodal data into higher order patterns."
pn3936,https://doi.org/10.1145/3290605.3300269,Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data,3,Simon Buckingham Shum,University of Technology Sydney,Sydney,Australia,false,false,"Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard to replicate online. Team members' embodied, multimodal interaction with each other and artefacts has been studied by researchers, but due to its complexity, has remained opaque to automated analysis. However, the ready availability of sensors makes it increasingly affordable to instrument work spaces to study teamwork and groupwork. The possibility of visualising key aspects of a collaboration has huge potential for both academic and professional learning, but a frontline challenge is the enrichment of quantitative data streams with the qualitative insights needed to make sense of them. In response, we introduce the concept of collaboration translucence, an approach to make visible selected features of group activity. This is grounded both theoretically (in the physical, epistemic, social and affective dimensions of group activity), and contextually (using domain-specific concepts). We illustrate the approach from the automated analysis of healthcare simulations to train nurses, generating four visual proxies that fuse multimodal data into higher order patterns."
pn4503,https://doi.org/10.1145/3290605.3300670,Mazi: Tangible Technologies as a Channel for Collaborative Play,1,Antonella Nonnis,Queen Mary University of London,London,United Kingdom,false,false,"This paper investigates how haptic and auditory stimulation can be playfully implemented as an accessible and stimulating form of interaction for children. We present the design of Mazi, a sonic Tangible User Interface (TUI) designed to encourage spontaneous and collaborative play between children with high support needs autism. We report on a five week study of Mazi with five children aged between 6 and 9 years old at a Special Education Needs (SEN) school in London, UK. We found that collaborative play emerged from the interaction with the system especially in regards to socialization and engagement. Our study contributes to exploring the potential of user-centered TUI development as a channel to facilitate social interaction while providing sensory regulation for children with SENs."
pn4503,https://doi.org/10.1145/3290605.3300670,Mazi: Tangible Technologies as a Channel for Collaborative Play,2,Nick Bryan-Kinns,Queen Mary University of London,London,United Kingdom,false,false,"This paper investigates how haptic and auditory stimulation can be playfully implemented as an accessible and stimulating form of interaction for children. We present the design of Mazi, a sonic Tangible User Interface (TUI) designed to encourage spontaneous and collaborative play between children with high support needs autism. We report on a five week study of Mazi with five children aged between 6 and 9 years old at a Special Education Needs (SEN) school in London, UK. We found that collaborative play emerged from the interaction with the system especially in regards to socialization and engagement. Our study contributes to exploring the potential of user-centered TUI development as a channel to facilitate social interaction while providing sensory regulation for children with SENs."
pn5572,https://doi.org/10.1145/3290605.3300549,"Healthy Lies: The Effects of Misrepresenting Player Health Data on Experience, Behavior, and Performance",1,Jason Wuertz,University of New Brunswick,Fredericton,Canada,false,false,"Game designers use a variety of techniques that mislead players with the goal of inducing play experience. For example, designers may manipulate data displays of player health—showing they have less health than they actually do—to induce tension. While commonly used, players make decisions based on in-game data displays, raising the question of how misrepresentations impact behavior and performance, and whether this might have unintended consequences. To provide a better understanding of how data misrepresentation impacts play, we compare two versions of a game: one that displays health accurately and one that misrepresents health. Our results suggest that even subtle manipulations to data displays can have a measurable effect on behavior and performance, and these changes can help explain differences in experience. We show that data misrepresentations need to be designed carefully to avoid unintended effects. Our work provides new directions for research into the design of misrepresentation in games."
pn5572,https://doi.org/10.1145/3290605.3300549,"Healthy Lies: The Effects of Misrepresenting Player Health Data on Experience, Behavior, and Performance",2,Max Birk,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Game designers use a variety of techniques that mislead players with the goal of inducing play experience. For example, designers may manipulate data displays of player health—showing they have less health than they actually do—to induce tension. While commonly used, players make decisions based on in-game data displays, raising the question of how misrepresentations impact behavior and performance, and whether this might have unintended consequences. To provide a better understanding of how data misrepresentation impacts play, we compare two versions of a game: one that displays health accurately and one that misrepresents health. Our results suggest that even subtle manipulations to data displays can have a measurable effect on behavior and performance, and these changes can help explain differences in experience. We show that data misrepresentations need to be designed carefully to avoid unintended effects. Our work provides new directions for research into the design of misrepresentation in games."
pn5572,https://doi.org/10.1145/3290605.3300549,"Healthy Lies: The Effects of Misrepresenting Player Health Data on Experience, Behavior, and Performance",3,Scott Bateman,University of New Brunswick,Fredericton,Canada,false,false,"Game designers use a variety of techniques that mislead players with the goal of inducing play experience. For example, designers may manipulate data displays of player health—showing they have less health than they actually do—to induce tension. While commonly used, players make decisions based on in-game data displays, raising the question of how misrepresentations impact behavior and performance, and whether this might have unintended consequences. To provide a better understanding of how data misrepresentation impacts play, we compare two versions of a game: one that displays health accurately and one that misrepresents health. Our results suggest that even subtle manipulations to data displays can have a measurable effect on behavior and performance, and these changes can help explain differences in experience. We show that data misrepresentations need to be designed carefully to avoid unintended effects. Our work provides new directions for research into the design of misrepresentation in games."
pn3458,https://doi.org/10.1145/3290605.3300296,A Player-Centric Approach to Designing Spatial Skill Training Games,1,Helen Wauck,University of Illinois Urbana-Champaign,Urbana,United States,true,false,"Certain video games show promise as tools for training spatial skills, one of the strongest predictors of future success in STEM. However, little is known about the gaming preferences of those who would benefit the most from such interventions: low spatial skill students. To provide guidance on how to design training games for this population, we conducted a survey of 350 participants from three populations: online college-age, students from a low SES high school, and students from a high SES high school. Participants took a timed test of spatial skills and then answered questions about their demographics, gameplay habits, preferences, and motivations. The only predictors of spatial skill were gender and population: female participants from online and low SES high school populations had the lowest spatial skill. In light of these findings, we provide design recommendations for game-based spatial skill interventions targeting low spatial skill students."
pn3458,https://doi.org/10.1145/3290605.3300296,A Player-Centric Approach to Designing Spatial Skill Training Games,2,Elisa Mekler,University of Basel,Basel,Switzerland,true,false,"Certain video games show promise as tools for training spatial skills, one of the strongest predictors of future success in STEM. However, little is known about the gaming preferences of those who would benefit the most from such interventions: low spatial skill students. To provide guidance on how to design training games for this population, we conducted a survey of 350 participants from three populations: online college-age, students from a low SES high school, and students from a high SES high school. Participants took a timed test of spatial skills and then answered questions about their demographics, gameplay habits, preferences, and motivations. The only predictors of spatial skill were gender and population: female participants from online and low SES high school populations had the lowest spatial skill. In light of these findings, we provide design recommendations for game-based spatial skill interventions targeting low spatial skill students."
pn3458,https://doi.org/10.1145/3290605.3300296,A Player-Centric Approach to Designing Spatial Skill Training Games,3,Wai-Tat Fu,University of Illinois,Urbana,United States,true,false,"Certain video games show promise as tools for training spatial skills, one of the strongest predictors of future success in STEM. However, little is known about the gaming preferences of those who would benefit the most from such interventions: low spatial skill students. To provide guidance on how to design training games for this population, we conducted a survey of 350 participants from three populations: online college-age, students from a low SES high school, and students from a high SES high school. Participants took a timed test of spatial skills and then answered questions about their demographics, gameplay habits, preferences, and motivations. The only predictors of spatial skill were gender and population: female participants from online and low SES high school populations had the lowest spatial skill. In light of these findings, we provide design recommendations for game-based spatial skill interventions targeting low spatial skill students."
pn9615,https://doi.org/10.1145/3290605.3300338,What.Hack: Engaging Anti-Phishing Training Through a Role-playing Phishing Simulation Game,1,Zikai Wen,Cornell University,Ithaca,United States,false,false,"Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing)."
pn9615,https://doi.org/10.1145/3290605.3300338,What.Hack: Engaging Anti-Phishing Training Through a Role-playing Phishing Simulation Game,2,Zhiqiu Lin,Cornell University,Ithaca,United States,false,false,"Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing)."
pn9615,https://doi.org/10.1145/3290605.3300338,What.Hack: Engaging Anti-Phishing Training Through a Role-playing Phishing Simulation Game,3,Rowena Chen,Cornell University,Ithaca,United States,false,false,"Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing)."
pn9615,https://doi.org/10.1145/3290605.3300338,What.Hack: Engaging Anti-Phishing Training Through a Role-playing Phishing Simulation Game,4,Erik Andersen,Cornell University,Ithaca,United States,false,false,"Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing)."
pn9561,https://doi.org/10.1145/3290605.3300812,What's Missing: The Role of Instructional Design in Children's Games-Based Learning,1,Laura Benton,University College London,London,United Kingdom,false,false,"Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning."
pn9561,https://doi.org/10.1145/3290605.3300812,What's Missing: The Role of Instructional Design in Children's Games-Based Learning,2,Asimina Vasalou,University College London,London,United Kingdom,false,false,"Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning."
pn9561,https://doi.org/10.1145/3290605.3300812,What's Missing: The Role of Instructional Design in Children's Games-Based Learning,3,Wolmet Barendregt,University of Gothenburg,Gothenburg,Sweden,false,false,"Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning."
pn9561,https://doi.org/10.1145/3290605.3300812,What's Missing: The Role of Instructional Design in Children's Games-Based Learning,4,Leona Bunting,University of Gothenburg,Gothenburg,Sweden,false,false,"Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning."
pn9561,https://doi.org/10.1145/3290605.3300812,What's Missing: The Role of Instructional Design in Children's Games-Based Learning,5,Andrea Révész,University College London,London,United Kingdom,false,false,"Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning."
pn5549,https://doi.org/10.1145/3290605.3300249,Casual Microtasking: Embedding Microtasks in Facebook,1,Nathan Hahn,Carnegie Mellon University,Pittsburgh,United States,false,false,"Microtasks enable people with limited time and context to contribute to a larger task. In this paper we explore casual microtasking, where microtasks are embedded into other primary activities so that they are available to be completed when convenient. We present a casual microtasking experience that inserts writing microtasks from an existing microwriting tool into the user's Facebook feed. From a two-week deployment of the system with nine people, we observe that casual microtasking enabled participants to get things done during their breaks, and that they tended to do so only after first engaging with Facebook's social content. Participants were most likely to complete the writing microtasks during periods of the day associated with low focus, and would occasionally use them as a springboard to open the original document in Word. These findings suggest casual microtasking can help people leverage spare micromoments to achieve meaningful micro-goals, and even encourage them to return to work."
pn5549,https://doi.org/10.1145/3290605.3300249,Casual Microtasking: Embedding Microtasks in Facebook,2,Shamsi Iqbal,Microsoft Research,Redmond,United States,false,false,"Microtasks enable people with limited time and context to contribute to a larger task. In this paper we explore casual microtasking, where microtasks are embedded into other primary activities so that they are available to be completed when convenient. We present a casual microtasking experience that inserts writing microtasks from an existing microwriting tool into the user's Facebook feed. From a two-week deployment of the system with nine people, we observe that casual microtasking enabled participants to get things done during their breaks, and that they tended to do so only after first engaging with Facebook's social content. Participants were most likely to complete the writing microtasks during periods of the day associated with low focus, and would occasionally use them as a springboard to open the original document in Word. These findings suggest casual microtasking can help people leverage spare micromoments to achieve meaningful micro-goals, and even encourage them to return to work."
pn5549,https://doi.org/10.1145/3290605.3300249,Casual Microtasking: Embedding Microtasks in Facebook,3,Jaime Teevan,Microsoft Research,Redmond,United States,false,false,"Microtasks enable people with limited time and context to contribute to a larger task. In this paper we explore casual microtasking, where microtasks are embedded into other primary activities so that they are available to be completed when convenient. We present a casual microtasking experience that inserts writing microtasks from an existing microwriting tool into the user's Facebook feed. From a two-week deployment of the system with nine people, we observe that casual microtasking enabled participants to get things done during their breaks, and that they tended to do so only after first engaging with Facebook's social content. Participants were most likely to complete the writing microtasks during periods of the day associated with low focus, and would occasionally use them as a springboard to open the original document in Word. These findings suggest casual microtasking can help people leverage spare micromoments to achieve meaningful micro-goals, and even encourage them to return to work."
pn4557,https://doi.org/10.1145/3290605.3300915,Geollery: A Mixed Reality Social Media Platform,1,Ruofei Du,"University of Maryland, College Park",College Park,United States,false,false,"We present Geollery, an interactive mixed reality social media platform for creating, sharing, and exploring geotagged information. Geollery introduces a real-time pipeline to progressively render an interactive mirrored world with three-dimensional (3D) buildings, internal user-generated content, and external geotagged social media. This mirrored world allows users to see, chat, and collaborate with remote participants with the same spatial context in an immersive virtual environment. We describe the system architecture of Geollery, its key interactive capabilities, and our design decisions. Finally, we conduct a user study with 20 participants to qualitatively compare Geollery with another social media system, Social Street View. Based on the participants' responses, we discuss the benefits and drawbacks of each system and derive key insights for designing an interactive mirrored world with geotagged social media. User feedback from our study reveals several use cases for Geollery including travel planning, virtual meetings, and family gathering."
pn4557,https://doi.org/10.1145/3290605.3300915,Geollery: A Mixed Reality Social Media Platform,2,David Li,"University of Maryland, College Park",College Park,United States,false,false,"We present Geollery, an interactive mixed reality social media platform for creating, sharing, and exploring geotagged information. Geollery introduces a real-time pipeline to progressively render an interactive mirrored world with three-dimensional (3D) buildings, internal user-generated content, and external geotagged social media. This mirrored world allows users to see, chat, and collaborate with remote participants with the same spatial context in an immersive virtual environment. We describe the system architecture of Geollery, its key interactive capabilities, and our design decisions. Finally, we conduct a user study with 20 participants to qualitatively compare Geollery with another social media system, Social Street View. Based on the participants' responses, we discuss the benefits and drawbacks of each system and derive key insights for designing an interactive mirrored world with geotagged social media. User feedback from our study reveals several use cases for Geollery including travel planning, virtual meetings, and family gathering."
pn4557,https://doi.org/10.1145/3290605.3300915,Geollery: A Mixed Reality Social Media Platform,3,Amitabh Varshney,"University of Maryland, College Park",College Park,United States,false,false,"We present Geollery, an interactive mixed reality social media platform for creating, sharing, and exploring geotagged information. Geollery introduces a real-time pipeline to progressively render an interactive mirrored world with three-dimensional (3D) buildings, internal user-generated content, and external geotagged social media. This mirrored world allows users to see, chat, and collaborate with remote participants with the same spatial context in an immersive virtual environment. We describe the system architecture of Geollery, its key interactive capabilities, and our design decisions. Finally, we conduct a user study with 20 participants to qualitatively compare Geollery with another social media system, Social Street View. Based on the participants' responses, we discuss the benefits and drawbacks of each system and derive key insights for designing an interactive mirrored world with geotagged social media. User feedback from our study reveals several use cases for Geollery including travel planning, virtual meetings, and family gathering."
pn3476,https://doi.org/10.1145/3290605.3300354,Discovering Alternative Treatments for Opioid Use Recovery Using Social Media,1,Stevie Chancellor,Georgia Institute of Technology,Atlanta,United States,false,false,"Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies. We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics."
pn3476,https://doi.org/10.1145/3290605.3300354,Discovering Alternative Treatments for Opioid Use Recovery Using Social Media,2,George Nitzburg,"Teachers' College, Columbia University",New York,United States,false,false,"Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies. We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics."
pn3476,https://doi.org/10.1145/3290605.3300354,Discovering Alternative Treatments for Opioid Use Recovery Using Social Media,3,Andrea Hu,Georgia Institute of Technology,Atlanta,United States,false,false,"Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies. We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics."
pn3476,https://doi.org/10.1145/3290605.3300354,Discovering Alternative Treatments for Opioid Use Recovery Using Social Media,4,Francisco Zampieri,Georgia Institute of Technology,Atlanta,United States,false,false,"Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies. We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics."
pn3476,https://doi.org/10.1145/3290605.3300354,Discovering Alternative Treatments for Opioid Use Recovery Using Social Media,5,Munmun De Choudhury,Georgia Institute of Technology,Atlanta,United States,false,false,"Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies. We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics."
pn3901,https://doi.org/10.1145/3290605.3300495,Everyday Experiences: Small Stories and Mental Illness on Instagram,1,Jessica Feuston,Northwestern University,Evanston,United States,true,false,"Despite historical precedence and modern prevalence, mental illness and associated disorders are frequently aligned with notions of deviance and, by association, abnormality. The view that mental illness deviates from an implicit social norm permeates the CHI community, impacting how scholars approach research in this space. In this paper, we challenge community and societal norms aligning mental illness with deviance. We combine semi-structured interviews with digital ethnography of public Instagram accounts to examine how Instagram users express mental illness. Drawing on small stories research, we find that individuals situate mental illness within their everyday lives and negotiate their tellings of experience due to the influence of various social control structures. We discuss implications for incorporating 'the everyday' into the design of technological solutions for marginalized communities and the ways in which researchers and designers may inadvertently perpetuate and instantiate stigma related to mental illness."
pn3901,https://doi.org/10.1145/3290605.3300495,Everyday Experiences: Small Stories and Mental Illness on Instagram,2,Anne Marie Piper,Northwestern University,Evanston,United States,true,false,"Despite historical precedence and modern prevalence, mental illness and associated disorders are frequently aligned with notions of deviance and, by association, abnormality. The view that mental illness deviates from an implicit social norm permeates the CHI community, impacting how scholars approach research in this space. In this paper, we challenge community and societal norms aligning mental illness with deviance. We combine semi-structured interviews with digital ethnography of public Instagram accounts to examine how Instagram users express mental illness. Drawing on small stories research, we find that individuals situate mental illness within their everyday lives and negotiate their tellings of experience due to the influence of various social control structures. We discuss implications for incorporating 'the everyday' into the design of technological solutions for marginalized communities and the ways in which researchers and designers may inadvertently perpetuate and instantiate stigma related to mental illness."
pn9702,https://doi.org/10.1145/3290605.3300342,The Magic Machine Workshops: Making Personal Design Knowledge,1,Kristina Andersen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"New technologies emerge into an increasingly complex everyday life. How can we engage users further into material practices that explore ideas and notions of these new things? This paper proposes a set of qualities for short, intense, workshop-like experiences, created to generate strong individual commitments, and expose underlying personal desires as drivers for ideas. By making use of open-ended making to engage participants in the imagination of new things, we aim to allow a broad range of knowledge to materialise, focused on the making of work that is about technology, rather than of technology."
pn9702,https://doi.org/10.1145/3290605.3300342,The Magic Machine Workshops: Making Personal Design Knowledge,2,Ron Wakkary,Eindhoven University of Technology,Burnaby/Surrey/Vancouver,Canada,false,false,"New technologies emerge into an increasingly complex everyday life. How can we engage users further into material practices that explore ideas and notions of these new things? This paper proposes a set of qualities for short, intense, workshop-like experiences, created to generate strong individual commitments, and expose underlying personal desires as drivers for ideas. By making use of open-ended making to engage participants in the imagination of new things, we aim to allow a broad range of knowledge to materialise, focused on the making of work that is about technology, rather than of technology."
pn2720,https://doi.org/10.1145/3290605.3300265,From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old,1,Laura Devendorf,University of Colorado Boulder,Boulder,United States,false,false,"Notions of what counts as a contribution to HCI continue to be contested as our field expands to accommodate perspectives from the arts and humanities. This paper aims to advance the position of the arts and further contribute to these debates by actively exploring what a ""non-contribution"" would look like in HCI. We do this by taking inspiration from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged and reworked practices of fine arts institutions by producing radically accessible, ephemeral, and modest works of ""art-amusement."" We use Fluxus to develop three analogous forms of ""HCI-amusements,"" each of which shed light on dominant practices and values within HCI by resisting to fit into its logics."
pn2720,https://doi.org/10.1145/3290605.3300265,From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old,2,Kristina Andersen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Notions of what counts as a contribution to HCI continue to be contested as our field expands to accommodate perspectives from the arts and humanities. This paper aims to advance the position of the arts and further contribute to these debates by actively exploring what a ""non-contribution"" would look like in HCI. We do this by taking inspiration from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged and reworked practices of fine arts institutions by producing radically accessible, ephemeral, and modest works of ""art-amusement."" We use Fluxus to develop three analogous forms of ""HCI-amusements,"" each of which shed light on dominant practices and values within HCI by resisting to fit into its logics."
pn2720,https://doi.org/10.1145/3290605.3300265,From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old,3,Daniela Rosner,University of Washington,Seattle,United States,false,false,"Notions of what counts as a contribution to HCI continue to be contested as our field expands to accommodate perspectives from the arts and humanities. This paper aims to advance the position of the arts and further contribute to these debates by actively exploring what a ""non-contribution"" would look like in HCI. We do this by taking inspiration from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged and reworked practices of fine arts institutions by producing radically accessible, ephemeral, and modest works of ""art-amusement."" We use Fluxus to develop three analogous forms of ""HCI-amusements,"" each of which shed light on dominant practices and values within HCI by resisting to fit into its logics."
pn2720,https://doi.org/10.1145/3290605.3300265,From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old,4,Ron Wakkary,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Notions of what counts as a contribution to HCI continue to be contested as our field expands to accommodate perspectives from the arts and humanities. This paper aims to advance the position of the arts and further contribute to these debates by actively exploring what a ""non-contribution"" would look like in HCI. We do this by taking inspiration from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged and reworked practices of fine arts institutions by producing radically accessible, ephemeral, and modest works of ""art-amusement."" We use Fluxus to develop three analogous forms of ""HCI-amusements,"" each of which shed light on dominant practices and values within HCI by resisting to fit into its logics."
pn2720,https://doi.org/10.1145/3290605.3300265,From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old,5,James Pierce,California College of the Arts,San Francisco/Berkeley,United States,false,false,"Notions of what counts as a contribution to HCI continue to be contested as our field expands to accommodate perspectives from the arts and humanities. This paper aims to advance the position of the arts and further contribute to these debates by actively exploring what a ""non-contribution"" would look like in HCI. We do this by taking inspiration from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged and reworked practices of fine arts institutions by producing radically accessible, ephemeral, and modest works of ""art-amusement."" We use Fluxus to develop three analogous forms of ""HCI-amusements,"" each of which shed light on dominant practices and values within HCI by resisting to fit into its logics."
pn4808,https://doi.org/10.1145/3290605.3300417,Automating the Intentional Encoding of Human-Designable Markers,1,Joshua Jung,University of Waterloo,Waterloo,Canada,false,false,"Recent work established that it is possible for human artists to encode information into hand-drawn markers, but it is difficult to do when simultaneously maintaining aesthetic quality. We present two methods for relieving the mental burden associated with encoding, while allowing an artist to draw as freely as possible. A 'Helper Overlay' guides the artist with real-time feedback indicating where visual features should be added or removed, and an 'Autocomplete Tool' directly adds necessary features to the drawing for the artist to touch up. Both methods are enabled by a two-part algorithm that uses a tree-search for finding 'major' changes and a dynamic programming method for finding the minimum number of 'minor' changes. A 24-person study demonstrates that a majority of participants prefer both tools over previous methods of manual encoding, with the Helper Overlay being the more popular of the two."
pn4808,https://doi.org/10.1145/3290605.3300417,Automating the Intentional Encoding of Human-Designable Markers,2,Rahul Iyer,University of Waterloo,Waterloo,Canada,false,false,"Recent work established that it is possible for human artists to encode information into hand-drawn markers, but it is difficult to do when simultaneously maintaining aesthetic quality. We present two methods for relieving the mental burden associated with encoding, while allowing an artist to draw as freely as possible. A 'Helper Overlay' guides the artist with real-time feedback indicating where visual features should be added or removed, and an 'Autocomplete Tool' directly adds necessary features to the drawing for the artist to touch up. Both methods are enabled by a two-part algorithm that uses a tree-search for finding 'major' changes and a dynamic programming method for finding the minimum number of 'minor' changes. A 24-person study demonstrates that a majority of participants prefer both tools over previous methods of manual encoding, with the Helper Overlay being the more popular of the two."
pn4808,https://doi.org/10.1145/3290605.3300417,Automating the Intentional Encoding of Human-Designable Markers,3,Daniel Vogel,University of Waterloo,Waterloo,Canada,false,false,"Recent work established that it is possible for human artists to encode information into hand-drawn markers, but it is difficult to do when simultaneously maintaining aesthetic quality. We present two methods for relieving the mental burden associated with encoding, while allowing an artist to draw as freely as possible. A 'Helper Overlay' guides the artist with real-time feedback indicating where visual features should be added or removed, and an 'Autocomplete Tool' directly adds necessary features to the drawing for the artist to touch up. Both methods are enabled by a two-part algorithm that uses a tree-search for finding 'major' changes and a dynamic programming method for finding the minimum number of 'minor' changes. A 24-person study demonstrates that a majority of participants prefer both tools over previous methods of manual encoding, with the Helper Overlay being the more popular of the two."
pn9888,https://doi.org/10.1145/3290605.3300794,Shaping Pro-Social Interaction in VR: An Emerging Design Framework,1,Joshua Mcveigh-Schultz,"University of California, Santa Cuz",Santa Cruz,United States,false,false,"Commercial social VR applications represent a diverse and evolving ecology with competing models of what it means to be social in VR. Drawing from expert interviews, this paper examines how the creators of different social VR applications think about how their platforms frame, support, shape, or constrain social interaction. The study covers a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs, Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying these applications, with particular attention paid to the ways that industry experts perceive, and seek to shape, the relationship between user experiences and design choices. We underscore considerations related to: (1) aesthetics of place (2) embodied affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest future research directions, and propose an emerging design framework for shaping pro-social behavior in VR."
pn9888,https://doi.org/10.1145/3290605.3300794,Shaping Pro-Social Interaction in VR: An Emerging Design Framework,2,Anya Kolesnichenko,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Commercial social VR applications represent a diverse and evolving ecology with competing models of what it means to be social in VR. Drawing from expert interviews, this paper examines how the creators of different social VR applications think about how their platforms frame, support, shape, or constrain social interaction. The study covers a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs, Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying these applications, with particular attention paid to the ways that industry experts perceive, and seek to shape, the relationship between user experiences and design choices. We underscore considerations related to: (1) aesthetics of place (2) embodied affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest future research directions, and propose an emerging design framework for shaping pro-social behavior in VR."
pn9888,https://doi.org/10.1145/3290605.3300794,Shaping Pro-Social Interaction in VR: An Emerging Design Framework,3,Katherine Isbister,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Commercial social VR applications represent a diverse and evolving ecology with competing models of what it means to be social in VR. Drawing from expert interviews, this paper examines how the creators of different social VR applications think about how their platforms frame, support, shape, or constrain social interaction. The study covers a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs, Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying these applications, with particular attention paid to the ways that industry experts perceive, and seek to shape, the relationship between user experiences and design choices. We underscore considerations related to: (1) aesthetics of place (2) embodied affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest future research directions, and propose an emerging design framework for shaping pro-social behavior in VR."
pn6035,https://doi.org/10.1145/3290605.3300924,Falcon: Balancing Interactive Latency and Resolution Sensitivity for Scalable Linked Visualizations,1,Dominik Moritz,University of Washington,Seattle,United States,false,false,"We contribute user-centered prefetching and indexing methods that provide low-latency interactions across linked visualizations, enabling cold-start exploration of billion-record datasets.We implement our methods in Falcon, a web-based system that makes principled trade-offs between latency and resolution to optimize brushing and view switching times.To optimize latency-sensitive brushing actions, Falcon reindexes data upon changes to the active view a user is brushing in.To limit view switching times, Falcon initially loads reduced interactive resolutions, then progressively improves them.Benchmarks show that Falcon sustains real-time interactivity of 50fps for pixel-level brushing and linking across multiple visualizations with no costly precomputation.We show constant brushing performance regardless of data size on datasets ranging from millions of records in the browser to billions when connected to a backing database system."
pn6035,https://doi.org/10.1145/3290605.3300924,Falcon: Balancing Interactive Latency and Resolution Sensitivity for Scalable Linked Visualizations,2,Bill Howe,University of Washington,Seattle,United States,false,false,"We contribute user-centered prefetching and indexing methods that provide low-latency interactions across linked visualizations, enabling cold-start exploration of billion-record datasets.We implement our methods in Falcon, a web-based system that makes principled trade-offs between latency and resolution to optimize brushing and view switching times.To optimize latency-sensitive brushing actions, Falcon reindexes data upon changes to the active view a user is brushing in.To limit view switching times, Falcon initially loads reduced interactive resolutions, then progressively improves them.Benchmarks show that Falcon sustains real-time interactivity of 50fps for pixel-level brushing and linking across multiple visualizations with no costly precomputation.We show constant brushing performance regardless of data size on datasets ranging from millions of records in the browser to billions when connected to a backing database system."
pn6035,https://doi.org/10.1145/3290605.3300924,Falcon: Balancing Interactive Latency and Resolution Sensitivity for Scalable Linked Visualizations,3,Jeffrey Heer,University of Washington,Seattle,United States,false,false,"We contribute user-centered prefetching and indexing methods that provide low-latency interactions across linked visualizations, enabling cold-start exploration of billion-record datasets.We implement our methods in Falcon, a web-based system that makes principled trade-offs between latency and resolution to optimize brushing and view switching times.To optimize latency-sensitive brushing actions, Falcon reindexes data upon changes to the active view a user is brushing in.To limit view switching times, Falcon initially loads reduced interactive resolutions, then progressively improves them.Benchmarks show that Falcon sustains real-time interactivity of 50fps for pixel-level brushing and linking across multiple visualizations with no costly precomputation.We show constant brushing performance regardless of data size on datasets ranging from millions of records in the browser to billions when connected to a backing database system."
pn6155,https://doi.org/10.1145/3290605.3300523,Interactive Repair of Tables Extracted from PDF Documents on Mobile Devices,1,Jane Hoffswell,University of Washington,Seattle,United States,false,false,"PDF documents often contain rich data tables that offer opportunities for dynamic reuse in new interactive applications. We describe a pipeline for extracting, analyzing, and parsing PDF tables based on existing machine learning and rule-based techniques. Implementing and deploying this pipeline on a corpus of 447 documents with 1,171 tables results in only 11 tables that are correctly extracted and parsed. To improve the results of automatic table analysis, we first present a taxonomy of errors that arise in the analysis pipeline and discuss the implications of cascading errors on the user experience. We then contribute a system with two sets of lightweight interaction techniques (gesture and toolbar), for viewing and repairing extraction errors in PDF tables on mobile devices. In an evaluation with 17 users involving both a phone and a tablet, participants effectively repaired common errors in 10 tables, with an average time of about 2 minutes per table."
pn6155,https://doi.org/10.1145/3290605.3300523,Interactive Repair of Tables Extracted from PDF Documents on Mobile Devices,2,Zhicheng Liu,Adobe Research,Seattle,United States,false,false,"PDF documents often contain rich data tables that offer opportunities for dynamic reuse in new interactive applications. We describe a pipeline for extracting, analyzing, and parsing PDF tables based on existing machine learning and rule-based techniques. Implementing and deploying this pipeline on a corpus of 447 documents with 1,171 tables results in only 11 tables that are correctly extracted and parsed. To improve the results of automatic table analysis, we first present a taxonomy of errors that arise in the analysis pipeline and discuss the implications of cascading errors on the user experience. We then contribute a system with two sets of lightweight interaction techniques (gesture and toolbar), for viewing and repairing extraction errors in PDF tables on mobile devices. In an evaluation with 17 users involving both a phone and a tablet, participants effectively repaired common errors in 10 tables, with an average time of about 2 minutes per table."
pn2807,https://doi.org/10.1145/3290605.3300807,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,1,Senthil Chandrasegaran,"University of California, Davis",Davis,United States,false,false,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content."
pn2807,https://doi.org/10.1145/3290605.3300807,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,2,Chris Bryan,Arizona State University,Tempe,United States,false,false,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content."
pn2807,https://doi.org/10.1145/3290605.3300807,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,3,Hidekazu Shidara,"University of California, Davis",Davis,United States,false,false,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content."
pn2807,https://doi.org/10.1145/3290605.3300807,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,4,Tung-Yen Chuang,"University of California, Davis",Davis,United States,false,false,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content."
pn2807,https://doi.org/10.1145/3290605.3300807,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,5,Kwan-Liu Ma,"University of California, Davis",Davis,United States,false,false,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,1,Kevin Hu,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,2,Snehalkumar 'Neil' Gaikwad,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,3,Madelon Hulsebos,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,4,Michiel Bakker,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,5,Emanuel Zgraggen,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,6,César Hidalgo,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,7,Tim Kraska,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,8,Guoliang Li,Tsinghua University,Beijing,China,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,9,Arvind Satyanarayan,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn3286,https://doi.org/10.1145/3290605.3300892,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,10,Çağatay Demiralp,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,1,Mahmood Sharif,Carnegie Mellon University,Pittsburgh,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,2,Kevin Roundy,Symantec Research Labs,Culver City,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,3,Matteo Dell'amico,Symantec Research Labs,Sophia Antipolis,France,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,4,Christopher Gates,Symantec Research Labs,Culver City,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,5,Daniel Kats,Symantec Research Labs,Culver City,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,6,Lujo Bauer,Carnegie Mellon University,Pittsburgh,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn6529,https://doi.org/10.1145/3290605.3300308,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,7,Nicolas Christin,Carnegie Mellon University,Pittsburgh,United States,false,false,"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
pn2000,https://doi.org/10.1145/3290605.3300579,"""If It's Important It Will Be A Headline"": Cybersecurity Information Seeking in Older Adults",1,James Nicholson,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"Older adults are increasingly vulnerable to cybersecurity attacks and scams. Yet we know relatively little about their understanding of cybersecurity, their information-seeking behaviours, and their trusted sources of information and advice in this domain. We conducted 22 semi-structured interviews with community-dwelling older adults in order to explore their cybersecurity information seeking behaviours. Following a thematic analysis of these interviews, we developed a cybersecurity information access framework that highlights shortcomings in older adults' choice of information resources. Specifically, we find that older users prioritise social resources based on availability, rather than cybersecurity expertise, and that they avoid using the Internet for cybersecurity information searches despite using it for other domains. Finally, we discuss the design of cybersecurity information dissemination strategies for older users, incorporating favoured sources such as TV adverts and radio programming."
pn2000,https://doi.org/10.1145/3290605.3300579,"""If It's Important It Will Be A Headline"": Cybersecurity Information Seeking in Older Adults",2,Lynne Coventry,Northumbria University,Newcast,United Kingdom,true,false,"Older adults are increasingly vulnerable to cybersecurity attacks and scams. Yet we know relatively little about their understanding of cybersecurity, their information-seeking behaviours, and their trusted sources of information and advice in this domain. We conducted 22 semi-structured interviews with community-dwelling older adults in order to explore their cybersecurity information seeking behaviours. Following a thematic analysis of these interviews, we developed a cybersecurity information access framework that highlights shortcomings in older adults' choice of information resources. Specifically, we find that older users prioritise social resources based on availability, rather than cybersecurity expertise, and that they avoid using the Internet for cybersecurity information searches despite using it for other domains. Finally, we discuss the design of cybersecurity information dissemination strategies for older users, incorporating favoured sources such as TV adverts and radio programming."
pn2000,https://doi.org/10.1145/3290605.3300579,"""If It's Important It Will Be A Headline"": Cybersecurity Information Seeking in Older Adults",3,Pamela Briggs,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"Older adults are increasingly vulnerable to cybersecurity attacks and scams. Yet we know relatively little about their understanding of cybersecurity, their information-seeking behaviours, and their trusted sources of information and advice in this domain. We conducted 22 semi-structured interviews with community-dwelling older adults in order to explore their cybersecurity information seeking behaviours. Following a thematic analysis of these interviews, we developed a cybersecurity information access framework that highlights shortcomings in older adults' choice of information resources. Specifically, we find that older users prioritise social resources based on availability, rather than cybersecurity expertise, and that they avoid using the Internet for cybersecurity information searches despite using it for other domains. Finally, we discuss the design of cybersecurity information dissemination strategies for older users, incorporating favoured sources such as TV adverts and radio programming."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",1,Verena Distler,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",2,Marie-Laure Zollinger,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",3,Carine Lallemand,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",4,Peter Roenne,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",5,Peter Ryan,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn3487,https://doi.org/10.1145/3290605.3300835,"Security – Visible, Yet Unseen?",6,Vincent Koenig,University of Luxembourg,Esch-Sur-Alzette,Luxembourg,false,false,"An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any security-related information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems."
pn5154,https://doi.org/10.1145/3290605.3300424,You 'Might' Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications,1,Yixin Zou,University of Michigan,Ann Arbor,United States,false,false,"Data breaches place affected individuals at significant risk of identity theft. Yet, prior studies have shown that many consumers do not take protective actions after receiving a data breach notification from a company. We analyzed 161 data breach notifications sent to consumers with respect to their readability, structure, risk communication, and presentation of potential actions. We find that notifications are long and require advanced reading skills. Many companies downplay or obscure the likelihood of the receiver being affected by the breach and associated risks. Moreover, potential actions and offered compensations are frequently described in lengthy paragraphs instead of clearly listed. Little information is provided regarding an action's urgency and effectiveness; little guidance is provided on which actions to prioritize. Based on our findings, we provide recommendations for designing more usable and informative data breach notifications that could help consumers better mitigate the consequences of being affected by a data breach."
pn5154,https://doi.org/10.1145/3290605.3300424,You 'Might' Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications,2,Shawn Danino,University of Michigan,Ann Arbor,United States,false,false,"Data breaches place affected individuals at significant risk of identity theft. Yet, prior studies have shown that many consumers do not take protective actions after receiving a data breach notification from a company. We analyzed 161 data breach notifications sent to consumers with respect to their readability, structure, risk communication, and presentation of potential actions. We find that notifications are long and require advanced reading skills. Many companies downplay or obscure the likelihood of the receiver being affected by the breach and associated risks. Moreover, potential actions and offered compensations are frequently described in lengthy paragraphs instead of clearly listed. Little information is provided regarding an action's urgency and effectiveness; little guidance is provided on which actions to prioritize. Based on our findings, we provide recommendations for designing more usable and informative data breach notifications that could help consumers better mitigate the consequences of being affected by a data breach."
pn5154,https://doi.org/10.1145/3290605.3300424,You 'Might' Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications,3,Kaiwen Sun,University of Michigan,Ann Arbor,United States,false,false,"Data breaches place affected individuals at significant risk of identity theft. Yet, prior studies have shown that many consumers do not take protective actions after receiving a data breach notification from a company. We analyzed 161 data breach notifications sent to consumers with respect to their readability, structure, risk communication, and presentation of potential actions. We find that notifications are long and require advanced reading skills. Many companies downplay or obscure the likelihood of the receiver being affected by the breach and associated risks. Moreover, potential actions and offered compensations are frequently described in lengthy paragraphs instead of clearly listed. Little information is provided regarding an action's urgency and effectiveness; little guidance is provided on which actions to prioritize. Based on our findings, we provide recommendations for designing more usable and informative data breach notifications that could help consumers better mitigate the consequences of being affected by a data breach."
pn5154,https://doi.org/10.1145/3290605.3300424,You 'Might' Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications,4,Florian Schaub,University of Michigan,Ann Arbor,United States,false,false,"Data breaches place affected individuals at significant risk of identity theft. Yet, prior studies have shown that many consumers do not take protective actions after receiving a data breach notification from a company. We analyzed 161 data breach notifications sent to consumers with respect to their readability, structure, risk communication, and presentation of potential actions. We find that notifications are long and require advanced reading skills. Many companies downplay or obscure the likelihood of the receiver being affected by the breach and associated risks. Moreover, potential actions and offered compensations are frequently described in lengthy paragraphs instead of clearly listed. Little information is provided regarding an action's urgency and effectiveness; little guidance is provided on which actions to prioritize. Based on our findings, we provide recommendations for designing more usable and informative data breach notifications that could help consumers better mitigate the consequences of being affected by a data breach."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,1,Heloisa Candello,IBM Research Brazil,Sao Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,2,Claudio Pinhanez,IBM Research Brazil,Sao Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,3,Mauro Pichiliani,IBM Research Brazil,Sao Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,4,Paulo Cavalin,IBM Research,São Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,5,Flavio Figueiredo,Universidade Federal de Minas Gerais,Belo Horizonte,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,6,Marisa Vasconcelos,IBM Research Brazil,Sao Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn2334,https://doi.org/10.1145/3290605.3300320,The Effect of Co-located Audiences on User Experience with Conversational Interfaces in Physical Spaces,7,Haylla Do Carmo,IBM Research Brazil,Sao Paulo,Brazil,true,false,"How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,1,Jennifer Pearson,Swansea University,Swansea,United Kingdom,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,2,Simon Robinson,Swansea University,Swansea,United Kingdom,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,3,Thomas Reitmaier,Swansea University,Swansea,United Kingdom,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,4,Matt Jones,Swansea University,Swansea,United Kingdom,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,5,Shashank Ahire,IIT Bombay,Mumbai,India,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,6,Anirudha Joshi,IIT Bombay,Mumbai,India,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,7,Deepak Sahoo,Swansea University,Swansea,United Kingdom,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,8,Nimish Maravi,IIT Bombay,Mumbai,India,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn6275,https://doi.org/10.1145/3290605.3300326,StreetWise: Smart Speakers vs Human Help in Public Slum Settings,9,Bhakti Bhikne,IIT Bombay,Mumbai,India,false,false,"This paper explores the use of conversational speech question and answer systems in the challenging context of public spaces in slums. A major part of this work is a comparison of the source and speed of the given responses; that is, either machine-powered and instant or human-powered and delayed. We examine these dimensions via a two-stage, multi-sited deployment. We report on a pilot deployment that helped refine the system, and a second deployment involving the installation of nine of each type of system within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries. We present the findings from a detailed analysis and comparison of the two question-answer corpora; discuss how these insights might help improve machine-powered smart speakers; and, highlight the potential benefits of multi-sited public speech installations within slum environments."
pn8998,https://doi.org/10.1145/3290605.3300277,The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface,1,Chelsea Myers,Drexel University,Philadelphia,United States,false,false,"Voice User Interfaces (VUIs) are increasing in popularity. However, their invisible nature with no or limited visuals makes it difficult for users to interact with unfamiliar VUIs. We analyze the impact of user characteristics and preferences on how users interact with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior through self-reported data, we extend this research by analyzing both VUI usage data and self-reported data to observe correlations between both data types. Results from our user study (n=50) led to four key findings: 1) programming experience did not have a wide-spread impact on performance metrics while 2) assimilation bias did, 3) participants with more technical confidence exhibited a trial-and-error approach, and 4) desiring more guidance from our VUI correlated with performance metrics that indicate cautious users."
pn8998,https://doi.org/10.1145/3290605.3300277,The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface,2,Anushay Furqan,Drexel University,Philadelphia,United States,false,false,"Voice User Interfaces (VUIs) are increasing in popularity. However, their invisible nature with no or limited visuals makes it difficult for users to interact with unfamiliar VUIs. We analyze the impact of user characteristics and preferences on how users interact with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior through self-reported data, we extend this research by analyzing both VUI usage data and self-reported data to observe correlations between both data types. Results from our user study (n=50) led to four key findings: 1) programming experience did not have a wide-spread impact on performance metrics while 2) assimilation bias did, 3) participants with more technical confidence exhibited a trial-and-error approach, and 4) desiring more guidance from our VUI correlated with performance metrics that indicate cautious users."
pn8998,https://doi.org/10.1145/3290605.3300277,The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface,3,Jichen Zhu,Drexel University,Philadelphia,United States,false,false,"Voice User Interfaces (VUIs) are increasing in popularity. However, their invisible nature with no or limited visuals makes it difficult for users to interact with unfamiliar VUIs. We analyze the impact of user characteristics and preferences on how users interact with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior through self-reported data, we extend this research by analyzing both VUI usage data and self-reported data to observe correlations between both data types. Results from our user study (n=50) led to four key findings: 1) programming experience did not have a wide-spread impact on performance metrics while 2) assimilation bias did, 3) participants with more technical confidence exhibited a trial-and-error approach, and 4) desiring more guidance from our VUI correlated with performance metrics that indicate cautious users."
pn5146,https://doi.org/10.1145/3290605.3300772,Understanding Affective Experiences with Conversational Agents,1,Xi Yang,Imperial College London,London,United Kingdom,false,false,"While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa and Cortana) have focused on evaluating usability and exploring capabilities of these systems, little work has examined users' affective experiences. In this paper we present a survey study with 171 participants to examine CA users' affective experiences. Specifically, we present four major usage scenarios, users' affective responses in these scenarios, and the factors which influenced the affective responses. We found that users' overall experience was positive with interest being the most salient positive emotion. Affective responses differed depending on the scenarios. Both pragmatic and hedonic qualities influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity, fluidity, seamlessness and responsiveness. The factors underlying hedonic quality are: comfort in human-machine conversation, pride of using cutting-edge technology, fun during use, perception of having a human-like assistant, concern about privacy and fear of causing distraction."
pn5146,https://doi.org/10.1145/3290605.3300772,Understanding Affective Experiences with Conversational Agents,2,Marco Aurisicchio,Imperial College London,London,United Kingdom,false,false,"While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa and Cortana) have focused on evaluating usability and exploring capabilities of these systems, little work has examined users' affective experiences. In this paper we present a survey study with 171 participants to examine CA users' affective experiences. Specifically, we present four major usage scenarios, users' affective responses in these scenarios, and the factors which influenced the affective responses. We found that users' overall experience was positive with interest being the most salient positive emotion. Affective responses differed depending on the scenarios. Both pragmatic and hedonic qualities influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity, fluidity, seamlessness and responsiveness. The factors underlying hedonic quality are: comfort in human-machine conversation, pride of using cutting-edge technology, fun during use, perception of having a human-like assistant, concern about privacy and fear of causing distraction."
pn5146,https://doi.org/10.1145/3290605.3300772,Understanding Affective Experiences with Conversational Agents,3,Weston Baxter,Imperial College London,London,United Kingdom,false,false,"While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa and Cortana) have focused on evaluating usability and exploring capabilities of these systems, little work has examined users' affective experiences. In this paper we present a survey study with 171 participants to examine CA users' affective experiences. Specifically, we present four major usage scenarios, users' affective responses in these scenarios, and the factors which influenced the affective responses. We found that users' overall experience was positive with interest being the most salient positive emotion. Affective responses differed depending on the scenarios. Both pragmatic and hedonic qualities influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity, fluidity, seamlessness and responsiveness. The factors underlying hedonic quality are: comfort in human-machine conversation, pride of using cutting-edge technology, fun during use, perception of having a human-like assistant, concern about privacy and fear of causing distraction."
pn8867,https://doi.org/10.1145/3290605.3300739,Trolled by the Trolley Problem: On What Matters for Ethical Decision Making in Automated Vehicles,1,Alexander Mirnig,University of Salzburg,Salzburg,Austria,true,false,"Automated vehicles have to make decisions, such as driving maneuvers or rerouting, based on environment data and decision algorithms. There is a question whether ethical aspects should be considered in these algorithms. When all available decisions within a situation have fatal consequences, this leads to a dilemma. Contemporary discourse surrounding this issue is dominated by the trolley problem, a specific version of such a dilemma. Based on an outline of its origins, we discuss the trolley problem and its viability to help solve the questions regarding ethical decision making in automated vehicles. We show that the trolley problem serves several important functions but is an ill-suited benchmark for the success or failure of an automated algorithm. We argue that research and design should focus on avoiding trolley-like problems at all rather than trying to solve an unsolvable dilemma and discuss alternative approaches on how to feasibly address ethical issues in automated agents."
pn8867,https://doi.org/10.1145/3290605.3300739,Trolled by the Trolley Problem: On What Matters for Ethical Decision Making in Automated Vehicles,2,Alexander Meschtscherjakov,University of Salzburg,Salzburg,Austria,true,false,"Automated vehicles have to make decisions, such as driving maneuvers or rerouting, based on environment data and decision algorithms. There is a question whether ethical aspects should be considered in these algorithms. When all available decisions within a situation have fatal consequences, this leads to a dilemma. Contemporary discourse surrounding this issue is dominated by the trolley problem, a specific version of such a dilemma. Based on an outline of its origins, we discuss the trolley problem and its viability to help solve the questions regarding ethical decision making in automated vehicles. We show that the trolley problem serves several important functions but is an ill-suited benchmark for the success or failure of an automated algorithm. We argue that research and design should focus on avoiding trolley-like problems at all rather than trying to solve an unsolvable dilemma and discuss alternative approaches on how to feasibly address ethical issues in automated agents."
pn4026,https://doi.org/10.1145/3290605.3300601,Exploring Factors that Influence Connected Drivers to (Not) Use or Follow Recommended Optimal Routes,1,Briane Paul Samson,De La Salle University,Hakodate,Japan,false,false,"Navigation applications are becoming ubiquitous in our daily navigation experiences. With the intention to circumnavigate congested roads, their route guidance always follows the basic assumption that drivers always want the fastest route. However, it is unclear how their recommendations are followed and what factors affect their adoption. We present the results of a semi-structured qualitative study with 17 drivers, mostly from the Philippines and Japan. We recorded their daily commutes and occasional trips, and inquired into their navigation practices, route choices and on-the-fly decision-making. We found that while drivers choose a recommended route in urgent situations, many still preferred to follow familiar routes. Drivers deviated because of a recommendation's use of unfamiliar roads, lack of local context, perceived driving unsuitability, and inconsistencies with realized navigation experiences. Our findings and implications emphasize their personalization needs, and how the right amount of algorithmic sophistication can encourage behavioral adaptation."
pn4026,https://doi.org/10.1145/3290605.3300601,Exploring Factors that Influence Connected Drivers to (Not) Use or Follow Recommended Optimal Routes,2,Yasuyuki Sumi,Future University Hakodate,Hakodate,Japan,false,false,"Navigation applications are becoming ubiquitous in our daily navigation experiences. With the intention to circumnavigate congested roads, their route guidance always follows the basic assumption that drivers always want the fastest route. However, it is unclear how their recommendations are followed and what factors affect their adoption. We present the results of a semi-structured qualitative study with 17 drivers, mostly from the Philippines and Japan. We recorded their daily commutes and occasional trips, and inquired into their navigation practices, route choices and on-the-fly decision-making. We found that while drivers choose a recommended route in urgent situations, many still preferred to follow familiar routes. Drivers deviated because of a recommendation's use of unfamiliar roads, lack of local context, perceived driving unsuitability, and inconsistencies with realized navigation experiences. Our findings and implications emphasize their personalization needs, and how the right amount of algorithmic sophistication can encourage behavioral adaptation."
pn1583,https://doi.org/10.1145/3290605.3300379,The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision when Distinguishing Posed from Spontaneous Smiles,1,Monica Perusquia-Hernandez,NTT Communication Science Laboratories,Atsugi,Japan,false,false,"Positive experiences are a success metric in product and service design. Quantifying smiles is a method of assessing them continuously. Smiles are usually a cue of positive affect, but they can also be fabricated voluntarily. Automatic detection is a promising complement to human perception in terms of identifying the differences between smile types. Computer vision (CV) and facial distal electromyography (EMG) have been proven successful in this task. This is the first study to use a wearable EMG that does not obstruct the face to compare the performance of CV and EMG measurements in the task of distinguishing between posed and spontaneous smiles. The results showed that EMG has the advantage of being able to identify covert behavior not available through vision. Moreover, CV appears to be able to identify visible dynamic features that human judges cannot account for. This sheds light on the role of non-observable behavior in distinguishing affect-related smiles from polite positive affect displays."
pn1583,https://doi.org/10.1145/3290605.3300379,The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision when Distinguishing Posed from Spontaneous Smiles,2,Saho Ayabe-Kanamura,University of Tsukuba,Tsukuba,Japan,false,false,"Positive experiences are a success metric in product and service design. Quantifying smiles is a method of assessing them continuously. Smiles are usually a cue of positive affect, but they can also be fabricated voluntarily. Automatic detection is a promising complement to human perception in terms of identifying the differences between smile types. Computer vision (CV) and facial distal electromyography (EMG) have been proven successful in this task. This is the first study to use a wearable EMG that does not obstruct the face to compare the performance of CV and EMG measurements in the task of distinguishing between posed and spontaneous smiles. The results showed that EMG has the advantage of being able to identify covert behavior not available through vision. Moreover, CV appears to be able to identify visible dynamic features that human judges cannot account for. This sheds light on the role of non-observable behavior in distinguishing affect-related smiles from polite positive affect displays."
pn1583,https://doi.org/10.1145/3290605.3300379,The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision when Distinguishing Posed from Spontaneous Smiles,3,Kenji Suzuki,University of Tsukuba,Tsukuba,Japan,false,false,"Positive experiences are a success metric in product and service design. Quantifying smiles is a method of assessing them continuously. Smiles are usually a cue of positive affect, but they can also be fabricated voluntarily. Automatic detection is a promising complement to human perception in terms of identifying the differences between smile types. Computer vision (CV) and facial distal electromyography (EMG) have been proven successful in this task. This is the first study to use a wearable EMG that does not obstruct the face to compare the performance of CV and EMG measurements in the task of distinguishing between posed and spontaneous smiles. The results showed that EMG has the advantage of being able to identify covert behavior not available through vision. Moreover, CV appears to be able to identify visible dynamic features that human judges cannot account for. This sheds light on the role of non-observable behavior in distinguishing affect-related smiles from polite positive affect displays."
pn1583,https://doi.org/10.1145/3290605.3300379,The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision when Distinguishing Posed from Spontaneous Smiles,4,Shiro Kumano,NTT Communication Science Laboratories,Atsugi,Japan,false,false,"Positive experiences are a success metric in product and service design. Quantifying smiles is a method of assessing them continuously. Smiles are usually a cue of positive affect, but they can also be fabricated voluntarily. Automatic detection is a promising complement to human perception in terms of identifying the differences between smile types. Computer vision (CV) and facial distal electromyography (EMG) have been proven successful in this task. This is the first study to use a wearable EMG that does not obstruct the face to compare the performance of CV and EMG measurements in the task of distinguishing between posed and spontaneous smiles. The results showed that EMG has the advantage of being able to identify covert behavior not available through vision. Moreover, CV appears to be able to identify visible dynamic features that human judges cannot account for. This sheds light on the role of non-observable behavior in distinguishing affect-related smiles from polite positive affect displays."
pn3660,https://doi.org/10.1145/3290605.3300904,How Do Humans Assess the Credibility on Web Blogs: Qualifying and Verifying Human Factors with Machine Learning,1,Yonggeol Jo,Ajou University,Suwon,Republic Of Korea,false,false,"The purpose of this paper is to understand the factors involved when a human judges the credibility of information and to develop a classification model for weblogs, a primary source of information for many people. Considering both computational and human-centered approaches, we conducted a user study designed to consider two cognitive procedures--(1) visceral, behavioral and (2) reflective assessments--in the evaluation of information credibility. The results of the 80-participant study highlight that human cognitive processing varies according to an individual's purpose and that humans consider the structures and styles of content in their reflective assessments. We experimentally proved these findings through the development and analysis of classification models using 16,304 real blog posts written by 2,944 bloggers. Our models yield greater accuracy and efficiency than the models with well-known best features identified in prior research"
pn3660,https://doi.org/10.1145/3290605.3300904,How Do Humans Assess the Credibility on Web Blogs: Qualifying and Verifying Human Factors with Machine Learning,2,Minwoo Kim,Ajou University,Suwon,Republic Of Korea,false,false,"The purpose of this paper is to understand the factors involved when a human judges the credibility of information and to develop a classification model for weblogs, a primary source of information for many people. Considering both computational and human-centered approaches, we conducted a user study designed to consider two cognitive procedures--(1) visceral, behavioral and (2) reflective assessments--in the evaluation of information credibility. The results of the 80-participant study highlight that human cognitive processing varies according to an individual's purpose and that humans consider the structures and styles of content in their reflective assessments. We experimentally proved these findings through the development and analysis of classification models using 16,304 real blog posts written by 2,944 bloggers. Our models yield greater accuracy and efficiency than the models with well-known best features identified in prior research"
pn3660,https://doi.org/10.1145/3290605.3300904,How Do Humans Assess the Credibility on Web Blogs: Qualifying and Verifying Human Factors with Machine Learning,3,Kyungsik Han,Ajou University,Suwon,Republic Of Korea,false,false,"The purpose of this paper is to understand the factors involved when a human judges the credibility of information and to develop a classification model for weblogs, a primary source of information for many people. Considering both computational and human-centered approaches, we conducted a user study designed to consider two cognitive procedures--(1) visceral, behavioral and (2) reflective assessments--in the evaluation of information credibility. The results of the 80-participant study highlight that human cognitive processing varies according to an individual's purpose and that humans consider the structures and styles of content in their reflective assessments. We experimentally proved these findings through the development and analysis of classification models using 16,304 real blog posts written by 2,944 bloggers. Our models yield greater accuracy and efficiency than the models with well-known best features identified in prior research"
pn2054,https://doi.org/10.1145/3290605.3300725,"Examining the ""Global"" Language of Emojis: Designing for Cultural Representation",1,Philippe Kimura-Thollander,Georgia Institute of Technology,Atlanta,United States,false,false,"Emojis are becoming an increasingly popular mode of communication between individuals worldwide, with researchers claiming them to be a type of ""ubiquitous language'' that can span different languages due to its pictorial nature. Our study uses a combination of methods to examine how emojis are adopted and perceived by individuals from diverse cultural backgrounds and 45 countries. Our survey and interview findings point to the existence of a cultural gap between user perceptions and the current emoji standard. Using participatory design, we sought to address this gap by designing 40 emojis and conducted another survey to evaluate their acceptability compared to existing Japanese emojis. We also draw on participant observation from a Unicode Consortium meeting on emoji addition. Our analysis leads us to discuss how emojis might be made more inclusive, diverse, and representative of the populations that use them."
pn2054,https://doi.org/10.1145/3290605.3300725,"Examining the ""Global"" Language of Emojis: Designing for Cultural Representation",2,Neha Kumar,Georgia Institute of Technology,Atlanta,United States,false,false,"Emojis are becoming an increasingly popular mode of communication between individuals worldwide, with researchers claiming them to be a type of ""ubiquitous language'' that can span different languages due to its pictorial nature. Our study uses a combination of methods to examine how emojis are adopted and perceived by individuals from diverse cultural backgrounds and 45 countries. Our survey and interview findings point to the existence of a cultural gap between user perceptions and the current emoji standard. Using participatory design, we sought to address this gap by designing 40 emojis and conducted another survey to evaluate their acceptability compared to existing Japanese emojis. We also draw on participant observation from a Unicode Consortium meeting on emoji addition. Our analysis leads us to discuss how emojis might be made more inclusive, diverse, and representative of the populations that use them."
pn5232,https://doi.org/10.1145/3290605.3300732,Together in Bed? Couples' Mobile Technology Use in Bed,1,Tarja Salmela,University of Lapland,Rovaniemi,Finland,false,false,"In this paper, we investigate the use of mobile technology in an underexplored context, the bed that couples share. Despite large amounts of research on the impact of pre-bedtime technology use on our sleep and mental state, scant research in the HCI field focuses on the physical bed as a negotiated site of technology use by couples. This paper explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies of both individual and shared technology use in bed, in the context of couple's relationships. We investigate the effects of mobile technology to couples' bed-sharing practices through in-depth interviews (n = 12) and an online survey (n = 117). We report on creative and negotiated bodily practices of mobile technology use by couples in bed, and the perceived effects on couples' verbal and physical interaction and the intimacy of the bed."
pn5232,https://doi.org/10.1145/3290605.3300732,Together in Bed? Couples' Mobile Technology Use in Bed,2,Ashley Colley,University of Lapland,Rovaniemi,Finland,false,false,"In this paper, we investigate the use of mobile technology in an underexplored context, the bed that couples share. Despite large amounts of research on the impact of pre-bedtime technology use on our sleep and mental state, scant research in the HCI field focuses on the physical bed as a negotiated site of technology use by couples. This paper explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies of both individual and shared technology use in bed, in the context of couple's relationships. We investigate the effects of mobile technology to couples' bed-sharing practices through in-depth interviews (n = 12) and an online survey (n = 117). We report on creative and negotiated bodily practices of mobile technology use by couples in bed, and the perceived effects on couples' verbal and physical interaction and the intimacy of the bed."
pn5232,https://doi.org/10.1145/3290605.3300732,Together in Bed? Couples' Mobile Technology Use in Bed,3,Jonna Häkkilä,University of Lapland,Rovaniemi,Finland,false,false,"In this paper, we investigate the use of mobile technology in an underexplored context, the bed that couples share. Despite large amounts of research on the impact of pre-bedtime technology use on our sleep and mental state, scant research in the HCI field focuses on the physical bed as a negotiated site of technology use by couples. This paper explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies of both individual and shared technology use in bed, in the context of couple's relationships. We investigate the effects of mobile technology to couples' bed-sharing practices through in-depth interviews (n = 12) and an online survey (n = 117). We report on creative and negotiated bodily practices of mobile technology use by couples in bed, and the perceived effects on couples' verbal and physical interaction and the intimacy of the bed."
pn5892,https://doi.org/10.1145/3290605.3300410,"""Everyone Has Some Personal Stuff"": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh",1,Syed Ishtiaque Ahmed,University of Toronto,Toronto,Canada,false,false,"People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain."
pn5892,https://doi.org/10.1145/3290605.3300410,"""Everyone Has Some Personal Stuff"": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh",2,Md. Romael Haque,Marquette University,Milwaukee,United States,false,false,"People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain."
pn5892,https://doi.org/10.1145/3290605.3300410,"""Everyone Has Some Personal Stuff"": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh",3,Irtaza Haider,Georgia Institute of Technology,Atlanta,United States,false,false,"People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain."
pn5892,https://doi.org/10.1145/3290605.3300410,"""Everyone Has Some Personal Stuff"": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh",4,Jay Chen,New York University,Abu Dhabi,Uae,false,false,"People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain."
pn5892,https://doi.org/10.1145/3290605.3300410,"""Everyone Has Some Personal Stuff"": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh",5,Nicola Dell,Cornell Tech,New York,United States,false,false,"People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,1,Daniel Lambton-Howard,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,2,Robert Anderson,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,3,Kyle Montague,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,4,Andrew Garbett,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,5,Shaun Hazeldine,International Federation of Red Cross and Red Crescent Societies,Geneva,Switzerland,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,6,Carlos Alvarez,International Federation of Red Cross and Red Crescent Societies,Geneva,Switzerland,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,7,John Sweeney,Narxoz University,Almaty,Kazakhstan,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,8,Patrick Olivier,Monash University,Melbourne,Australia,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn6082,https://doi.org/10.1145/3290605.3300389,WhatFutures: Designing Large-Scale Engagements on WhatsApp,9,Ahmed Kharrufa,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"WhatsApp, as the world's most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designed WhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity – including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey – we present a reflection upon the design decisions underpinning WhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications."
pn9535,https://doi.org/10.1145/3290605.3300404,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,1,Don Samitha Elvitigala,The University of Auckland,Auckland,New Zealand,false,false,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture."
pn9535,https://doi.org/10.1145/3290605.3300404,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,2,Denys Matthies,The University of Auckland,Auckland,New Zealand,false,false,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture."
pn9535,https://doi.org/10.1145/3290605.3300404,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,3,Löic David,The University of Auckland,Auckland,New Zealand,false,false,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture."
pn9535,https://doi.org/10.1145/3290605.3300404,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,4,Chamod Weerasinghe,University of Auckland,Auckland,New Zealand,false,false,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture."
pn9535,https://doi.org/10.1145/3290605.3300404,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,5,Suranga Nanayakkara,The University of Auckland,Auckland,New Zealand,false,false,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,1,Francisco Kiss,University of Stuttgart,Stuttgart,Germany,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,2,Paweł Woźniak,Utrecht University,Utrecht,Netherlands,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,3,Felix Scheerer,University of Stuttgart,Stuttgart,Germany,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,4,Julia Dominiak,Lodz University of Technology,Łódź,Poland,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,5,Andrzej Romanowski,Lodz University of Technology,Łódź,Poland,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn4939,https://doi.org/10.1145/3290605.3300467,Clairbuoyance: Improving Directional Perception for Swimmers,6,Albrecht Schmidt,Ludwig Maximilian University of Munich,Munich,Germany,true,false,"While we usually have no trouble with orientation, our sense of direction frequently fails in the absence of a frame of reference. Open-water swimmers raise their heads to look for a reference point, since disorientation might result in exhaustion or even drowning. In this paper, we report on Clairbuoyance - a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles. We conducted an experiment with two versions of Clairbuoyance: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. Participants swam to a series of targets. Proficient swimmers preferred the discrete mode; novice users the continuous one. We determined that both versions of Clairbuoyance enabled reaching the target faster than without the help of the system, although the discrete mode increased error. Based on the results, we contribute insights for designing directional guidance feedback for swimmers."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,1,Herman Saksono,Northeastern University,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,2,Carmen Castaneda-Sceppa,Northeastern University,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,3,Jessica Hoffman,Northeastern University,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,4,Magy Seif El-Nasr,Northeastern University,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,5,Vivien Morris,Mattapan Food and Fitness Coalition,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn6025,https://doi.org/10.1145/3290605.3300543,Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,6,Andrea Parker,Northeastern University,Boston,United States,false,false,"Wearable activity trackers can encourage physical activity (PA)—a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active—wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data."
pn8283,https://doi.org/10.1145/3290605.3300624,A Tale of Two Perspectives: A Conceptual Framework of User Expectations and Experiences of Instructional Fitness Apps,1,Ahed Aladwan,The University of Melbourne,Melbourne,Australia,false,true,"We present a conceptual framework grounded in both users' reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined different forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specific domain (instructional fitness apps). We first extracted the particular instances using users' online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman's design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs."
pn8283,https://doi.org/10.1145/3290605.3300624,A Tale of Two Perspectives: A Conceptual Framework of User Expectations and Experiences of Instructional Fitness Apps,2,Ryan Kelly,The University of Melbourne,Melbourne,Australia,false,true,"We present a conceptual framework grounded in both users' reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined different forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specific domain (instructional fitness apps). We first extracted the particular instances using users' online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman's design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs."
pn8283,https://doi.org/10.1145/3290605.3300624,A Tale of Two Perspectives: A Conceptual Framework of User Expectations and Experiences of Instructional Fitness Apps,3,Steven Baker,The University of Melbourne,Melbourne,Australia,false,true,"We present a conceptual framework grounded in both users' reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined different forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specific domain (instructional fitness apps). We first extracted the particular instances using users' online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman's design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs."
pn8283,https://doi.org/10.1145/3290605.3300624,A Tale of Two Perspectives: A Conceptual Framework of User Expectations and Experiences of Instructional Fitness Apps,4,Eduardo Velloso,University of Melbourne,Melbourne,Australia,false,true,"We present a conceptual framework grounded in both users' reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined different forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specific domain (instructional fitness apps). We first extracted the particular instances using users' online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman's design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs."
pn7883,https://doi.org/10.1145/3290605.3300245,BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming,1,Yasha Iravantchi,Carnegie Mellon University,Pittsburgh,United States,false,false,"BeamBand is a wrist-worn system that uses ultrasonic beamforming for hand gesture sensing. Using an array of small transducers, arranged on the wrist, we can ensem-ble acoustic wavefronts to project acoustic energy at spec-ified angles and focal lengths. This allows us to interro-gate the surface geometry of the hand with inaudible sound in a raster-scan-like manner, from multiple view-points. We use the resulting, characteristic reflections to recognize hand pose at 8 FPS. In our user study, we found that BeamBand supports a six-class hand gesture set at 94.6% accuracy. Even across sessions, when the sensor is removed and reworn later, accuracy remains high: 89.4%. We describe our software and hardware, and future ave-nues for integration into devices such as smartwatches and VR controllers."
pn7883,https://doi.org/10.1145/3290605.3300245,BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming,2,Mayank Goel,Carnegie Mellon University,Pittsburgh,United States,false,false,"BeamBand is a wrist-worn system that uses ultrasonic beamforming for hand gesture sensing. Using an array of small transducers, arranged on the wrist, we can ensem-ble acoustic wavefronts to project acoustic energy at spec-ified angles and focal lengths. This allows us to interro-gate the surface geometry of the hand with inaudible sound in a raster-scan-like manner, from multiple view-points. We use the resulting, characteristic reflections to recognize hand pose at 8 FPS. In our user study, we found that BeamBand supports a six-class hand gesture set at 94.6% accuracy. Even across sessions, when the sensor is removed and reworn later, accuracy remains high: 89.4%. We describe our software and hardware, and future ave-nues for integration into devices such as smartwatches and VR controllers."
pn7883,https://doi.org/10.1145/3290605.3300245,BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming,3,Chris Harrison,Carnegie Mellon University,Pittsburgh,United States,false,false,"BeamBand is a wrist-worn system that uses ultrasonic beamforming for hand gesture sensing. Using an array of small transducers, arranged on the wrist, we can ensem-ble acoustic wavefronts to project acoustic energy at spec-ified angles and focal lengths. This allows us to interro-gate the surface geometry of the hand with inaudible sound in a raster-scan-like manner, from multiple view-points. We use the resulting, characteristic reflections to recognize hand pose at 8 FPS. In our user study, we found that BeamBand supports a six-class hand gesture set at 94.6% accuracy. Even across sessions, when the sensor is removed and reworn later, accuracy remains high: 89.4%. We describe our software and hardware, and future ave-nues for integration into devices such as smartwatches and VR controllers."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,1,Chun Yu,Global Innovation eXchange Institute,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,2,Xiaoying Wei,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,3,Shubh Vachher,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,4,Yue Qin,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,5,Chen Liang,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,6,Yueting Weng,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,7,Yizheng Gu,Tsinghua University,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn4185,https://doi.org/10.1145/3290605.3300935,HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-based Stereo Vision,8,Yuanchun Shi,Global Innovation eXchange Institute,Beijing,China,false,false,"We present HandSee, a novel sensing technique that can capture the state and movement of the user's hands touching or gripping a smartphone. We place a right angle prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. We develop a pipeline to extract the depth image of hands from a monocular RGB image, which consists of three components: a stereo matching algorithm to estimate the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect hand skin, and a merging algorithm that outputs the depth image of the hands. Building on the output, a substantial set of valuable interaction information, such as fingers' 3D location, gripping posture, and finger identity can be recognized concurrently. Due to this unique sensing ability, HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones."
pn5822,https://doi.org/10.1145/3290605.3300568,Sensing Fine-Grained Hand Activity with Smartwatches,1,Gierad Laput,Carnegie Mellon University,Pittsburgh,United States,false,false,"Capturing fine-grained hand activity could make computational experiences more powerful and contextually aware. Indeed, philosopher Immanuel Kant argued, ""the hand is the visible part of the brain."" However, most prior work has focused on detecting whole-body activities, such as walking, running and bicycling. In this work, we explore the feasibility of sensing hand activities from commodity smartwatches, which are the most practical vehicle for achieving this vision. Our investigations started with a 50 participant, in-the-wild study, which captured hand activity labels over nearly 1000 worn hours. We then studied this data to scope our research goals and inform our technical approach. We conclude with a second, in-lab study that evaluates our classification stack, demonstrating 95.2% accuracy across 25 hand activities. Our work highlights an underutilized, yet highly complementary contextual channel that could unlock a wide range of promising applications."
pn5822,https://doi.org/10.1145/3290605.3300568,Sensing Fine-Grained Hand Activity with Smartwatches,2,Chris Harrison,Carnegie Mellon University,Pittsburgh,United States,false,false,"Capturing fine-grained hand activity could make computational experiences more powerful and contextually aware. Indeed, philosopher Immanuel Kant argued, ""the hand is the visible part of the brain."" However, most prior work has focused on detecting whole-body activities, such as walking, running and bicycling. In this work, we explore the feasibility of sensing hand activities from commodity smartwatches, which are the most practical vehicle for achieving this vision. Our investigations started with a 50 participant, in-the-wild study, which captured hand activity labels over nearly 1000 worn hours. We then studied this data to scope our research goals and inform our technical approach. We conclude with a second, in-lab study that evaluates our classification stack, demonstrating 95.2% accuracy across 25 hand activities. Our work highlights an underutilized, yet highly complementary contextual channel that could unlock a wide range of promising applications."
pn4396,https://doi.org/10.1145/3290605.3300632,Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects,1,Adwait Sharma,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects."
pn4396,https://doi.org/10.1145/3290605.3300632,Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects,2,Joan Sol Roo,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects."
pn4396,https://doi.org/10.1145/3290605.3300632,Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects,3,Jürgen Steimle,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects."
pn8088,https://doi.org/10.1145/3290605.3300585,Implementing Multi-Touch Gestures with Touch Groups and Cross Events,1,Steve Oney,University of Michigan,Ann Arbor,United States,true,false,"Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures, which we illustrate through a series of examples. Further, in two user evaluations of these programming primitives, we found that multi-touch behaviors implemented in these programming primitives are more understandable than those implemented with standard touch events."
pn8088,https://doi.org/10.1145/3290605.3300585,Implementing Multi-Touch Gestures with Touch Groups and Cross Events,2,Rebecca Krosnick,University of Michigan,Ann Arbor,United States,true,false,"Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures, which we illustrate through a series of examples. Further, in two user evaluations of these programming primitives, we found that multi-touch behaviors implemented in these programming primitives are more understandable than those implemented with standard touch events."
pn8088,https://doi.org/10.1145/3290605.3300585,Implementing Multi-Touch Gestures with Touch Groups and Cross Events,3,Joel Brandt,Adobe,Santa Monica,United States,true,false,"Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures, which we illustrate through a series of examples. Further, in two user evaluations of these programming primitives, we found that multi-touch behaviors implemented in these programming primitives are more understandable than those implemented with standard touch events."
pn8088,https://doi.org/10.1145/3290605.3300585,Implementing Multi-Touch Gestures with Touch Groups and Cross Events,4,Brad Myers,Carnegie Mellon University,Pittsburgh,United States,true,false,"Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures, which we illustrate through a series of examples. Further, in two user evaluations of these programming primitives, we found that multi-touch behaviors implemented in these programming primitives are more understandable than those implemented with standard touch events."
pn5550,https://doi.org/10.1145/3290605.3300919,Estimating Touch Force with Barometric Pressure Sensors,1,Philip Quinn,Google,Mountain View,United States,false,false,"Finger pressure offers a new dimension for touch interaction, where input is defined by its spatial position and orthogonal force. However, the limited availability and complexity of integrated force-sensing hardware in mobile devices is a barrier to exploring this design space. This paper presents a synthesis of two features in recent mobile devices – a barometric sensor (pressure altimeter) and ingress protection – to sense a user's touch force. When a user applies force to a device's display, it flexes inward and causes an increase in atmospheric pressure within the sealed chassis. This increase in pressure can be sensed by the device's internal barometer. However, this change is uncontrolled and requires a calibration model to map atmospheric pressure to touch force. This paper derives such a model and demonstrates its viability on four commercially-available devices (including two with dedicated force sensors). The results show this method is sensitive to forces of less than 1 N, and is comparable to dedicated force sensors."
pn4911,https://doi.org/10.1145/3290605.3300317,Direct Finger Manipulation of 3D Object Image with Ultrasound Haptic Feedback,1,Atsushi Matsubayashi,University of Tokyo,Tokyo,Japan,false,false,"In this study, we prototype and examine a system that allows a user to manipulate a 3D virtual object with multiple fingers without wearing any device. An autostereoscopic display produces a 3D image and a depth sensor measures the movement of the fingers. When a user touches a virtual object, haptic feedback is provided by ultrasound phased arrays. By estimating the cross section of the finger in contact with the virtual object and by creating a force pattern around it, it is possible for the user to recognize the position of the surface relative to the finger. To evaluate our system, we conducted two experiments to show that the proposed feedback method is effective in recognizing the object surface and thereby enables the user to grasp the object quickly without seeing it."
pn4911,https://doi.org/10.1145/3290605.3300317,Direct Finger Manipulation of 3D Object Image with Ultrasound Haptic Feedback,2,Yasutoshi Makino,University of Tokyo,Kashiwa,Japan,false,false,"In this study, we prototype and examine a system that allows a user to manipulate a 3D virtual object with multiple fingers without wearing any device. An autostereoscopic display produces a 3D image and a depth sensor measures the movement of the fingers. When a user touches a virtual object, haptic feedback is provided by ultrasound phased arrays. By estimating the cross section of the finger in contact with the virtual object and by creating a force pattern around it, it is possible for the user to recognize the position of the surface relative to the finger. To evaluate our system, we conducted two experiments to show that the proposed feedback method is effective in recognizing the object surface and thereby enables the user to grasp the object quickly without seeing it."
pn4911,https://doi.org/10.1145/3290605.3300317,Direct Finger Manipulation of 3D Object Image with Ultrasound Haptic Feedback,3,Hiroyuki Shinoda,University of Tokyo,Kashiwa,Japan,false,false,"In this study, we prototype and examine a system that allows a user to manipulate a 3D virtual object with multiple fingers without wearing any device. An autostereoscopic display produces a 3D image and a depth sensor measures the movement of the fingers. When a user touches a virtual object, haptic feedback is provided by ultrasound phased arrays. By estimating the cross section of the finger in contact with the virtual object and by creating a force pattern around it, it is possible for the user to recognize the position of the surface relative to the finger. To evaluate our system, we conducted two experiments to show that the proposed feedback method is effective in recognizing the object surface and thereby enables the user to grasp the object quickly without seeing it."
pn8300,https://doi.org/10.1145/3290605.3300351,Sampling Strategy for Ultrasonic Mid-Air Haptics,1,William Frier,University of Sussex,Brighton,United Kingdom,false,false,"Mid-air tactile stimulation using ultrasonics has been used in a variety of human computer interfaces in the form of prototypes as well as products. When generating these tactile patterns with mid-air tactile ultrasonic displays, the common approach has been to sample the patterns using the hardware update rate capabilities to their full extent. In the current study we show that the hardware update rate can impact perception, but unexpectedly we find that higher update rates do not improve pattern perception. In a first user study, we highlight the effect of update rate on the perceived strength of a pattern, especially for patterns rendered at slow rate of less than 10 Hz. In a second user study, we identify the evolution of the optimal update rate according to variations in pattern size. Our main results show that update rate should be designated as additional parameter for tactile patterns. We also discuss how the relationships we defined in the current study can be implemented into designer tools so that designers remain oblivious to this additional complexity."
pn8300,https://doi.org/10.1145/3290605.3300351,Sampling Strategy for Ultrasonic Mid-Air Haptics,2,Dario Pittera,University of Sussex,Brighton And Hove,United Kingdom,false,false,"Mid-air tactile stimulation using ultrasonics has been used in a variety of human computer interfaces in the form of prototypes as well as products. When generating these tactile patterns with mid-air tactile ultrasonic displays, the common approach has been to sample the patterns using the hardware update rate capabilities to their full extent. In the current study we show that the hardware update rate can impact perception, but unexpectedly we find that higher update rates do not improve pattern perception. In a first user study, we highlight the effect of update rate on the perceived strength of a pattern, especially for patterns rendered at slow rate of less than 10 Hz. In a second user study, we identify the evolution of the optimal update rate according to variations in pattern size. Our main results show that update rate should be designated as additional parameter for tactile patterns. We also discuss how the relationships we defined in the current study can be implemented into designer tools so that designers remain oblivious to this additional complexity."
pn8300,https://doi.org/10.1145/3290605.3300351,Sampling Strategy for Ultrasonic Mid-Air Haptics,3,Damien Ablart,University of sussex,Brighton,United Kingdom,false,false,"Mid-air tactile stimulation using ultrasonics has been used in a variety of human computer interfaces in the form of prototypes as well as products. When generating these tactile patterns with mid-air tactile ultrasonic displays, the common approach has been to sample the patterns using the hardware update rate capabilities to their full extent. In the current study we show that the hardware update rate can impact perception, but unexpectedly we find that higher update rates do not improve pattern perception. In a first user study, we highlight the effect of update rate on the perceived strength of a pattern, especially for patterns rendered at slow rate of less than 10 Hz. In a second user study, we identify the evolution of the optimal update rate according to variations in pattern size. Our main results show that update rate should be designated as additional parameter for tactile patterns. We also discuss how the relationships we defined in the current study can be implemented into designer tools so that designers remain oblivious to this additional complexity."
pn8300,https://doi.org/10.1145/3290605.3300351,Sampling Strategy for Ultrasonic Mid-Air Haptics,4,Marianna Obrist,University of Sussex,Brighton,United Kingdom,false,false,"Mid-air tactile stimulation using ultrasonics has been used in a variety of human computer interfaces in the form of prototypes as well as products. When generating these tactile patterns with mid-air tactile ultrasonic displays, the common approach has been to sample the patterns using the hardware update rate capabilities to their full extent. In the current study we show that the hardware update rate can impact perception, but unexpectedly we find that higher update rates do not improve pattern perception. In a first user study, we highlight the effect of update rate on the perceived strength of a pattern, especially for patterns rendered at slow rate of less than 10 Hz. In a second user study, we identify the evolution of the optimal update rate according to variations in pattern size. Our main results show that update rate should be designated as additional parameter for tactile patterns. We also discuss how the relationships we defined in the current study can be implemented into designer tools so that designers remain oblivious to this additional complexity."
pn8300,https://doi.org/10.1145/3290605.3300351,Sampling Strategy for Ultrasonic Mid-Air Haptics,5,Sriram Subramanian,University of Sussex,Brighton,United Kingdom,false,false,"Mid-air tactile stimulation using ultrasonics has been used in a variety of human computer interfaces in the form of prototypes as well as products. When generating these tactile patterns with mid-air tactile ultrasonic displays, the common approach has been to sample the patterns using the hardware update rate capabilities to their full extent. In the current study we show that the hardware update rate can impact perception, but unexpectedly we find that higher update rates do not improve pattern perception. In a first user study, we highlight the effect of update rate on the perceived strength of a pattern, especially for patterns rendered at slow rate of less than 10 Hz. In a second user study, we identify the evolution of the optimal update rate according to variations in pattern size. Our main results show that update rate should be designated as additional parameter for tactile patterns. We also discuss how the relationships we defined in the current study can be implemented into designer tools so that designers remain oblivious to this additional complexity."
pn9976,https://doi.org/10.1145/3290605.3300814,SmartManikin: Virtual Humans with Agency for Design Tools,1,Bokyung Lee,KAIST,Daejeon,Republic Of Korea,false,false,"When designing comfort and usability in products, designers need to evaluate aspects ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins are employed as a reference in early-stage tools and for evaluation in the later stages. However, tools to intuitively interact with virtual humans are lacking. In this paper, we introduceSmartManikin, a mannequin with agency that responds to high-level commands and to real-time design changes. We first captured human poses with respect to desk configurations, identified key features of the pose and trained regression functions to estimate the optimal features at a given desk setup. The SmartManikin's pose is generated by the predicted features as well as by using forward and inverse kinematics. We present our design, implementation, and an evaluation with expert designers. The results revealed that SmartManikin enhances the design experience by providing feedback concerning comfort and health in real time."
pn9976,https://doi.org/10.1145/3290605.3300814,SmartManikin: Virtual Humans with Agency for Design Tools,2,Taeil Jin,KAIST,Daejeon,Republic Of Korea,false,false,"When designing comfort and usability in products, designers need to evaluate aspects ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins are employed as a reference in early-stage tools and for evaluation in the later stages. However, tools to intuitively interact with virtual humans are lacking. In this paper, we introduceSmartManikin, a mannequin with agency that responds to high-level commands and to real-time design changes. We first captured human poses with respect to desk configurations, identified key features of the pose and trained regression functions to estimate the optimal features at a given desk setup. The SmartManikin's pose is generated by the predicted features as well as by using forward and inverse kinematics. We present our design, implementation, and an evaluation with expert designers. The results revealed that SmartManikin enhances the design experience by providing feedback concerning comfort and health in real time."
pn9976,https://doi.org/10.1145/3290605.3300814,SmartManikin: Virtual Humans with Agency for Design Tools,3,Sung-Hee Lee,KAIST,Daejeon,Republic Of Korea,false,false,"When designing comfort and usability in products, designers need to evaluate aspects ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins are employed as a reference in early-stage tools and for evaluation in the later stages. However, tools to intuitively interact with virtual humans are lacking. In this paper, we introduceSmartManikin, a mannequin with agency that responds to high-level commands and to real-time design changes. We first captured human poses with respect to desk configurations, identified key features of the pose and trained regression functions to estimate the optimal features at a given desk setup. The SmartManikin's pose is generated by the predicted features as well as by using forward and inverse kinematics. We present our design, implementation, and an evaluation with expert designers. The results revealed that SmartManikin enhances the design experience by providing feedback concerning comfort and health in real time."
pn9976,https://doi.org/10.1145/3290605.3300814,SmartManikin: Virtual Humans with Agency for Design Tools,4,Daniel Saakes,KAIST,Daejeon,Republic Of Korea,false,false,"When designing comfort and usability in products, designers need to evaluate aspects ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins are employed as a reference in early-stage tools and for evaluation in the later stages. However, tools to intuitively interact with virtual humans are lacking. In this paper, we introduceSmartManikin, a mannequin with agency that responds to high-level commands and to real-time design changes. We first captured human poses with respect to desk configurations, identified key features of the pose and trained regression functions to estimate the optimal features at a given desk setup. The SmartManikin's pose is generated by the predicted features as well as by using forward and inverse kinematics. We present our design, implementation, and an evaluation with expert designers. The results revealed that SmartManikin enhances the design experience by providing feedback concerning comfort and health in real time."
pn8634,https://doi.org/10.1145/3290605.3300482,Crowdsourcing Interface Feature Design with Bayesian Optimization,1,John Dudley,University of Cambridge,Cambridge,United Kingdom,false,false,"Designing novel interfaces is challenging. Designers typically rely on experience or subjective judgment in the absence of analytical or objective means for selecting interface parameters. We demonstrate Bayesian optimization as an efficient tool for objective interface feature refinement. Specifically, we show that crowdsourcing paired with Bayesian optimization can rapidly and effectively assist interface design across diverse deployment environments. Experiment 1 evaluates the approach on a familiar 2D interface design problem: a map search and review use case. Adding a degree of complexity, Experiment 2 extends Experiment 1 by switching the deployment environment to mobile-based virtual reality. The approach is then demonstrated as a case study for a fundamentally new and unfamiliar interaction design problem: web-based augmented reality. Finally, we show how the model generated as an outcome of the refinement process can be used for user simulation and queried to deliver various design insights."
pn8634,https://doi.org/10.1145/3290605.3300482,Crowdsourcing Interface Feature Design with Bayesian Optimization,2,Jason Jacques,University of Cambridge,Cambridge,United Kingdom,false,false,"Designing novel interfaces is challenging. Designers typically rely on experience or subjective judgment in the absence of analytical or objective means for selecting interface parameters. We demonstrate Bayesian optimization as an efficient tool for objective interface feature refinement. Specifically, we show that crowdsourcing paired with Bayesian optimization can rapidly and effectively assist interface design across diverse deployment environments. Experiment 1 evaluates the approach on a familiar 2D interface design problem: a map search and review use case. Adding a degree of complexity, Experiment 2 extends Experiment 1 by switching the deployment environment to mobile-based virtual reality. The approach is then demonstrated as a case study for a fundamentally new and unfamiliar interaction design problem: web-based augmented reality. Finally, we show how the model generated as an outcome of the refinement process can be used for user simulation and queried to deliver various design insights."
pn8634,https://doi.org/10.1145/3290605.3300482,Crowdsourcing Interface Feature Design with Bayesian Optimization,3,Per Ola Kristensson,University of Cambridge,Cambridge,United Kingdom,false,false,"Designing novel interfaces is challenging. Designers typically rely on experience or subjective judgment in the absence of analytical or objective means for selecting interface parameters. We demonstrate Bayesian optimization as an efficient tool for objective interface feature refinement. Specifically, we show that crowdsourcing paired with Bayesian optimization can rapidly and effectively assist interface design across diverse deployment environments. Experiment 1 evaluates the approach on a familiar 2D interface design problem: a map search and review use case. Adding a degree of complexity, Experiment 2 extends Experiment 1 by switching the deployment environment to mobile-based virtual reality. The approach is then demonstrated as a case study for a fundamentally new and unfamiliar interaction design problem: web-based augmented reality. Finally, we show how the model generated as an outcome of the refinement process can be used for user simulation and queried to deliver various design insights."
pn1801,https://doi.org/10.1145/3290605.3300686,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,1,Maria Shugrina,University of Toronto,Toronto,Canada,false,false,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field."
pn1801,https://doi.org/10.1145/3290605.3300686,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,2,Wenjia Zhang,University of Toronto,Toronto,Canada,false,false,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field."
pn1801,https://doi.org/10.1145/3290605.3300686,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,3,Fanny Chevalier,University of Toronto,Toronto,Canada,false,false,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field."
pn1801,https://doi.org/10.1145/3290605.3300686,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,4,Sanja Fidler,University of Toronto,Toronto,Canada,false,false,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field."
pn1801,https://doi.org/10.1145/3290605.3300686,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,5,Karan Singh,University of Toronto,Toronto,Canada,false,false,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,1,Matjaž Kljun,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,2,Klen Copic Pucihar,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,3,Jason Alexander,Lancaster University,Lancaster,United Kingdom,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,4,Maheshya Weerasinghe,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,5,Cuauhtli Campos,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,6,Julie Ducasse,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,7,Barbara Kopacin,University of Primorska,Koper,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,8,Jens Grubert,Coburg University,Coburg,Germany,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,9,Paul Coulton,Lancaster University,Lancaster,United Kingdom,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn8011,https://doi.org/10.1145/3290605.3300333,Augmentation not Duplication: Considerations for the Design of Digitally-Augmented Comic Books,10,Miha ?Elar,Astral Film,Ljubljana,Slovenia,false,false,"Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media."
pn9085,https://doi.org/10.1145/3290605.3300331,RayCursor: A 3D Pointing Facilitation Technique based on Raycasting,1,Marc Baloup,Université de Lille,Villeneuve D'ascq,France,false,false,"Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user's motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature."
pn9085,https://doi.org/10.1145/3290605.3300331,RayCursor: A 3D Pointing Facilitation Technique based on Raycasting,2,Thomas Pietrzak,Université de Lille,Villeneuve D'ascq,France,false,false,"Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user's motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature."
pn9085,https://doi.org/10.1145/3290605.3300331,RayCursor: A 3D Pointing Facilitation Technique based on Raycasting,3,Géry Casiez,Université de Lille,Villeneuve D'ascq,France,false,false,"Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user's motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,1,Arnaud Prouzeau,Monash University,Melbourne,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,2,Maxime Cordeil,Monash University,Melbourne,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,3,Clement Robin,Monash University,Melbourne,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,4,Barrett Ens,Monash University,Melbourne,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,5,Bruce Thomas,University of South Australia,Mawson Lakes,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4170,https://doi.org/10.1145/3290605.3300555,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,6,Tim Dwyer,Monash University,Melbourne,Australia,false,false,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane."
pn4657,https://doi.org/10.1145/3290605.3300842,Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation,1,Diako Mardanbegi,Lancaster University,Lancaster,United Kingdom,false,false,"Target disambiguation is a common problem in gaze interfaces, as eye tracking has accuracy and precision limitations. In 3D environments this is compounded by objects overlapping in the field of view, as a result of their positioning at different depth with partial occlusion. We introduce VOR depth estimation, a method based on the Vestibulo-ocular reflex of the eyes in compensation of head movement, and explore its application to resolve target ambiguity. The method estimates gaze depth by comparing the rotations of the eye and the head when the users look at a target and deliberately rotate their head. We show that VOR eye movement presents an alternative to vergence for gaze depth estimation, that is feasible also with monocular tracking. In an evaluation of its use for target disambiguation, our method outperforms vergence for targets presented at greater depth."
pn4657,https://doi.org/10.1145/3290605.3300842,Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation,2,Tobias Langlotz,University of Otago,Dunedin,New Zealand,false,false,"Target disambiguation is a common problem in gaze interfaces, as eye tracking has accuracy and precision limitations. In 3D environments this is compounded by objects overlapping in the field of view, as a result of their positioning at different depth with partial occlusion. We introduce VOR depth estimation, a method based on the Vestibulo-ocular reflex of the eyes in compensation of head movement, and explore its application to resolve target ambiguity. The method estimates gaze depth by comparing the rotations of the eye and the head when the users look at a target and deliberately rotate their head. We show that VOR eye movement presents an alternative to vergence for gaze depth estimation, that is feasible also with monocular tracking. In an evaluation of its use for target disambiguation, our method outperforms vergence for targets presented at greater depth."
pn4657,https://doi.org/10.1145/3290605.3300842,Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation,3,Hans Gellersen,Lancaster University,Lancaster,United Kingdom,false,false,"Target disambiguation is a common problem in gaze interfaces, as eye tracking has accuracy and precision limitations. In 3D environments this is compounded by objects overlapping in the field of view, as a result of their positioning at different depth with partial occlusion. We introduce VOR depth estimation, a method based on the Vestibulo-ocular reflex of the eyes in compensation of head movement, and explore its application to resolve target ambiguity. The method estimates gaze depth by comparing the rotations of the eye and the head when the users look at a target and deliberately rotate their head. We show that VOR eye movement presents an alternative to vergence for gaze depth estimation, that is feasible also with monocular tracking. In an evaluation of its use for target disambiguation, our method outperforms vergence for targets presented at greater depth."
pn6639,https://doi.org/10.1145/3290605.3300848,Crossing-Based Selection with Virtual Reality Head-Mounted Displays,1,Huawei Tu,Nanjing University of Aeronautics and Astronautics,Nanjing,China,false,false,"This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR."
pn6639,https://doi.org/10.1145/3290605.3300848,Crossing-Based Selection with Virtual Reality Head-Mounted Displays,2,Susu Huang,Nanjing University of Aeronautics and Astronautics,Nanjing,China,false,false,"This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR."
pn6639,https://doi.org/10.1145/3290605.3300848,Crossing-Based Selection with Virtual Reality Head-Mounted Displays,3,Jiabin Yuan,Nanjing University of Aeronautics and Astronautics,Nanjing,China,false,false,"This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR."
pn6639,https://doi.org/10.1145/3290605.3300848,Crossing-Based Selection with Virtual Reality Head-Mounted Displays,4,Xiangshi Ren,Kochi University of Technology,Kochi,Japan,false,false,"This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR."
pn6639,https://doi.org/10.1145/3290605.3300848,Crossing-Based Selection with Virtual Reality Head-Mounted Displays,5,Feng Tian,"Institute of software, Chinese Academy of Sciences",Beijing,China,false,false,"This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR."
pn5909,https://doi.org/10.1145/3290605.3300494,An Exploration of Speech-Based Productivity Support in the Car,1,Nikolas Martelaro,Accenture Technology Labs,San Francisco,United States,false,false,"In-car intelligent assistants offer the opportunity to help drivers productively use previously unclaimed time during their commute.However, engaging in secondary tasks can reduce attention on driving and thus may affect road safety.Any interface used while driving, even if speech-based, cannot consider non-driving tasks in isolation of driving---alerts for safer driving and timing of the non-driving tasks are crucial to maintaining safety.In this work, we explore experiences with a speech-based assistant that attempts to help drivers safely complete complex productivity tasks.Via a controlled simulator study, we look at how level of support and road context alerts from the assistant influence a driver's ability to drive safely while writing a document or creating slides via speech.Our results suggest ways to support speech-based productivity interactions and how speech-based road context alerts may influence driver behavior."
pn5909,https://doi.org/10.1145/3290605.3300494,An Exploration of Speech-Based Productivity Support in the Car,2,Jaime Teevan,Microsoft Research,Redmond,United States,false,false,"In-car intelligent assistants offer the opportunity to help drivers productively use previously unclaimed time during their commute.However, engaging in secondary tasks can reduce attention on driving and thus may affect road safety.Any interface used while driving, even if speech-based, cannot consider non-driving tasks in isolation of driving---alerts for safer driving and timing of the non-driving tasks are crucial to maintaining safety.In this work, we explore experiences with a speech-based assistant that attempts to help drivers safely complete complex productivity tasks.Via a controlled simulator study, we look at how level of support and road context alerts from the assistant influence a driver's ability to drive safely while writing a document or creating slides via speech.Our results suggest ways to support speech-based productivity interactions and how speech-based road context alerts may influence driver behavior."
pn5909,https://doi.org/10.1145/3290605.3300494,An Exploration of Speech-Based Productivity Support in the Car,3,Shamsi Iqbal,Microsoft Research,Redmond,United States,false,false,"In-car intelligent assistants offer the opportunity to help drivers productively use previously unclaimed time during their commute.However, engaging in secondary tasks can reduce attention on driving and thus may affect road safety.Any interface used while driving, even if speech-based, cannot consider non-driving tasks in isolation of driving---alerts for safer driving and timing of the non-driving tasks are crucial to maintaining safety.In this work, we explore experiences with a speech-based assistant that attempts to help drivers safely complete complex productivity tasks.Via a controlled simulator study, we look at how level of support and road context alerts from the assistant influence a driver's ability to drive safely while writing a document or creating slides via speech.Our results suggest ways to support speech-based productivity interactions and how speech-based road context alerts may influence driver behavior."
pn4250,https://doi.org/10.1145/3290605.3300284,"How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights",1,Kathrin Pollmann,University of Stuttgart,Stuttgart,Germany,false,false,"Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants' concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace."
pn4250,https://doi.org/10.1145/3290605.3300284,"How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights",2,Oilver Stefani,Psychiatric University Clinics,Basel,Switzerland,false,false,"Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants' concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace."
pn4250,https://doi.org/10.1145/3290605.3300284,"How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights",3,Amelie Bengsch,Fraunhofer Institute for Industrial Engineering IAO,Stuttgart,Germany,false,false,"Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants' concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace."
pn4250,https://doi.org/10.1145/3290605.3300284,"How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights",4,Matthias Peissner,Fraunhofer Insitute for Industrial Engineering IAO,Stuttgart,Germany,false,false,"Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants' concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace."
pn4250,https://doi.org/10.1145/3290605.3300284,"How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights",5,Mathias Vukeli?,Fraunhofer Institute for Industrial Engineering IAO,Stuttgart,Germany,false,false,"Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants' concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace."
pn1047,https://doi.org/10.1145/3290605.3300635,Using Time and Space Efficiently in Driverless Cars: Findings of a Co-Design Study,1,Gunnar Stevens,Hochschule Bonn-Rhein-Sieg,Sankt Augustin,Germany,true,false,"The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs."
pn1047,https://doi.org/10.1145/3290605.3300635,Using Time and Space Efficiently in Driverless Cars: Findings of a Co-Design Study,2,Paul Bossauer,Bonn-Rhein-Sieg University of Applied Sciences,Sankt Augustin,Germany,true,false,"The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs."
pn1047,https://doi.org/10.1145/3290605.3300635,Using Time and Space Efficiently in Driverless Cars: Findings of a Co-Design Study,3,Stephanie Vonholdt,Hochschule Bonn-Rhein-Sieg,Sankt Augustin,Germany,true,false,"The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs."
pn1047,https://doi.org/10.1145/3290605.3300635,Using Time and Space Efficiently in Driverless Cars: Findings of a Co-Design Study,4,Christina Pakusch,Bonn-Rhein-Sieg University,Sankt Augustin,Germany,true,false,"The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs."
pn6201,https://doi.org/10.1145/3290605.3300867,Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing,1,Rob Semmens,Naval Postgraduate School,Monterey,United States,false,false,"Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times.We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption."
pn6201,https://doi.org/10.1145/3290605.3300867,Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing,2,Nikolas Martelaro,Accenture Technology Labs,San Francisco,United States,false,false,"Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times.We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption."
pn6201,https://doi.org/10.1145/3290605.3300867,Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing,3,Pushyami Kaveti,Northeastern University,Boston,United States,false,false,"Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times.We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption."
pn6201,https://doi.org/10.1145/3290605.3300867,Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing,4,Simon Stent,Toyota Research Institute,Cambridge,United States,false,false,"Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times.We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption."
pn6201,https://doi.org/10.1145/3290605.3300867,Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing,5,Wendy Ju,Cornell Tech,New York,United States,false,false,"Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times.We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption."
pn1963,https://doi.org/10.1145/3290605.3300726,Time to Scale: Generalizable Affect Detection for Tens of Thousands of Students across An Entire School Year,1,Stephen Hutt,Univeristy of Colorado Boulder,Boulder,United States,false,false,"We developed generalizable affect detectors using 133,966 instances of 18 affective states collected from 69,174 students who interacted with an online math learning platform called Algebra Nation over the entire school year. To enable scalability and generalizability, we used generic interaction features (e.g., viewing a video, taking a quiz), which do not require specialized sensors and are domain- and (to a certain extent) system-independent. We experimented with standard classifiers, recurrent neural networks, and genetically evolved neural networks for affect modeling. Prediction accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise) to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized to a different set of Geometry students (n = 28,458) on the same platform. We discuss implications for scaling up affect detection for affect-sensitive online learning environments which aim to improve engagement and learning by detecting and responding to student affect."
pn1963,https://doi.org/10.1145/3290605.3300726,Time to Scale: Generalizable Affect Detection for Tens of Thousands of Students across An Entire School Year,2,Joseph Grafsgaard,University of Colorado Boulder,Boulder,United States,false,false,"We developed generalizable affect detectors using 133,966 instances of 18 affective states collected from 69,174 students who interacted with an online math learning platform called Algebra Nation over the entire school year. To enable scalability and generalizability, we used generic interaction features (e.g., viewing a video, taking a quiz), which do not require specialized sensors and are domain- and (to a certain extent) system-independent. We experimented with standard classifiers, recurrent neural networks, and genetically evolved neural networks for affect modeling. Prediction accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise) to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized to a different set of Geometry students (n = 28,458) on the same platform. We discuss implications for scaling up affect detection for affect-sensitive online learning environments which aim to improve engagement and learning by detecting and responding to student affect."
pn1963,https://doi.org/10.1145/3290605.3300726,Time to Scale: Generalizable Affect Detection for Tens of Thousands of Students across An Entire School Year,3,Sidney D'mello,University of Colorado Boulder,Boulder,United States,false,false,"We developed generalizable affect detectors using 133,966 instances of 18 affective states collected from 69,174 students who interacted with an online math learning platform called Algebra Nation over the entire school year. To enable scalability and generalizability, we used generic interaction features (e.g., viewing a video, taking a quiz), which do not require specialized sensors and are domain- and (to a certain extent) system-independent. We experimented with standard classifiers, recurrent neural networks, and genetically evolved neural networks for affect modeling. Prediction accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise) to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized to a different set of Geometry students (n = 28,458) on the same platform. We discuss implications for scaling up affect detection for affect-sensitive online learning environments which aim to improve engagement and learning by detecting and responding to student affect."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",1,Sinem Aslan,Intel Corporation,Hillsboro,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",2,Nese Alyuz,Intel Corporation,Hillsboro,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",3,Cagri Tanriover,Intel Corporation,Hillsboro,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",4,Sinem Mete,Bahcesehir University,Istanbul,Turkey,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",5,Eda Okur,Intel Corporation,Hillsboro,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",6,Sidney D'mello,University of Colorado Boulder,Boulder,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn3257,https://doi.org/10.1145/3290605.3300534,"Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",7,Asli Arslan Esme,Intel Corporation,Hillsboro,United States,false,false,"We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",1,Aditi Mallavarapu,University of Illinois at Chicago,Chicago,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",2,Leilah Lyons,New York Hall of Science,Corona,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",3,Stephen Uzzo,New York Hall of Science,Corona,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",4,Wren Thompson,New York Hall of Science,Corona,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",5,Rinat Levy-Cohen,Fordham University,New York,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn5928,https://doi.org/10.1145/3290605.3300237,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Exhibit",6,Brian Slattery,University of Illinois at Chicago,Chicago,United States,false,false,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,1,Dominic Difranzo,Cornell University,Ithaca,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,2,Yoon Hyung Choi,Cornell University,Ithaca,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,3,Amanda Purington,Cornell University,Ithaca,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,4,Jessie Taft,Cornell Tech,New York,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,5,Janis Whitlock,Cornell University,Ithaca,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn1337,https://doi.org/10.1145/3290605.3300533,Social Media TestDrive: Real-World Social Media Education for the Next Generation,6,Natalya Bazarova,Cornell University,Ithaca,United States,false,false,"Social media sites are where life happens for many of today's young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology."
pn3155,https://doi.org/10.1145/3290605.3300489,Influencers in Multiplayer Online Shooters: Evidence of Social Contagion in Playtime and Social Play,1,Alessandro Canossa,Ubisoft Massive Entertainment,Malmo,Sweden,true,false,"In a wide range of social networks, people's behavior is influenced by social contagion: we do what our network does. Networks often feature particularly influential individuals, commonly called ""influencers."" Existing work suggests that in-game social networks in online games are similar to real-life social networks in many respects. However, we do not know whether there are in-game equivalents to influencers. We therefore applied standard social network features used to identify influencers to the online multiplayer shooter Tom Clancy's The Division. Results show that network feature-defined influencers had indeed an outsized impact on playtime and social play of players joining their in-game network."
pn3155,https://doi.org/10.1145/3290605.3300489,Influencers in Multiplayer Online Shooters: Evidence of Social Contagion in Playtime and Social Play,2,Ahmad Azadvar,Ubisoft Massive Entertainment,Malmo,Sweden,true,false,"In a wide range of social networks, people's behavior is influenced by social contagion: we do what our network does. Networks often feature particularly influential individuals, commonly called ""influencers."" Existing work suggests that in-game social networks in online games are similar to real-life social networks in many respects. However, we do not know whether there are in-game equivalents to influencers. We therefore applied standard social network features used to identify influencers to the online multiplayer shooter Tom Clancy's The Division. Results show that network feature-defined influencers had indeed an outsized impact on playtime and social play of players joining their in-game network."
pn3155,https://doi.org/10.1145/3290605.3300489,Influencers in Multiplayer Online Shooters: Evidence of Social Contagion in Playtime and Social Play,3,Casper Harteveld,Northeastern University,Boston,United States,true,false,"In a wide range of social networks, people's behavior is influenced by social contagion: we do what our network does. Networks often feature particularly influential individuals, commonly called ""influencers."" Existing work suggests that in-game social networks in online games are similar to real-life social networks in many respects. However, we do not know whether there are in-game equivalents to influencers. We therefore applied standard social network features used to identify influencers to the online multiplayer shooter Tom Clancy's The Division. Results show that network feature-defined influencers had indeed an outsized impact on playtime and social play of players joining their in-game network."
pn3155,https://doi.org/10.1145/3290605.3300489,Influencers in Multiplayer Online Shooters: Evidence of Social Contagion in Playtime and Social Play,4,Anders Drachen,University of York,York,United Kingdom,true,false,"In a wide range of social networks, people's behavior is influenced by social contagion: we do what our network does. Networks often feature particularly influential individuals, commonly called ""influencers."" Existing work suggests that in-game social networks in online games are similar to real-life social networks in many respects. However, we do not know whether there are in-game equivalents to influencers. We therefore applied standard social network features used to identify influencers to the online multiplayer shooter Tom Clancy's The Division. Results show that network feature-defined influencers had indeed an outsized impact on playtime and social play of players joining their in-game network."
pn3155,https://doi.org/10.1145/3290605.3300489,Influencers in Multiplayer Online Shooters: Evidence of Social Contagion in Playtime and Social Play,5,Sebastian Deterding,University of York,York,United Kingdom,true,false,"In a wide range of social networks, people's behavior is influenced by social contagion: we do what our network does. Networks often feature particularly influential individuals, commonly called ""influencers."" Existing work suggests that in-game social networks in online games are similar to real-life social networks in many respects. However, we do not know whether there are in-game equivalents to influencers. We therefore applied standard social network features used to identify influencers to the online multiplayer shooter Tom Clancy's The Division. Results show that network feature-defined influencers had indeed an outsized impact on playtime and social play of players joining their in-game network."
pn6671,https://doi.org/10.1145/3290605.3300239,To Asymmetry and Beyond!: Improving Social Connectedness by Increasing Designed Interdependence in Cooperative Play,1,John Harris,University of Waterloo,Waterloo,Canada,true,false,"Social play can have numerous health benefits but research has shown that not all multiplayer games are effective at promoting social engagement. Asymmetric cooperative games have shown promise in this regard but the design and dynamics of this unique style of play is not yet well understood. To address this, we present the results of two player experience studies using our custom prototype game Beam Me 'Round, Scotty! 2: the first comparing symmetric cooperative play (e.g., where players have the same interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players have differing roles, abilities, interfaces, etc.) and the second comparing the effect of increasing degrees of interdependence between play partners. Our results not only indicate that asymmetric cooperative games may enhance players' perceptions of connectedness, social engagement, immersion, and comfort with a game's controls, but also demonstrate how to further improve these outcomes via deliberate mechanical design changes, such as changes in cooperative action timing and direction of dependence."
pn6671,https://doi.org/10.1145/3290605.3300239,To Asymmetry and Beyond!: Improving Social Connectedness by Increasing Designed Interdependence in Cooperative Play,2,Mark Hancock,University of Waterloo,Waterloo,Canada,true,false,"Social play can have numerous health benefits but research has shown that not all multiplayer games are effective at promoting social engagement. Asymmetric cooperative games have shown promise in this regard but the design and dynamics of this unique style of play is not yet well understood. To address this, we present the results of two player experience studies using our custom prototype game Beam Me 'Round, Scotty! 2: the first comparing symmetric cooperative play (e.g., where players have the same interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players have differing roles, abilities, interfaces, etc.) and the second comparing the effect of increasing degrees of interdependence between play partners. Our results not only indicate that asymmetric cooperative games may enhance players' perceptions of connectedness, social engagement, immersion, and comfort with a game's controls, but also demonstrate how to further improve these outcomes via deliberate mechanical design changes, such as changes in cooperative action timing and direction of dependence."
pn4898,https://doi.org/10.1145/3290605.3300623,Frame Analysis of Voice Interaction Gameplay,1,Fraser Allison,The University of Melbourne,Parkville,Australia,false,false,"Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games."
pn4898,https://doi.org/10.1145/3290605.3300623,Frame Analysis of Voice Interaction Gameplay,2,Joshua Newn,The University of Melbourne,Parkville,Australia,false,false,"Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games."
pn4898,https://doi.org/10.1145/3290605.3300623,Frame Analysis of Voice Interaction Gameplay,3,Wally Smith,The University of Melbourne,Melbourne,Australia,false,false,"Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games."
pn4898,https://doi.org/10.1145/3290605.3300623,Frame Analysis of Voice Interaction Gameplay,4,Marcus Carter,The University of Sydney,Sydney,Australia,false,false,"Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games."
pn4898,https://doi.org/10.1145/3290605.3300623,Frame Analysis of Voice Interaction Gameplay,5,Martin Gibbs,The University of Melbourne,Melbourne,Australia,false,false,"Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games."
pn7646,https://doi.org/10.1145/3290605.3300263,Designing 'True Colors': A Social Wearable that Affords Vulnerability,1,Ella Dagan,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play."
pn7646,https://doi.org/10.1145/3290605.3300263,Designing 'True Colors': A Social Wearable that Affords Vulnerability,2,Elena Márquez Segura,Uppsala University,Uppsala,Sweden,false,false,"Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play."
pn7646,https://doi.org/10.1145/3290605.3300263,Designing 'True Colors': A Social Wearable that Affords Vulnerability,3,Ferran Altarriba Bertran,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play."
pn7646,https://doi.org/10.1145/3290605.3300263,Designing 'True Colors': A Social Wearable that Affords Vulnerability,4,Miguel Flores,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play."
pn7646,https://doi.org/10.1145/3290605.3300263,Designing 'True Colors': A Social Wearable that Affords Vulnerability,5,Katherine Isbister,"University of California, Santa Cruz",Santa Cruz,United States,false,false,"Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,1,Kevin Doherty,Trinity College Dublin,Dublin,Ireland,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,2,José Marcano-Belisario,Imperial College London,London,United Kingdom,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,3,Martin Cohn,Imperial College London,London,United Kingdom,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,4,Nikolaos Mastellos,Imperial College London,London,United Kingdom,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,5,Cecily Morrison,Microsoft Research Cambridge,Cambridge,United Kingdom,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,6,Josip Car,Imperial College London,London,United Kingdom,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn5584,https://doi.org/10.1145/3290605.3300416,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,7,Gavin Doherty,Trinity College Dublin,Dublin,Ireland,false,true,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,1,Sindhu Kiranmai Ernala,Georgia Institute of Technology,Atlanta,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,2,Michael Birnbaum,Zucker Hillside Hospital,Glen Oaks,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,3,Kristin Candan,Zucker Hillside Hospital,Glen Oaks,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,4,Asra Rizvi,Zucker Hillside Hospital,Glen Oaks,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,5,William Sterling,Zucker Hillside Hospital,Glen Oaks,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,6,John Kane,Zucker Hillside Hospital,Glen Oaks,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn6609,https://doi.org/10.1145/3290605.3300364,Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,7,Munmun De Choudhury,Georgia Institute of Technology,Atlanta,United States,false,false,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as ""proxy diagnostic signals"" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelinesfor future research."
pn3129,https://doi.org/10.1145/3290605.3300655,Student Perspectives on Digital Phenotyping: The Acceptability of Using Smartphone Data to Assess Mental Health,1,John Rooksby,Northumbria University,Newcastle,United Kingdom,true,false,"There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students' smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed."
pn3129,https://doi.org/10.1145/3290605.3300655,Student Perspectives on Digital Phenotyping: The Acceptability of Using Smartphone Data to Assess Mental Health,2,Alistair Morrison,Universtity of Glasgow,Glasgow,United Kingdom,true,false,"There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students' smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed."
pn3129,https://doi.org/10.1145/3290605.3300655,Student Perspectives on Digital Phenotyping: The Acceptability of Using Smartphone Data to Assess Mental Health,3,Dave Murray-Rust,Edinburgh University,Edinburgh,United Kingdom,true,false,"There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students' smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,1,Giorgio Roffo,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,2,Dong-Bach Vo,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,3,Mohammad Tayarani,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,4,Maki Rooksby,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,5,Alessandra Sorrentino,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,6,Simona Di Folco,Edinburgh University,Edinburgh,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,7,Helen Minnis,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,8,Stephen Brewster,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn5186,https://doi.org/10.1145/3290605.3300825,Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children,9,Alessandro Vinciarelli,University of Glasgow,Glasgow,United Kingdom,false,false,"This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health."
pn6206,https://doi.org/10.1145/3290605.3300526,Metaphoria: An Algorithmic Companion for Metaphor Creation,1,Katy Gero,Columbia University,New York,United States,false,false,"Creative writing, from poetry to journalism, is at the crux of human ingenuity and social interaction. Existing creative writing support tools produce entire passages or fully formed sentences, but these approaches fail to adapt to the writer's own ideas and intentions. Instead we posit to build tools that generate ideas coherent with the writer's context and encourage writers to produce divergent outcomes. To explore this, we focus on supporting metaphor creation. We present Metaphoria, an interactive system that generates metaphorical connections based on an input word from the writer. Our studies show that Metaphoria provides more coherent suggestions than existing systems, and supports the expression of writers' unique intentions. We discuss the complex issue of ownership in human-machine collaboration and how to build adaptive creativity support tools in other domains."
pn6206,https://doi.org/10.1145/3290605.3300526,Metaphoria: An Algorithmic Companion for Metaphor Creation,2,Lydia Chilton,Columbia University,New York,United States,false,false,"Creative writing, from poetry to journalism, is at the crux of human ingenuity and social interaction. Existing creative writing support tools produce entire passages or fully formed sentences, but these approaches fail to adapt to the writer's own ideas and intentions. Instead we posit to build tools that generate ideas coherent with the writer's context and encourage writers to produce divergent outcomes. To explore this, we focus on supporting metaphor creation. We present Metaphoria, an interactive system that generates metaphorical connections based on an input word from the writer. Our studies show that Metaphoria provides more coherent suggestions than existing systems, and supports the expression of writers' unique intentions. We discuss the complex issue of ownership in human-machine collaboration and how to build adaptive creativity support tools in other domains."
pn7921,https://doi.org/10.1145/3290605.3300619,Mapping the Landscape of Creativity Support Tools in HCI,1,Jonas Frich,Aarhus University,Aarhus,Denmark,false,false,"Creativity Support Tools (CSTs) play a fundamental role in the study of creativity in Human-Computer Interaction (HCI). Even so, there is no consensus definition of the term 'CST' in HCI, and in most studies, CSTs have been construed as one-off exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study's implications for future HCI research on CSTs and digital creativity."
pn7921,https://doi.org/10.1145/3290605.3300619,Mapping the Landscape of Creativity Support Tools in HCI,2,Lindsay Macdonald Vermeulen,Aarhus University,Aarhus,Denmark,false,false,"Creativity Support Tools (CSTs) play a fundamental role in the study of creativity in Human-Computer Interaction (HCI). Even so, there is no consensus definition of the term 'CST' in HCI, and in most studies, CSTs have been construed as one-off exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study's implications for future HCI research on CSTs and digital creativity."
pn7921,https://doi.org/10.1145/3290605.3300619,Mapping the Landscape of Creativity Support Tools in HCI,3,Christian Remy,Aarhus University,Aarhus,Denmark,false,false,"Creativity Support Tools (CSTs) play a fundamental role in the study of creativity in Human-Computer Interaction (HCI). Even so, there is no consensus definition of the term 'CST' in HCI, and in most studies, CSTs have been construed as one-off exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study's implications for future HCI research on CSTs and digital creativity."
pn7921,https://doi.org/10.1145/3290605.3300619,Mapping the Landscape of Creativity Support Tools in HCI,4,Michael Biskjaer,Aarhus University,Aarhus,Denmark,false,false,"Creativity Support Tools (CSTs) play a fundamental role in the study of creativity in Human-Computer Interaction (HCI). Even so, there is no consensus definition of the term 'CST' in HCI, and in most studies, CSTs have been construed as one-off exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study's implications for future HCI research on CSTs and digital creativity."
pn7921,https://doi.org/10.1145/3290605.3300619,Mapping the Landscape of Creativity Support Tools in HCI,5,Peter Dalsgaard,Aarhus University,Aarhus,Denmark,false,false,"Creativity Support Tools (CSTs) play a fundamental role in the study of creativity in Human-Computer Interaction (HCI). Even so, there is no consensus definition of the term 'CST' in HCI, and in most studies, CSTs have been construed as one-off exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study's implications for future HCI research on CSTs and digital creativity."
pn6942,https://doi.org/10.1145/3290605.3300615,Empowering Expression for Users with Aphasia through Constrained Creativity,1,Timothy Neate,"City, University of London",London,United Kingdom,true,false,"Creative activities allow people to express themselves in rich, nuanced ways. However, being creative does not always come easily. For example, people with speech and language impairments, such as aphasia, face challenges in creative activities that involve language. In this paper, we explore the concept of constrained creativity as a way of addressing this challenge and enabling creative writing. We report an app, MakeWrite, that supports the constrained creation of digital texts through automated redaction. The app was co-designed with and for people with aphasia and was subsequently explored in a workshop with a group of people with aphasia. Participants were not only successful in crafting novel language, but, importantly, self-reported that the app was crucial in enabling them to do so. We refect on the potential of technology-supported constrained creativity as a means of empowering expression amongst users with diverse needs."
pn6942,https://doi.org/10.1145/3290605.3300615,Empowering Expression for Users with Aphasia through Constrained Creativity,2,Abi Roper,"City, University of London",London,United Kingdom,true,false,"Creative activities allow people to express themselves in rich, nuanced ways. However, being creative does not always come easily. For example, people with speech and language impairments, such as aphasia, face challenges in creative activities that involve language. In this paper, we explore the concept of constrained creativity as a way of addressing this challenge and enabling creative writing. We report an app, MakeWrite, that supports the constrained creation of digital texts through automated redaction. The app was co-designed with and for people with aphasia and was subsequently explored in a workshop with a group of people with aphasia. Participants were not only successful in crafting novel language, but, importantly, self-reported that the app was crucial in enabling them to do so. We refect on the potential of technology-supported constrained creativity as a means of empowering expression amongst users with diverse needs."
pn6942,https://doi.org/10.1145/3290605.3300615,Empowering Expression for Users with Aphasia through Constrained Creativity,3,Stephanie Wilson,"City, University of London",London,United Kingdom,true,false,"Creative activities allow people to express themselves in rich, nuanced ways. However, being creative does not always come easily. For example, people with speech and language impairments, such as aphasia, face challenges in creative activities that involve language. In this paper, we explore the concept of constrained creativity as a way of addressing this challenge and enabling creative writing. We report an app, MakeWrite, that supports the constrained creation of digital texts through automated redaction. The app was co-designed with and for people with aphasia and was subsequently explored in a workshop with a group of people with aphasia. Participants were not only successful in crafting novel language, but, importantly, self-reported that the app was crucial in enabling them to do so. We refect on the potential of technology-supported constrained creativity as a means of empowering expression amongst users with diverse needs."
pn6942,https://doi.org/10.1145/3290605.3300615,Empowering Expression for Users with Aphasia through Constrained Creativity,4,Jane Marshall,"City, University of London",London,United Kingdom,true,false,"Creative activities allow people to express themselves in rich, nuanced ways. However, being creative does not always come easily. For example, people with speech and language impairments, such as aphasia, face challenges in creative activities that involve language. In this paper, we explore the concept of constrained creativity as a way of addressing this challenge and enabling creative writing. We report an app, MakeWrite, that supports the constrained creation of digital texts through automated redaction. The app was co-designed with and for people with aphasia and was subsequently explored in a workshop with a group of people with aphasia. Participants were not only successful in crafting novel language, but, importantly, self-reported that the app was crucial in enabling them to do so. We refect on the potential of technology-supported constrained creativity as a means of empowering expression amongst users with diverse needs."
pn3952,https://doi.org/10.1145/3290605.3300312,A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact,1,Piyum Fernando,Arizona State University,Tempe,United States,false,false,"Dynamic elements of the drawing process (e.g., order of compilation, speed, length, and pressure of strokes) are considered important because they can reveal the technique, process, and emotions of the artist. To explore how sensing, visualizing, and sharing these aspects of the creative process might shape art making and art viewing experiences, we designed a research probe which unobtrusively tracks and visualizes the movement and pressure of the artist's pencil on an easel. Using our probe, we conducted studies with artists and art viewers, which reveal digital and physical representations of creative process as a means of reflecting on a multitude of factors about the finished artwork, including technique, style, and the emotions of the artists. We conclude by discussing future directions for HCI systems that sense and visualize aspects of the creative process in digitally-mediated arts, as well as the social considerations of sharing and curating intimate process information."
pn3952,https://doi.org/10.1145/3290605.3300312,A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact,2,Jennifer Weiler,Arizona State University,Tempe,United States,false,false,"Dynamic elements of the drawing process (e.g., order of compilation, speed, length, and pressure of strokes) are considered important because they can reveal the technique, process, and emotions of the artist. To explore how sensing, visualizing, and sharing these aspects of the creative process might shape art making and art viewing experiences, we designed a research probe which unobtrusively tracks and visualizes the movement and pressure of the artist's pencil on an easel. Using our probe, we conducted studies with artists and art viewers, which reveal digital and physical representations of creative process as a means of reflecting on a multitude of factors about the finished artwork, including technique, style, and the emotions of the artists. We conclude by discussing future directions for HCI systems that sense and visualize aspects of the creative process in digitally-mediated arts, as well as the social considerations of sharing and curating intimate process information."
pn3952,https://doi.org/10.1145/3290605.3300312,A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact,3,Stacey Kuznetsov,Arizona State University,Tempe,United States,false,false,"Dynamic elements of the drawing process (e.g., order of compilation, speed, length, and pressure of strokes) are considered important because they can reveal the technique, process, and emotions of the artist. To explore how sensing, visualizing, and sharing these aspects of the creative process might shape art making and art viewing experiences, we designed a research probe which unobtrusively tracks and visualizes the movement and pressure of the artist's pencil on an easel. Using our probe, we conducted studies with artists and art viewers, which reveal digital and physical representations of creative process as a means of reflecting on a multitude of factors about the finished artwork, including technique, style, and the emotions of the artists. We conclude by discussing future directions for HCI systems that sense and visualize aspects of the creative process in digitally-mediated arts, as well as the social considerations of sharing and curating intimate process information."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,1,Thomas Muender,University of Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,2,Anke Reinschluessel,University of Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,3,Sean Drewes,Universität Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,4,Dirk Wenig,University of Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,5,Tanja Döring,University of Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn6742,https://doi.org/10.1145/3290605.3300903,Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,6,Rainer Malaka,University of Bremen,Bremen,Germany,false,false,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions."
pn5617,https://doi.org/10.1145/3290605.3300479,Enhancing Texture Perception in Virtual Reality Using 3D-Printed Hair Structures,1,Donald Degraen,"Intel Visual Computing Institute (IVCI), Saarland Informatics Campus",Saarbrücken,Germany,true,false,"Experiencing materials in virtual reality (VR) is enhanced by combining visual and haptic feedback. While VR easily allows changes to visual appearances, modifying haptic impressions remains challenging. Existing passive haptic techniques require access to a large set of tangible proxies. To reduce the number of physical representations, we look towards fabrication to create more versatile counterparts. In a user study, 3D-printed hairs with length varying in steps of 2.5 mm were used to influence the feeling of roughness and hardness. By overlaying fabricated hair with visual textures, the resolution of the user's haptic perception increased. As changing haptic sensations are able to elicit perceptual switches, our approach can extend a limited set of textures to a much broader set of material impressions. Our results give insights into the effectiveness of 3D-printed hair for enhancing texture perception in VR."
pn5617,https://doi.org/10.1145/3290605.3300479,Enhancing Texture Perception in Virtual Reality Using 3D-Printed Hair Structures,2,André Zenner,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,true,false,"Experiencing materials in virtual reality (VR) is enhanced by combining visual and haptic feedback. While VR easily allows changes to visual appearances, modifying haptic impressions remains challenging. Existing passive haptic techniques require access to a large set of tangible proxies. To reduce the number of physical representations, we look towards fabrication to create more versatile counterparts. In a user study, 3D-printed hairs with length varying in steps of 2.5 mm were used to influence the feeling of roughness and hardness. By overlaying fabricated hair with visual textures, the resolution of the user's haptic perception increased. As changing haptic sensations are able to elicit perceptual switches, our approach can extend a limited set of textures to a much broader set of material impressions. Our results give insights into the effectiveness of 3D-printed hair for enhancing texture perception in VR."
pn5617,https://doi.org/10.1145/3290605.3300479,Enhancing Texture Perception in Virtual Reality Using 3D-Printed Hair Structures,3,Antonio Krüger,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,true,false,"Experiencing materials in virtual reality (VR) is enhanced by combining visual and haptic feedback. While VR easily allows changes to visual appearances, modifying haptic impressions remains challenging. Existing passive haptic techniques require access to a large set of tangible proxies. To reduce the number of physical representations, we look towards fabrication to create more versatile counterparts. In a user study, 3D-printed hairs with length varying in steps of 2.5 mm were used to influence the feeling of roughness and hardness. By overlaying fabricated hair with visual textures, the resolution of the user's haptic perception increased. As changing haptic sensations are able to elicit perceptual switches, our approach can extend a limited set of textures to a much broader set of material impressions. Our results give insights into the effectiveness of 3D-printed hair for enhancing texture perception in VR."
pn5107,https://doi.org/10.1145/3290605.3300921,Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality,1,Lev Poretski,University of Haifa,Haifa,Israel,false,false,"As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer–whether physical or virtual–dominates the development of relatedness and ownership feelings, highlighting the importance of the ""real"" physical layer in shaping users' perceptions."
pn5107,https://doi.org/10.1145/3290605.3300921,Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality,2,Ofer Arazy,University of Haifa,Haifa,Israel,false,false,"As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer–whether physical or virtual–dominates the development of relatedness and ownership feelings, highlighting the importance of the ""real"" physical layer in shaping users' perceptions."
pn5107,https://doi.org/10.1145/3290605.3300921,Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality,3,Joel Lanir,University of Haifa,Haifa,Israel,false,false,"As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer–whether physical or virtual–dominates the development of relatedness and ownership feelings, highlighting the importance of the ""real"" physical layer in shaping users' perceptions."
pn5107,https://doi.org/10.1145/3290605.3300921,Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality,4,Shalev Shachar,The University of Haifa,Haifa Israel,Israel,false,false,"As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer–whether physical or virtual–dominates the development of relatedness and ownership feelings, highlighting the importance of the ""real"" physical layer in shaping users' perceptions."
pn5107,https://doi.org/10.1145/3290605.3300921,Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality,5,Oded Nov,New York University,New York,United States,false,false,"As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer–whether physical or virtual–dominates the development of relatedness and ownership feelings, highlighting the importance of the ""real"" physical layer in shaping users' perceptions."
pn4148,https://doi.org/10.1145/3290605.3300613,Barriers to End-User Designers of Augmented Fabrication,1,Chandan Mahapatra,Rochester Institute of Technology,Rochester,United States,false,false,"Augmented fabrication is the practice of designing and fabricating an artifact to work with existing objects. Although common both in the wild and as an area for research tools, little is known about how novices approach the task of designing under the constraints of interfacing with real-world objects. In this paper, we report the results of a study of fifteen novice end users in an augmented fabrication design task. We discuss obstacles encountered in four contexts: capturing information about physical objects, transferring information to 3D~modeling software, digitally modeling a new object, and evaluating whether the new object will work when fabricated. Based on our findings, we suggest how future tools can better support augmented fabrication in each of these contexts."
pn4148,https://doi.org/10.1145/3290605.3300613,Barriers to End-User Designers of Augmented Fabrication,2,Jonas Jensen,University of Copenhagen,Copenhagen,Denmark,false,false,"Augmented fabrication is the practice of designing and fabricating an artifact to work with existing objects. Although common both in the wild and as an area for research tools, little is known about how novices approach the task of designing under the constraints of interfacing with real-world objects. In this paper, we report the results of a study of fifteen novice end users in an augmented fabrication design task. We discuss obstacles encountered in four contexts: capturing information about physical objects, transferring information to 3D~modeling software, digitally modeling a new object, and evaluating whether the new object will work when fabricated. Based on our findings, we suggest how future tools can better support augmented fabrication in each of these contexts."
pn4148,https://doi.org/10.1145/3290605.3300613,Barriers to End-User Designers of Augmented Fabrication,3,Mick Mcquaid,Rochester Institute of Technology,Rochester,United States,false,false,"Augmented fabrication is the practice of designing and fabricating an artifact to work with existing objects. Although common both in the wild and as an area for research tools, little is known about how novices approach the task of designing under the constraints of interfacing with real-world objects. In this paper, we report the results of a study of fifteen novice end users in an augmented fabrication design task. We discuss obstacles encountered in four contexts: capturing information about physical objects, transferring information to 3D~modeling software, digitally modeling a new object, and evaluating whether the new object will work when fabricated. Based on our findings, we suggest how future tools can better support augmented fabrication in each of these contexts."
pn4148,https://doi.org/10.1145/3290605.3300613,Barriers to End-User Designers of Augmented Fabrication,4,Daniel Ashbrook,University of Copenhagen,Rochester,Denmark,false,false,"Augmented fabrication is the practice of designing and fabricating an artifact to work with existing objects. Although common both in the wild and as an area for research tools, little is known about how novices approach the task of designing under the constraints of interfacing with real-world objects. In this paper, we report the results of a study of fifteen novice end users in an augmented fabrication design task. We discuss obstacles encountered in four contexts: capturing information about physical objects, transferring information to 3D~modeling software, digitally modeling a new object, and evaluating whether the new object will work when fabricated. Based on our findings, we suggest how future tools can better support augmented fabrication in each of these contexts."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",1,Chris Bevan,University of Bristol,Bristol,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",2,David Green,University of the West of England,Bristol,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",3,Harry Farmer,University of Bath,Bath,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",4,Mandy Rose,University of the West of England,Bristol,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",5,Kirsten Cater,University of Bristol,Bristol,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",6,Danaë Stanton Fraser,University of Bath,Bath,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn9262,https://doi.org/10.1145/3290605.3300736,"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences",7,Helen Brown,University of Bath,Bath,United Kingdom,true,false,"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area."
pn4341,https://doi.org/10.1145/3290605.3300426,Experimental Analysis of Barehand Mid-air Mode-Switching Techniques in Virtual Reality,1,Hemant Bhaskar Surale,University of Waterloo,Waterloo,Canada,true,false,"We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard ""subtraction method"" protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR."
pn4341,https://doi.org/10.1145/3290605.3300426,Experimental Analysis of Barehand Mid-air Mode-Switching Techniques in Virtual Reality,2,Fabrice Matulic,Preferred Networks Inc.,Tokyo,Japan,true,false,"We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard ""subtraction method"" protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR."
pn4341,https://doi.org/10.1145/3290605.3300426,Experimental Analysis of Barehand Mid-air Mode-Switching Techniques in Virtual Reality,3,Daniel Vogel,University of Waterloo,Waterloo,Canada,true,false,"We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard ""subtraction method"" protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR."
pn2285,https://doi.org/10.1145/3290605.3300767,What is Mixed Reality?,1,Maximilian Speicher,University of Michigan,Ann Arbor,United States,true,false,"What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape."
pn2285,https://doi.org/10.1145/3290605.3300767,What is Mixed Reality?,2,Brian Hall,University of Michigan,Ann Arbor,United States,true,false,"What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape."
pn2285,https://doi.org/10.1145/3290605.3300767,What is Mixed Reality?,3,Michael Nebeling,University of Michigan,Ann Arbor,United States,true,false,"What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape."
pn3292,https://doi.org/10.1145/3290605.3300580,Engaging Lived and Virtual Realities,1,Aditya Vishwanath,Stanford University,Stanford,United States,false,false,"We examined the integration of VR into informal and less-structured learning environments in Atlanta (USA) and Mumbai (India) through a process of co-design, co-creation, and co-learning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments."
pn3292,https://doi.org/10.1145/3290605.3300580,Engaging Lived and Virtual Realities,2,Naveena Karusala,University of Washington,Seattle,United States,false,false,"We examined the integration of VR into informal and less-structured learning environments in Atlanta (USA) and Mumbai (India) through a process of co-design, co-creation, and co-learning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments."
pn3292,https://doi.org/10.1145/3290605.3300580,Engaging Lived and Virtual Realities,3,Marisol Wong-Villacres,Georgia Institute of Technology,Atlanta,United States,false,false,"We examined the integration of VR into informal and less-structured learning environments in Atlanta (USA) and Mumbai (India) through a process of co-design, co-creation, and co-learning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments."
pn3292,https://doi.org/10.1145/3290605.3300580,Engaging Lived and Virtual Realities,4,Neha Kumar,Georgia Institute of Technology,Atlanta,United States,false,false,"We examined the integration of VR into informal and less-structured learning environments in Atlanta (USA) and Mumbai (India) through a process of co-design, co-creation, and co-learning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",1,Michael Muller,IBM Research,Cambridge,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",2,Ingrid Lange,IBM Research,Cambridge,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",3,Dakuo Wang,IBM Research,Yorktown Heights,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",4,David Piorkowski,IBM Research,Yorktown Heights,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",5,Jason Tsay,IBM Research,Yorktown Heights,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",6,Q. Liao,IBM Research,Yorktown Heights,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",7,Casey Dugan,IBM Research,Cambridge,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn4706,https://doi.org/10.1145/3290605.3300356,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation",8,Thomas Erickson,Unaffiliated,Minneapolis,United States,false,false,"With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices."
pn2193,https://doi.org/10.1145/3290605.3300685,Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics,1,Sebastian Feger,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science's most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices."
pn2193,https://doi.org/10.1145/3290605.3300685,Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics,2,Sünje Dallmeier-Tiessen,CERN,Geneva,Switzerland,false,false,"Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science's most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices."
pn2193,https://doi.org/10.1145/3290605.3300685,Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics,3,Albrecht Schmidt,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science's most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices."
pn2193,https://doi.org/10.1145/3290605.3300685,Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics,4,Paweł Woźniak,Utrecht University,Utrecht,Netherlands,false,false,"Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science's most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices."
pn4094,https://doi.org/10.1145/3290605.3300874,An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts,1,Nadia Boukhelifa,"UMR GMPA, AgroParisTech, INRA, Univ. Paris-Saclay",Versailles-Grignon,France,false,false,"Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems."
pn4094,https://doi.org/10.1145/3290605.3300874,An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts,2,Anastasia Bezerianos,Univ. Paris-Sud,Paris,France,false,false,"Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems."
pn4094,https://doi.org/10.1145/3290605.3300874,An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts,3,Ioan Cristian Trelea,"UMR GMPA, AgroParisTech, INRA, Univ. Paris-Saclay",Versailles-Grignon,France,false,false,"Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems."
pn4094,https://doi.org/10.1145/3290605.3300874,An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts,4,Nathalie Méjean Perrot,"UMR GMPA, AgroParisTech, INRA, Univ. Paris-Saclay",Versailles-Grignon,France,false,false,"Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems."
pn4094,https://doi.org/10.1145/3290605.3300874,An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts,5,Evelyne Lutton,"UMR GMPA, AgroParisTech, INRA, Univ. Paris-Saclay",Versailles-Grignon,France,false,false,"Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,1,Shunan Guo,East China Normal University,Shanghai,China,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,2,Fan Du,Adobe Research,San Jose,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,3,Sana Malik,Adobe Research,San Jose,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,4,Eunyee Koh,Adobe Research,San Jose,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,5,Sungchul Kim,Adobe Research,San Jose,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,6,Zhicheng Liu,Adobe Research,Seattle,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,7,Donghyun Kim,Adobe Research,San Jose,United States,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,8,Hongyuan Zha,East China Normal University,Shanghai,China,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn8453,https://doi.org/10.1145/3290605.3300803,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,9,Nan Cao,Tongji University,Shanghai,China,false,false,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions."
pn3628,https://doi.org/10.1145/3290605.3300798,Tool Extension in Human–Computer Interaction,1,Joanna Bergström,University of Copenhagen,Copenhagen,Denmark,false,false,"Tool use extends people's representations of the immediately actionable space around them. Physical tools thereby become integrated in people's body schemas. We introduce a measure for tool extension in HCI by using a visual-tactile interference paradigm. In this paradigm, an index of tool extension is given by response time differences between crossmodally congruent and incongruent stimuli; tactile on the hand and visual on the tool. We use this measure to examine if and how findings on tool extension apply to interaction with computer-based tools. Our first experiment shows that touchpad and mouse both provide tool extension over a baseline condition without a tool. A second experiment shows a higher degree of tool extension for a realistic avatar hand compared to an abstract pointer for interaction in virtual reality. In sum, our measure can detect tool extension with computer-based tools and differentiate interfaces by their degree of extension."
pn3628,https://doi.org/10.1145/3290605.3300798,Tool Extension in Human–Computer Interaction,2,Aske Mottelson,University of Copenhagen,Copenhagen,Denmark,false,false,"Tool use extends people's representations of the immediately actionable space around them. Physical tools thereby become integrated in people's body schemas. We introduce a measure for tool extension in HCI by using a visual-tactile interference paradigm. In this paradigm, an index of tool extension is given by response time differences between crossmodally congruent and incongruent stimuli; tactile on the hand and visual on the tool. We use this measure to examine if and how findings on tool extension apply to interaction with computer-based tools. Our first experiment shows that touchpad and mouse both provide tool extension over a baseline condition without a tool. A second experiment shows a higher degree of tool extension for a realistic avatar hand compared to an abstract pointer for interaction in virtual reality. In sum, our measure can detect tool extension with computer-based tools and differentiate interfaces by their degree of extension."
pn3628,https://doi.org/10.1145/3290605.3300798,Tool Extension in Human–Computer Interaction,3,Andreea Muresan,University of Copenhagen,Copenhagen,Denmark,false,false,"Tool use extends people's representations of the immediately actionable space around them. Physical tools thereby become integrated in people's body schemas. We introduce a measure for tool extension in HCI by using a visual-tactile interference paradigm. In this paradigm, an index of tool extension is given by response time differences between crossmodally congruent and incongruent stimuli; tactile on the hand and visual on the tool. We use this measure to examine if and how findings on tool extension apply to interaction with computer-based tools. Our first experiment shows that touchpad and mouse both provide tool extension over a baseline condition without a tool. A second experiment shows a higher degree of tool extension for a realistic avatar hand compared to an abstract pointer for interaction in virtual reality. In sum, our measure can detect tool extension with computer-based tools and differentiate interfaces by their degree of extension."
pn3628,https://doi.org/10.1145/3290605.3300798,Tool Extension in Human–Computer Interaction,4,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,false,false,"Tool use extends people's representations of the immediately actionable space around them. Physical tools thereby become integrated in people's body schemas. We introduce a measure for tool extension in HCI by using a visual-tactile interference paradigm. In this paradigm, an index of tool extension is given by response time differences between crossmodally congruent and incongruent stimuli; tactile on the hand and visual on the tool. We use this measure to examine if and how findings on tool extension apply to interaction with computer-based tools. Our first experiment shows that touchpad and mouse both provide tool extension over a baseline condition without a tool. A second experiment shows a higher degree of tool extension for a realistic avatar hand compared to an abstract pointer for interaction in virtual reality. In sum, our measure can detect tool extension with computer-based tools and differentiate interfaces by their degree of extension."
pn1856,https://doi.org/10.1145/3290605.3300327,Ways of Knowing When Research Subjects Care,1,Dorothy Howard,"University of California, San Diego",La Jolla,United States,true,false,"This paper investigates a hidden dimension of research with real world stakes: research subjects who care -- sometimes deeply -- about the topic of the research in which they participate. They manifest this care, we show, by managing how they are represented in the research process, by exercising politics in shaping knowledge production, and sometimes in experiencing trauma in the process. We draw first-hand reflections on participation in diversity research on Wikipedia, transforming participants from objects of study to active negotiators of research process. We depict how care, vulnerability, harm, and emotions shape ethnographic and qualitative data. We argue that, especially in reflexive cultures, research subjects are active agents with agendas, accountabilities, and political projects of their own. We propose ethics of care and collaboration to open up new possibilities for knowledge production and socio-technical intervention in HCI."
pn1856,https://doi.org/10.1145/3290605.3300327,Ways of Knowing When Research Subjects Care,2,Lilly Irani,"University of California, San Diego",La Jolla,United States,true,false,"This paper investigates a hidden dimension of research with real world stakes: research subjects who care -- sometimes deeply -- about the topic of the research in which they participate. They manifest this care, we show, by managing how they are represented in the research process, by exercising politics in shaping knowledge production, and sometimes in experiencing trauma in the process. We draw first-hand reflections on participation in diversity research on Wikipedia, transforming participants from objects of study to active negotiators of research process. We depict how care, vulnerability, harm, and emotions shape ethnographic and qualitative data. We argue that, especially in reflexive cultures, research subjects are active agents with agendas, accountabilities, and political projects of their own. We propose ethics of care and collaboration to open up new possibilities for knowledge production and socio-technical intervention in HCI."
pn4644,https://doi.org/10.1145/3290605.3300647,"Explicating ""Implicit Interaction"": An Examination of the Concept and Challenges for Research",1,Barış Serim,University of Helsinki,Helsinki,Finland,false,false,"The term implicit interaction is often used to denote interactions that differ from traditional purposeful and attention demanding ways of interacting with computers. However, there is a lack of agreement about the term's precise meaning. This paper develops implicit interaction further as an analytic concept and identifies the methodological challenges related to HCI's particular design orientation. We first review meanings of implicit as unintentional, attentional background, unawareness, unconsciousness and implicature, and compare them in regards to the entity they qualify, the design motivation they emphasize and their constructive validity for what makes good interaction. We then demonstrate how the methodological challenges can be addressed with greater precision by using an updated, intentionality-based definition that specifies an input–effect relationship as the entity of implicit. We conclude by identifying a number of new considerations for design and evaluation, and by reflecting on the concepts of user and system agency in HCI."
pn4644,https://doi.org/10.1145/3290605.3300647,"Explicating ""Implicit Interaction"": An Examination of the Concept and Challenges for Research",2,Giulio Jacucci,University of Helsinki,Helsinki,Finland,false,false,"The term implicit interaction is often used to denote interactions that differ from traditional purposeful and attention demanding ways of interacting with computers. However, there is a lack of agreement about the term's precise meaning. This paper develops implicit interaction further as an analytic concept and identifies the methodological challenges related to HCI's particular design orientation. We first review meanings of implicit as unintentional, attentional background, unawareness, unconsciousness and implicature, and compare them in regards to the entity they qualify, the design motivation they emphasize and their constructive validity for what makes good interaction. We then demonstrate how the methodological challenges can be addressed with greater precision by using an updated, intentionality-based definition that specifies an input–effect relationship as the entity of implicit. We conclude by identifying a number of new considerations for design and evaluation, and by reflecting on the concepts of user and system agency in HCI."
pn1452,https://doi.org/10.1145/3290605.3300565,Personas and Identity: Looking at Multiple Identities to Inform the Construction of Personas,1,Nicola Marsden,Heilbronn University,Heilbronn,Germany,false,false,"Personas are valuable tools to help designers get to know their users and adopt their perspectives. Yet people are complex and multiple identities have to be considered in their interplay to account for a comprehensive representation – otherwise, personas might be superficial and prone to activate stereotypes. Therefore, the way users' identities are presented in a limited set of personas is crucial to account for diversity and highlight facets which otherwise would go unnoticed. In this paper, we introduce an approach to the development of personas informed by social identity theory. The effectiveness of this approach is investigated in a qualitative study in the context of the design process for an e-learning platform for women in tech. The results suggest that considering multiple identities in the construction of personas adds value when designing technologies."
pn1452,https://doi.org/10.1145/3290605.3300565,Personas and Identity: Looking at Multiple Identities to Inform the Construction of Personas,2,Monika Pröbster,Heilbronn University,Heilbronn,Germany,false,false,"Personas are valuable tools to help designers get to know their users and adopt their perspectives. Yet people are complex and multiple identities have to be considered in their interplay to account for a comprehensive representation – otherwise, personas might be superficial and prone to activate stereotypes. Therefore, the way users' identities are presented in a limited set of personas is crucial to account for diversity and highlight facets which otherwise would go unnoticed. In this paper, we introduce an approach to the development of personas informed by social identity theory. The effectiveness of this approach is investigated in a qualitative study in the context of the design process for an e-learning platform for women in tech. The results suggest that considering multiple identities in the construction of personas adds value when designing technologies."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,1,Junichi Yamaoka,The University of Tokyo,Cambridge,United States,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,2,Mustafa Doga Dogan,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,3,Katarina Bulovic,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,4,Kazuya Saito,The University of Tokyo,Tokyo,Japan,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,5,Yoshihiro Kawahara,The University of Tokyo,Bunkyo-Ku,Japan,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,6,Yasuaki Kakehi,The University of Tokyo,Tokyo,Japan,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn8058,https://doi.org/10.1145/3290605.3300858,FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures,7,Stefanie Mueller,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements."
pn3232,https://doi.org/10.1145/3290605.3300929,LASEC: Instant Fabrication of Stretchable Circuits Using a Laser Cutter,1,Daniel Groeger,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper introduces LASEC, the first technique for instant do-it-yourself fabrication of circuits with custom stretchability on a conventional laser cutter and in a single pass. The approach is based on integrated cutting and ablation of a two-layer material using parametric design patterns. These patterns enable the designer to customize the desired stretchability of the circuit, to combine stretchable with non-stretchable areas, or to integrate areas of different stretchability. For adding circuits on such stretchable cut patterns, we contribute routing strategies and a real-time routing algorithm. An interactive design tool assists designers by automatically generating patterns and circuits from a high-level specification of the desired interface. The approach is compatible with off-the-shelf materials and can realize transparent interfaces. Several application examples demonstrate the versatility of the novel technique for applications in wearable computing, interactive textiles, and stretchable input devices."
pn3232,https://doi.org/10.1145/3290605.3300929,LASEC: Instant Fabrication of Stretchable Circuits Using a Laser Cutter,2,Jürgen Steimle,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper introduces LASEC, the first technique for instant do-it-yourself fabrication of circuits with custom stretchability on a conventional laser cutter and in a single pass. The approach is based on integrated cutting and ablation of a two-layer material using parametric design patterns. These patterns enable the designer to customize the desired stretchability of the circuit, to combine stretchable with non-stretchable areas, or to integrate areas of different stretchability. For adding circuits on such stretchable cut patterns, we contribute routing strategies and a real-time routing algorithm. An interactive design tool assists designers by automatically generating patterns and circuits from a high-level specification of the desired interface. The approach is compatible with off-the-shelf materials and can realize transparent interfaces. Several application examples demonstrate the versatility of the novel technique for applications in wearable computing, interactive textiles, and stretchable input devices."
pn4864,https://doi.org/10.1145/3290605.3300797,"FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects",1,Saiganesh Swaminathan,Carnegie Mellon University,Pittsburgh,United States,false,false,"3D printing offers significant potential in creating highly customized interactive and functional objects. However, at present ability to manufacture functional objects is limited by available materials (e.g., various polymers) and their process properties. For instance, many functional objects need stronger materials which may be satisfied with metal printers. However, to create wholly interactive devices, we need both conductors and insulators to create wiring, and electronic components to complete circuits. Unfortunately, the single material nature of metal printing, and its inherent high temperatures, preclude this. Thus, in 3D printed devices, we have had a choice of strong materials, or embedded interactivity, but not both. In this paper, we introduce a set of techniques we call FiberWire, which leverages a new commercially available capability to 3D print carbon fiber composite objects. These objects are light weight and mechanically strong, and our techniques demonstrate a means to embed circuitry for interactive devices within them. With FiberWire, we describe a fabrication pipeline takes advantage of laser etching and fiber printing between layers of carbon-fiber composite to form low resistance conductors, thereby enabling the fabrication of electronics directly embedded into mechanically strong objects. Utilizing the fabrication pipeline, we show a range of sensor designs, their performance characterization on these new materials and finally three fully printed example object that are both interactive and mechanically strong -- a bicycle handle bar with interactive controls, a swing and impact sensing golf club and an interactive game controller (Figure 1)."
pn4864,https://doi.org/10.1145/3290605.3300797,"FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects",2,Kadri Bugra Ozutemiz,Carnegie Mellon University,Pittsburgh,United States,false,false,"3D printing offers significant potential in creating highly customized interactive and functional objects. However, at present ability to manufacture functional objects is limited by available materials (e.g., various polymers) and their process properties. For instance, many functional objects need stronger materials which may be satisfied with metal printers. However, to create wholly interactive devices, we need both conductors and insulators to create wiring, and electronic components to complete circuits. Unfortunately, the single material nature of metal printing, and its inherent high temperatures, preclude this. Thus, in 3D printed devices, we have had a choice of strong materials, or embedded interactivity, but not both. In this paper, we introduce a set of techniques we call FiberWire, which leverages a new commercially available capability to 3D print carbon fiber composite objects. These objects are light weight and mechanically strong, and our techniques demonstrate a means to embed circuitry for interactive devices within them. With FiberWire, we describe a fabrication pipeline takes advantage of laser etching and fiber printing between layers of carbon-fiber composite to form low resistance conductors, thereby enabling the fabrication of electronics directly embedded into mechanically strong objects. Utilizing the fabrication pipeline, we show a range of sensor designs, their performance characterization on these new materials and finally three fully printed example object that are both interactive and mechanically strong -- a bicycle handle bar with interactive controls, a swing and impact sensing golf club and an interactive game controller (Figure 1)."
pn4864,https://doi.org/10.1145/3290605.3300797,"FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects",3,Carmel Majidi,Carnegie Mellon University,Pittsburgh,United States,false,false,"3D printing offers significant potential in creating highly customized interactive and functional objects. However, at present ability to manufacture functional objects is limited by available materials (e.g., various polymers) and their process properties. For instance, many functional objects need stronger materials which may be satisfied with metal printers. However, to create wholly interactive devices, we need both conductors and insulators to create wiring, and electronic components to complete circuits. Unfortunately, the single material nature of metal printing, and its inherent high temperatures, preclude this. Thus, in 3D printed devices, we have had a choice of strong materials, or embedded interactivity, but not both. In this paper, we introduce a set of techniques we call FiberWire, which leverages a new commercially available capability to 3D print carbon fiber composite objects. These objects are light weight and mechanically strong, and our techniques demonstrate a means to embed circuitry for interactive devices within them. With FiberWire, we describe a fabrication pipeline takes advantage of laser etching and fiber printing between layers of carbon-fiber composite to form low resistance conductors, thereby enabling the fabrication of electronics directly embedded into mechanically strong objects. Utilizing the fabrication pipeline, we show a range of sensor designs, their performance characterization on these new materials and finally three fully printed example object that are both interactive and mechanically strong -- a bicycle handle bar with interactive controls, a swing and impact sensing golf club and an interactive game controller (Figure 1)."
pn4864,https://doi.org/10.1145/3290605.3300797,"FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects",4,Scott Hudson,Carnegie Mellon University,Pittsburgh,United States,false,false,"3D printing offers significant potential in creating highly customized interactive and functional objects. However, at present ability to manufacture functional objects is limited by available materials (e.g., various polymers) and their process properties. For instance, many functional objects need stronger materials which may be satisfied with metal printers. However, to create wholly interactive devices, we need both conductors and insulators to create wiring, and electronic components to complete circuits. Unfortunately, the single material nature of metal printing, and its inherent high temperatures, preclude this. Thus, in 3D printed devices, we have had a choice of strong materials, or embedded interactivity, but not both. In this paper, we introduce a set of techniques we call FiberWire, which leverages a new commercially available capability to 3D print carbon fiber composite objects. These objects are light weight and mechanically strong, and our techniques demonstrate a means to embed circuitry for interactive devices within them. With FiberWire, we describe a fabrication pipeline takes advantage of laser etching and fiber printing between layers of carbon-fiber composite to form low resistance conductors, thereby enabling the fabrication of electronics directly embedded into mechanically strong objects. Utilizing the fabrication pipeline, we show a range of sensor designs, their performance characterization on these new materials and finally three fully printed example object that are both interactive and mechanically strong -- a bicycle handle bar with interactive controls, a swing and impact sensing golf club and an interactive game controller (Figure 1)."
pn3624,https://doi.org/10.1145/3290605.3300407,VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits,1,Yoonji Kim,KAIST,Daejeon,Republic Of Korea,false,false,"Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort."
pn3624,https://doi.org/10.1145/3290605.3300407,VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits,2,Youngkyung Choi,KAIST,Daejeon,Republic Of Korea,false,false,"Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort."
pn3624,https://doi.org/10.1145/3290605.3300407,VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits,3,Hyein Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort."
pn3624,https://doi.org/10.1145/3290605.3300407,VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits,4,Geehyuk Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort."
pn3624,https://doi.org/10.1145/3290605.3300407,VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits,5,Andrea Bianchi,KAIST,Daejeon,Republic Of Korea,false,false,"Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort."
pn7105,https://doi.org/10.1145/3290605.3300823,Engaging Low-Income African American Older Adults in Health Discussions through Community-based Design Workshops,1,Christina Harrington,Northwestern University,Evanston,United States,false,false,"Community-based approaches to participatory design, such as the design workshop, promise to engage underserved populations in collaborative dialog and provide a platform for promoting the views of communities who are not typically given a space to engage in design. Yet, we know little about how design workshops as a research site can engage underserved individuals (i.e., due to class, race, or age status) or address personal concerns (e.g., health). As a way of exploring these issues, we conducted a series of five design workshops with low-income African-American older adults to understand their health experiences. Our findings reveal three insights associated with the design workshop and the topic of health: comfort with community versus personal health; the sociocultural configuration of interaction; and empowerment in the context of systematic inequality of opportunity. We discuss the importance of understanding the situated nature of design workshops, particularly when engaging underserved groups in the topic of health, and the potential of the design workshop as a mechanism for activism."
pn7105,https://doi.org/10.1145/3290605.3300823,Engaging Low-Income African American Older Adults in Health Discussions through Community-based Design Workshops,2,Katya Borgos-Rodriguez,Northwestern University,Evanston,United States,false,false,"Community-based approaches to participatory design, such as the design workshop, promise to engage underserved populations in collaborative dialog and provide a platform for promoting the views of communities who are not typically given a space to engage in design. Yet, we know little about how design workshops as a research site can engage underserved individuals (i.e., due to class, race, or age status) or address personal concerns (e.g., health). As a way of exploring these issues, we conducted a series of five design workshops with low-income African-American older adults to understand their health experiences. Our findings reveal three insights associated with the design workshop and the topic of health: comfort with community versus personal health; the sociocultural configuration of interaction; and empowerment in the context of systematic inequality of opportunity. We discuss the importance of understanding the situated nature of design workshops, particularly when engaging underserved groups in the topic of health, and the potential of the design workshop as a mechanism for activism."
pn7105,https://doi.org/10.1145/3290605.3300823,Engaging Low-Income African American Older Adults in Health Discussions through Community-based Design Workshops,3,Anne Marie Piper,Northwestern University,Evanston,United States,false,false,"Community-based approaches to participatory design, such as the design workshop, promise to engage underserved populations in collaborative dialog and provide a platform for promoting the views of communities who are not typically given a space to engage in design. Yet, we know little about how design workshops as a research site can engage underserved individuals (i.e., due to class, race, or age status) or address personal concerns (e.g., health). As a way of exploring these issues, we conducted a series of five design workshops with low-income African-American older adults to understand their health experiences. Our findings reveal three insights associated with the design workshop and the topic of health: comfort with community versus personal health; the sociocultural configuration of interaction; and empowerment in the context of systematic inequality of opportunity. We discuss the importance of understanding the situated nature of design workshops, particularly when engaging underserved groups in the topic of health, and the potential of the design workshop as a mechanism for activism."
pn3976,https://doi.org/10.1145/3290605.3300822,Co-Designing Food Trackers with Dietitians: Identifying Design Opportunities for Food Tracker Customization,1,Yuhan Luo,"University of Maryland, College Park",College Park,United States,false,false,"We report co-design workshops with registered dietitians conducted to identify opportunities for designing customizable food trackers. Dietitians typically see patients who have different dietary problems, thus having different information needs. However, existing food trackers such as paper-based diaries and mobile apps are rarely customizable, making it difficult to capture necessary data for both patients and dietitians. During the co-design sessions, dietitians created representative patient personas and designed food trackers for each persona. We found a wide range of potential tracking items such as food, reflection, symptom, activity, and physical state. Depending on patients' dietary problems and dietitians' practice, the necessity and importance of these tracking items vary. We identify opportunities for patients and healthcare providers to collaborate around data tracking and sharing through customization. We also discuss how to structure co-design workshops to solicit the design considerations of self-tracking tools for patients with specific health problems."
pn3976,https://doi.org/10.1145/3290605.3300822,Co-Designing Food Trackers with Dietitians: Identifying Design Opportunities for Food Tracker Customization,2,Peiyi Liu,"University of Maryland, College Park",College Park,United States,false,false,"We report co-design workshops with registered dietitians conducted to identify opportunities for designing customizable food trackers. Dietitians typically see patients who have different dietary problems, thus having different information needs. However, existing food trackers such as paper-based diaries and mobile apps are rarely customizable, making it difficult to capture necessary data for both patients and dietitians. During the co-design sessions, dietitians created representative patient personas and designed food trackers for each persona. We found a wide range of potential tracking items such as food, reflection, symptom, activity, and physical state. Depending on patients' dietary problems and dietitians' practice, the necessity and importance of these tracking items vary. We identify opportunities for patients and healthcare providers to collaborate around data tracking and sharing through customization. We also discuss how to structure co-design workshops to solicit the design considerations of self-tracking tools for patients with specific health problems."
pn3976,https://doi.org/10.1145/3290605.3300822,Co-Designing Food Trackers with Dietitians: Identifying Design Opportunities for Food Tracker Customization,3,Eun Kyoung Choe,"University of Maryland, College Park",College Park,United States,false,false,"We report co-design workshops with registered dietitians conducted to identify opportunities for designing customizable food trackers. Dietitians typically see patients who have different dietary problems, thus having different information needs. However, existing food trackers such as paper-based diaries and mobile apps are rarely customizable, making it difficult to capture necessary data for both patients and dietitians. During the co-design sessions, dietitians created representative patient personas and designed food trackers for each persona. We found a wide range of potential tracking items such as food, reflection, symptom, activity, and physical state. Depending on patients' dietary problems and dietitians' practice, the necessity and importance of these tracking items vary. We identify opportunities for patients and healthcare providers to collaborate around data tracking and sharing through customization. We also discuss how to structure co-design workshops to solicit the design considerations of self-tracking tools for patients with specific health problems."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,1,Eivind Flobak,University of Bergen,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,2,Jo D. Wake,University of Bergen,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,3,Joakim Vindenes,University of Bergen,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,4,Smiti Kahlon,Haukeland University Hospital,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,5,Tine Nordgreen,Haukeland University Hospital,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn4016,https://doi.org/10.1145/3290605.3300799,Participatory Design of VR Scenarios for Exposure Therapy,6,Frode Guribye,University of Bergen,Bergen,Norway,false,false,"Virtual reality (VR) applications for exposure therapy predominantly use computer-generated imagery to create controlled environments in which users can be exposed to their fears. Creating 3D animations, however, is demanding and time-consuming. This paper presents a participatory approach for prototyping VR scenarios that are enabled by 360° video and grounded in lived experiences. We organized a participatory workshop with adolescents to prototype such scenarios, consisting of iterative phases of ideation, storyboarding, live-action plays recorded by a 360° camera, and group evaluation. Through an analysis of the participants' interactions, we outline how they worked to design prototypes that depict situations relevant to those with a fear of public speaking. Our analysis also explores how participants used their experiences and reflections as resources for design. Six clinical psychologists evaluated the prototypes from the workshop and concluded they were viable therapeutic tools, emphasizing the immersive, realistic experience they presented. We argue that our approach makes the design of VR scenarios more accessible."
pn8273,https://doi.org/10.1145/3290605.3300880,Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process,1,Timothy Neate,"City, University of London",London,United Kingdom,true,false,"Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson's disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also afforded additional benefits including empowering users within a more accessible design process. Reflecting on the outcomes from the different user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly."
pn8273,https://doi.org/10.1145/3290605.3300880,Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process,2,Aikaterini Bourazeri,"City, University of London",London,United Kingdom,true,false,"Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson's disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also afforded additional benefits including empowering users within a more accessible design process. Reflecting on the outcomes from the different user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly."
pn8273,https://doi.org/10.1145/3290605.3300880,Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process,3,Abi Roper,"City, University of London",London,United Kingdom,true,false,"Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson's disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also afforded additional benefits including empowering users within a more accessible design process. Reflecting on the outcomes from the different user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly."
pn8273,https://doi.org/10.1145/3290605.3300880,Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process,4,Simone Stumpf,"City, University of London",London,United Kingdom,true,false,"Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson's disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also afforded additional benefits including empowering users within a more accessible design process. Reflecting on the outcomes from the different user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly."
pn8273,https://doi.org/10.1145/3290605.3300880,Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process,5,Stephanie Wilson,"City, University of London",London,United Kingdom,true,false,"Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson's disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also afforded additional benefits including empowering users within a more accessible design process. Reflecting on the outcomes from the different user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly."
pn2194,https://doi.org/10.1145/3290605.3300334,Swire: Sketch-based User Interface Retrieval,1,Forrest Huang,"University of California, Berkeley",Berkeley,United States,false,false,"Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process."
pn2194,https://doi.org/10.1145/3290605.3300334,Swire: Sketch-based User Interface Retrieval,2,John Canny,"University of California, Berkeley",Berkeley,United States,false,false,"Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process."
pn2194,https://doi.org/10.1145/3290605.3300334,Swire: Sketch-based User Interface Retrieval,3,Jeffrey Nichols,Google LLC,Mountain View,United States,false,false,"Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process."
pn6358,https://doi.org/10.1145/3290605.3300406,Mobi3DSketch: 3D Sketching in Mobile AR,1,Kin Chung Kwan,City University of Hong Kong,Hong Kong,Hong Kong,false,false,"Mid-air 3D sketching has been mainly explored in Virtual Reality (VR) and typically requires special hardware for motion capture and immersive, stereoscopic displays. The recently developed motion tracking algorithms allow real-time tracking of mobile devices, and have enabled a few mobile applications for 3D sketching in Augmented Reality (AR). However, they are more suitable for making simple drawings only, since they do not consider special challenges with mobile AR 3D sketching, including the lack of stereo display, narrow field of view, and the coupling of 2D input, 3D input and display. To address these issues, we present Mobi3DSketch, which integrates multiple sources of inputs with tools, mainly different versions of 3D snapping and planar/curves surface proxies. Our multimodal interface supports both absolute and relative drawing, allowing easy creation of 3D concept designs in situ. The effectiveness and expressiveness of Mobi3DSketch are demonstrated via a pilot study."
pn6358,https://doi.org/10.1145/3290605.3300406,Mobi3DSketch: 3D Sketching in Mobile AR,2,Hongbo Fu,City University of Hong Kong,Hong Kong,Hong Kong,false,false,"Mid-air 3D sketching has been mainly explored in Virtual Reality (VR) and typically requires special hardware for motion capture and immersive, stereoscopic displays. The recently developed motion tracking algorithms allow real-time tracking of mobile devices, and have enabled a few mobile applications for 3D sketching in Augmented Reality (AR). However, they are more suitable for making simple drawings only, since they do not consider special challenges with mobile AR 3D sketching, including the lack of stereo display, narrow field of view, and the coupling of 2D input, 3D input and display. To address these issues, we present Mobi3DSketch, which integrates multiple sources of inputs with tools, mainly different versions of 3D snapping and planar/curves surface proxies. Our multimodal interface supports both absolute and relative drawing, allowing easy creation of 3D concept designs in situ. The effectiveness and expressiveness of Mobi3DSketch are demonstrated via a pilot study."
pn6240,https://doi.org/10.1145/3290605.3300362,I'm Sensing in the Rain: Spatial Incongruity in Visual-Tactile Mid-Air Stimulation Can Elicit Ownership in VR Users,1,Dario Pittera,University of Sussex,Brighton,United Kingdom,false,false,"Major virtual reality (VR) companies are trying to enhance the sense of immersion in virtual environments by implementing haptic feedback in their systems (e.g., Oculus Touch). It is known that tactile stimulation adds realism to a virtual environment. In addition, when users are not limited by wearing any attachments (e.g., gloves), it is even possible to create more immersive experiences. Mid-air haptic technology provides contactless haptic feedback and offers the potential for creating such immersive VR experiences. However, one of the limitations of mid-air haptics resides in the need for freehand tracking systems (e.g., Leap Motion) to deliver tactile feedback to the user's hand. These tracking systems are not accurate, limiting designers capability of delivering spatially precise tactile stimulation. Here, we investigated an alternative way to convey incongruent visual-tactile stimulation that can be used to create the illusion of a congruent visual-tactile experience, while participants experience the phenomenon of the rubber hand illusion in VR."
pn6240,https://doi.org/10.1145/3290605.3300362,I'm Sensing in the Rain: Spatial Incongruity in Visual-Tactile Mid-Air Stimulation Can Elicit Ownership in VR Users,2,Elia Gatti,University of Sussex,Brighton,United Kingdom,false,false,"Major virtual reality (VR) companies are trying to enhance the sense of immersion in virtual environments by implementing haptic feedback in their systems (e.g., Oculus Touch). It is known that tactile stimulation adds realism to a virtual environment. In addition, when users are not limited by wearing any attachments (e.g., gloves), it is even possible to create more immersive experiences. Mid-air haptic technology provides contactless haptic feedback and offers the potential for creating such immersive VR experiences. However, one of the limitations of mid-air haptics resides in the need for freehand tracking systems (e.g., Leap Motion) to deliver tactile feedback to the user's hand. These tracking systems are not accurate, limiting designers capability of delivering spatially precise tactile stimulation. Here, we investigated an alternative way to convey incongruent visual-tactile stimulation that can be used to create the illusion of a congruent visual-tactile experience, while participants experience the phenomenon of the rubber hand illusion in VR."
pn6240,https://doi.org/10.1145/3290605.3300362,I'm Sensing in the Rain: Spatial Incongruity in Visual-Tactile Mid-Air Stimulation Can Elicit Ownership in VR Users,3,Marianna Obrist,University of Sussex,Brighton,United Kingdom,false,false,"Major virtual reality (VR) companies are trying to enhance the sense of immersion in virtual environments by implementing haptic feedback in their systems (e.g., Oculus Touch). It is known that tactile stimulation adds realism to a virtual environment. In addition, when users are not limited by wearing any attachments (e.g., gloves), it is even possible to create more immersive experiences. Mid-air haptic technology provides contactless haptic feedback and offers the potential for creating such immersive VR experiences. However, one of the limitations of mid-air haptics resides in the need for freehand tracking systems (e.g., Leap Motion) to deliver tactile feedback to the user's hand. These tracking systems are not accurate, limiting designers capability of delivering spatially precise tactile stimulation. Here, we investigated an alternative way to convey incongruent visual-tactile stimulation that can be used to create the illusion of a congruent visual-tactile experience, while participants experience the phenomenon of the rubber hand illusion in VR."
pn6722,https://doi.org/10.1145/3290605.3300287,Painting with CATS: Camera-Aided Texture Synthesis,1,Ticha Sethapakdi,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present CATS, a digital painting system that synthesizes textures from live video in real-time, short-cutting the typical brush- and texture- gathering workflow. Through the use of boundary-aware texture synthesis, CATS produces strokes that are non-repeating and blend smoothly with each other. This allows CATS to produce paintings that would be difficult to create with traditional art supplies or existing software. We evaluated the effectiveness of CATS by asking artists to integrate the tool into their creative practice for two weeks; their paintings and feedback demonstrate that CATS is an expressive tool which can be used to create richly textured paintings."
pn6722,https://doi.org/10.1145/3290605.3300287,Painting with CATS: Camera-Aided Texture Synthesis,2,James Mccann,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present CATS, a digital painting system that synthesizes textures from live video in real-time, short-cutting the typical brush- and texture- gathering workflow. Through the use of boundary-aware texture synthesis, CATS produces strokes that are non-repeating and blend smoothly with each other. This allows CATS to produce paintings that would be difficult to create with traditional art supplies or existing software. We evaluated the effectiveness of CATS by asking artists to integrate the tool into their creative practice for two weeks; their paintings and feedback demonstrate that CATS is an expressive tool which can be used to create richly textured paintings."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,1,Fereshteh Shahmiri,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,2,Chaoyu Chen,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,3,Anandghan Waghmare,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,4,Dingtian Zhang,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,5,Shivan Mittal,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,6,Steven Zhang,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,7,Yi-Cheng Wang,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,8,Zhong Lin Wang,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,9,Thad Starner,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn2346,https://doi.org/10.1145/3290605.3300775,Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input,10,Gregory Abowd,Georgia Institute of Technology,Atlanta,United States,false,false,"We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications."
pn7256,https://doi.org/10.1145/3290605.3300551,EnhancedTouchX: Smart Bracelets for Augmenting Interpersonal Touch Interactions,1,Taku Hachisu,University of Tsukuba,Tsukuba,Japan,false,false,"EnhancedTouchX, a bracelet-type interpersonal body area network device, not only detects but also quantifies interpersonal hand-to-hand touch interactions. Without any wired connection, it can identify the direction and gestures of a touch. The developed device can connect to an external device via Bluetooth Low Energy for monitoring and logging where, when, how long, who, and how the touch interactions occurred. These daily augmented touch interactions provided by such contextual information would offer a variety of applications to facilitate social interactions. Our experiment, conducted with several pairs of participants, demonstrates that the devices can identify the direction of a touch (from one initiating the touch (active touch) to the one being touched (passive touch)) with 95% accuracy. In addition, the devices are also capable of identifying four types of touch gestures with 85% accuracy using a simple threshold classifier."
pn7256,https://doi.org/10.1145/3290605.3300551,EnhancedTouchX: Smart Bracelets for Augmenting Interpersonal Touch Interactions,2,Baptiste Bourreau,University of Tsukuba,Tsukuba,Japan,false,false,"EnhancedTouchX, a bracelet-type interpersonal body area network device, not only detects but also quantifies interpersonal hand-to-hand touch interactions. Without any wired connection, it can identify the direction and gestures of a touch. The developed device can connect to an external device via Bluetooth Low Energy for monitoring and logging where, when, how long, who, and how the touch interactions occurred. These daily augmented touch interactions provided by such contextual information would offer a variety of applications to facilitate social interactions. Our experiment, conducted with several pairs of participants, demonstrates that the devices can identify the direction of a touch (from one initiating the touch (active touch) to the one being touched (passive touch)) with 95% accuracy. In addition, the devices are also capable of identifying four types of touch gestures with 85% accuracy using a simple threshold classifier."
pn7256,https://doi.org/10.1145/3290605.3300551,EnhancedTouchX: Smart Bracelets for Augmenting Interpersonal Touch Interactions,3,Kenji Suzuki,University of Tsukuba,Tsukuba,Japan,false,false,"EnhancedTouchX, a bracelet-type interpersonal body area network device, not only detects but also quantifies interpersonal hand-to-hand touch interactions. Without any wired connection, it can identify the direction and gestures of a touch. The developed device can connect to an external device via Bluetooth Low Energy for monitoring and logging where, when, how long, who, and how the touch interactions occurred. These daily augmented touch interactions provided by such contextual information would offer a variety of applications to facilitate social interactions. Our experiment, conducted with several pairs of participants, demonstrates that the devices can identify the direction of a touch (from one initiating the touch (active touch) to the one being touched (passive touch)) with 95% accuracy. In addition, the devices are also capable of identifying four types of touch gestures with 85% accuracy using a simple threshold classifier."
pn8026,https://doi.org/10.1145/3290605.3300400,ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist,1,Roshan Peiris,Keio University Graduate School of Media Design,Yokohama,Japan,false,false,"Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in a real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability."
pn8026,https://doi.org/10.1145/3290605.3300400,ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist,2,Yuan-Ling Feng,Keio University Graduate School of Media Design,Yokohama,Japan,false,false,"Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in a real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability."
pn8026,https://doi.org/10.1145/3290605.3300400,ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist,3,Liwei Chan,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in a real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability."
pn8026,https://doi.org/10.1145/3290605.3300400,ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist,4,Kouta Minamizawa,Keio University Graduate School of Media Design,Yokohama,Japan,false,false,"Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in a real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability."
pn8087,https://doi.org/10.1145/3290605.3300254,EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios,1,Ruolin Wang,Tsinghua University,Beijing,China,true,false,"Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use."
pn8087,https://doi.org/10.1145/3290605.3300254,EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios,2,Chun Yu,Tsinghua University,Beijing,China,true,false,"Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use."
pn8087,https://doi.org/10.1145/3290605.3300254,EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios,3,Xing-Dong Yang,Dartmouth College,Hanover,United States,true,false,"Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use."
pn8087,https://doi.org/10.1145/3290605.3300254,EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios,4,Weijie He,Tsinghua University,Beijing,China,true,false,"Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use."
pn8087,https://doi.org/10.1145/3290605.3300254,EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios,5,Yuanchun Shi,Tsinghua University,Beijing,China,true,false,"Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use."
pn3811,https://doi.org/10.1145/3290605.3300486,Thinking Too Classically: Toward a Research Agenda for Human-Quantum Computer Interaction,1,Zahra Ashktorab,IBM Research AI,Yorktown Heights,United States,false,false,"Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of ""quantum native"" programmers."
pn3811,https://doi.org/10.1145/3290605.3300486,Thinking Too Classically: Toward a Research Agenda for Human-Quantum Computer Interaction,2,Justin Weisz,IBM Research AI,Yorktown Heights,United States,false,false,"Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of ""quantum native"" programmers."
pn3811,https://doi.org/10.1145/3290605.3300486,Thinking Too Classically: Toward a Research Agenda for Human-Quantum Computer Interaction,3,Maryam Ashoori,IBM Research AI,Yorktown Heights,United States,false,false,"Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of ""quantum native"" programmers."
pn3889,https://doi.org/10.1145/3290605.3300918,SwarmHaptics: Haptic Display with Swarm Robots,1,Lawrence Kim,Stanford University,Stanford,United States,true,false,"This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a flat surface and apply haptic patterns to the user's hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics."
pn3889,https://doi.org/10.1145/3290605.3300918,SwarmHaptics: Haptic Display with Swarm Robots,2,Sean Follmer,Stanford University,Stanford,United States,true,false,"This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a flat surface and apply haptic patterns to the user's hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics."
pn2589,https://doi.org/10.1145/3290605.3300347,"On the Internet, Nobody Knows You're a Dog... Unless You're Another Dog",1,Ilyena Hirskyj-Douglas,Aalto University,Helsinki,Finland,false,false,"How humans use computers has evolved from human–machine interfaces to human–human computer mediated communication. Whilst the field of animal–computer interaction has roots in HCI, technology developed in this area currently only supports animal– computer communication. This design fiction paper presents animal–animal connected interfaces, using dogs as an instance. Through a co-design workshop, we created six proposals. The designs focused on what a dog internet could look like and how interactions might be presented. Analysis of the narratives and conceived designs indicated that participants' concerns focused around asymmetries within the interaction. This resulted in the use of objects seen as familiar to dogs. This was conjoined with interest in how to initiate and end interactions, which was often achieved through notification systems. This paper builds upon HCI methods for unconventional users, and applies a design fiction approach to uncover key questions towards the creation of animal-to-animal interfaces."
pn2589,https://doi.org/10.1145/3290605.3300347,"On the Internet, Nobody Knows You're a Dog... Unless You're Another Dog",2,Andrés Lucero,Aalto University,Helsinki,Finland,false,false,"How humans use computers has evolved from human–machine interfaces to human–human computer mediated communication. Whilst the field of animal–computer interaction has roots in HCI, technology developed in this area currently only supports animal– computer communication. This design fiction paper presents animal–animal connected interfaces, using dogs as an instance. Through a co-design workshop, we created six proposals. The designs focused on what a dog internet could look like and how interactions might be presented. Analysis of the narratives and conceived designs indicated that participants' concerns focused around asymmetries within the interaction. This resulted in the use of objects seen as familiar to dogs. This was conjoined with interest in how to initiate and end interactions, which was often achieved through notification systems. This paper builds upon HCI methods for unconventional users, and applies a design fiction approach to uncover key questions towards the creation of animal-to-animal interfaces."
pn6234,https://doi.org/10.1145/3290605.3300496,Blockchain Assemblages: Whiteboxing Technology and Transforming Infrastructural Imaginaries,1,Karim Jabbar,University of Copenhagen,Copenhagen,Denmark,false,false,"In this paper we unpack empirical data from two domains within the Blockchain information infrastructure: The cryptocurrency trading domain, and the energy domain. Through these accounts we introduce the relational concepts of Blockchain Assemblages and Whiteboxing. Blockchain assemblages comprise configurations of digital and analogue artefacts that are entangled with imaginaries about the current and future state of the Blockchain information infrastructure. Rather than being a black box, Blockchain assemblages alternate between being dynamic and stable entities. We propose Whiteboxing as the sociomaterial process which drives blockchain assemblages in their dynamic state to be (re)configured, while related artefacts and imaginaries are simultaneously transformed, creating dynamic representations. Whiteboxing is triggered during disconfirming events when representations are discovered as problematic. Complementing existing historical accounts demonstrating technologies in the making, the contribution of this paper, proposes whiteboxing as an analytical concept which allows us to unpack how contemporary technologies are created through entrepreneurial activities."
pn6234,https://doi.org/10.1145/3290605.3300496,Blockchain Assemblages: Whiteboxing Technology and Transforming Infrastructural Imaginaries,2,Pernille Bjørn,University of Copenhagen,Copenhagen,Denmark,false,false,"In this paper we unpack empirical data from two domains within the Blockchain information infrastructure: The cryptocurrency trading domain, and the energy domain. Through these accounts we introduce the relational concepts of Blockchain Assemblages and Whiteboxing. Blockchain assemblages comprise configurations of digital and analogue artefacts that are entangled with imaginaries about the current and future state of the Blockchain information infrastructure. Rather than being a black box, Blockchain assemblages alternate between being dynamic and stable entities. We propose Whiteboxing as the sociomaterial process which drives blockchain assemblages in their dynamic state to be (re)configured, while related artefacts and imaginaries are simultaneously transformed, creating dynamic representations. Whiteboxing is triggered during disconfirming events when representations are discovered as problematic. Complementing existing historical accounts demonstrating technologies in the making, the contribution of this paper, proposes whiteboxing as an analytical concept which allows us to unpack how contemporary technologies are created through entrepreneurial activities."
pn4225,https://doi.org/10.1145/3290605.3300752,I'm a Giant: Walking in Large Virtual Environments at High Speed Gains,1,Parastoo Abtahi,Stanford University,Stanford,United States,false,false,"Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for."
pn4225,https://doi.org/10.1145/3290605.3300752,I'm a Giant: Walking in Large Virtual Environments at High Speed Gains,2,Mar Gonzalez-Franco,Microsoft Research,Redmond,United States,false,false,"Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for."
pn4225,https://doi.org/10.1145/3290605.3300752,I'm a Giant: Walking in Large Virtual Environments at High Speed Gains,3,Eyal Ofek,Microsoft Research,Redmond,United States,false,false,"Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for."
pn4225,https://doi.org/10.1145/3290605.3300752,I'm a Giant: Walking in Large Virtual Environments at High Speed Gains,4,Anthony Steed,University College London,London,United Kingdom,false,false,"Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,1,Emily Shaw,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,2,Tessa Roper,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,3,Tommy Nilsson,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,4,Glyn Lawson,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,5,Sue Cobb,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn6148,https://doi.org/10.1145/3290605.3300856,The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation,6,Daniel Miller,University of Nottingham,Nottingham,United Kingdom,false,false,"Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."
pn4364,https://doi.org/10.1145/3290605.3300365,Putting the Value in VR: How to Systematically and Iteratively Develop a Value-Based VR Application with a Complex Target Group,1,Hanneke Kip,University of Twente,Enschede,Netherlands,false,false,"In development, implementation and evaluation of eHealth it is essential to account for stakeholders' perspectives, opinions and values, which are statements that specify what stakeholders want to achieve or improve via a technology. The use of values enables developers to systematically include stakeholders' perspectives and the context of use in an eHealth development process. However, there are relatively few papers that explain how to use values in technology development. Consequently, in this paper we show how we formulated values during the multi-method, interdisciplinary and iterative development process of a VR application for a complex setting: forensic mental healthcare. We report the main foundations for these values: the outcomes of an online questionnaire with patients, therapists and other stakeholders (n=146) and interviews with patients and therapists (n=18). We show how a multidisciplinary project team used these qualitative results to formulate and adapt values and create lo-fi prototypes of a VR application. We discuss the importance of a systematic development process with multiple formative evaluations for eHealth and reflect on the role of values within this."
pn4364,https://doi.org/10.1145/3290605.3300365,Putting the Value in VR: How to Systematically and Iteratively Develop a Value-Based VR Application with a Complex Target Group,2,Saskia Kelders,University of Twente,Enschede,Netherlands,false,false,"In development, implementation and evaluation of eHealth it is essential to account for stakeholders' perspectives, opinions and values, which are statements that specify what stakeholders want to achieve or improve via a technology. The use of values enables developers to systematically include stakeholders' perspectives and the context of use in an eHealth development process. However, there are relatively few papers that explain how to use values in technology development. Consequently, in this paper we show how we formulated values during the multi-method, interdisciplinary and iterative development process of a VR application for a complex setting: forensic mental healthcare. We report the main foundations for these values: the outcomes of an online questionnaire with patients, therapists and other stakeholders (n=146) and interviews with patients and therapists (n=18). We show how a multidisciplinary project team used these qualitative results to formulate and adapt values and create lo-fi prototypes of a VR application. We discuss the importance of a systematic development process with multiple formative evaluations for eHealth and reflect on the role of values within this."
pn4364,https://doi.org/10.1145/3290605.3300365,Putting the Value in VR: How to Systematically and Iteratively Develop a Value-Based VR Application with a Complex Target Group,3,Lisette Van Gemert-Pijnen,University of Twente,Enschede,Netherlands,false,false,"In development, implementation and evaluation of eHealth it is essential to account for stakeholders' perspectives, opinions and values, which are statements that specify what stakeholders want to achieve or improve via a technology. The use of values enables developers to systematically include stakeholders' perspectives and the context of use in an eHealth development process. However, there are relatively few papers that explain how to use values in technology development. Consequently, in this paper we show how we formulated values during the multi-method, interdisciplinary and iterative development process of a VR application for a complex setting: forensic mental healthcare. We report the main foundations for these values: the outcomes of an online questionnaire with patients, therapists and other stakeholders (n=146) and interviews with patients and therapists (n=18). We show how a multidisciplinary project team used these qualitative results to formulate and adapt values and create lo-fi prototypes of a VR application. We discuss the importance of a systematic development process with multiple formative evaluations for eHealth and reflect on the role of values within this."
pn4941,https://doi.org/10.1145/3290605.3300577,RealityCheck: Blending Virtual Environments with Situated Physical Reality,1,Jeremy Hartmann,University of Waterloo,Redmond,United States,false,false,"Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences."
pn4941,https://doi.org/10.1145/3290605.3300577,RealityCheck: Blending Virtual Environments with Situated Physical Reality,2,Christian Holz,Microsoft Research,Redmond,United States,false,false,"Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences."
pn4941,https://doi.org/10.1145/3290605.3300577,RealityCheck: Blending Virtual Environments with Situated Physical Reality,3,Eyal Ofek,Microsoft Research,Redmond,United States,false,false,"Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences."
pn4941,https://doi.org/10.1145/3290605.3300577,RealityCheck: Blending Virtual Environments with Situated Physical Reality,4,Andrew Wilson,Microsoft Research,Redmond,United States,false,false,"Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,1,Jun Zhao,University of Oxford,Oxford,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,2,Ge Wang,University College London,London,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,3,Carys Dally,University of Oxford,Oxford,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,4,Petr Slovak,University College London,London,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,5,Julian Edbrooke-Childs,Anna Freud Centre,London,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,6,Max Van Kleek,University of Oxford,Oxford,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn3968,https://doi.org/10.1145/3290605.3300336,'I make up a silly name': Understanding Children's Perception of Privacy Risks Online,7,Nigel Shadbolt,University of Oxford,Oxford,United Kingdom,false,false,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online."
pn5071,https://doi.org/10.1145/3290605.3300497,Risk vs. Restriction: The Tension between Providing a Sense of Normalcy and Keeping Foster Teens Safe Online,1,Karla Badillo-Urquiola,University of Central Florida,Orlando,United States,false,true,"Foster youth are particularly vulnerable to offline risks; yet, little is known about their online risk experiences or how foster parents mediate technology use in the home. We conducted 29 interviews with foster parents of 42 teens (ages 13-17) who were part of the child welfare system. Foster parents faced significant challenges relating to technology mediation in the home. Based on parental accounts, over half of the foster teens encountered high-risk situations that involved interacting with unsafe people online, resulting in rape, sex trafficking, and/or psychological harm. Overall, foster parents were at a loss for how to balance online safety with technology access in a way that engendered positive relationships with their foster teens. Instead, parents often resorted to outright restriction. Our research highlights the importance of considering the unique needs of foster families and designing technologies to address the challenges faced by this vulnerable population of teens and parents."
pn5071,https://doi.org/10.1145/3290605.3300497,Risk vs. Restriction: The Tension between Providing a Sense of Normalcy and Keeping Foster Teens Safe Online,2,Xinru Page,Bentley University,Waltham,United States,false,true,"Foster youth are particularly vulnerable to offline risks; yet, little is known about their online risk experiences or how foster parents mediate technology use in the home. We conducted 29 interviews with foster parents of 42 teens (ages 13-17) who were part of the child welfare system. Foster parents faced significant challenges relating to technology mediation in the home. Based on parental accounts, over half of the foster teens encountered high-risk situations that involved interacting with unsafe people online, resulting in rape, sex trafficking, and/or psychological harm. Overall, foster parents were at a loss for how to balance online safety with technology access in a way that engendered positive relationships with their foster teens. Instead, parents often resorted to outright restriction. Our research highlights the importance of considering the unique needs of foster families and designing technologies to address the challenges faced by this vulnerable population of teens and parents."
pn5071,https://doi.org/10.1145/3290605.3300497,Risk vs. Restriction: The Tension between Providing a Sense of Normalcy and Keeping Foster Teens Safe Online,3,Pamela Wisniewski,University of Central Florida,Orlando,United States,false,true,"Foster youth are particularly vulnerable to offline risks; yet, little is known about their online risk experiences or how foster parents mediate technology use in the home. We conducted 29 interviews with foster parents of 42 teens (ages 13-17) who were part of the child welfare system. Foster parents faced significant challenges relating to technology mediation in the home. Based on parental accounts, over half of the foster teens encountered high-risk situations that involved interacting with unsafe people online, resulting in rape, sex trafficking, and/or psychological harm. Overall, foster parents were at a loss for how to balance online safety with technology access in a way that engendered positive relationships with their foster teens. Instead, parents often resorted to outright restriction. Our research highlights the importance of considering the unique needs of foster families and designing technologies to address the challenges faced by this vulnerable population of teens and parents."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",1,Jason Yip,University of Washinton,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",2,Kiley Sobel,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",3,Xin Gao,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",4,Allison Hishikawa,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",5,Alexis Lim,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",6,Laura Meng,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",7,Romaine Flor Ofiana,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",8,Justin Park,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7127,https://doi.org/10.1145/3290605.3300303,"Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies",9,Alexis Hiniker,University of Washington,Seattle,United States,false,false,"In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term ""creepy."" To understand children's perceptions of ""creepy technologies,"" we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is ""creepy."" By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise."
pn7167,https://doi.org/10.1145/3290605.3300824,It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard,1,Kaiwen Sun,University of Michigan,Ann Arbor,United States,false,false,"Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education."
pn7167,https://doi.org/10.1145/3290605.3300824,It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard,2,Abraham Mhaidli,University of Michigan,Ann Arbor,United States,false,false,"Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education."
pn7167,https://doi.org/10.1145/3290605.3300824,It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard,3,Sonakshi Watel,University of Michigan,Ann Arbor,United States,false,false,"Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education."
pn7167,https://doi.org/10.1145/3290605.3300824,It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard,4,Christopher Brooks,University of Michigan,Ann Arbor,United States,false,false,"Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education."
pn7167,https://doi.org/10.1145/3290605.3300824,It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard,5,Florian Schaub,University of Michigan,Ann Arbor,United States,false,false,"Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education."
pn4483,https://doi.org/10.1145/3290605.3300378,From Director's Cut to User's Cut: to Watch a Brain-Controlled Film is to Edit it,1,Richard Ramchurn,The University of Nottingham,Nottingham,United Kingdom,true,false,"Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions."
pn4483,https://doi.org/10.1145/3290605.3300378,From Director's Cut to User's Cut: to Watch a Brain-Controlled Film is to Edit it,2,Sarah Martindale,University of Nottingham,Nottingham,United Kingdom,true,false,"Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions."
pn4483,https://doi.org/10.1145/3290605.3300378,From Director's Cut to User's Cut: to Watch a Brain-Controlled Film is to Edit it,3,Max Wilson,University of Nottingham,Nottingham,United Kingdom,true,false,"Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions."
pn4483,https://doi.org/10.1145/3290605.3300378,From Director's Cut to User's Cut: to Watch a Brain-Controlled Film is to Edit it,4,Steve Benford,University of Nottingham,Nottingham,United Kingdom,true,false,"Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions."
pn3475,https://doi.org/10.1145/3290605.3300703,SuperVision: Playing with Gaze Aversion and Peripheral Vision,1,Argenis Ramirez Gomez,Lancaster University,Lancaster,United Kingdom,false,false,"In this work, we challenge the Gaze interaction paradigm ""What you see is what you get"" to introduce ""playing with peripheral vision"". We developed the conceptual framework to introduce this novel gaze-aware game dynamic. We illustrated the concept with SuperVision, a collection of three games that play with peripheral vision. We propose perceptual and interaction challenges that require players not to look and rely on their periphery. To validate the game dynamic and experience, we conducted a user study with twenty-four participants. Results show how the game concept created an engaging and playful experience playing with peripheral vision. Participants showed proficiency in overcoming the game challenges, developing clear strategies to succeed. Moreover, we found evidence that playing the game can affect our visual skills, with greater peripheral awareness."
pn3475,https://doi.org/10.1145/3290605.3300703,SuperVision: Playing with Gaze Aversion and Peripheral Vision,2,Hans Gellersen,Lancaster University,Lancaster,United Kingdom,false,false,"In this work, we challenge the Gaze interaction paradigm ""What you see is what you get"" to introduce ""playing with peripheral vision"". We developed the conceptual framework to introduce this novel gaze-aware game dynamic. We illustrated the concept with SuperVision, a collection of three games that play with peripheral vision. We propose perceptual and interaction challenges that require players not to look and rely on their periphery. To validate the game dynamic and experience, we conducted a user study with twenty-four participants. Results show how the game concept created an engaging and playful experience playing with peripheral vision. Participants showed proficiency in overcoming the game challenges, developing clear strategies to succeed. Moreover, we found evidence that playing the game can affect our visual skills, with greater peripheral awareness."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,1,Rawan Alghofaili,George Mason University,Fairfax,United States,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,2,Yasuhito Sawahata,Japan Broadcasting Corporation,Setagaya,Japan,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,3,Haikun Huang,University of Massachusetts Boston,Boston,United States,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,4,Hsueh-Cheng Wang,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,5,Takaaki Shiratori,Facebook Reality Labs,Pittsburgh,United States,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn3380,https://doi.org/10.1145/3290605.3300578,Lost in Style: Gaze-driven Adaptive Aid for VR Navigation,6,Lap-Fai Yu,George Mason University,Fairfax,United States,false,false,"A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,1,Zhuying Li,RMIT University,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,2,Yan Wang,RMIT University,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,3,Wei Wang,University of Melbourne,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,4,Weikang Chen,University of Melbourne,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,5,Ti Hoang,RMIT University,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,6,Stefan Greuter,Deakin University,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn4095,https://doi.org/10.1145/3290605.3300806,HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,7,Florian Mueller,RMIT University,Melbourne,Australia,false,false,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors."
pn3907,https://doi.org/10.1145/3290605.3300626,Power Struggles and Disciplined Designers – A Nexus Analytic Inquiry on Cross-Disciplinary Research and Design,1,Netta Iivari,University of Oulu,Oulu,Finland,false,false,"Design is at the heart of Human Computer Interaction research and practice. In the research community, there has emerged an increasing interest in understanding and conceptualizing our research practice, particularly such entailing design. However, reflective discussion around the associated challenges and practicalities is yet limited. Moreover, so far there is limited discussion on the cross-disciplinary nature of our research and design practices: although cross-disciplinarity has been brought up as an ideal and a necessity, its practicalities and complexities remain yet poorly explored. This study examines a cross-disciplinary research project with a number of researcher-designers representing different disciplines acting as 'designers', while having a divergent understanding of it and of who has authority to do it. The study relies on nexus analysis as a sensitizing device and shows how various discourses, epistemologies and histories shape cross-disciplinary research and design. Critical reflection around our research practice entailing design is called for."
pn2085,https://doi.org/10.1145/3290605.3300279,A Practice-Led Account of the Conceptual Evolution of UX Knowledge,1,Yubo Kou,Florida State University,Tallahassee,United States,false,false,"The contours of user experience (UX) design practice have been shaped by a diverse array of practitioners and disciplines, resulting in a diffuse and decentralized body of UX-specific disciplinary knowledge. The rapidly shifting space that UX knowledge occupies, in conjunction with a long-existing research-practice gap, presents unique challenges and opportunities to UX educators and aspiring UX designers. In this paper, we analyzed a corpus of question and answer communication on UX Stack Exchange using a practice-led approach, identifying and documenting practitioners' conceptions of UX knowledge over a nine year period. Specifically, we used natural language processing techniques and qualitative content analysis to identify a disciplinary vocabulary invoked by UX designers in this online community, as well as conceptual trajectories spanning over nine years which could shed light on the evolution of UX practice. We further describe the implications of our findings for HCI research and UX education."
pn2085,https://doi.org/10.1145/3290605.3300279,A Practice-Led Account of the Conceptual Evolution of UX Knowledge,2,Colin Gray,Purdue University,West Lafayette,United States,false,false,"The contours of user experience (UX) design practice have been shaped by a diverse array of practitioners and disciplines, resulting in a diffuse and decentralized body of UX-specific disciplinary knowledge. The rapidly shifting space that UX knowledge occupies, in conjunction with a long-existing research-practice gap, presents unique challenges and opportunities to UX educators and aspiring UX designers. In this paper, we analyzed a corpus of question and answer communication on UX Stack Exchange using a practice-led approach, identifying and documenting practitioners' conceptions of UX knowledge over a nine year period. Specifically, we used natural language processing techniques and qualitative content analysis to identify a disciplinary vocabulary invoked by UX designers in this online community, as well as conceptual trajectories spanning over nine years which could shed light on the evolution of UX practice. We further describe the implications of our findings for HCI research and UX education."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,1,Gavin Wood,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,2,Thomas Dylan,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,3,Abigail Durrant,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,4,Pablo Torres,University College London,London,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,5,Philip Ulrich,Canterbury Christ Church University,Canterbury,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,6,Amanda Carr,Canterbury Christ Church University,Canterbury,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,7,Mutlu Cukurova,UCL Institute of Education,London,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,8,Denise Downey,The Cedarwood Trust,North Shields,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,9,Phil Mcgrath,The Cedarwood Trust,North Shields,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,10,Madeline Balaam,Royal Institute of Technology (KTH),Stockholm,Sweden,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,11,Alice Ferguson,Playing Out CIC,Bristol,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,12,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn5255,https://doi.org/10.1145/3290605.3300909,Designing for Digital Playing Out,13,Shaun Lawson,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,1,Madeline Balaam,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,2,Rob Comber,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,3,Rachel Clarke,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,4,Charles Windlin,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,5,Anna Ståhl,"RISE, Research Institutes of Sweden",Stockholm,Sweden,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,6,Kristina Höök,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9662,https://doi.org/10.1145/3290605.3300832,Emotion Work in Experience-Centered Design,7,Geraldine Fitzpatrick,Technische Universität Wien,Vienna,Austria,true,false,"Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate."
pn9792,https://doi.org/10.1145/3290605.3300654,Understanding the Impact of TVIs on Technology Use and Selection by Children with Visual Impairments,1,Catherine Baker,Creighton University,Omaha,United States,false,false,"The use of technology in educational settings is extremely common. For many visually impaired children, educational settings are the first place they are exposed to the assistive technology that they will need to access mainstream computing devices. Current laws provide support for students to receive training from Teachers of the Visually Impaired (TVIs) on these assistive devices. Therefore, TVIs play an important role in the selection and training of technology. Through our interviews with TVIs, we discovered the factors that impact which technologies they select, how they attempt to mitigate the stigma associated with certain technologies, and the challenges that students face in learning assistive technologies. Through this research, we identified three needs that future research on assistive technology should address: (1) increasing focus on built-in accessibility features, (2) providing support for independent learning and exploration, and (3) creating technologies that can support users with progressive vision loss."
pn9792,https://doi.org/10.1145/3290605.3300654,Understanding the Impact of TVIs on Technology Use and Selection by Children with Visual Impairments,2,Lauren Milne,Macalester University,St Paul,United States,false,false,"The use of technology in educational settings is extremely common. For many visually impaired children, educational settings are the first place they are exposed to the assistive technology that they will need to access mainstream computing devices. Current laws provide support for students to receive training from Teachers of the Visually Impaired (TVIs) on these assistive devices. Therefore, TVIs play an important role in the selection and training of technology. Through our interviews with TVIs, we discovered the factors that impact which technologies they select, how they attempt to mitigate the stigma associated with certain technologies, and the challenges that students face in learning assistive technologies. Through this research, we identified three needs that future research on assistive technology should address: (1) increasing focus on built-in accessibility features, (2) providing support for independent learning and exploration, and (3) creating technologies that can support users with progressive vision loss."
pn9792,https://doi.org/10.1145/3290605.3300654,Understanding the Impact of TVIs on Technology Use and Selection by Children with Visual Impairments,3,Richard Ladner,University of Washington,Seattle,United States,false,false,"The use of technology in educational settings is extremely common. For many visually impaired children, educational settings are the first place they are exposed to the assistive technology that they will need to access mainstream computing devices. Current laws provide support for students to receive training from Teachers of the Visually Impaired (TVIs) on these assistive devices. Therefore, TVIs play an important role in the selection and training of technology. Through our interviews with TVIs, we discovered the factors that impact which technologies they select, how they attempt to mitigate the stigma associated with certain technologies, and the challenges that students face in learning assistive technologies. Through this research, we identified three needs that future research on assistive technology should address: (1) increasing focus on built-in accessibility features, (2) providing support for independent learning and exploration, and (3) creating technologies that can support users with progressive vision loss."
pn8972,https://doi.org/10.1145/3290605.3300722,StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories,1,Varsha Koushik,University of Colorado Boulder,Boulder,United States,true,false,"Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block-based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block-based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools."
pn8972,https://doi.org/10.1145/3290605.3300722,StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories,2,Darren Guinness,University of Colorado Boulder,Boulder,United States,true,false,"Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block-based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block-based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools."
pn8972,https://doi.org/10.1145/3290605.3300722,StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories,3,Shaun Kane,University of Colorado Boulder,Boulder,United States,true,false,"Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block-based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block-based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools."
pn7499,https://doi.org/10.1145/3290605.3300744,"""It Broadens My Mind"": Empowering People with Cognitive Disabilities through Computing Education",1,Varsha Koushik,University of Colorado Boulder,Boulder,United States,false,false,"Computer science education is widely viewed as a path to empowerment for young people, potentially leading to higher education, careers, and development of computational thinking skills. However, few resources exist for people with cognitive disabilities to learn computer science. In this paper, we document our observations of a successful program in which young adults with cognitive disabilities are trained in computing concepts. Through field observations and interviews, we identify instructional strategies used by this group, accessibility challenges encountered by this group, and how instructors and students leverage peer learning to support technical education. Our findings lead to guidelines for developing tools and curricula to support young adults with cognitive disabilities in learning computer science."
pn7499,https://doi.org/10.1145/3290605.3300744,"""It Broadens My Mind"": Empowering People with Cognitive Disabilities through Computing Education",2,Shaun Kane,University of Colorado Boulder,Boulder,United States,false,false,"Computer science education is widely viewed as a path to empowerment for young people, potentially leading to higher education, careers, and development of computational thinking skills. However, few resources exist for people with cognitive disabilities to learn computer science. In this paper, we document our observations of a successful program in which young adults with cognitive disabilities are trained in computing concepts. Through field observations and interviews, we identify instructional strategies used by this group, accessibility challenges encountered by this group, and how instructors and students leverage peer learning to support technical education. Our findings lead to guidelines for developing tools and curricula to support young adults with cognitive disabilities in learning computer science."
pn7322,https://doi.org/10.1145/3290605.3300240,DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities,1,Leandro Flórez-Aristizábal,Institución Universitaria Antonio José Camacho,Cali,Colombia,false,false,"Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities."
pn7322,https://doi.org/10.1145/3290605.3300240,DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities,2,Sandra Cano,Universidad de San Buenaventura,Cali,Colombia,false,false,"Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities."
pn7322,https://doi.org/10.1145/3290605.3300240,DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities,3,César Collazos,Universidad del Cauca,Popayán,Colombia,false,false,"Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities."
pn7322,https://doi.org/10.1145/3290605.3300240,DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities,4,Andrés Solano,Universidad Autónoma de Occidente,Cali,Colombia,false,false,"Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities."
pn7322,https://doi.org/10.1145/3290605.3300240,DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities,5,Stephen Brewster,University of Glasgow,Glasgow,United Kingdom,false,false,"Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities."
pn4777,https://doi.org/10.1145/3290605.3300519,'Think secure from the beginning': A Survey with Software Developers,1,Hala Assal,Carleton University,Ottawa,Canada,false,true,"Vulnerabilities persist despite existing software security initiatives and best practices. This paper focuses on the human factors of software security, including human behaviour and motivation. We conducted an online survey to explore the interplay between developers and software security processes, e.g., we looked into how developers influence and are influenced by these processes. Our data included responses from 123 software developers currently employed in North America who work on various types of software applications. Whereas developers are often held responsible for security vulnerabilities, our analysis shows that the real issues frequently stem from a lack of organizational or process support to handle security throughout development tasks. Our participants are self-motivated towards software security, and the majority did not dismiss it but identified obstacles to achieving secure code. Our work highlights the need to look beyond the individual, and take a holistic approach to investigate organizational issues influencing software security."
pn4777,https://doi.org/10.1145/3290605.3300519,'Think secure from the beginning': A Survey with Software Developers,2,Sonia Chiasson,Carleton University,Ottawa,Canada,false,true,"Vulnerabilities persist despite existing software security initiatives and best practices. This paper focuses on the human factors of software security, including human behaviour and motivation. We conducted an online survey to explore the interplay between developers and software security processes, e.g., we looked into how developers influence and are influenced by these processes. Our data included responses from 123 software developers currently employed in North America who work on various types of software applications. Whereas developers are often held responsible for security vulnerabilities, our analysis shows that the real issues frequently stem from a lack of organizational or process support to handle security throughout development tasks. Our participants are self-motivated towards software security, and the majority did not dismiss it but identified obstacles to achieving secure code. Our work highlights the need to look beyond the individual, and take a holistic approach to investigate organizational issues influencing software security."
pn8307,https://doi.org/10.1145/3290605.3300370,"""If you want, I can store the encrypted password."": A Password-Storage Field Study with Freelance Developers",1,Alena Naiakshina,University of Bonn,Bonn,Germany,true,false,"In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether computer science students need to be told to write code that stores passwords securely. The authors' results showed that, without explicit prompting, none of the students implemented secure password storage. When asked about this oversight, a common answer was that they would have implemented secure storage - if they were creating code for a company. To shed light on this possible confusion, we conducted a mixed-methods field study with developers. We hired freelance developers online and gave them a similar password storage task followed by a questionnaire to gain additional insights into their work. From our research, we offer two contributions. First of all, we reveal that, similar to the students, freelancers do not store passwords securely unless prompted, they have misconceptions about secure password storage, and they use outdated methods. Secondly, we discuss the methodological implications of using freelancers and students in developer studies."
pn8307,https://doi.org/10.1145/3290605.3300370,"""If you want, I can store the encrypted password."": A Password-Storage Field Study with Freelance Developers",2,Anastasia Danilova,University of Bonn,Bonn,Germany,true,false,"In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether computer science students need to be told to write code that stores passwords securely. The authors' results showed that, without explicit prompting, none of the students implemented secure password storage. When asked about this oversight, a common answer was that they would have implemented secure storage - if they were creating code for a company. To shed light on this possible confusion, we conducted a mixed-methods field study with developers. We hired freelance developers online and gave them a similar password storage task followed by a questionnaire to gain additional insights into their work. From our research, we offer two contributions. First of all, we reveal that, similar to the students, freelancers do not store passwords securely unless prompted, they have misconceptions about secure password storage, and they use outdated methods. Secondly, we discuss the methodological implications of using freelancers and students in developer studies."
pn8307,https://doi.org/10.1145/3290605.3300370,"""If you want, I can store the encrypted password."": A Password-Storage Field Study with Freelance Developers",3,Eva Gerlitz,University of Bonn,Bonn,Germany,true,false,"In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether computer science students need to be told to write code that stores passwords securely. The authors' results showed that, without explicit prompting, none of the students implemented secure password storage. When asked about this oversight, a common answer was that they would have implemented secure storage - if they were creating code for a company. To shed light on this possible confusion, we conducted a mixed-methods field study with developers. We hired freelance developers online and gave them a similar password storage task followed by a questionnaire to gain additional insights into their work. From our research, we offer two contributions. First of all, we reveal that, similar to the students, freelancers do not store passwords securely unless prompted, they have misconceptions about secure password storage, and they use outdated methods. Secondly, we discuss the methodological implications of using freelancers and students in developer studies."
pn8307,https://doi.org/10.1145/3290605.3300370,"""If you want, I can store the encrypted password."": A Password-Storage Field Study with Freelance Developers",4,Emanuel Von Zezschwitz,University of Bonn,Bonn,Germany,true,false,"In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether computer science students need to be told to write code that stores passwords securely. The authors' results showed that, without explicit prompting, none of the students implemented secure password storage. When asked about this oversight, a common answer was that they would have implemented secure storage - if they were creating code for a company. To shed light on this possible confusion, we conducted a mixed-methods field study with developers. We hired freelance developers online and gave them a similar password storage task followed by a questionnaire to gain additional insights into their work. From our research, we offer two contributions. First of all, we reveal that, similar to the students, freelancers do not store passwords securely unless prompted, they have misconceptions about secure password storage, and they use outdated methods. Secondly, we discuss the methodological implications of using freelancers and students in developer studies."
pn8307,https://doi.org/10.1145/3290605.3300370,"""If you want, I can store the encrypted password."": A Password-Storage Field Study with Freelance Developers",5,Matthew Smith,University of Bonn,Bonn,Germany,true,false,"In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether computer science students need to be told to write code that stores passwords securely. The authors' results showed that, without explicit prompting, none of the students implemented secure password storage. When asked about this oversight, a common answer was that they would have implemented secure storage - if they were creating code for a company. To shed light on this possible confusion, we conducted a mixed-methods field study with developers. We hired freelance developers online and gave them a similar password storage task followed by a questionnaire to gain additional insights into their work. From our research, we offer two contributions. First of all, we reveal that, similar to the students, freelancers do not store passwords securely unless prompted, they have misconceptions about secure password storage, and they use outdated methods. Secondly, we discuss the methodological implications of using freelancers and students in developer studies."
pn3773,https://doi.org/10.1145/3290605.3300663,Security Managers Are Not The Enemy Either,1,Lena Reinfelder,Friedrich-Alexander-Universität Erlangen-Nürnberg,Erlangen,Germany,true,false,"Security managers are leading employees whose decisions shape security measures and thus influence the everyday work of all users in their organizations. To understand how security managers handle user requirements and behavior, we conducted semi-structured interviews with seven security managers from large-scale German companies. Our results indicate that due to the absence of organizational structures that include users into security development processes, security managers unintentionally obtain a negative view on users. Their distrust towards users leads to the creation of technical security measures that cannot be influenced by users in any way. However, as previous research has repeatedly shown, rigid security measures lead to frustration and discouragement of users, and also to creative (but usually insecure) methods of security circumvention. We conclude that in order to break through this vicious cycle, security managers need organizational structures, methods and tools that facilitate systematic feedback from users."
pn3773,https://doi.org/10.1145/3290605.3300663,Security Managers Are Not The Enemy Either,2,Robert Landwirth,Technical University Darmstadt,Darmstadt,Germany,true,false,"Security managers are leading employees whose decisions shape security measures and thus influence the everyday work of all users in their organizations. To understand how security managers handle user requirements and behavior, we conducted semi-structured interviews with seven security managers from large-scale German companies. Our results indicate that due to the absence of organizational structures that include users into security development processes, security managers unintentionally obtain a negative view on users. Their distrust towards users leads to the creation of technical security measures that cannot be influenced by users in any way. However, as previous research has repeatedly shown, rigid security measures lead to frustration and discouragement of users, and also to creative (but usually insecure) methods of security circumvention. We conclude that in order to break through this vicious cycle, security managers need organizational structures, methods and tools that facilitate systematic feedback from users."
pn3773,https://doi.org/10.1145/3290605.3300663,Security Managers Are Not The Enemy Either,3,Zinaida Benenson,Friedrich-Alexander-Universität Erlangen-Nürnberg,Erlangen,Germany,true,false,"Security managers are leading employees whose decisions shape security measures and thus influence the everyday work of all users in their organizations. To understand how security managers handle user requirements and behavior, we conducted semi-structured interviews with seven security managers from large-scale German companies. Our results indicate that due to the absence of organizational structures that include users into security development processes, security managers unintentionally obtain a negative view on users. Their distrust towards users leads to the creation of technical security measures that cannot be influenced by users in any way. However, as previous research has repeatedly shown, rigid security measures lead to frustration and discouragement of users, and also to creative (but usually insecure) methods of security circumvention. We conclude that in order to break through this vicious cycle, security managers need organizational structures, methods and tools that facilitate systematic feedback from users."
pn9132,https://doi.org/10.1145/3290605.3300901,"Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers",1,Nora Mcdonald,Drexel University,Philadelphia,United States,false,false,Anonymity can enable both healthy online interactions like support-seeking and toxic behaviors like hate speech. How do online service providers balance these threats and opportunities? This two-part qualitative study examines the challenges perceived by open collaboration service providers in allowing anonymous contributions to their projects. We interviewed eleven people familiar with organizational decisions related to privacy and security at five open collaboration projects and followed up with an analysis of public discussions about anonymous contribution to Wikipedia. We contrast our findings with prior work on threats perceived by project volunteers and explore misalignment between policies aiming to serve contributors and the privacy practices of contributors themselves.
pn9132,https://doi.org/10.1145/3290605.3300901,"Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers",2,Benjamin Mako Hill,University of Washington,Seattle,United States,false,false,Anonymity can enable both healthy online interactions like support-seeking and toxic behaviors like hate speech. How do online service providers balance these threats and opportunities? This two-part qualitative study examines the challenges perceived by open collaboration service providers in allowing anonymous contributions to their projects. We interviewed eleven people familiar with organizational decisions related to privacy and security at five open collaboration projects and followed up with an analysis of public discussions about anonymous contribution to Wikipedia. We contrast our findings with prior work on threats perceived by project volunteers and explore misalignment between policies aiming to serve contributors and the privacy practices of contributors themselves.
pn9132,https://doi.org/10.1145/3290605.3300901,"Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers",3,Rachel Greenstadt,New York University,New York,United States,false,false,Anonymity can enable both healthy online interactions like support-seeking and toxic behaviors like hate speech. How do online service providers balance these threats and opportunities? This two-part qualitative study examines the challenges perceived by open collaboration service providers in allowing anonymous contributions to their projects. We interviewed eleven people familiar with organizational decisions related to privacy and security at five open collaboration projects and followed up with an analysis of public discussions about anonymous contribution to Wikipedia. We contrast our findings with prior work on threats perceived by project volunteers and explore misalignment between policies aiming to serve contributors and the privacy practices of contributors themselves.
pn9132,https://doi.org/10.1145/3290605.3300901,"Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers",4,Andrea Forte,Drexel University,Philadelphia,United States,false,false,Anonymity can enable both healthy online interactions like support-seeking and toxic behaviors like hate speech. How do online service providers balance these threats and opportunities? This two-part qualitative study examines the challenges perceived by open collaboration service providers in allowing anonymous contributions to their projects. We interviewed eleven people familiar with organizational decisions related to privacy and security at five open collaboration projects and followed up with an analysis of public discussions about anonymous contribution to Wikipedia. We contrast our findings with prior work on threats perceived by project volunteers and explore misalignment between policies aiming to serve contributors and the privacy practices of contributors themselves.
pn1919,https://doi.org/10.1145/3290605.3300393,Towards Understanding the Link Between Age and Smartphone Authentication,1,Lina Qiu,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"While previous work on smartphone (un)locking has revealed real world usage patterns, several aspects still need to be explored. In this paper, we fill one of these knowledge gaps: the interplay between age and smartphone authentication behavior. To do this, we performed a two-month long field study (N = 134). Our results indicate that there are indeed significant differences across age. For instance, younger participants were more likely to use biometric unlocking mechanisms and older participants relied more on auto locks."
pn1919,https://doi.org/10.1145/3290605.3300393,Towards Understanding the Link Between Age and Smartphone Authentication,2,Alexander De Luca,Google,Zurich,Switzerland,false,false,"While previous work on smartphone (un)locking has revealed real world usage patterns, several aspects still need to be explored. In this paper, we fill one of these knowledge gaps: the interplay between age and smartphone authentication behavior. To do this, we performed a two-month long field study (N = 134). Our results indicate that there are indeed significant differences across age. For instance, younger participants were more likely to use biometric unlocking mechanisms and older participants relied more on auto locks."
pn1919,https://doi.org/10.1145/3290605.3300393,Towards Understanding the Link Between Age and Smartphone Authentication,3,Ildar Muslukhov,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"While previous work on smartphone (un)locking has revealed real world usage patterns, several aspects still need to be explored. In this paper, we fill one of these knowledge gaps: the interplay between age and smartphone authentication behavior. To do this, we performed a two-month long field study (N = 134). Our results indicate that there are indeed significant differences across age. For instance, younger participants were more likely to use biometric unlocking mechanisms and older participants relied more on auto locks."
pn1919,https://doi.org/10.1145/3290605.3300393,Towards Understanding the Link Between Age and Smartphone Authentication,4,Konstantin Beznosov,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"While previous work on smartphone (un)locking has revealed real world usage patterns, several aspects still need to be explored. In this paper, we fill one of these knowledge gaps: the interplay between age and smartphone authentication behavior. To do this, we performed a two-month long field study (N = 134). Our results indicate that there are indeed significant differences across age. For instance, younger participants were more likely to use biometric unlocking mechanisms and older participants relied more on auto locks."
pn8660,https://doi.org/10.1145/3290605.3300819,Vulnerability & Blame: Making Sense of Unauthorized Access to Smartphones,1,Diogo Marques,Universidade de Lisboa,Lisbon,Portugal,false,false,"Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice."
pn8660,https://doi.org/10.1145/3290605.3300819,Vulnerability & Blame: Making Sense of Unauthorized Access to Smartphones,2,Tiago Guerreiro,Universidade de Lisboa,Lisbon,Portugal,false,false,"Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice."
pn8660,https://doi.org/10.1145/3290605.3300819,Vulnerability & Blame: Making Sense of Unauthorized Access to Smartphones,3,Luis Carriço,Universidade de Lisboa,Lisbon,Portugal,false,false,"Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice."
pn8660,https://doi.org/10.1145/3290605.3300819,Vulnerability & Blame: Making Sense of Unauthorized Access to Smartphones,4,Ivan Beschastnikh,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice."
pn8660,https://doi.org/10.1145/3290605.3300819,Vulnerability & Blame: Making Sense of Unauthorized Access to Smartphones,5,Konstantin Beznosov,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,1,Mohamed Khamis,University of Glasgow,Glasgow,United Kingdom,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,2,Tobias Seitz,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,3,Leonhard Mertl,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,4,Alice Nguyen,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,5,Mario Schneller,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2675,https://doi.org/10.1145/3290605.3300916,Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by using Graphic Filters for Password Masking,6,Zhe Li,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches."
pn2303,https://doi.org/10.1145/3290605.3300381,"""Pretty Close to a Must-Have:"" Balancing Usability Desire and Security Concern in Biometric Adoption",1,Flynn Wolf,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"We report on a qualitative inquiry among security-expert and non-expert mobile device users about the adoption of biometric authentication using semi-structured interviews(n=38, 19/19 expert/non-expert). Security experts more readily adopted biometrics than non-experts but also harbored greater distrust towards its use for sensitive transactions,feared biometric signature compromise, and in some cases distrusted newer facial recognition methods. Both groups harbored misconceptions, such as misunderstanding of the functional role of biometrics in authentication, and were about equally likely to have stopped using biometrics due to usability. Implications include the need for tailored training for security-informed advocates, better design for device sharing and co-registration, and consideration for usability needs in work environments. Refinement of these features would remove perceived obstacles to ubiquitous computing among the growing population of mobile technology users sensitized to security risk."
pn2303,https://doi.org/10.1145/3290605.3300381,"""Pretty Close to a Must-Have:"" Balancing Usability Desire and Security Concern in Biometric Adoption",2,Ravi Kuber,"University of Maryland, Baltimore County",Baltimore,United States,false,false,"We report on a qualitative inquiry among security-expert and non-expert mobile device users about the adoption of biometric authentication using semi-structured interviews(n=38, 19/19 expert/non-expert). Security experts more readily adopted biometrics than non-experts but also harbored greater distrust towards its use for sensitive transactions,feared biometric signature compromise, and in some cases distrusted newer facial recognition methods. Both groups harbored misconceptions, such as misunderstanding of the functional role of biometrics in authentication, and were about equally likely to have stopped using biometrics due to usability. Implications include the need for tailored training for security-informed advocates, better design for device sharing and co-registration, and consideration for usability needs in work environments. Refinement of these features would remove perceived obstacles to ubiquitous computing among the growing population of mobile technology users sensitized to security risk."
pn2303,https://doi.org/10.1145/3290605.3300381,"""Pretty Close to a Must-Have:"" Balancing Usability Desire and Security Concern in Biometric Adoption",3,Adam Aviv,United States Naval Academy,Annapolis,United States,false,false,"We report on a qualitative inquiry among security-expert and non-expert mobile device users about the adoption of biometric authentication using semi-structured interviews(n=38, 19/19 expert/non-expert). Security experts more readily adopted biometrics than non-experts but also harbored greater distrust towards its use for sensitive transactions,feared biometric signature compromise, and in some cases distrusted newer facial recognition methods. Both groups harbored misconceptions, such as misunderstanding of the functional role of biometrics in authentication, and were about equally likely to have stopped using biometrics due to usability. Implications include the need for tailored training for security-informed advocates, better design for device sharing and co-registration, and consideration for usability needs in work environments. Refinement of these features would remove perceived obstacles to ubiquitous computing among the growing population of mobile technology users sensitized to security risk."
pn6238,https://doi.org/10.1145/3290605.3300423,A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation,1,Jacob Ritchie,University of Toronto,Toronto,Canada,false,false,"Designers are often discouraged from creating data visualizations that omit or distort information, because they can easily be misleading. However, the same representations that could be used to deceive can provide benefits when chosen to appropriately align with user tasks. We present an interaction technique, Perceptual Glimpses, which allows for the transparent presentation of so-called 'deceptive' views of information that are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level exaggeration caused by a truncated axis on a bar chart was reduced under some conditions, but users require guidance to avoid errors, and view presentation order may affect trust. When Perceptual Glimpses was extended to display a range of views that might otherwise be deceptive or difficult to understand if shown out of context, users were able to understand and leverage these transformations to perform a range of low-level tasks. Design recommendations and examples suggest extensions of the technique."
pn6238,https://doi.org/10.1145/3290605.3300423,A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation,2,Daniel Wigdor,University of Toronto,Toronto,Canada,false,false,"Designers are often discouraged from creating data visualizations that omit or distort information, because they can easily be misleading. However, the same representations that could be used to deceive can provide benefits when chosen to appropriately align with user tasks. We present an interaction technique, Perceptual Glimpses, which allows for the transparent presentation of so-called 'deceptive' views of information that are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level exaggeration caused by a truncated axis on a bar chart was reduced under some conditions, but users require guidance to avoid errors, and view presentation order may affect trust. When Perceptual Glimpses was extended to display a range of views that might otherwise be deceptive or difficult to understand if shown out of context, users were able to understand and leverage these transformations to perform a range of low-level tasks. Design recommendations and examples suggest extensions of the technique."
pn6238,https://doi.org/10.1145/3290605.3300423,A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation,3,Fanny Chevalier,University of Toronto,Toronto,Canada,false,false,"Designers are often discouraged from creating data visualizations that omit or distort information, because they can easily be misleading. However, the same representations that could be used to deceive can provide benefits when chosen to appropriately align with user tasks. We present an interaction technique, Perceptual Glimpses, which allows for the transparent presentation of so-called 'deceptive' views of information that are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level exaggeration caused by a truncated axis on a bar chart was reduced under some conditions, but users require guidance to avoid errors, and view presentation order may affect trust. When Perceptual Glimpses was extended to display a range of views that might otherwise be deceptive or difficult to understand if shown out of context, users were able to understand and leverage these transformations to perform a range of low-level tasks. Design recommendations and examples suggest extensions of the technique."
pn5257,https://doi.org/10.1145/3290605.3300576,Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment,1,Ha-Kyung Kong,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants."
pn5257,https://doi.org/10.1145/3290605.3300576,Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment,2,Zhicheng Liu,Adobe Research,Seattle,United States,false,false,"Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants."
pn5257,https://doi.org/10.1145/3290605.3300576,Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment,3,Karrie Karahalios,Adobe Research,Urbana,United States,false,false,"Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants."
pn5024,https://doi.org/10.1145/3290605.3300418,Ethical Dimensions of Visualization Research,1,Michael Correll,Tableau Research,Seattle,United States,true,false,"Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations."
pn8432,https://doi.org/10.1145/3290605.3300748,Put Your Warning Where Your Link Is: Improving and Evaluating Email Phishing Warnings,1,Justin Petelka,University of Washington,Seattle,United States,true,false,"Phishing emails often disguise a link's actual URL. Thus, common anti-phishing advice is to check a link's URL before clicking, but email clients do not support this well. Automated phishing detection enables email clients to warn users that an email is suspicious, but current warnings are often not specific. We evaluated the effects on phishing susceptibility of (1) moving phishing warnings close to the suspicious link in the email, (2) displaying the warning on hover interactions with the link, and (3) forcing attention to the warning by deactivating the original link, forcing users to click the URL in the warning. We assessed the effectiveness of such link-focused phishing warning designs in a between-subjects online experiment (n=701). We found that link-focused phishing warnings reduced phishing click-through rates compared to email banner warnings; forced attention warnings were most effective. We discuss the implications of our findings for phishing warning design."
pn8432,https://doi.org/10.1145/3290605.3300748,Put Your Warning Where Your Link Is: Improving and Evaluating Email Phishing Warnings,2,Yixin Zou,University of Michigan,Ann Arbor,United States,true,false,"Phishing emails often disguise a link's actual URL. Thus, common anti-phishing advice is to check a link's URL before clicking, but email clients do not support this well. Automated phishing detection enables email clients to warn users that an email is suspicious, but current warnings are often not specific. We evaluated the effects on phishing susceptibility of (1) moving phishing warnings close to the suspicious link in the email, (2) displaying the warning on hover interactions with the link, and (3) forcing attention to the warning by deactivating the original link, forcing users to click the URL in the warning. We assessed the effectiveness of such link-focused phishing warning designs in a between-subjects online experiment (n=701). We found that link-focused phishing warnings reduced phishing click-through rates compared to email banner warnings; forced attention warnings were most effective. We discuss the implications of our findings for phishing warning design."
pn8432,https://doi.org/10.1145/3290605.3300748,Put Your Warning Where Your Link Is: Improving and Evaluating Email Phishing Warnings,3,Florian Schaub,University of Michigan,Ann Arbor,United States,true,false,"Phishing emails often disguise a link's actual URL. Thus, common anti-phishing advice is to check a link's URL before clicking, but email clients do not support this well. Automated phishing detection enables email clients to warn users that an email is suspicious, but current warnings are often not specific. We evaluated the effects on phishing susceptibility of (1) moving phishing warnings close to the suspicious link in the email, (2) displaying the warning on hover interactions with the link, and (3) forcing attention to the warning by deactivating the original link, forcing users to click the URL in the warning. We assessed the effectiveness of such link-focused phishing warning designs in a between-subjects online experiment (n=701). We found that link-focused phishing warnings reduced phishing click-through rates compared to email banner warnings; forced attention warnings were most effective. We discuss the implications of our findings for phishing warning design."
pn7786,https://doi.org/10.1145/3290605.3300299,Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability,1,Juergen Baumgartner,University of Fribourg,Fribourg,Switzerland,true,false,"We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices."
pn7786,https://doi.org/10.1145/3290605.3300299,Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability,2,Naomi Frei,University of Fribourg,Fribourg,Switzerland,true,false,"We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices."
pn7786,https://doi.org/10.1145/3290605.3300299,Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability,3,Mascha Kleinke,University of Fribourg,Fribourg,Switzerland,true,false,"We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices."
pn7786,https://doi.org/10.1145/3290605.3300299,Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability,4,Juergen Sauer,University of Fribourg,Fribourg,Switzerland,true,false,"We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices."
pn7786,https://doi.org/10.1145/3290605.3300299,Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability,5,Andreas Sonderegger,EPFL,Lausanne,Switzerland,true,false,"We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices."
pn3398,https://doi.org/10.1145/3290605.3300293,HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation,1,Jorge Piazentin Ono,New York University,New York,United States,true,false,"The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way."
pn3398,https://doi.org/10.1145/3290605.3300293,HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation,2,Arvi Gjoka,New York University,New York,United States,true,false,"The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way."
pn3398,https://doi.org/10.1145/3290605.3300293,HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation,3,Justin Salamon,New York University,New York,United States,true,false,"The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way."
pn3398,https://doi.org/10.1145/3290605.3300293,HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation,4,Carlos Dietrich,New York University,New York University,United States,true,false,"The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way."
pn3398,https://doi.org/10.1145/3290605.3300293,HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation,5,Claudio Silva,New York University,New York,United States,true,false,"The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way."
pn7312,https://doi.org/10.1145/3290605.3300449,Interpreting the Diversity in Subjective Judgments,1,Jean-Bernard Martens,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"In a CHI paper from 10 years ago, entitled ""Accounting for Diversity in Subjective Judgments"", an interesting dichotomy was reported between, on the one side, the increased use of idiosyncratic constructs when judging the user experience of diverse products and, on the other hand, the statistical methods available to analyze such data. The paper more specifically proposed a method to extract diverse perspectives (called views) from experimental data. The current paper provides three improvements of this existing method by: 1) showing that a little-known approach for clustering attributes, called VARCLUS, can be applied and extended to provide a more optimal algorithm, 2) showing how the VARCLUS method can be applied to perform both within- and across-subject analysis, and 3) providing access to the VARCLUS method by incorporating it in ILLMO, a user-friendly and freely available program for interactive statistics."
pn1990,https://doi.org/10.1145/3290605.3300672,Ten-Minute Silence: A New Notification UX of Mobile Instant Messenger,1,In-Geon Shin,KAIST,Daejeon,Republic Of Korea,false,false,"People receive a tremendous number of messages through mobile instant messaging (MIM), which generates crowded notifications. This study highlights our attempt to create a new notification rule to reduce this crowdedness, which can be recognized by both senders and recipients. We developed an MIM app that provides only one notification per conversation session, which is a group of consecutive messages distinguished based on a ten-minute silence period. Through the two-week field study, 20,957 message logs and interview data from 17 participants revealed that MIM notifications affect not only the recipients' experiences before opening the app but also the entire conversation experience, including that of the senders. The new notification rule created new social norms for the participants' use of MIM. We report themes about the changes in the MIM experience, which will expand the role of notifications for future MIM apps."
pn1990,https://doi.org/10.1145/3290605.3300672,Ten-Minute Silence: A New Notification UX of Mobile Instant Messenger,2,Jin-Min Seok,KAIST,Daejeon,Republic Of Korea,false,false,"People receive a tremendous number of messages through mobile instant messaging (MIM), which generates crowded notifications. This study highlights our attempt to create a new notification rule to reduce this crowdedness, which can be recognized by both senders and recipients. We developed an MIM app that provides only one notification per conversation session, which is a group of consecutive messages distinguished based on a ten-minute silence period. Through the two-week field study, 20,957 message logs and interview data from 17 participants revealed that MIM notifications affect not only the recipients' experiences before opening the app but also the entire conversation experience, including that of the senders. The new notification rule created new social norms for the participants' use of MIM. We report themes about the changes in the MIM experience, which will expand the role of notifications for future MIM apps."
pn1990,https://doi.org/10.1145/3290605.3300672,Ten-Minute Silence: A New Notification UX of Mobile Instant Messenger,3,Youn-Kyung Lim,KAIST,Daejeon,Republic Of Korea,false,false,"People receive a tremendous number of messages through mobile instant messaging (MIM), which generates crowded notifications. This study highlights our attempt to create a new notification rule to reduce this crowdedness, which can be recognized by both senders and recipients. We developed an MIM app that provides only one notification per conversation session, which is a group of consecutive messages distinguished based on a ten-minute silence period. Through the two-week field study, 20,957 message logs and interview data from 17 participants revealed that MIM notifications affect not only the recipients' experiences before opening the app but also the entire conversation experience, including that of the senders. The new notification rule created new social norms for the participants' use of MIM. We report themes about the changes in the MIM experience, which will expand the role of notifications for future MIM apps."
pn2584,https://doi.org/10.1145/3290605.3300697,Overcoming Distractions during Transitions from Break to Work using a Conversational Website-Blocking System,1,Vincent Tseng,Cornell University,Ithaca,United States,false,false,"Work breaks--both physical and digital--play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged ""cyberloafing"". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully."
pn2584,https://doi.org/10.1145/3290605.3300697,Overcoming Distractions during Transitions from Break to Work using a Conversational Website-Blocking System,2,Matthew Lee,FXPAL,Palo Alto,United States,false,false,"Work breaks--both physical and digital--play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged ""cyberloafing"". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully."
pn2584,https://doi.org/10.1145/3290605.3300697,Overcoming Distractions during Transitions from Break to Work using a Conversational Website-Blocking System,3,Laurent Denoue,FXPAL,Palo Alto,United States,false,false,"Work breaks--both physical and digital--play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged ""cyberloafing"". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully."
pn2584,https://doi.org/10.1145/3290605.3300697,Overcoming Distractions during Transitions from Break to Work using a Conversational Website-Blocking System,4,Daniel Avrahami,FXPAL,Palo Alto,United States,false,false,"Work breaks--both physical and digital--play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged ""cyberloafing"". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully."
pn8266,https://doi.org/10.1145/3290605.3300758,Poirot: A Web Inspector for Designers,1,Kesler Tanner,Stanford University,Stanford,United States,true,false,"To better understand the issues designers face as they interact with developers and use developer tools to create websites, we conducted a formative investigation consisting of interviews, a survey, and an analysis of professional design documents. Based on insights gained from these efforts, we developed Poirot, a web inspection tool for designers that enables them to make style edits to websites using a familiar graphical interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals. We observed common problems designers experience when using Chrome DevTools and found that when using Poirot, designers were more successful in accomplishing typical design tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived cognitive load and was overwhelmingly preferred by the designers in our study."
pn8266,https://doi.org/10.1145/3290605.3300758,Poirot: A Web Inspector for Designers,2,Naomi Johnson,University of Virginia,Charlottesville,United States,true,false,"To better understand the issues designers face as they interact with developers and use developer tools to create websites, we conducted a formative investigation consisting of interviews, a survey, and an analysis of professional design documents. Based on insights gained from these efforts, we developed Poirot, a web inspection tool for designers that enables them to make style edits to websites using a familiar graphical interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals. We observed common problems designers experience when using Chrome DevTools and found that when using Poirot, designers were more successful in accomplishing typical design tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived cognitive load and was overwhelmingly preferred by the designers in our study."
pn8266,https://doi.org/10.1145/3290605.3300758,Poirot: A Web Inspector for Designers,3,James Landay,Stanford University,Stanford,United States,true,false,"To better understand the issues designers face as they interact with developers and use developer tools to create websites, we conducted a formative investigation consisting of interviews, a survey, and an analysis of professional design documents. Based on insights gained from these efforts, we developed Poirot, a web inspection tool for designers that enables them to make style edits to websites using a familiar graphical interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals. We observed common problems designers experience when using Chrome DevTools and found that when using Poirot, designers were more successful in accomplishing typical design tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived cognitive load and was overwhelmingly preferred by the designers in our study."
pn5716,https://doi.org/10.1145/3290605.3300738,Guideline-Based Evaluation of Web Readability,1,Aliaksei Miniukovich,University of Trento,Trento,Italy,false,false,"Effortless reading remains an issue for many Web users, despite a large number of readability guidelines available to designers. This paper presents a study of manual and automatic use of 39 readability guidelines in webpage evaluation. The study collected the ground-truth readability for a set of 50 webpages using eye-tracking with average and dyslexic readers (n = 79). It then matched the ground truth against human-based (n = 35) and automatic evaluations. The results validated 22 guidelines as being connected to readability. The comparison between human-based and automatic results also revealed a complex framework: algorithms were better or as good as human experts at evaluating webpages on specific guidelines – particularly those about low-level features of webpage legibility and text formatting. However, multiple guidelines still required a human judgment related to understanding and interpreting webpage content. These results contribute a guideline categorization laying the ground for future design evaluation methods."
pn5716,https://doi.org/10.1145/3290605.3300738,Guideline-Based Evaluation of Web Readability,2,Michele Scaltritti,Università degli Studi di Trento,Rovereto,Italy,false,false,"Effortless reading remains an issue for many Web users, despite a large number of readability guidelines available to designers. This paper presents a study of manual and automatic use of 39 readability guidelines in webpage evaluation. The study collected the ground-truth readability for a set of 50 webpages using eye-tracking with average and dyslexic readers (n = 79). It then matched the ground truth against human-based (n = 35) and automatic evaluations. The results validated 22 guidelines as being connected to readability. The comparison between human-based and automatic results also revealed a complex framework: algorithms were better or as good as human experts at evaluating webpages on specific guidelines – particularly those about low-level features of webpage legibility and text formatting. However, multiple guidelines still required a human judgment related to understanding and interpreting webpage content. These results contribute a guideline categorization laying the ground for future design evaluation methods."
pn5716,https://doi.org/10.1145/3290605.3300738,Guideline-Based Evaluation of Web Readability,3,Simone Sulpizio,Vita-Salute San Raffaele University,Milan,Italy,false,false,"Effortless reading remains an issue for many Web users, despite a large number of readability guidelines available to designers. This paper presents a study of manual and automatic use of 39 readability guidelines in webpage evaluation. The study collected the ground-truth readability for a set of 50 webpages using eye-tracking with average and dyslexic readers (n = 79). It then matched the ground truth against human-based (n = 35) and automatic evaluations. The results validated 22 guidelines as being connected to readability. The comparison between human-based and automatic results also revealed a complex framework: algorithms were better or as good as human experts at evaluating webpages on specific guidelines – particularly those about low-level features of webpage legibility and text formatting. However, multiple guidelines still required a human judgment related to understanding and interpreting webpage content. These results contribute a guideline categorization laying the ground for future design evaluation methods."
pn5716,https://doi.org/10.1145/3290605.3300738,Guideline-Based Evaluation of Web Readability,4,Antonella De Angeli,Free University of Bolzano,Bolzano,Italy,false,false,"Effortless reading remains an issue for many Web users, despite a large number of readability guidelines available to designers. This paper presents a study of manual and automatic use of 39 readability guidelines in webpage evaluation. The study collected the ground-truth readability for a set of 50 webpages using eye-tracking with average and dyslexic readers (n = 79). It then matched the ground truth against human-based (n = 35) and automatic evaluations. The results validated 22 guidelines as being connected to readability. The comparison between human-based and automatic results also revealed a complex framework: algorithms were better or as good as human experts at evaluating webpages on specific guidelines – particularly those about low-level features of webpage legibility and text formatting. However, multiple guidelines still required a human judgment related to understanding and interpreting webpage content. These results contribute a guideline categorization laying the ground for future design evaluation methods."
pn3996,https://doi.org/10.1145/3290605.3300754,The Impact of Web Browser Reader Views on Reading Speed and User Experience,1,Qisheng Li,University of Washington,Seattle,United States,false,false,"As reading increasingly shifts from paper to online media, many web browsers now provide a ""Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills."
pn3996,https://doi.org/10.1145/3290605.3300754,The Impact of Web Browser Reader Views on Reading Speed and User Experience,2,Meredith Morris,Microsoft Research,Redmond,United States,false,false,"As reading increasingly shifts from paper to online media, many web browsers now provide a ""Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills."
pn3996,https://doi.org/10.1145/3290605.3300754,The Impact of Web Browser Reader Views on Reading Speed and User Experience,3,Adam Fourney,Microsoft Research,Redmond,United States,false,false,"As reading increasingly shifts from paper to online media, many web browsers now provide a ""Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills."
pn3996,https://doi.org/10.1145/3290605.3300754,The Impact of Web Browser Reader Views on Reading Speed and User Experience,4,Kevin Larson,Microsoft,Redmond,United States,false,false,"As reading increasingly shifts from paper to online media, many web browsers now provide a ""Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills."
pn3996,https://doi.org/10.1145/3290605.3300754,The Impact of Web Browser Reader Views on Reading Speed and User Experience,5,Katharina Reinecke,University of Washington,Seattle,United States,false,false,"As reading increasingly shifts from paper to online media, many web browsers now provide a ""Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,1,Leah Findlater,University of Washington,Seattle,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,2,Bonnie Chinh,University of Washington,Seattle,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,3,Dhruv Jain,University of Washington,Seattle,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,4,Jon Froehlich,University of Washington,Seattle,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,5,Raja Kushalnagar,Gallaudet University,Washington,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn4748,https://doi.org/10.1145/3290605.3300276,Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies,6,Angela Lin,University of Washington,Seattle,United States,false,false,"To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,1,Dhruv Jain,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,2,Angela Lin,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,3,Rose Guttman,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,4,Marcus Amalachandran,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,5,Aileen Zeng,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,6,Leah Findlater,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn2227,https://doi.org/10.1145/3290605.3300324,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,7,Jon Froehlich,University of Washington,Seattle,United States,false,false,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust."
pn8704,https://doi.org/10.1145/3290605.3300531,"Social, Cultural and Systematic Frustrations Motivating the Formation of a DIY Hearing Loss Hacking Community",1,Aisling Ann O'kane,University of Bristol,Bristol,United Kingdom,false,false,"Research on attitudes to assistive technology (AT) has shown both the positive and negative impact of these technologies on quality of life. Building on this research, we examine the sociocultural and technological frustrations with hearing loss (HL) technologies that motivate personal approaches to solving these issues. Drawing on meet-up observations and contextual interview data, we detail participants' experiences of and attitudes towards hearing AT that influences hacking hearing loss. Hearing AT is misunderstood as a solution to the impairment, influencing one-to-one interactions, cultural norms, and systematic frustrations. Participants' exasperation with the slow development of top-down solutions has led some members to design and develop their own personalised solutions. Beyond capturing a segment of the growing DIY health and wellbeing phenomenon, our findings extend beyond implications for design to present recommendations for the hearing loss industry, policy makers, and importantly, for researchers engaging with grassroots DIY health movements."
pn8704,https://doi.org/10.1145/3290605.3300531,"Social, Cultural and Systematic Frustrations Motivating the Formation of a DIY Hearing Loss Hacking Community",2,Abdinasir Aliomar,University College London,London,United Kingdom,false,false,"Research on attitudes to assistive technology (AT) has shown both the positive and negative impact of these technologies on quality of life. Building on this research, we examine the sociocultural and technological frustrations with hearing loss (HL) technologies that motivate personal approaches to solving these issues. Drawing on meet-up observations and contextual interview data, we detail participants' experiences of and attitudes towards hearing AT that influences hacking hearing loss. Hearing AT is misunderstood as a solution to the impairment, influencing one-to-one interactions, cultural norms, and systematic frustrations. Participants' exasperation with the slow development of top-down solutions has led some members to design and develop their own personalised solutions. Beyond capturing a segment of the growing DIY health and wellbeing phenomenon, our findings extend beyond implications for design to present recommendations for the hearing loss industry, policy makers, and importantly, for researchers engaging with grassroots DIY health movements."
pn8704,https://doi.org/10.1145/3290605.3300531,"Social, Cultural and Systematic Frustrations Motivating the Formation of a DIY Hearing Loss Hacking Community",3,Rebecca Zheng,University College London,London,United Kingdom,false,false,"Research on attitudes to assistive technology (AT) has shown both the positive and negative impact of these technologies on quality of life. Building on this research, we examine the sociocultural and technological frustrations with hearing loss (HL) technologies that motivate personal approaches to solving these issues. Drawing on meet-up observations and contextual interview data, we detail participants' experiences of and attitudes towards hearing AT that influences hacking hearing loss. Hearing AT is misunderstood as a solution to the impairment, influencing one-to-one interactions, cultural norms, and systematic frustrations. Participants' exasperation with the slow development of top-down solutions has led some members to design and develop their own personalised solutions. Beyond capturing a segment of the growing DIY health and wellbeing phenomenon, our findings extend beyond implications for design to present recommendations for the hearing loss industry, policy makers, and importantly, for researchers engaging with grassroots DIY health movements."
pn8704,https://doi.org/10.1145/3290605.3300531,"Social, Cultural and Systematic Frustrations Motivating the Formation of a DIY Hearing Loss Hacking Community",4,Britta Schulte,University College London,London,United Kingdom,false,false,"Research on attitudes to assistive technology (AT) has shown both the positive and negative impact of these technologies on quality of life. Building on this research, we examine the sociocultural and technological frustrations with hearing loss (HL) technologies that motivate personal approaches to solving these issues. Drawing on meet-up observations and contextual interview data, we detail participants' experiences of and attitudes towards hearing AT that influences hacking hearing loss. Hearing AT is misunderstood as a solution to the impairment, influencing one-to-one interactions, cultural norms, and systematic frustrations. Participants' exasperation with the slow development of top-down solutions has led some members to design and develop their own personalised solutions. Beyond capturing a segment of the growing DIY health and wellbeing phenomenon, our findings extend beyond implications for design to present recommendations for the hearing loss industry, policy makers, and importantly, for researchers engaging with grassroots DIY health movements."
pn8704,https://doi.org/10.1145/3290605.3300531,"Social, Cultural and Systematic Frustrations Motivating the Formation of a DIY Hearing Loss Hacking Community",5,Gianluca Trombetta,Hearing Hacks,Barcelona,Spain,false,false,"Research on attitudes to assistive technology (AT) has shown both the positive and negative impact of these technologies on quality of life. Building on this research, we examine the sociocultural and technological frustrations with hearing loss (HL) technologies that motivate personal approaches to solving these issues. Drawing on meet-up observations and contextual interview data, we detail participants' experiences of and attitudes towards hearing AT that influences hacking hearing loss. Hearing AT is misunderstood as a solution to the impairment, influencing one-to-one interactions, cultural norms, and systematic frustrations. Participants' exasperation with the slow development of top-down solutions has led some members to design and develop their own personalised solutions. Beyond capturing a segment of the growing DIY health and wellbeing phenomenon, our findings extend beyond implications for design to present recommendations for the hearing loss industry, policy makers, and importantly, for researchers engaging with grassroots DIY health movements."
pn3004,https://doi.org/10.1145/3290605.3300259,Changing Perspective: A Co-Design Approach to Explore Future Possibilities of Divergent Hearing,1,Judith Dörrenbächer,University of Siegen,Siegen,Germany,false,false,"Conventional hearing aids frame hearing impairment almost exclusively as a problem. In the present paper, we took an alternative approach by focusing on positive future possibilities of 'divergent hearing'. To this end, we developed a method to speculate simultaneously about not-yet-experienced positive meanings and not-yet-existing technology. First, we gathered already existing activities in which divergent hearing was experienced as an advantage rather than as a burden. These activities were then condensed into 'Prompts of Positive Possibilities' (PPP), such as ""Creating a shelter to feel safe in"". In performative sessions, participants were given these PPPs and 'Open Probes' to enact novel everyday activities. This led to 26 possible meanings and according devices, such as ""Being able to listen back into the past with a rewinder"". The paper provides valuable insights into the interests and expectations of people with divergent hearing as well as a methodological contribution to a possibility-driven design."
pn3004,https://doi.org/10.1145/3290605.3300259,Changing Perspective: A Co-Design Approach to Explore Future Possibilities of Divergent Hearing,2,Marc Hassenzahl,University of Siegen,Siegen,Germany,false,false,"Conventional hearing aids frame hearing impairment almost exclusively as a problem. In the present paper, we took an alternative approach by focusing on positive future possibilities of 'divergent hearing'. To this end, we developed a method to speculate simultaneously about not-yet-experienced positive meanings and not-yet-existing technology. First, we gathered already existing activities in which divergent hearing was experienced as an advantage rather than as a burden. These activities were then condensed into 'Prompts of Positive Possibilities' (PPP), such as ""Creating a shelter to feel safe in"". In performative sessions, participants were given these PPPs and 'Open Probes' to enact novel everyday activities. This led to 26 possible meanings and according devices, such as ""Being able to listen back into the past with a rewinder"". The paper provides valuable insights into the interests and expectations of people with divergent hearing as well as a methodological contribution to a possibility-driven design."
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,1,Teng Han,University of Manitoba,Winnipeg,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,2,Jie Liu,"Institute of Software, Chinese Academy of Sciences",Beijing,China,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,3,Khalad Hasan,University of British Columbia - Okanagan,Kelowna,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,4,Mingming Fan,University of Toronto,Toronto,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,5,Junhyeok Kim,University of Manitoba,Winnipeg,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,6,Jiannan Li,University of Toronto,Toronto,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,7,Xiangmin Fan,"Institute of Software, Chinese Academy of Sciences",Beijing,China,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,8,Feng Tian,"Institute of Software, Chinese Academy of Sciences",Beijing,China,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,9,Edward Lank,University of Waterloo,Waterloo,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4873,https://doi.org/10.1145/3290605.3300731,PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones,10,Pourang Irani,University of Manitoba,Winnipeg,Canada,false,false,"Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction?"
pn4509,https://doi.org/10.1145/3290605.3300442,ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input,1,Christian Corsten,RWTH Aachen University,Aachen,Germany,false,false,"Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5"". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused significantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border."
pn4509,https://doi.org/10.1145/3290605.3300442,ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input,2,Marcel Lahaye,RWTH Aachen University,Aachen,Germany,false,false,"Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5"". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused significantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border."
pn4509,https://doi.org/10.1145/3290605.3300442,ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input,3,Jan Borchers,RWTH Aachen University,Aachen,Germany,false,false,"Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5"". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused significantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border."
pn4509,https://doi.org/10.1145/3290605.3300442,ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input,4,Simon Voelker,RWTH Aachen University,Aachen,Germany,false,false,"Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5"". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused significantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,1,Yang Zhang,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,2,Michel Pahud,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,3,Christian Holz,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,4,Haijun Xia,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,5,Gierad Laput,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,6,Michael Mcguffin,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,7,Xiao Tu,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,8,Andrew Mittereder,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,9,Fei Su,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,10,William Buxton,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn6323,https://doi.org/10.1145/3290605.3300285,Sensing Posture-Aware Pen+Touch Interaction on Tablets,11,Ken Hinckley,Microsoft Research,Redmond,United States,true,false,"Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference."
pn8854,https://doi.org/10.1145/3290605.3300430,Typing on Split Keyboards with Peripheral Vision,1,Yiqin Lu,Tsinghua University,Beijing,China,false,false,"Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well co-existed with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would significantly improve the text entry performance on a split keyboard."
pn8854,https://doi.org/10.1145/3290605.3300430,Typing on Split Keyboards with Peripheral Vision,2,Chun Yu,Tsinghua University,Beijing,China,false,false,"Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well co-existed with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would significantly improve the text entry performance on a split keyboard."
pn8854,https://doi.org/10.1145/3290605.3300430,Typing on Split Keyboards with Peripheral Vision,3,Shuyi Fan,Tsinghua University,Beijing,China,false,false,"Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well co-existed with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would significantly improve the text entry performance on a split keyboard."
pn8854,https://doi.org/10.1145/3290605.3300430,Typing on Split Keyboards with Peripheral Vision,4,Xiaojun Bi,Stony Brook University,Stony Brook,United States,false,false,"Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well co-existed with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would significantly improve the text entry performance on a split keyboard."
pn8854,https://doi.org/10.1145/3290605.3300430,Typing on Split Keyboards with Peripheral Vision,5,Yuanchun Shi,Tsinghua University,Beijing,China,false,false,"Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well co-existed with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would significantly improve the text entry performance on a split keyboard."
pn4550,https://doi.org/10.1145/3290605.3300472,Impulse Buying: Design Practices and Consumer Needs,1,Carol Moser,University of Michigan,Ann Arbor,United States,false,false,"E-commerce sites have an incentive to encourage impulse buying, even when not in the consumer's best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1, we find that e-commerce sites contain multiple features that encourage impulsive buying, including those that lower perceived risks, leverage social influence, and enhance perceived proximity to the product. Conversely, from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance, (b) enforce spending limits and postponement, (c) increase checkout effort, (d) make costs more salient, and (e) reduce product desire. These findings inform the design of ""friction'' technologies that help users make more deliberative consumer choices."
pn4550,https://doi.org/10.1145/3290605.3300472,Impulse Buying: Design Practices and Consumer Needs,2,Sarita Schoenebeck,University of Michigan,Ann Arbor,United States,false,false,"E-commerce sites have an incentive to encourage impulse buying, even when not in the consumer's best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1, we find that e-commerce sites contain multiple features that encourage impulsive buying, including those that lower perceived risks, leverage social influence, and enhance perceived proximity to the product. Conversely, from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance, (b) enforce spending limits and postponement, (c) increase checkout effort, (d) make costs more salient, and (e) reduce product desire. These findings inform the design of ""friction'' technologies that help users make more deliberative consumer choices."
pn4550,https://doi.org/10.1145/3290605.3300472,Impulse Buying: Design Practices and Consumer Needs,3,Paul Resnick,University of Michigan,Ann Arbor,United States,false,false,"E-commerce sites have an incentive to encourage impulse buying, even when not in the consumer's best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1, we find that e-commerce sites contain multiple features that encourage impulsive buying, including those that lower perceived risks, leverage social influence, and enhance perceived proximity to the product. Conversely, from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance, (b) enforce spending limits and postponement, (c) increase checkout effort, (d) make costs more salient, and (e) reduce product desire. These findings inform the design of ""friction'' technologies that help users make more deliberative consumer choices."
pn1800,https://doi.org/10.1145/3290605.3300535,How do People Sort by Ratings?,1,Jerry Talton,"Carta, Inc.",New York,United States,false,false,"Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting --- comparing averages --- unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask ""How do people sort by ratings?"" In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users' preferences."
pn1800,https://doi.org/10.1145/3290605.3300535,How do People Sort by Ratings?,2,Krishna Dusad,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting --- comparing averages --- unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask ""How do people sort by ratings?"" In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users' preferences."
pn1800,https://doi.org/10.1145/3290605.3300535,How do People Sort by Ratings?,3,Konstantinos Koiliaris,University of Illinois at Urbana-Champaign,Champaign,United States,false,false,"Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting --- comparing averages --- unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask ""How do people sort by ratings?"" In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users' preferences."
pn1800,https://doi.org/10.1145/3290605.3300535,How do People Sort by Ratings?,4,Ranjitha Kumar,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting --- comparing averages --- unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask ""How do people sort by ratings?"" In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users' preferences."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,1,Chris Elsden,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,2,Ludwig Trotter,Lancaster University,Lancaster,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,3,Mike Harding,Lancaster University,Lancaster,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,4,Nigel Davies,Lancaster University,Lancaster,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,5,Chris Speed,Edinburgh University,Edinburgh,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn6623,https://doi.org/10.1145/3290605.3300609,Programmable Donations: Exploring Escrow-Based Conditional Giving,6,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general."
pn9853,https://doi.org/10.1145/3290605.3300887,Inalienability: Understanding Digital Gifts,1,Jocelyn Spence,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper takes on one of the rarely articulated yet important questions pertaining to digital media objects: how do HCI and design researchers understand 'gifting' when the object can just as easily be 'shared'? This question has often been implied and occasionally answered, though only partially. We propose the concept of 'inalienability', taken from the gifting literature, as a useful theory for clarifying what design researchers mean by gifting in a digital context. We apply 'inalienability' to three papers from the ACM Digital Library and one ongoing project, spanning nearly two decades of HCI and design research, that combine 'gifting and 'sharing' in their frameworks. In this way we show how applying the concept of 'inalienability' can clarify behaviours that mark gifting as a unique activity, frame research questions around gifting and sharing, outline specific next steps for gifting research, and suggest design strategies in this area."
pn5636,https://doi.org/10.1145/3290605.3300923,HapTwist: Creating Interactive Haptic Proxies in Virtual Reality Using Low-cost Twistable Artefacts,1,Kening Zhu,City University of Hong Kong,Hong Kong,China,false,false,"In this paper, we present a series of studies on using Rubik's Twist, a type of low-cost twistable artefact, to create haptic proxies for various hand-graspable VR objects. Our pilot studies validated the feasibility and effectiveness of Rubik's-Twist-based haptic proxies. The pilot results also revealed user challenges in the physical shape creation, motivating the development of the HapTwist toolkit. The toolkit consists of the shape-generation algorithm, the software interface for shape-construction guidance and interaction authoring, and the hardware modules for constructing interactive haptic proxies. The user studies showed that HapTwist was easy to learn and use, and it significantly improved user performance in creating interactive haptic proxies with Rubik's Twist. Furthermore, HapTwist-generated haptic proxies achieved similar VR experience as the real objects."
pn5636,https://doi.org/10.1145/3290605.3300923,HapTwist: Creating Interactive Haptic Proxies in Virtual Reality Using Low-cost Twistable Artefacts,2,Taizhou Chen,City University of Hong Kong,Hong Kong,China,false,false,"In this paper, we present a series of studies on using Rubik's Twist, a type of low-cost twistable artefact, to create haptic proxies for various hand-graspable VR objects. Our pilot studies validated the feasibility and effectiveness of Rubik's-Twist-based haptic proxies. The pilot results also revealed user challenges in the physical shape creation, motivating the development of the HapTwist toolkit. The toolkit consists of the shape-generation algorithm, the software interface for shape-construction guidance and interaction authoring, and the hardware modules for constructing interactive haptic proxies. The user studies showed that HapTwist was easy to learn and use, and it significantly improved user performance in creating interactive haptic proxies with Rubik's Twist. Furthermore, HapTwist-generated haptic proxies achieved similar VR experience as the real objects."
pn5636,https://doi.org/10.1145/3290605.3300923,HapTwist: Creating Interactive Haptic Proxies in Virtual Reality Using Low-cost Twistable Artefacts,3,Feng Han,Hong Kong University of Science and Technology,Hong Kong,China,false,false,"In this paper, we present a series of studies on using Rubik's Twist, a type of low-cost twistable artefact, to create haptic proxies for various hand-graspable VR objects. Our pilot studies validated the feasibility and effectiveness of Rubik's-Twist-based haptic proxies. The pilot results also revealed user challenges in the physical shape creation, motivating the development of the HapTwist toolkit. The toolkit consists of the shape-generation algorithm, the software interface for shape-construction guidance and interaction authoring, and the hardware modules for constructing interactive haptic proxies. The user studies showed that HapTwist was easy to learn and use, and it significantly improved user performance in creating interactive haptic proxies with Rubik's Twist. Furthermore, HapTwist-generated haptic proxies achieved similar VR experience as the real objects."
pn5636,https://doi.org/10.1145/3290605.3300923,HapTwist: Creating Interactive Haptic Proxies in Virtual Reality Using Low-cost Twistable Artefacts,4,Yi-Shiun Wu,EPFL,Lausanne,Switzerland,false,false,"In this paper, we present a series of studies on using Rubik's Twist, a type of low-cost twistable artefact, to create haptic proxies for various hand-graspable VR objects. Our pilot studies validated the feasibility and effectiveness of Rubik's-Twist-based haptic proxies. The pilot results also revealed user challenges in the physical shape creation, motivating the development of the HapTwist toolkit. The toolkit consists of the shape-generation algorithm, the software interface for shape-construction guidance and interaction authoring, and the hardware modules for constructing interactive haptic proxies. The user studies showed that HapTwist was easy to learn and use, and it significantly improved user performance in creating interactive haptic proxies with Rubik's Twist. Furthermore, HapTwist-generated haptic proxies achieved similar VR experience as the real objects."
pn8661,https://doi.org/10.1145/3290605.3300566,Hands Holding Clues for Object Recognition in Teachable Machines,1,Kyungjun Lee,"University of Maryland, College Park",College Park,United States,false,false,"Camera manipulation confounds the use of object recognition applications by blind people. This is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. Leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classification. We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We confirm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. With a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers."
pn8661,https://doi.org/10.1145/3290605.3300566,Hands Holding Clues for Object Recognition in Teachable Machines,2,Hernisa Kacorri,"University of Maryland, College Park",College Park,United States,false,false,"Camera manipulation confounds the use of object recognition applications by blind people. This is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. Leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classification. We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We confirm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. With a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers."
pn3483,https://doi.org/10.1145/3290605.3300504,Active Edge: Designing Squeeze Gestures for the Google Pixel 2,1,Philip Quinn,Google,Mountain View,United States,false,false,"Active Edge is a feature of Google Pixel 2 smartphone devices that creates a force-sensitive interaction surface along their sides, allowing users to perform gestures by holding and squeezing their device. Supported by strain gauge elements adhered to the inner sidewalls of the device chassis, these gestures can be more natural and ergonomic than on-screen (touch) counterparts. Developing these interactions is an integration of several components: (1) an insight and understanding of the user experiences that benefit from squeeze gestures; (2) hardware with the sensitivity and reliability to sense a user's squeeze in any operating environment; (3) a gesture design that discriminates intentional squeezes from innocuous handling; and (4) an interaction design to promote a discoverable and satisfying user experience. This paper describes the design and evaluation of Active Edge in these areas as part of the product's development and engineering."
pn3483,https://doi.org/10.1145/3290605.3300504,Active Edge: Designing Squeeze Gestures for the Google Pixel 2,2,Seungyon Lee,Google,Mountain View,United States,false,false,"Active Edge is a feature of Google Pixel 2 smartphone devices that creates a force-sensitive interaction surface along their sides, allowing users to perform gestures by holding and squeezing their device. Supported by strain gauge elements adhered to the inner sidewalls of the device chassis, these gestures can be more natural and ergonomic than on-screen (touch) counterparts. Developing these interactions is an integration of several components: (1) an insight and understanding of the user experiences that benefit from squeeze gestures; (2) hardware with the sensitivity and reliability to sense a user's squeeze in any operating environment; (3) a gesture design that discriminates intentional squeezes from innocuous handling; and (4) an interaction design to promote a discoverable and satisfying user experience. This paper describes the design and evaluation of Active Edge in these areas as part of the product's development and engineering."
pn3483,https://doi.org/10.1145/3290605.3300504,Active Edge: Designing Squeeze Gestures for the Google Pixel 2,3,Melissa Barnhart,Google,Mountain View,United States,false,false,"Active Edge is a feature of Google Pixel 2 smartphone devices that creates a force-sensitive interaction surface along their sides, allowing users to perform gestures by holding and squeezing their device. Supported by strain gauge elements adhered to the inner sidewalls of the device chassis, these gestures can be more natural and ergonomic than on-screen (touch) counterparts. Developing these interactions is an integration of several components: (1) an insight and understanding of the user experiences that benefit from squeeze gestures; (2) hardware with the sensitivity and reliability to sense a user's squeeze in any operating environment; (3) a gesture design that discriminates intentional squeezes from innocuous handling; and (4) an interaction design to promote a discoverable and satisfying user experience. This paper describes the design and evaluation of Active Edge in these areas as part of the product's development and engineering."
pn3483,https://doi.org/10.1145/3290605.3300504,Active Edge: Designing Squeeze Gestures for the Google Pixel 2,4,Shumin Zhai,Google,Mountain View,United States,false,false,"Active Edge is a feature of Google Pixel 2 smartphone devices that creates a force-sensitive interaction surface along their sides, allowing users to perform gestures by holding and squeezing their device. Supported by strain gauge elements adhered to the inner sidewalls of the device chassis, these gestures can be more natural and ergonomic than on-screen (touch) counterparts. Developing these interactions is an integration of several components: (1) an insight and understanding of the user experiences that benefit from squeeze gestures; (2) hardware with the sensitivity and reliability to sense a user's squeeze in any operating environment; (3) a gesture design that discriminates intentional squeezes from innocuous handling; and (4) an interaction design to promote a discoverable and satisfying user experience. This paper describes the design and evaluation of Active Edge in these areas as part of the product's development and engineering."
pn1284,https://doi.org/10.1145/3290605.3300244,RotoSwype: Word-Gesture Typing using a Ring,1,Aakar Gupta,University of Waterloo,Waterloo,Canada,false,false,"We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques."
pn1284,https://doi.org/10.1145/3290605.3300244,RotoSwype: Word-Gesture Typing using a Ring,2,Cheng Ji,University of Waterloo,Waterloo,Canada,false,false,"We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques."
pn1284,https://doi.org/10.1145/3290605.3300244,RotoSwype: Word-Gesture Typing using a Ring,3,Hui-Shyong Yeo,University of St Andrews,Fife,United Kingdom,false,false,"We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques."
pn1284,https://doi.org/10.1145/3290605.3300244,RotoSwype: Word-Gesture Typing using a Ring,4,Aaron Quigley,University of St Andrews,St Andrews,United Kingdom,false,false,"We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques."
pn1284,https://doi.org/10.1145/3290605.3300244,RotoSwype: Word-Gesture Typing using a Ring,5,Daniel Vogel,University of Waterloo,Waterloo,Canada,false,false,"We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques."
pn1270,https://doi.org/10.1145/3290605.3300304,Causeway: Scaling Situated Learning with Micro-Role Hierarchies,1,David Lee,"University of California, Santa Cruz",Santa Cruz,United States,true,false,"While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-of-concept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles."
pn1270,https://doi.org/10.1145/3290605.3300304,Causeway: Scaling Situated Learning with Micro-Role Hierarchies,2,Emily Hamedian,"University of California, Santa Cruz",Santa Cruz,United States,true,false,"While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-of-concept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles."
pn1270,https://doi.org/10.1145/3290605.3300304,Causeway: Scaling Situated Learning with Micro-Role Hierarchies,3,Greg Wolff,"University of California, Santa Cruz",Santa Cruz,United States,true,false,"While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-of-concept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles."
pn1270,https://doi.org/10.1145/3290605.3300304,Causeway: Scaling Situated Learning with Micro-Role Hierarchies,4,Amy Liu,LinkedIn,Sunnyvale,United States,true,false,"While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-of-concept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles."
pn2144,https://doi.org/10.1145/3290605.3300668,Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning,1,Di (Laura) Chen,University of Toronto,Toronto,Canada,false,false,"Online language lessons have adopted live broadcasted videos to provide more real-time interactive experiences between language teachers and learners. However, learner interactions are primarily limited to the built-in text chat in the live stream. Using text alone, learners cannot get feedback on important aspects of a language, such as speaking skills, that are afforded only by offering richer types of interactions. We present results from a 2-week in-the-wild study, in which we investigate the use of text, audio, video, image, and stickers as interaction tools for language teachers and learners in live streaming. Our language teacher explored three different teaching strategies over four live streamed English lessons, while nine students watched and interacted using multimodal tools. The findings reveal that multimodal communication yields instant feedback and increased engagement, but its use is dependent on factors such as group size, surroundings, time, and online identity."
pn2144,https://doi.org/10.1145/3290605.3300668,Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning,2,Dustin Freeman,Escape Character Inc.,Toronto,Canada,false,false,"Online language lessons have adopted live broadcasted videos to provide more real-time interactive experiences between language teachers and learners. However, learner interactions are primarily limited to the built-in text chat in the live stream. Using text alone, learners cannot get feedback on important aspects of a language, such as speaking skills, that are afforded only by offering richer types of interactions. We present results from a 2-week in-the-wild study, in which we investigate the use of text, audio, video, image, and stickers as interaction tools for language teachers and learners in live streaming. Our language teacher explored three different teaching strategies over four live streamed English lessons, while nine students watched and interacted using multimodal tools. The findings reveal that multimodal communication yields instant feedback and increased engagement, but its use is dependent on factors such as group size, surroundings, time, and online identity."
pn2144,https://doi.org/10.1145/3290605.3300668,Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning,3,Ravin Balakrishnan,University of Toronto,Toronto,Canada,false,false,"Online language lessons have adopted live broadcasted videos to provide more real-time interactive experiences between language teachers and learners. However, learner interactions are primarily limited to the built-in text chat in the live stream. Using text alone, learners cannot get feedback on important aspects of a language, such as speaking skills, that are afforded only by offering richer types of interactions. We present results from a 2-week in-the-wild study, in which we investigate the use of text, audio, video, image, and stickers as interaction tools for language teachers and learners in live streaming. Our language teacher explored three different teaching strategies over four live streamed English lessons, while nine students watched and interacted using multimodal tools. The findings reveal that multimodal communication yields instant feedback and increased engagement, but its use is dependent on factors such as group size, surroundings, time, and online identity."
pn4310,https://doi.org/10.1145/3290605.3300662,How Do Distance Learners Connect?,1,Na Sun,Pennsylvania State University,State College,United States,true,false,"Distance learners often experience social isolation and impoverished social interaction with their remote peers. To better understand the connections that distance learners are able to build with peers, we interviewed them about whether and how they perceive or cultivate connections with one another. Our analysis reveals how connections in an online learning environment are formed and experienced across different social contexts and technology affordances, and what strategies and practices enable and inhibit these connections. We discuss the implications of our findings for concepts of shared identity and evolving peer relationships among online learners and for design directions that might address their social needs."
pn4310,https://doi.org/10.1145/3290605.3300662,How Do Distance Learners Connect?,2,Xiying Wang,Pennsylvania State University,University Park,United States,true,false,"Distance learners often experience social isolation and impoverished social interaction with their remote peers. To better understand the connections that distance learners are able to build with peers, we interviewed them about whether and how they perceive or cultivate connections with one another. Our analysis reveals how connections in an online learning environment are formed and experienced across different social contexts and technology affordances, and what strategies and practices enable and inhibit these connections. We discuss the implications of our findings for concepts of shared identity and evolving peer relationships among online learners and for design directions that might address their social needs."
pn4310,https://doi.org/10.1145/3290605.3300662,How Do Distance Learners Connect?,3,Mary Beth Rosson,Pennsylvania State University,University Park,United States,true,false,"Distance learners often experience social isolation and impoverished social interaction with their remote peers. To better understand the connections that distance learners are able to build with peers, we interviewed them about whether and how they perceive or cultivate connections with one another. Our analysis reveals how connections in an online learning environment are formed and experienced across different social contexts and technology affordances, and what strategies and practices enable and inhibit these connections. We discuss the implications of our findings for concepts of shared identity and evolving peer relationships among online learners and for design directions that might address their social needs."
pn9736,https://doi.org/10.1145/3290605.3300816,Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report,1,Namrata Srivastava,The University of Melbourne,Melbourne,Australia,false,false,"With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions."
pn9736,https://doi.org/10.1145/3290605.3300816,Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report,2,Eduardo Velloso,University of Melbourne,Melbourne,Australia,false,false,"With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions."
pn9736,https://doi.org/10.1145/3290605.3300816,Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report,3,Jason Lodge,University of Queensland,Brisbane,Australia,false,false,"With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions."
pn9736,https://doi.org/10.1145/3290605.3300816,Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report,4,Sarah Erfani,The University of Melbourne,Melbourne,Australia,false,false,"With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions."
pn9736,https://doi.org/10.1145/3290605.3300816,Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report,5,James Bailey,The University of Melbourne,Melbourne,Australia,false,false,"With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,1,Adrian Hazzard,University of Nottingham,Nottingham,United Kingdom,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,2,Chris Greenhalgh,University of Nottingham,Nottingham,United Kingdom,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,3,Maria Kallionpaa,Aalborg University,Aalborg,Denmark,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,4,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,5,Anne Veinberg,Leiden University,Leiden,Netherlands,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,6,Zubin Kanga,"Royal Holloway, University of London",Egham,United Kingdom,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn6187,https://doi.org/10.1145/3290605.3300260,Failing with Style: Designing for Aesthetic Failure in Interactive Performance,7,Andrew Mcpherson,Queen Mary University of London,London,United Kingdom,false,false,"Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system."
pn3132,https://doi.org/10.1145/3290605.3300369,Exploring the Plurality of Black Women's Gameplay Experiences,1,Yolanda Rankin,Florida State University,Tallahassee,United States,false,false,"Few gender-focused studies of video games explore the gameplay experiences of women of color, and those that do tend to only emphasize negative phenomena (i.e., racial or gender discrimination). In this paper, we conduct an exploratory case study attending to the motivations and gaming practices of Black college women. Questionnaire responses and focus group discussion illuminate the plurality of gameplay experiences for this specific population of Black college women. Sixty-five percent of this population enjoy the ubiquity of mobile games with casual and puzzle games being the most popular genres. However, academic responsibilities and competing recreational interests inhibit frequent gameplay. Consequently, this population of Black college women represent two types of casual gamers who report positive gameplay experiences, providing insights into creating a more inclusive gaming subculture."
pn3132,https://doi.org/10.1145/3290605.3300369,Exploring the Plurality of Black Women's Gameplay Experiences,2,Na-Eun Han,Florida State University,Tallahassee,United States,false,false,"Few gender-focused studies of video games explore the gameplay experiences of women of color, and those that do tend to only emphasize negative phenomena (i.e., racial or gender discrimination). In this paper, we conduct an exploratory case study attending to the motivations and gaming practices of Black college women. Questionnaire responses and focus group discussion illuminate the plurality of gameplay experiences for this specific population of Black college women. Sixty-five percent of this population enjoy the ubiquity of mobile games with casual and puzzle games being the most popular genres. However, academic responsibilities and competing recreational interests inhibit frequent gameplay. Consequently, this population of Black college women represent two types of casual gamers who report positive gameplay experiences, providing insights into creating a more inclusive gaming subculture."
pn3820,https://doi.org/10.1145/3290605.3300795,Behind the Voices: The Practice and Challenges of Esports Casters,1,Lucas Kempe-Cook,Indiana University,Bloomington,United States,false,false,"Casters commentate on a live, streamed video game for a large online audience. Drawing from 20 semi-structured interviews with amateur casters of either Dota 2 or Rocket League video games and over 20 hours of participant observations, we describe the distinctive practices of two types of casters, play-by-play and color commentary. Play-by-play casters are adept at improvising a rich narrative of hype on top of live games, whereas color commentators methodically prepare to fill in the gaps of live play with informative analysis. Casters often start out alone, relying upon reflective practice to hone their craft. Through examining challenges faced by amateur casters, we identified three design opportunities for game designers to support casters and would-be casters as first-class users. Such designs would provide an antidote to the challenges faced by amateur casters: those of the lack of social support for casting, camerawork, and data availability."
pn3820,https://doi.org/10.1145/3290605.3300795,Behind the Voices: The Practice and Challenges of Esports Casters,2,Stephen Sher,Indiana University,Bloomington,United States,false,false,"Casters commentate on a live, streamed video game for a large online audience. Drawing from 20 semi-structured interviews with amateur casters of either Dota 2 or Rocket League video games and over 20 hours of participant observations, we describe the distinctive practices of two types of casters, play-by-play and color commentary. Play-by-play casters are adept at improvising a rich narrative of hype on top of live games, whereas color commentators methodically prepare to fill in the gaps of live play with informative analysis. Casters often start out alone, relying upon reflective practice to hone their craft. Through examining challenges faced by amateur casters, we identified three design opportunities for game designers to support casters and would-be casters as first-class users. Such designs would provide an antidote to the challenges faced by amateur casters: those of the lack of social support for casting, camerawork, and data availability."
pn3820,https://doi.org/10.1145/3290605.3300795,Behind the Voices: The Practice and Challenges of Esports Casters,3,Norman Su,Indiana University,Bloomington,United States,false,false,"Casters commentate on a live, streamed video game for a large online audience. Drawing from 20 semi-structured interviews with amateur casters of either Dota 2 or Rocket League video games and over 20 hours of participant observations, we describe the distinctive practices of two types of casters, play-by-play and color commentary. Play-by-play casters are adept at improvising a rich narrative of hype on top of live games, whereas color commentators methodically prepare to fill in the gaps of live play with informative analysis. Casters often start out alone, relying upon reflective practice to hone their craft. Through examining challenges faced by amateur casters, we identified three design opportunities for game designers to support casters and would-be casters as first-class users. Such designs would provide an antidote to the challenges faced by amateur casters: those of the lack of social support for casting, camerawork, and data availability."
pn3554,https://doi.org/10.1145/3290605.3300453,The Role of Gaming During Difficult Life Experiences,1,Ioanna Iacovides,University of York,York,United Kingdom,false,false,"HCI has become increasingly interested in the use of technology during difficult life experiences. Yet despite considerable popularity, little is known about how and why people engage with games in times of personal difficulty. Based on a qualitative analysis of an online survey (N=95), our findings indicate that games offered players much needed respite from stress, supported them in dealing with their feelings, facilitated social connections, stimulated personal change and growth, and provided a lifeline in times of existential doubt. However, despite an emphasis on gaming as being able to support coping in ways other activities did not, participants also referred to games as unproductive and as an obstacle to living well. We discuss these findings in relation to both coping process and outcome, while considering tensions around the potential benefits and perceived value of gaming."
pn3554,https://doi.org/10.1145/3290605.3300453,The Role of Gaming During Difficult Life Experiences,2,Elisa Mekler,University of Basel,Basel,Switzerland,false,false,"HCI has become increasingly interested in the use of technology during difficult life experiences. Yet despite considerable popularity, little is known about how and why people engage with games in times of personal difficulty. Based on a qualitative analysis of an online survey (N=95), our findings indicate that games offered players much needed respite from stress, supported them in dealing with their feelings, facilitated social connections, stimulated personal change and growth, and provided a lifeline in times of existential doubt. However, despite an emphasis on gaming as being able to support coping in ways other activities did not, participants also referred to games as unproductive and as an obstacle to living well. We discuss these findings in relation to both coping process and outcome, while considering tensions around the potential benefits and perceived value of gaming."
pn6364,https://doi.org/10.1145/3290605.3300517,The Right to the Sustainable Smart City,1,Sara Heitlinger,"City, University of London",London,United Kingdom,true,false,"Environmental concerns have driven an interest in sustainable smart cities, through the monitoring and optimisation of networked infrastructures. At the same time, there are concerns about who these interventions and services are for, and who benefits. HCI researchers and designers interested in civic life have started to call for the democratisation of urban space through resistance and political action to challenge state and corporate claims. This paper contributes to an emerging body of work that seeks to involve citizens in the design of sustainable smart cities, particularly in the context of marginalised and culturally diverse urban communities. We present a study involving co-designing Internet of Things with urban agricultural communities and discuss three ways in which design can participate in the right to the sustainable smart city through designing for the commons, care, and biocultural diversity."
pn6364,https://doi.org/10.1145/3290605.3300517,The Right to the Sustainable Smart City,2,Nick Bryan-Kinns,Queen Mary University of London,London,United Kingdom,true,false,"Environmental concerns have driven an interest in sustainable smart cities, through the monitoring and optimisation of networked infrastructures. At the same time, there are concerns about who these interventions and services are for, and who benefits. HCI researchers and designers interested in civic life have started to call for the democratisation of urban space through resistance and political action to challenge state and corporate claims. This paper contributes to an emerging body of work that seeks to involve citizens in the design of sustainable smart cities, particularly in the context of marginalised and culturally diverse urban communities. We present a study involving co-designing Internet of Things with urban agricultural communities and discuss three ways in which design can participate in the right to the sustainable smart city through designing for the commons, care, and biocultural diversity."
pn6364,https://doi.org/10.1145/3290605.3300517,The Right to the Sustainable Smart City,3,Rob Comber,KTH Royal Institute of Technology,Stockholm,Sweden,true,false,"Environmental concerns have driven an interest in sustainable smart cities, through the monitoring and optimisation of networked infrastructures. At the same time, there are concerns about who these interventions and services are for, and who benefits. HCI researchers and designers interested in civic life have started to call for the democratisation of urban space through resistance and political action to challenge state and corporate claims. This paper contributes to an emerging body of work that seeks to involve citizens in the design of sustainable smart cities, particularly in the context of marginalised and culturally diverse urban communities. We present a study involving co-designing Internet of Things with urban agricultural communities and discuss three ways in which design can participate in the right to the sustainable smart city through designing for the commons, care, and biocultural diversity."
pn5162,https://doi.org/10.1145/3290605.3300547,Symbiotic Encounters: HCI and Sustainable Agriculture,1,Szu-Yu (Cyn) Liu,Indiana University,Bloomington,United States,true,false,"Recent sustainable HCI research has advocated ""working with nature"" as a potentially efficacious alternative to human efforts to control it: yet it is less clear how to do so. We contribute to the theoretical aspect of this research by presenting an ethnographic study on alternative farming practices, in which the farm is not so much a system but an assemblage characterized by multiple systems or rationalities always evolving and changing. In them, relationships among species alternate between mutually beneficial in one moment (or season), and harmful in the next. If HCI is to participate in and to support working with nature, we believe that it will have to situate itself within such assemblages and temporalities. In this work, we look into nontraditional users (e.g., nonhumans) and emerging forms of uses (e.g., interactions between human and other species) to help open a design space for technological interventions. We offer three ethnographic accounts in which farmers—and ourselves as researchers—learn to notice, respond, and engage in symbiotic encounters with companion species and the living soil itself."
pn5162,https://doi.org/10.1145/3290605.3300547,Symbiotic Encounters: HCI and Sustainable Agriculture,2,Shaowen Bardzell,Indiana University,Bloomington,United States,true,false,"Recent sustainable HCI research has advocated ""working with nature"" as a potentially efficacious alternative to human efforts to control it: yet it is less clear how to do so. We contribute to the theoretical aspect of this research by presenting an ethnographic study on alternative farming practices, in which the farm is not so much a system but an assemblage characterized by multiple systems or rationalities always evolving and changing. In them, relationships among species alternate between mutually beneficial in one moment (or season), and harmful in the next. If HCI is to participate in and to support working with nature, we believe that it will have to situate itself within such assemblages and temporalities. In this work, we look into nontraditional users (e.g., nonhumans) and emerging forms of uses (e.g., interactions between human and other species) to help open a design space for technological interventions. We offer three ethnographic accounts in which farmers—and ourselves as researchers—learn to notice, respond, and engage in symbiotic encounters with companion species and the living soil itself."
pn5162,https://doi.org/10.1145/3290605.3300547,Symbiotic Encounters: HCI and Sustainable Agriculture,3,Jeffrey Bardzell,Indiana University,Bloomington,United States,true,false,"Recent sustainable HCI research has advocated ""working with nature"" as a potentially efficacious alternative to human efforts to control it: yet it is less clear how to do so. We contribute to the theoretical aspect of this research by presenting an ethnographic study on alternative farming practices, in which the farm is not so much a system but an assemblage characterized by multiple systems or rationalities always evolving and changing. In them, relationships among species alternate between mutually beneficial in one moment (or season), and harmful in the next. If HCI is to participate in and to support working with nature, we believe that it will have to situate itself within such assemblages and temporalities. In this work, we look into nontraditional users (e.g., nonhumans) and emerging forms of uses (e.g., interactions between human and other species) to help open a design space for technological interventions. We offer three ethnographic accounts in which farmers—and ourselves as researchers—learn to notice, respond, and engage in symbiotic encounters with companion species and the living soil itself."
pn1991,https://doi.org/10.1145/3290605.3300375,Sharing Economy Design Cards,1,Anton Fedosov,Università della Svizzera italiana,Lugano,Switzerland,false,false,"Sharing economy services have become increasingly popular. In addition to various well-known for-profit activities in this space (e.g., ride and apartment sharing), many community groups and non-profit organizations offer collections of shared things (e.g., books, tools) that explicitly aim to benefit local communities. We expect that both non-profit and for-profit approaches will see an increased use in the future. To support designers in devising new sharing economy services, we developed the Sharing Economy Design Cards, a design toolkit in the form of a card deck. We present two deployments of the cards: (1) in individual interviews with 16 designers and sharing economy domain experts; and (2) in two workshops with 5 participants each. Our findings show that the use of the cards not only facilitates the creation of future sharing platforms and services in a collaborative setting, but also helps to evaluate existing sharing economy services as an individual activity."
pn1991,https://doi.org/10.1145/3290605.3300375,Sharing Economy Design Cards,2,Masako Kitazaki,"Fuji Xerox Co., Ltd.",Tokyo,Japan,false,false,"Sharing economy services have become increasingly popular. In addition to various well-known for-profit activities in this space (e.g., ride and apartment sharing), many community groups and non-profit organizations offer collections of shared things (e.g., books, tools) that explicitly aim to benefit local communities. We expect that both non-profit and for-profit approaches will see an increased use in the future. To support designers in devising new sharing economy services, we developed the Sharing Economy Design Cards, a design toolkit in the form of a card deck. We present two deployments of the cards: (1) in individual interviews with 16 designers and sharing economy domain experts; and (2) in two workshops with 5 participants each. Our findings show that the use of the cards not only facilitates the creation of future sharing platforms and services in a collaborative setting, but also helps to evaluate existing sharing economy services as an individual activity."
pn1991,https://doi.org/10.1145/3290605.3300375,Sharing Economy Design Cards,3,William Odom,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Sharing economy services have become increasingly popular. In addition to various well-known for-profit activities in this space (e.g., ride and apartment sharing), many community groups and non-profit organizations offer collections of shared things (e.g., books, tools) that explicitly aim to benefit local communities. We expect that both non-profit and for-profit approaches will see an increased use in the future. To support designers in devising new sharing economy services, we developed the Sharing Economy Design Cards, a design toolkit in the form of a card deck. We present two deployments of the cards: (1) in individual interviews with 16 designers and sharing economy domain experts; and (2) in two workshops with 5 participants each. Our findings show that the use of the cards not only facilitates the creation of future sharing platforms and services in a collaborative setting, but also helps to evaluate existing sharing economy services as an individual activity."
pn1991,https://doi.org/10.1145/3290605.3300375,Sharing Economy Design Cards,4,Marc Langheinrich,Università della Svizzera italiana,Lugano,Switzerland,false,false,"Sharing economy services have become increasingly popular. In addition to various well-known for-profit activities in this space (e.g., ride and apartment sharing), many community groups and non-profit organizations offer collections of shared things (e.g., books, tools) that explicitly aim to benefit local communities. We expect that both non-profit and for-profit approaches will see an increased use in the future. To support designers in devising new sharing economy services, we developed the Sharing Economy Design Cards, a design toolkit in the form of a card deck. We present two deployments of the cards: (1) in individual interviews with 16 designers and sharing economy domain experts; and (2) in two workshops with 5 participants each. Our findings show that the use of the cards not only facilitates the creation of future sharing platforms and services in a collaborative setting, but also helps to evaluate existing sharing economy services as an individual activity."
jrnl1125,https://doi.org/10.1145/3290607.3313847,Assisted Shifting of Electricity Use: A Long-Term Study of Managing Residential Heating,1,Rikke Hagensby Jensen,The Technical Faculty of IT and Design,Aalborg,Denmark,false,false,"Shifting is an energy-conserving interaction strategy for moving energy consumption to times where it is sustainably favorable. This interaction strategy is attracting increasing interest within sustainable HCI studies. While most of these consider how interactive technology can change household behavior, only a few report on how shifting is experienced in everyday life when assisted by automation. In this study, we investigate an interactive technology that assists households to shift electricity consumption to times when electricity is cheap or more sustainable. Our study was conducted as a long-term field deployment for 6-18 months with eight households, each living with an interactive prototype that shifts running times for a heat pump within user-defined boundaries. Our findings show that managing heat pumps toward assisted shifting was well-received by all households because it was a convenient way to shift electricity consumption. Shifting electricity use facilitated price savings of 6.8-16.9%. Nevertheless, our findings also reveal a conflict between the system design, and how householders actually interact with their heating system and experience assisted shifting. Based on the eight households' experiences, we present three overall themes of convenience, control, and complexity that each describes different aspects of long-term real-life use of automatic technology assisting households to shift electricity use. We discuss the broader implications of these findings and the role of design and future sustainability technology in everyday life."
jrnl1125,https://doi.org/10.1145/3290607.3313847,Assisted Shifting of Electricity Use: A Long-Term Study of Managing Residential Heating,2,Jesper Kjeldskov,Aalborg University,Aalborg,Denmark,false,false,"Shifting is an energy-conserving interaction strategy for moving energy consumption to times where it is sustainably favorable. This interaction strategy is attracting increasing interest within sustainable HCI studies. While most of these consider how interactive technology can change household behavior, only a few report on how shifting is experienced in everyday life when assisted by automation. In this study, we investigate an interactive technology that assists households to shift electricity consumption to times when electricity is cheap or more sustainable. Our study was conducted as a long-term field deployment for 6-18 months with eight households, each living with an interactive prototype that shifts running times for a heat pump within user-defined boundaries. Our findings show that managing heat pumps toward assisted shifting was well-received by all households because it was a convenient way to shift electricity consumption. Shifting electricity use facilitated price savings of 6.8-16.9%. Nevertheless, our findings also reveal a conflict between the system design, and how householders actually interact with their heating system and experience assisted shifting. Based on the eight households' experiences, we present three overall themes of convenience, control, and complexity that each describes different aspects of long-term real-life use of automatic technology assisting households to shift electricity use. We discuss the broader implications of these findings and the role of design and future sustainability technology in everyday life."
jrnl1125,https://doi.org/10.1145/3290607.3313847,Assisted Shifting of Electricity Use: A Long-Term Study of Managing Residential Heating,3,Mikael Skov,Aalborg University,Aalborg,Denmark,false,false,"Shifting is an energy-conserving interaction strategy for moving energy consumption to times where it is sustainably favorable. This interaction strategy is attracting increasing interest within sustainable HCI studies. While most of these consider how interactive technology can change household behavior, only a few report on how shifting is experienced in everyday life when assisted by automation. In this study, we investigate an interactive technology that assists households to shift electricity consumption to times when electricity is cheap or more sustainable. Our study was conducted as a long-term field deployment for 6-18 months with eight households, each living with an interactive prototype that shifts running times for a heat pump within user-defined boundaries. Our findings show that managing heat pumps toward assisted shifting was well-received by all households because it was a convenient way to shift electricity consumption. Shifting electricity use facilitated price savings of 6.8-16.9%. Nevertheless, our findings also reveal a conflict between the system design, and how householders actually interact with their heating system and experience assisted shifting. Based on the eight households' experiences, we present three overall themes of convenience, control, and complexity that each describes different aspects of long-term real-life use of automatic technology assisting households to shift electricity use. We discuss the broader implications of these findings and the role of design and future sustainability technology in everyday life."
pn3414,https://doi.org/10.1145/3290605.3300329,Empowerment on the Margins: The Online Experiences of Community Health Workers,1,Azra Ismail,Georgia Institute of Technology,Atlanta,United States,true,false,"Research in Human-Computer Interaction for Development (HCI4D) routinely relies on and engages with the increasing penetration of smartphones and the internet. We examine the mobile, internet, and social media practices of women community health workers, for whom internet access has newly become possible. These workers are uniquely positioned at the intersections of various communities of practice---their familial units, workplaces, networks of health workers, larger communities, and the online world. However, they remain at the margins of each, on account of difference in gender, class, literacies, professional expertise, and more. Our findings unpack the legitimate peripheral participation of these workers; examining how they appropriate smartphones and the internet to move away from the peripheries to fully participate in these communities. We discuss how their activities are motivated by moves towards empowerment, digitization, and improved healthcare provision. We consider how future work might support, leverage, and extend their efforts."
pn3414,https://doi.org/10.1145/3290605.3300329,Empowerment on the Margins: The Online Experiences of Community Health Workers,2,Neha Kumar,Georgia Institute of Technology,Atlanta,United States,true,false,"Research in Human-Computer Interaction for Development (HCI4D) routinely relies on and engages with the increasing penetration of smartphones and the internet. We examine the mobile, internet, and social media practices of women community health workers, for whom internet access has newly become possible. These workers are uniquely positioned at the intersections of various communities of practice---their familial units, workplaces, networks of health workers, larger communities, and the online world. However, they remain at the margins of each, on account of difference in gender, class, literacies, professional expertise, and more. Our findings unpack the legitimate peripheral participation of these workers; examining how they appropriate smartphones and the internet to move away from the peripheries to fully participate in these communities. We discuss how their activities are motivated by moves towards empowerment, digitization, and improved healthcare provision. We consider how future work might support, leverage, and extend their efforts."
pn3412,https://doi.org/10.1145/3290605.3300791,"Who Gets to Future? Race, Representation, and Design Methods in Africatown",1,Jasper Tran O'leary,University of Washington,Seattle,United States,false,false,"This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression."
pn3412,https://doi.org/10.1145/3290605.3300791,"Who Gets to Future? Race, Representation, and Design Methods in Africatown",2,Sara Zewde,Studio Zewde,Seattle,United States,false,false,"This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression."
pn3412,https://doi.org/10.1145/3290605.3300791,"Who Gets to Future? Race, Representation, and Design Methods in Africatown",3,Jennifer Mankoff,University of Washington,Seattle,United States,false,false,"This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression."
pn3412,https://doi.org/10.1145/3290605.3300791,"Who Gets to Future? Race, Representation, and Design Methods in Africatown",4,Daniela Rosner,University of Washington,Seattle,United States,false,false,"This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression."
pn8952,https://doi.org/10.1145/3290605.3300914,The Parenting Actor-Network of Latino Immigrants in the United States,1,Marisol Wong-Villacres,Escuela Superior Politecnica del Litoral,Atlanta,United States,false,false,"The field of Human-Computer Interaction (HCI) has shown a growing interest in how technology might support parenting. An area that remains underexplored is the design of technology to support parents from nondominant groups in positively impacting their children's education. Drawing on Actor-Network Theory (ANT), our paper takes a sociotechnical view of low-income Latino Spanish-speaking immigrants in the U.S.---a large nondominant group---attempting to form alliances with other actors such as teachers, the broader community, and technology to exchange information that might enrich their children's education. The use of ANT allowed us to advance work on parenting in HCI by providing a deeper understanding of the reasons---including attributes embedded in technology---impacting the quality of information channels in the parental engagement network of a nondominant group. Further, our ANT analysis illuminates a discussion of challenges and opportunities for technology to intervene in the network in ways that align with all actors' needs and harness their potentialities."
pn8952,https://doi.org/10.1145/3290605.3300914,The Parenting Actor-Network of Latino Immigrants in the United States,2,Neha Kumar,Georgia Institute of Technology,Atlanta,United States,false,false,"The field of Human-Computer Interaction (HCI) has shown a growing interest in how technology might support parenting. An area that remains underexplored is the design of technology to support parents from nondominant groups in positively impacting their children's education. Drawing on Actor-Network Theory (ANT), our paper takes a sociotechnical view of low-income Latino Spanish-speaking immigrants in the U.S.---a large nondominant group---attempting to form alliances with other actors such as teachers, the broader community, and technology to exchange information that might enrich their children's education. The use of ANT allowed us to advance work on parenting in HCI by providing a deeper understanding of the reasons---including attributes embedded in technology---impacting the quality of information channels in the parental engagement network of a nondominant group. Further, our ANT analysis illuminates a discussion of challenges and opportunities for technology to intervene in the network in ways that align with all actors' needs and harness their potentialities."
pn8952,https://doi.org/10.1145/3290605.3300914,The Parenting Actor-Network of Latino Immigrants in the United States,3,Betsy Disalvo,Georgia Institute of Technology,Atlanta,United States,false,false,"The field of Human-Computer Interaction (HCI) has shown a growing interest in how technology might support parenting. An area that remains underexplored is the design of technology to support parents from nondominant groups in positively impacting their children's education. Drawing on Actor-Network Theory (ANT), our paper takes a sociotechnical view of low-income Latino Spanish-speaking immigrants in the U.S.---a large nondominant group---attempting to form alliances with other actors such as teachers, the broader community, and technology to exchange information that might enrich their children's education. The use of ANT allowed us to advance work on parenting in HCI by providing a deeper understanding of the reasons---including attributes embedded in technology---impacting the quality of information channels in the parental engagement network of a nondominant group. Further, our ANT analysis illuminates a discussion of challenges and opportunities for technology to intervene in the network in ways that align with all actors' needs and harness their potentialities."
pn6717,https://doi.org/10.1145/3290605.3300810,Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia,1,Débora De Castro Leal,University of Siegen,Siegen,Germany,false,true,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict."
pn6717,https://doi.org/10.1145/3290605.3300810,Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia,2,Max Krüger,University of Siegen,Siegen,Germany,false,true,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict."
pn6717,https://doi.org/10.1145/3290605.3300810,Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia,3,Kaoru Misaki,International Institute of Socio-Informatics,Bonn,Germany,false,true,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict."
pn6717,https://doi.org/10.1145/3290605.3300810,Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia,4,Dave Randall,University of Siegen,Siegen,Germany,false,true,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict."
pn6717,https://doi.org/10.1145/3290605.3300810,Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia,5,Volker Wulf,University of Siegen,Siegen,Germany,false,true,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,1,Nam Wook Kim,Microsoft Research,Redmond,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,2,Nathalie Henry Riche,Microsoft Research,Redmond,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,3,Benjamin Bach,Edinburgh University,Edinburgh,United Kingdom,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,4,Guanpeng Xu,Phillips Academy,Andover,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,5,Matthew Brehmer,Microsoft Research,Redmond,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,6,Ken Hinckley,Microsoft Research,Redmond,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,7,Michel Pahud,Microsoft Research,Redmond,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,8,Haijun Xia,University of Toronto,Toronto,Canada,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,9,Michael Mcguffin,École de Technologie Supérieure ÉTS,Montreal,Canada,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn1744,https://doi.org/10.1145/3290605.3300335,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,10,Hanspeter Pfister,Harvard University,Cambridge,United States,false,false,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics."
pn8162,https://doi.org/10.1145/3290605.3300280,Understanding Visual Cues in Visualizations Accompanied by Audio Narrations,1,Ha Kyung Kong,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type."
pn8162,https://doi.org/10.1145/3290605.3300280,Understanding Visual Cues in Visualizations Accompanied by Audio Narrations,2,Wenjie Zhu,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type."
pn8162,https://doi.org/10.1145/3290605.3300280,Understanding Visual Cues in Visualizations Accompanied by Audio Narrations,3,Zhicheng Liu,Adobe Research,Seattle,United States,false,false,"It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type."
pn8162,https://doi.org/10.1145/3290605.3300280,Understanding Visual Cues in Visualizations Accompanied by Audio Narrations,4,Karrie Karahalios,Adobe Research,Urbana,United States,false,false,"It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,1,Zezhong Wang,Edinburgh University,Edinburgh,United Kingdom,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,2,Shunming Wang,Peking University,Beijing,China,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,3,Matteo Farinella,Columbia University,New York,United States,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,4,Dave Murray-Rust,Edinburgh University,Edinburgh,United Kingdom,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,5,Nathalie Henry Riche,Microsoft Research,Redmond,United States,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9942,https://doi.org/10.1145/3290605.3300483,Comparing Effectiveness and Engagement of Data Comics and Infographics,6,Benjamin Bach,Edinburgh University,Edinburgh,United Kingdom,false,false,"This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics."
pn9266,https://doi.org/10.1145/3290605.3300499,GameViews: Understanding and Supporting Data-driven Sports Storytelling,1,Qiyu Zhi,University of Notre Dame,Notre Dame,United States,true,false,"Various stakeholders in the sports domain rely on the analysis and presentation of sports data to derive insights. In particular, sportswriters construct game stories using statistical information; fans share their viewpoints based on the real-time stats while watching the game. In this paper, we explore how these stakeholders construct data-driven sports stories. We began by observing a sportswriter, then analyzed published sports stories, and characterized 1500 fan comments about particular sporting events. We found that their story needs were similar in some respects while quite different in others. Based on the findings, we implemented two exploratory prototypes: GameViews-Writers for sportswriters to quickly extract key game information and GameViews-Fans to support a real-time data-driven game-viewing experience for fans. We report insights from two user studies conducted with four professional sportswriters and eight sports fans, respectively. We discuss the results of these studies and present several avenues for future work."
pn9266,https://doi.org/10.1145/3290605.3300499,GameViews: Understanding and Supporting Data-driven Sports Storytelling,2,Suwen Lin,University of Notre Dame,Notre Dame,United States,true,false,"Various stakeholders in the sports domain rely on the analysis and presentation of sports data to derive insights. In particular, sportswriters construct game stories using statistical information; fans share their viewpoints based on the real-time stats while watching the game. In this paper, we explore how these stakeholders construct data-driven sports stories. We began by observing a sportswriter, then analyzed published sports stories, and characterized 1500 fan comments about particular sporting events. We found that their story needs were similar in some respects while quite different in others. Based on the findings, we implemented two exploratory prototypes: GameViews-Writers for sportswriters to quickly extract key game information and GameViews-Fans to support a real-time data-driven game-viewing experience for fans. We report insights from two user studies conducted with four professional sportswriters and eight sports fans, respectively. We discuss the results of these studies and present several avenues for future work."
pn9266,https://doi.org/10.1145/3290605.3300499,GameViews: Understanding and Supporting Data-driven Sports Storytelling,3,Poorna Talkad Sukumar,University of Notre Dame,South Bend,United States,true,false,"Various stakeholders in the sports domain rely on the analysis and presentation of sports data to derive insights. In particular, sportswriters construct game stories using statistical information; fans share their viewpoints based on the real-time stats while watching the game. In this paper, we explore how these stakeholders construct data-driven sports stories. We began by observing a sportswriter, then analyzed published sports stories, and characterized 1500 fan comments about particular sporting events. We found that their story needs were similar in some respects while quite different in others. Based on the findings, we implemented two exploratory prototypes: GameViews-Writers for sportswriters to quickly extract key game information and GameViews-Fans to support a real-time data-driven game-viewing experience for fans. We report insights from two user studies conducted with four professional sportswriters and eight sports fans, respectively. We discuss the results of these studies and present several avenues for future work."
pn9266,https://doi.org/10.1145/3290605.3300499,GameViews: Understanding and Supporting Data-driven Sports Storytelling,4,Ronald Metoyer,University of Notre Dame,South Bend,United States,true,false,"Various stakeholders in the sports domain rely on the analysis and presentation of sports data to derive insights. In particular, sportswriters construct game stories using statistical information; fans share their viewpoints based on the real-time stats while watching the game. In this paper, we explore how these stakeholders construct data-driven sports stories. We began by observing a sportswriter, then analyzed published sports stories, and characterized 1500 fan comments about particular sporting events. We found that their story needs were similar in some respects while quite different in others. Based on the findings, we implemented two exploratory prototypes: GameViews-Writers for sportswriters to quickly extract key game information and GameViews-Fans to support a real-time data-driven game-viewing experience for fans. We report insights from two user studies conducted with four professional sportswriters and eight sports fans, respectively. We discuss the results of these studies and present several avenues for future work."
pn4385,https://doi.org/10.1145/3290605.3300717,Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems,1,Johannes Kunkel,University of Duisburg-Essen,Duisburg,Germany,false,false,"Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness."
pn4385,https://doi.org/10.1145/3290605.3300717,Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems,2,Tim Donkers,University of Duisburg-Essen,Duisburg,Germany,false,false,"Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness."
pn4385,https://doi.org/10.1145/3290605.3300717,Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems,3,Lisa Michael,University of Duisburg-Essen,Duisburg,Germany,false,false,"Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness."
pn4385,https://doi.org/10.1145/3290605.3300717,Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems,4,Catalin-Mihai Barbu,University of Duisburg-Essen,Duisburg,Germany,false,false,"Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness."
pn4385,https://doi.org/10.1145/3290605.3300717,Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems,5,Jürgen Ziegler,University of Duisburg-Essen,Duisburg,Germany,false,false,"Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness."
pn5445,https://doi.org/10.1145/3290605.3300683,Search as News Curator: The Role of Google in Shaping Attention to News Information,1,Daniel Trielli,Northwestern University,Evanston,United States,true,false,"This paper presents an algorithm audit of the Google Top Stories box, a prominent component of search engine results and powerful driver of traffic to news publishers. As such, it is important in shaping user attention towards news outlets and topics. By analyzing the number of appearances of news article links we contribute a series of novel analyses that provide an in-depth characterization of news source diversity and its implications for attention via Google search. We present results indicating a considerable degree of source concentration (with variation among search terms), a slight exaggeration in the ideological skew of news in comparison to a baseline, and a quantification of how the presentation of items translates into traffic and attention for publishers. We contribute insights that underscore the power that Google wields in exposing users to diverse news information, and raise important questions and opportunities for future work on algorithmic news curation."
pn5445,https://doi.org/10.1145/3290605.3300683,Search as News Curator: The Role of Google in Shaping Attention to News Information,2,Nicholas Diakopoulos,Northwestern University,Evanston,United States,true,false,"This paper presents an algorithm audit of the Google Top Stories box, a prominent component of search engine results and powerful driver of traffic to news publishers. As such, it is important in shaping user attention towards news outlets and topics. By analyzing the number of appearances of news article links we contribute a series of novel analyses that provide an in-depth characterization of news source diversity and its implications for attention via Google search. We present results indicating a considerable degree of source concentration (with variation among search terms), a slight exaggeration in the ideological skew of news in comparison to a baseline, and a quantification of how the presentation of items translates into traffic and attention for publishers. We contribute insights that underscore the power that Google wields in exposing users to diverse news information, and raise important questions and opportunities for future work on algorithmic news curation."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,1,Caitlin Kuhlman,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,2,Diana Doherty,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,3,Malika Nurbekova,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,4,Goutham Deva,Worcester Polytechnic Intstitute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,5,Zarni Phyo,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,6,Paul-Henry Schoenhagen,Worcester Polytechnic Intstitute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,7,Maryann Vanvalkenburg,Worcester Polytechnic Intstitute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,8,Elke Rundensteiner,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn7885,https://doi.org/10.1145/3290605.3300742,Evaluating Preference Collection Methods for Interactive Ranking Analytics,9,Lane Harrison,Worcester Polytechnic Institute,Worcester,United States,false,false,"Rankings distill a large number of factors into simple comparative models to facilitate complex decision making. Yet key questions remain in the design of mixed-initiative systems for ranking, in particular how best to collect users' preferences to produce high-quality rankings that users trust and employ in the real world. To address this challenge we evaluate the relative merits of three preference collection methods for ranking in a crowdsourced study. We find that with a categorical binning technique, users interact with a large amount of data quickly, organizing information using broad strokes. Alternative interaction modes using pairwise comparisons or sub-lists result in smaller, targeted input from users. We consider how well each interaction mode addresses design goals for interactive ranking systems. Our study indicates that the categorical approach provides the best value-added benefit to users, requiring minimal effort to create sufficient training data for the underlying ranking algorithm."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,1,Dylan Moore,Stanford University,Stanford,United States,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,2,Tobias Dahl,SINTEF,Trondheim,Norway,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,3,Paula Varela,Nofima,Ås,Norway,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,4,Wendy Ju,Cornell Tech,New York,United States,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,5,Tormod Næs,Nofima,Ås,Norway,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn5846,https://doi.org/10.1145/3290605.3300730,Unintended Consonances: Methods to Understand Robot Motor Sound Perception,6,Ingunn Berget,Nofima,Ås,Norway,false,false,"Recent research suggests that a robot's motors make sounds that can influence users' perception of the robot's characteristics. To more deeply understand users' associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community."
pn3963,https://doi.org/10.1145/3290605.3300770,Do People Consume the News they Trust?,1,Harsh Taneja,University of Illinois Urbana-Champaign,Champaign-Urbana,United States,false,false,"It is reasonable to expect trusted news organizations to have more engaged users. However, given the lowest levels of trust in media and the several intermediaries involved in digital news consumption, recent studies posit that trust and usage may not be related. We argue that while trust may not relate to overall news usage, given that much of it is incidental, but it could still explain intentional usage. We correlated passively metered usage from digital trace data on 35 national news outlets in the US with their trustworthiness from a nationally representative survey, for three discrete months. We find no association between trust and overall user engagement, but a positive relationship between trustworthiness and direct visits, the latter a measure of intentional usage. These relationships held for outlets despite their partisan leanings, multi-platform presence and their mainstream nature."
pn3963,https://doi.org/10.1145/3290605.3300770,Do People Consume the News they Trust?,2,Katie Yaeger,University of Missouri,Columbia,United States,false,false,"It is reasonable to expect trusted news organizations to have more engaged users. However, given the lowest levels of trust in media and the several intermediaries involved in digital news consumption, recent studies posit that trust and usage may not be related. We argue that while trust may not relate to overall news usage, given that much of it is incidental, but it could still explain intentional usage. We correlated passively metered usage from digital trace data on 35 national news outlets in the US with their trustworthiness from a nationally representative survey, for three discrete months. We find no association between trust and overall user engagement, but a positive relationship between trustworthiness and direct visits, the latter a measure of intentional usage. These relationships held for outlets despite their partisan leanings, multi-platform presence and their mainstream nature."
pn2815,https://doi.org/10.1145/3290605.3300529,Just Give Me What I Want: How People Use and Evaluate Music Search,1,Christine Hosey,Spotify,Somerville,United States,false,false,"Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search."
pn2815,https://doi.org/10.1145/3290605.3300529,Just Give Me What I Want: How People Use and Evaluate Music Search,2,Lara Vujović,TripAdvisor,Needham,United States,false,false,"Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search."
pn2815,https://doi.org/10.1145/3290605.3300529,Just Give Me What I Want: How People Use and Evaluate Music Search,3,Brian St. Thomas,Spotify,Somerville,United States,false,false,"Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search."
pn2815,https://doi.org/10.1145/3290605.3300529,Just Give Me What I Want: How People Use and Evaluate Music Search,4,Jean Garcia-Gathright,Spotify,Somerville,United States,false,false,"Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search."
pn2815,https://doi.org/10.1145/3290605.3300529,Just Give Me What I Want: How People Use and Evaluate Music Search,5,Jennifer Thom,Spotify,Somerville,United States,false,false,"Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search."
pn6203,https://doi.org/10.1145/3290605.3300820,Understanding Online News Behaviors,1,Frank Bentley,Yahoo/Oath,Sunnyvale,United States,false,false,"The news landscape has been changing dramatically over the past few years. Whereas news once came from a small set of highly edited sources, now people can find news from thousands of news sites online, through a variety of channels such as web search, social media, email newsletters, or direct browsing. We set out to understand how Americans read news online using web browser logs collected from 174 diverse participants. We found that 20% of all news sessions started with a web search, that 16% started from social media, that 61% of news sessions only involved a single news domain, and that 47% of our participants read news from both sides of the political spectrum. We conclude with key implications for online news, social media, and search sites to encourage more balanced news browsing."
pn6203,https://doi.org/10.1145/3290605.3300820,Understanding Online News Behaviors,2,Katie Quehl,Yahoo/Oath,Sunnyvale,United States,false,false,"The news landscape has been changing dramatically over the past few years. Whereas news once came from a small set of highly edited sources, now people can find news from thousands of news sites online, through a variety of channels such as web search, social media, email newsletters, or direct browsing. We set out to understand how Americans read news online using web browser logs collected from 174 diverse participants. We found that 20% of all news sessions started with a web search, that 16% started from social media, that 61% of news sessions only involved a single news domain, and that 47% of our participants read news from both sides of the political spectrum. We conclude with key implications for online news, social media, and search sites to encourage more balanced news browsing."
pn6203,https://doi.org/10.1145/3290605.3300820,Understanding Online News Behaviors,3,Jordan Wirfs-Brock,Yahoo/Oath,Sunnyvale,United States,false,false,"The news landscape has been changing dramatically over the past few years. Whereas news once came from a small set of highly edited sources, now people can find news from thousands of news sites online, through a variety of channels such as web search, social media, email newsletters, or direct browsing. We set out to understand how Americans read news online using web browser logs collected from 174 diverse participants. We found that 20% of all news sessions started with a web search, that 16% started from social media, that 61% of news sessions only involved a single news domain, and that 47% of our participants read news from both sides of the political spectrum. We conclude with key implications for online news, social media, and search sites to encourage more balanced news browsing."
pn6203,https://doi.org/10.1145/3290605.3300820,Understanding Online News Behaviors,4,Melissa Bica,Yahoo/Oath,Sunnyvale,United States,false,false,"The news landscape has been changing dramatically over the past few years. Whereas news once came from a small set of highly edited sources, now people can find news from thousands of news sites online, through a variety of channels such as web search, social media, email newsletters, or direct browsing. We set out to understand how Americans read news online using web browser logs collected from 174 diverse participants. We found that 20% of all news sessions started with a web search, that 16% started from social media, that 61% of news sessions only involved a single news domain, and that 47% of our participants read news from both sides of the political spectrum. We conclude with key implications for online news, social media, and search sites to encourage more balanced news browsing."
pn1318,https://doi.org/10.1145/3290605.3300256,Impact of Contextual Factors on Snapchat Public Sharing,1,Hana Habib,Carnegie Mellon University,Pittsburgh,United States,true,false,"Public sharing is integral to online platforms. This includes the popular multimedia messaging application Snapchat, on which public sharing is relatively new and unexplored in prior research. In mobile-first applications, sharing contexts are dynamic. However, it is unclear how context impacts users' sharing decisions. As platforms increasingly rely on user-generated content, it is important to also broadly understand user motivations and considerations in public sharing. We explored these aspects of content sharing through a survey of 1,515 Snapchat users. Our results indicate that users primarily have intrinsic motivations for publicly sharing Snaps, such as to share an experience with the world, but also have considerations related to audience and sensitivity of content. Additionally, we found that Snaps shared publicly were contextually different from those privately shared. Our findings suggest that content sharing systems can be designed to support sharing motivations, yet also be sensitive to private contexts."
pn1318,https://doi.org/10.1145/3290605.3300256,Impact of Contextual Factors on Snapchat Public Sharing,2,Neil Shah,Snap Inc.,Santa Monica,United States,true,false,"Public sharing is integral to online platforms. This includes the popular multimedia messaging application Snapchat, on which public sharing is relatively new and unexplored in prior research. In mobile-first applications, sharing contexts are dynamic. However, it is unclear how context impacts users' sharing decisions. As platforms increasingly rely on user-generated content, it is important to also broadly understand user motivations and considerations in public sharing. We explored these aspects of content sharing through a survey of 1,515 Snapchat users. Our results indicate that users primarily have intrinsic motivations for publicly sharing Snaps, such as to share an experience with the world, but also have considerations related to audience and sensitivity of content. Additionally, we found that Snaps shared publicly were contextually different from those privately shared. Our findings suggest that content sharing systems can be designed to support sharing motivations, yet also be sensitive to private contexts."
pn1318,https://doi.org/10.1145/3290605.3300256,Impact of Contextual Factors on Snapchat Public Sharing,3,Rajan Vaish,Snap Inc.,Santa Monica,United States,true,false,"Public sharing is integral to online platforms. This includes the popular multimedia messaging application Snapchat, on which public sharing is relatively new and unexplored in prior research. In mobile-first applications, sharing contexts are dynamic. However, it is unclear how context impacts users' sharing decisions. As platforms increasingly rely on user-generated content, it is important to also broadly understand user motivations and considerations in public sharing. We explored these aspects of content sharing through a survey of 1,515 Snapchat users. Our results indicate that users primarily have intrinsic motivations for publicly sharing Snaps, such as to share an experience with the world, but also have considerations related to audience and sensitivity of content. Additionally, we found that Snaps shared publicly were contextually different from those privately shared. Our findings suggest that content sharing systems can be designed to support sharing motivations, yet also be sensitive to private contexts."
pn9973,https://doi.org/10.1145/3290605.3300838,Warping Deixis: Distorting Gestures to Enhance Collaboration,1,Maurício Sousa,INESC-ID Lisboa,Lisboa,Portugal,false,false,"When engaged in communication, people often rely on pointing gestures to refer to out-of-reach content. However, observers frequently misinterpret the target of a pointing gesture. Previous research suggests that to perform a pointing gesture, people place the index finger on or close to a line connecting the eye to the referent, while observers interpret pointing gestures by extrapolating the referent using a vector defined by the arm and index finger. In this paper we present Warping Deixis, a novel approach to improving the perception of pointing gestures and facilitate communication in collaborative Extended Reality environments. By warping the virtual representation of the pointing individual, we are able to match the pointing expression to the observer's perception. We evaluated our approach in a co-located side by side virtual reality scenario. Results suggest that our approach is effective in improving the interpretation of pointing gestures in shared virtual environments."
pn9973,https://doi.org/10.1145/3290605.3300838,Warping Deixis: Distorting Gestures to Enhance Collaboration,2,Rafael Dos Anjos,INESC-ID Lisboa,Lisboa,Portugal,false,false,"When engaged in communication, people often rely on pointing gestures to refer to out-of-reach content. However, observers frequently misinterpret the target of a pointing gesture. Previous research suggests that to perform a pointing gesture, people place the index finger on or close to a line connecting the eye to the referent, while observers interpret pointing gestures by extrapolating the referent using a vector defined by the arm and index finger. In this paper we present Warping Deixis, a novel approach to improving the perception of pointing gestures and facilitate communication in collaborative Extended Reality environments. By warping the virtual representation of the pointing individual, we are able to match the pointing expression to the observer's perception. We evaluated our approach in a co-located side by side virtual reality scenario. Results suggest that our approach is effective in improving the interpretation of pointing gestures in shared virtual environments."
pn9973,https://doi.org/10.1145/3290605.3300838,Warping Deixis: Distorting Gestures to Enhance Collaboration,3,Daniel Mendes,INESC-ID Lisboa,Lisboa,Portugal,false,false,"When engaged in communication, people often rely on pointing gestures to refer to out-of-reach content. However, observers frequently misinterpret the target of a pointing gesture. Previous research suggests that to perform a pointing gesture, people place the index finger on or close to a line connecting the eye to the referent, while observers interpret pointing gestures by extrapolating the referent using a vector defined by the arm and index finger. In this paper we present Warping Deixis, a novel approach to improving the perception of pointing gestures and facilitate communication in collaborative Extended Reality environments. By warping the virtual representation of the pointing individual, we are able to match the pointing expression to the observer's perception. We evaluated our approach in a co-located side by side virtual reality scenario. Results suggest that our approach is effective in improving the interpretation of pointing gestures in shared virtual environments."
pn9973,https://doi.org/10.1145/3290605.3300838,Warping Deixis: Distorting Gestures to Enhance Collaboration,4,Mark Billinghurst,University of South Australia,Mawson Lakes,Australia,false,false,"When engaged in communication, people often rely on pointing gestures to refer to out-of-reach content. However, observers frequently misinterpret the target of a pointing gesture. Previous research suggests that to perform a pointing gesture, people place the index finger on or close to a line connecting the eye to the referent, while observers interpret pointing gestures by extrapolating the referent using a vector defined by the arm and index finger. In this paper we present Warping Deixis, a novel approach to improving the perception of pointing gestures and facilitate communication in collaborative Extended Reality environments. By warping the virtual representation of the pointing individual, we are able to match the pointing expression to the observer's perception. We evaluated our approach in a co-located side by side virtual reality scenario. Results suggest that our approach is effective in improving the interpretation of pointing gestures in shared virtual environments."
pn9973,https://doi.org/10.1145/3290605.3300838,Warping Deixis: Distorting Gestures to Enhance Collaboration,5,Joaquim Jorge,INESC-ID Lisboa,Lisboa,Portugal,false,false,"When engaged in communication, people often rely on pointing gestures to refer to out-of-reach content. However, observers frequently misinterpret the target of a pointing gesture. Previous research suggests that to perform a pointing gesture, people place the index finger on or close to a line connecting the eye to the referent, while observers interpret pointing gestures by extrapolating the referent using a vector defined by the arm and index finger. In this paper we present Warping Deixis, a novel approach to improving the perception of pointing gestures and facilitate communication in collaborative Extended Reality environments. By warping the virtual representation of the pointing individual, we are able to match the pointing expression to the observer's perception. We evaluated our approach in a co-located side by side virtual reality scenario. Results suggest that our approach is effective in improving the interpretation of pointing gestures in shared virtual environments."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,1,Andrew Webb,"Texas A&M University and Inria, Université Paris-Saclay",Paris,France,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,2,Hannah Fowler,Texas A&M University,College Station,United States,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,3,Andruid Kerne,Texas A&M University,College Station,United States,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,4,Galen Newman,Texas A&M University,College Station,United States,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,5,Jun-Hyun Kim,Michigan State University,East Lansing,United States,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn2126,https://doi.org/10.1145/3290605.3300818,Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action,6,Wendy Mackay,INRIA,Paris,France,false,false,"Our observations of landscape architecture students revealed a new phenomenon—interstices. Their bimanual interactions with a pen and touch surface involved various sustained hand gestures, interleaved between their regular commands. Positioning of the non-preferred hand indicates anticipated actions, including: sustained hovering near the surface; pulled back but still floating above the surface; and resting in their laps. We ran a second study with 14 landscape architect students which confirmed our observations, and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting. We conclude with directions for future research and challenges for designers and researchers."
pn6181,https://doi.org/10.1145/3290605.3300437,The Effect of Stereo Display Deficiencies on Virtual Hand Pointing,1,Mayra Barrera Machuca,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"The limitations of stereo display systems affect depth perception, e.g., due to the vergence-accommodation conflict or diplopia. We performed three studies to understand how stereo display deficiencies impact 3D pointing for targets in front of a screen and close to the user, i.e., in peripersonal space. Our first two experiments compare movements with and without a change in visual depth for virtual respectively physical targets. Results indicate that selecting targets along the depth axis is slower and has less throughput for virtual targets, while physical pointing demonstrates the opposite result. We then propose a new 3D extension for Fitts' law that models the effect of stereo display deficiencies. Next, our third experiment verifies the model and measures more broadly how the change in visual depth between targets affects pointing performance in peripersonal space and confirms significant effects on time and throughput. Finally, we discuss implications for 3D user interface design."
pn6181,https://doi.org/10.1145/3290605.3300437,The Effect of Stereo Display Deficiencies on Virtual Hand Pointing,2,Wolfgang Stuerzlinger,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"The limitations of stereo display systems affect depth perception, e.g., due to the vergence-accommodation conflict or diplopia. We performed three studies to understand how stereo display deficiencies impact 3D pointing for targets in front of a screen and close to the user, i.e., in peripersonal space. Our first two experiments compare movements with and without a change in visual depth for virtual respectively physical targets. Results indicate that selecting targets along the depth axis is slower and has less throughput for virtual targets, while physical pointing demonstrates the opposite result. We then propose a new 3D extension for Fitts' law that models the effect of stereo display deficiencies. Next, our third experiment verifies the model and measures more broadly how the change in visual depth between targets affects pointing performance in peripersonal space and confirms significant effects on time and throughput. Finally, we discuss implications for 3D user interface design."
pn2413,https://doi.org/10.1145/3290605.3300706,Encumbered Interaction: a Study of Musicians Preparing to Perform,1,Juan Pablo Martinez Avila,The University of Nottingham,Nottingham,United Kingdom,true,false,"Guitars are physical instruments that require skillful two-handed use. Their use is also supported by diverse digital and physical resources, such as videos and chord charts. To understand the challenges of interacting with supporting resources at the same time as playing we conducted an ethnographic study of the preparation activities of working musicians. We observe successive stages of individual and collaborative preparation, in which working musicians engage with a diverse range of digital and physical resources to support their preparation. Interaction with this complex ecology of digital and physical resources is finely interwoven into their embodied musical practices, which are usually encumbered by having their instrument in hand, and often by playing. We identify challenges for augmenting guitars within the rehearsal process by supporting interaction that is encumbered, contextual and connected, and suggest a range of possible responses."
pn2413,https://doi.org/10.1145/3290605.3300706,Encumbered Interaction: a Study of Musicians Preparing to Perform,2,Chris Greenhalgh,The University of Nottingham,Nottingham,United Kingdom,true,false,"Guitars are physical instruments that require skillful two-handed use. Their use is also supported by diverse digital and physical resources, such as videos and chord charts. To understand the challenges of interacting with supporting resources at the same time as playing we conducted an ethnographic study of the preparation activities of working musicians. We observe successive stages of individual and collaborative preparation, in which working musicians engage with a diverse range of digital and physical resources to support their preparation. Interaction with this complex ecology of digital and physical resources is finely interwoven into their embodied musical practices, which are usually encumbered by having their instrument in hand, and often by playing. We identify challenges for augmenting guitars within the rehearsal process by supporting interaction that is encumbered, contextual and connected, and suggest a range of possible responses."
pn2413,https://doi.org/10.1145/3290605.3300706,Encumbered Interaction: a Study of Musicians Preparing to Perform,3,Adrian Hazzard,The University of Nottingham,Nottingham,United Kingdom,true,false,"Guitars are physical instruments that require skillful two-handed use. Their use is also supported by diverse digital and physical resources, such as videos and chord charts. To understand the challenges of interacting with supporting resources at the same time as playing we conducted an ethnographic study of the preparation activities of working musicians. We observe successive stages of individual and collaborative preparation, in which working musicians engage with a diverse range of digital and physical resources to support their preparation. Interaction with this complex ecology of digital and physical resources is finely interwoven into their embodied musical practices, which are usually encumbered by having their instrument in hand, and often by playing. We identify challenges for augmenting guitars within the rehearsal process by supporting interaction that is encumbered, contextual and connected, and suggest a range of possible responses."
pn2413,https://doi.org/10.1145/3290605.3300706,Encumbered Interaction: a Study of Musicians Preparing to Perform,4,Steve Benford,The University of Nottingham,Nottingham,United Kingdom,true,false,"Guitars are physical instruments that require skillful two-handed use. Their use is also supported by diverse digital and physical resources, such as videos and chord charts. To understand the challenges of interacting with supporting resources at the same time as playing we conducted an ethnographic study of the preparation activities of working musicians. We observe successive stages of individual and collaborative preparation, in which working musicians engage with a diverse range of digital and physical resources to support their preparation. Interaction with this complex ecology of digital and physical resources is finely interwoven into their embodied musical practices, which are usually encumbered by having their instrument in hand, and often by playing. We identify challenges for augmenting guitars within the rehearsal process by supporting interaction that is encumbered, contextual and connected, and suggest a range of possible responses."
pn2413,https://doi.org/10.1145/3290605.3300706,Encumbered Interaction: a Study of Musicians Preparing to Perform,5,Alan Chamberlain,The University of Nottingham,Nottingham,United Kingdom,true,false,"Guitars are physical instruments that require skillful two-handed use. Their use is also supported by diverse digital and physical resources, such as videos and chord charts. To understand the challenges of interacting with supporting resources at the same time as playing we conducted an ethnographic study of the preparation activities of working musicians. We observe successive stages of individual and collaborative preparation, in which working musicians engage with a diverse range of digital and physical resources to support their preparation. Interaction with this complex ecology of digital and physical resources is finely interwoven into their embodied musical practices, which are usually encumbered by having their instrument in hand, and often by playing. We identify challenges for augmenting guitars within the rehearsal process by supporting interaction that is encumbered, contextual and connected, and suggest a range of possible responses."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",1,Sylvain Pauchet,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",2,Jean-Luc Vinot,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",3,Catherine Letondal,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",4,Alexandre Lemort,Ingenuity i/o,Ramonville Saint-Agne,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",5,Claire Lavenir,Intactile Design,Montpellier,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",6,Timothée Lecomte,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",7,Stéphanie Rey,Berger-Levrault,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",8,Valentin Becquet,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn6777,https://doi.org/10.1145/3290605.3300384,"Multi-plié: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration",9,Guillaume Crouzet,University of Toulouse - ENAC,Toulouse,France,false,false,"We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations."
pn5910,https://doi.org/10.1145/3290605.3300355,Shape Changing Surfaces and Structures: Design Tools and Methods for Electroactive Polymers,1,Karmen Franinović,Zurich University of the Arts,Zurich,Switzerland,true,false,"Electroactive polymers (EAP) are a promising material for shape changing interfaces, soft robotics and other novel design explorations. However, the uptake of EAP prototyping in design, art and architecture has been slow due to limited commercial availability, challenging high voltage electronics and lack of simple fabrication techniques. This paper introduces DIY tools for building and activating EAP prototypes, together with design methods for making novel shape-changing surfaces and structures, outside of material science labs. We present iterations of our methods and tools, their use and evaluation in participatory workshops and public installations and how they affect the design outcomes. We discuss unique aesthetic and interactive experiences enabled by the organic and subtle movement of semi-transparent EAP membranes. Finally, we summarise the potential of design tools and methods to facilitate increased exploration of interactive EAP prototypes and outline future steps."
pn5910,https://doi.org/10.1145/3290605.3300355,Shape Changing Surfaces and Structures: Design Tools and Methods for Electroactive Polymers,2,Luke Franzke,Zurich University of the Arts,Zurich,Switzerland,true,false,"Electroactive polymers (EAP) are a promising material for shape changing interfaces, soft robotics and other novel design explorations. However, the uptake of EAP prototyping in design, art and architecture has been slow due to limited commercial availability, challenging high voltage electronics and lack of simple fabrication techniques. This paper introduces DIY tools for building and activating EAP prototypes, together with design methods for making novel shape-changing surfaces and structures, outside of material science labs. We present iterations of our methods and tools, their use and evaluation in participatory workshops and public installations and how they affect the design outcomes. We discuss unique aesthetic and interactive experiences enabled by the organic and subtle movement of semi-transparent EAP membranes. Finally, we summarise the potential of design tools and methods to facilitate increased exploration of interactive EAP prototypes and outline future steps."
pn5953,https://doi.org/10.1145/3290605.3300332,Finding Information on Non-Rectangular Interfaces,1,Florine Simon,University of Toulouse,Toulouse,France,false,false,"With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays."
pn5953,https://doi.org/10.1145/3290605.3300332,Finding Information on Non-Rectangular Interfaces,2,Anne Roudaut,University of Bristol,Bristol,United Kingdom,false,false,"With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays."
pn5953,https://doi.org/10.1145/3290605.3300332,Finding Information on Non-Rectangular Interfaces,3,Pourang Irani,University of Manitoba,Winnipeg,Canada,false,false,"With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays."
pn5953,https://doi.org/10.1145/3290605.3300332,Finding Information on Non-Rectangular Interfaces,4,Marcos Serrano,University of Toulouse,Toulouse,France,false,false,"With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,1,Jianzhe Gu,Carnegie Mellon University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,2,David Breen,Carnegie Mellon University,Philadelphia,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,3,Jenny Hu,Carnegie Mellon Univeristy,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,4,Lifeng Zhu,Southeast University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,5,Ye Tao,Zhejiang Univeristy,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,6,Tyson Van De Zande,Carnegie Mellon University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,7,Guanyun Wang,Carnegie Mellon University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,8,Yongjie Zhang,Carnegie Mellon University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn9335,https://doi.org/10.1145/3290605.3300267,Geodesy: Self-rising 2.5D Tiles by Printing along 2D Geodesic Closed Path,9,Lining Yao,Carnegie Mellon University,Pittsburgh,United States,false,false,"Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples."
pn7357,https://doi.org/10.1145/3290605.3300851,Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery,1,Haikun Huang,"University of Massachusetts, Boston",Boston,United States,false,false,"As 360 deg cameras and virtual reality headsets become more popular, panorama images have become increasingly ubiquitous. While sounds are essential in delivering immersive and interactive user experiences, most panorama images, however, do not come with native audio. In this paper, we propose an automatic algorithm to augment static panorama images through realistic audio assignment. We accomplish this goal through object detection, scene classification, object depth estimation, and audio source placement. We built an audio file database composed of over $500$ audio files to facilitate this process. We designed and conducted a user study to verify the efficacy of various components in our pipeline. We run our method on a large variety of panorama images of indoor and outdoor scenes. By analyzing the statistics, we learned the relative importance of these components, which can be used in prioritizing for power-sensitive time-critical tasks like mobile augmented reality (AR) applications."
pn7357,https://doi.org/10.1145/3290605.3300851,Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery,2,Michael Solah,"University of Massachusetts, Boston",Boston,United States,false,false,"As 360 deg cameras and virtual reality headsets become more popular, panorama images have become increasingly ubiquitous. While sounds are essential in delivering immersive and interactive user experiences, most panorama images, however, do not come with native audio. In this paper, we propose an automatic algorithm to augment static panorama images through realistic audio assignment. We accomplish this goal through object detection, scene classification, object depth estimation, and audio source placement. We built an audio file database composed of over $500$ audio files to facilitate this process. We designed and conducted a user study to verify the efficacy of various components in our pipeline. We run our method on a large variety of panorama images of indoor and outdoor scenes. By analyzing the statistics, we learned the relative importance of these components, which can be used in prioritizing for power-sensitive time-critical tasks like mobile augmented reality (AR) applications."
pn7357,https://doi.org/10.1145/3290605.3300851,Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery,3,Dingzeyu Li,Adobe Research,Seattle,United States,false,false,"As 360 deg cameras and virtual reality headsets become more popular, panorama images have become increasingly ubiquitous. While sounds are essential in delivering immersive and interactive user experiences, most panorama images, however, do not come with native audio. In this paper, we propose an automatic algorithm to augment static panorama images through realistic audio assignment. We accomplish this goal through object detection, scene classification, object depth estimation, and audio source placement. We built an audio file database composed of over $500$ audio files to facilitate this process. We designed and conducted a user study to verify the efficacy of various components in our pipeline. We run our method on a large variety of panorama images of indoor and outdoor scenes. By analyzing the statistics, we learned the relative importance of these components, which can be used in prioritizing for power-sensitive time-critical tasks like mobile augmented reality (AR) applications."
pn7357,https://doi.org/10.1145/3290605.3300851,Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery,4,Lap-Fai Yu,George Mason University,Fairfax,United States,false,false,"As 360 deg cameras and virtual reality headsets become more popular, panorama images have become increasingly ubiquitous. While sounds are essential in delivering immersive and interactive user experiences, most panorama images, however, do not come with native audio. In this paper, we propose an automatic algorithm to augment static panorama images through realistic audio assignment. We accomplish this goal through object detection, scene classification, object depth estimation, and audio source placement. We built an audio file database composed of over $500$ audio files to facilitate this process. We designed and conducted a user study to verify the efficacy of various components in our pipeline. We run our method on a large variety of panorama images of indoor and outdoor scenes. By analyzing the statistics, we learned the relative importance of these components, which can be used in prioritizing for power-sensitive time-critical tasks like mobile augmented reality (AR) applications."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,1,Jon Rogers,University of Dundee,Dundee,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,2,Loraine Clarke,University of Dundee,Dundee,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,3,Martin Skelly,University of Dundee,Dundee,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,4,Nick Taylor,University of Dundee,Dundee,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,5,Pete Thomas,University of Dundee,Dundee,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,6,Michelle Thorne,Mozilla Foundation,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,7,Solana Larsen,Mozilla Foundation,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,8,Katarzyna Odrozek,Mozilla Foundation,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,9,Julia Kloiber,Mozilla Foundation,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,10,Peter Bihr,Mozilla Foundation,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,11,Anab Jain,Superflux,London,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,12,Jon Arden,Superflux,London,United Kingdom,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn2655,https://doi.org/10.1145/3290605.3300344,Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet,13,Max Von Grafenstein,Berlin University of the Arts,Berlin,Germany,false,false,"Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape."
pn3933,https://doi.org/10.1145/3290605.3300721,Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments,1,Tiffany Kwok,ETH Zurich,Zurich,Switzerland,false,false,"Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world."
pn3933,https://doi.org/10.1145/3290605.3300721,Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments,2,Peter Kiefer,ETH Zurich,Zurich,Switzerland,false,false,"Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world."
pn3933,https://doi.org/10.1145/3290605.3300721,Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments,3,Victor Schinazi,ETH Zurich,Zurich,Switzerland,false,false,"Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world."
pn3933,https://doi.org/10.1145/3290605.3300721,Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments,4,Benjamin Adams,University of Canterbury,Christchurch,New Zealand,false,false,"Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world."
pn3933,https://doi.org/10.1145/3290605.3300721,Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments,5,Martin Raubal,ETH Zurich,Zurich,Switzerland,false,false,"Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world."
pn7405,https://doi.org/10.1145/3290605.3300833,Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction,1,Selina Jeanne Sutton,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention has been paid to the design of VUI voice output beyond intelligibility and naturalness. We draw on the field of sociophonetics - the study of the social factors that influence the production and perception of speech - to highlight how current VUIs are based on a limited and homogenised set of voice outputs. We argue that current systems do not adequately consider the diversity of peoples' speech, how that diversity represents sociocultural identities, and how voices have the potential to shape user perceptions and experiences. Ultimately, as other technological developments have influenced the ideologies of language, the voice outputs of VUIs will influence the ideologies of speech. Based on our argument, we pose three design strategies for VUI voice output design - individualisation, context awareness, and diversification - to motivate new ways of conceptualising and designing these technologies."
pn7405,https://doi.org/10.1145/3290605.3300833,Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction,2,Paul Foulkes,University of York,York,United Kingdom,false,false,"While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention has been paid to the design of VUI voice output beyond intelligibility and naturalness. We draw on the field of sociophonetics - the study of the social factors that influence the production and perception of speech - to highlight how current VUIs are based on a limited and homogenised set of voice outputs. We argue that current systems do not adequately consider the diversity of peoples' speech, how that diversity represents sociocultural identities, and how voices have the potential to shape user perceptions and experiences. Ultimately, as other technological developments have influenced the ideologies of language, the voice outputs of VUIs will influence the ideologies of speech. Based on our argument, we pose three design strategies for VUI voice output design - individualisation, context awareness, and diversification - to motivate new ways of conceptualising and designing these technologies."
pn7405,https://doi.org/10.1145/3290605.3300833,Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction,3,David Kirk,Northumbria Univeristy,Newcastle Upon Tyne,United Kingdom,false,false,"While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention has been paid to the design of VUI voice output beyond intelligibility and naturalness. We draw on the field of sociophonetics - the study of the social factors that influence the production and perception of speech - to highlight how current VUIs are based on a limited and homogenised set of voice outputs. We argue that current systems do not adequately consider the diversity of peoples' speech, how that diversity represents sociocultural identities, and how voices have the potential to shape user perceptions and experiences. Ultimately, as other technological developments have influenced the ideologies of language, the voice outputs of VUIs will influence the ideologies of speech. Based on our argument, we pose three design strategies for VUI voice output design - individualisation, context awareness, and diversification - to motivate new ways of conceptualising and designing these technologies."
pn7405,https://doi.org/10.1145/3290605.3300833,Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction,4,Shaun Lawson,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention has been paid to the design of VUI voice output beyond intelligibility and naturalness. We draw on the field of sociophonetics - the study of the social factors that influence the production and perception of speech - to highlight how current VUIs are based on a limited and homogenised set of voice outputs. We argue that current systems do not adequately consider the diversity of peoples' speech, how that diversity represents sociocultural identities, and how voices have the potential to shape user perceptions and experiences. Ultimately, as other technological developments have influenced the ideologies of language, the voice outputs of VUIs will influence the ideologies of speech. Based on our argument, we pose three design strategies for VUI voice output design - individualisation, context awareness, and diversification - to motivate new ways of conceptualising and designing these technologies."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,1,Arne Berger,Chemnitz University of Technology,Chemnitz,Germany,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,2,William Odom,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,3,Michael Storz,Chemnitz University of Technology,Chemnitz,Germany,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,4,Andreas Bischof,Chemnitz University of Technology,Chemnitz,Germany,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,5,Albrecht Kurze,Chemnitz University of Technology,Chemnitz,Germany,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn5134,https://doi.org/10.1145/3290605.3300631,The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home,6,Eva Hornecker,Bauhaus-Universität Weimar,Weimar,Germany,false,false,"Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,1,Aloha Ambe,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,2,Margot Brereton,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,3,Alessandro Soro,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,4,Min Zhen Chai,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,5,Laurie Buys,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn8007,https://doi.org/10.1145/3290605.3300552,Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience,6,Paul Roe,Queensland University of Technology,Brisbane,Australia,false,false,"We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits."
pn9474,https://doi.org/10.1145/3290605.3300751,Gehna: Exploring the Design Space of Jewelry as an Input Modality,1,Jatin Arora,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Jewelry weaves into our everyday lives as no other wearable does. It comes in many wearable forms, is fashionable, and can adorn any part of the body. In this paper, through an exploratory, Research through Design (RtD) process, we tap into this vast potential space of input interaction that jewelry can enable. We do so by first identifying a small set of fundamental structural elements --- called Jewelements --- that any jewelry is composed of, and then defining their properties that enable the interaction. We leverage this synthesis along with observational data and literature to formulate a design space of jewelry-enabled input techniques. This work encapsulates both the extensions of common existing input methods (e.g., touch) as well as new ones inspired by jewelry. Furthermore, we discuss our prototypical sensor-based implementations. Through this work, we invite the community to engage in the conversation on how jewelry as a material can help shape wearable-based input."
pn9474,https://doi.org/10.1145/3290605.3300751,Gehna: Exploring the Design Space of Jewelry as an Input Modality,2,Kartik Mathur,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Jewelry weaves into our everyday lives as no other wearable does. It comes in many wearable forms, is fashionable, and can adorn any part of the body. In this paper, through an exploratory, Research through Design (RtD) process, we tap into this vast potential space of input interaction that jewelry can enable. We do so by first identifying a small set of fundamental structural elements --- called Jewelements --- that any jewelry is composed of, and then defining their properties that enable the interaction. We leverage this synthesis along with observational data and literature to formulate a design space of jewelry-enabled input techniques. This work encapsulates both the extensions of common existing input methods (e.g., touch) as well as new ones inspired by jewelry. Furthermore, we discuss our prototypical sensor-based implementations. Through this work, we invite the community to engage in the conversation on how jewelry as a material can help shape wearable-based input."
pn9474,https://doi.org/10.1145/3290605.3300751,Gehna: Exploring the Design Space of Jewelry as an Input Modality,3,Aryan Saini,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Jewelry weaves into our everyday lives as no other wearable does. It comes in many wearable forms, is fashionable, and can adorn any part of the body. In this paper, through an exploratory, Research through Design (RtD) process, we tap into this vast potential space of input interaction that jewelry can enable. We do so by first identifying a small set of fundamental structural elements --- called Jewelements --- that any jewelry is composed of, and then defining their properties that enable the interaction. We leverage this synthesis along with observational data and literature to formulate a design space of jewelry-enabled input techniques. This work encapsulates both the extensions of common existing input methods (e.g., touch) as well as new ones inspired by jewelry. Furthermore, we discuss our prototypical sensor-based implementations. Through this work, we invite the community to engage in the conversation on how jewelry as a material can help shape wearable-based input."
pn9474,https://doi.org/10.1145/3290605.3300751,Gehna: Exploring the Design Space of Jewelry as an Input Modality,4,Aman Parnami,Indraprastha Institute of Information Technology,New Delhi,India,false,false,"Jewelry weaves into our everyday lives as no other wearable does. It comes in many wearable forms, is fashionable, and can adorn any part of the body. In this paper, through an exploratory, Research through Design (RtD) process, we tap into this vast potential space of input interaction that jewelry can enable. We do so by first identifying a small set of fundamental structural elements --- called Jewelements --- that any jewelry is composed of, and then defining their properties that enable the interaction. We leverage this synthesis along with observational data and literature to formulate a design space of jewelry-enabled input techniques. This work encapsulates both the extensions of common existing input methods (e.g., touch) as well as new ones inspired by jewelry. Furthermore, we discuss our prototypical sensor-based implementations. Through this work, we invite the community to engage in the conversation on how jewelry as a material can help shape wearable-based input."
pn8463,https://doi.org/10.1145/3290605.3300723,Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT,1,Sarah Fox,"University of California, San Diego",La Jolla,United States,false,true,"This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies—or, connected devices imbued with computational capacity—became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings."
pn8463,https://doi.org/10.1145/3290605.3300723,Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT,2,Kiley Sobel,University of Washington,Seattle,United States,false,true,"This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies—or, connected devices imbued with computational capacity—became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings."
pn8463,https://doi.org/10.1145/3290605.3300723,Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT,3,Daniela Rosner,University of Washington,Seattle,United States,false,true,"This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies—or, connected devices imbued with computational capacity—became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings."
pn4049,https://doi.org/10.1145/3290605.3300346,Playing Blind: Revealing the World of Gamers with Visual Impairment,1,Ronny Andrade,The University of Melbourne,"Melbourne,",Australia,false,false,"Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, ""in-the-wild"" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games."
pn4049,https://doi.org/10.1145/3290605.3300346,Playing Blind: Revealing the World of Gamers with Visual Impairment,2,Melissa Rogerson,The University of Melbourne,Melbourne,Australia,false,false,"Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, ""in-the-wild"" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games."
pn4049,https://doi.org/10.1145/3290605.3300346,Playing Blind: Revealing the World of Gamers with Visual Impairment,3,Jenny Waycott,The University of Melbourne,Melbourne,Australia,false,false,"Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, ""in-the-wild"" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games."
pn4049,https://doi.org/10.1145/3290605.3300346,Playing Blind: Revealing the World of Gamers with Visual Impairment,4,Steven Baker,The University of Melbourne,Melbourne,Australia,false,false,"Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, ""in-the-wild"" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games."
pn4049,https://doi.org/10.1145/3290605.3300346,Playing Blind: Revealing the World of Gamers with Visual Impairment,5,Frank Vetere,The University of Melbourne,Melbourne,Australia,false,false,"Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, ""in-the-wild"" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games."
pn9829,https://doi.org/10.1145/3290605.3300262,Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users,1,Liam Mason,University of Lincoln,Lincoln,United Kingdom,false,false,"Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA."
pn9829,https://doi.org/10.1145/3290605.3300262,Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users,2,Kathrin Gerling,KU Leuven,Leuven,Belgium,false,false,"Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA."
pn9829,https://doi.org/10.1145/3290605.3300262,Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users,3,Patrick Dickinson,University of Lincoln,Lincoln,United Kingdom,false,false,"Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA."
pn9829,https://doi.org/10.1145/3290605.3300262,Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users,4,Antonella De Angeli,University of Lincoln,Lincoln,United Kingdom,false,false,"Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA."
pn1500,https://doi.org/10.1145/3290605.3300861,Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment,1,Frederico Da Rocha Tomé Filho,University of Ontario Institute of Technology,Oshawa,Canada,false,false,"Board games present accessibility barriers for players with visual impairment since they often employ visuals alone to communicate gameplay information. Our research focuses on board game accessibility for those with visual impairment. This paper describes a three-phase study conducted to develop board game accessibility adaptation guidelines. These guidelines were developed through a user-centered design approach that included in-depth interviews and a series of user studies using two adapted board games. Our findings indicate that participants with and without visual impairment were able to play the adapted games, exhibiting a balanced experience whereby participants had complete autonomy and were provided with equal chances of victory. Our paper also contributes to the game and accessibility communities through the development of adaptation guidelines that allow board games to become inclusive irrespective of a player's visual impairment."
pn1500,https://doi.org/10.1145/3290605.3300861,Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment,2,Pejman Mirza-Babaei,University of Ontario Institute of Technology,Oshawa,Canada,false,false,"Board games present accessibility barriers for players with visual impairment since they often employ visuals alone to communicate gameplay information. Our research focuses on board game accessibility for those with visual impairment. This paper describes a three-phase study conducted to develop board game accessibility adaptation guidelines. These guidelines were developed through a user-centered design approach that included in-depth interviews and a series of user studies using two adapted board games. Our findings indicate that participants with and without visual impairment were able to play the adapted games, exhibiting a balanced experience whereby participants had complete autonomy and were provided with equal chances of victory. Our paper also contributes to the game and accessibility communities through the development of adaptation guidelines that allow board games to become inclusive irrespective of a player's visual impairment."
pn1500,https://doi.org/10.1145/3290605.3300861,Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment,3,Bill Kapralos,University of Ontario Institute of Technology,Oshawa,Canada,false,false,"Board games present accessibility barriers for players with visual impairment since they often employ visuals alone to communicate gameplay information. Our research focuses on board game accessibility for those with visual impairment. This paper describes a three-phase study conducted to develop board game accessibility adaptation guidelines. These guidelines were developed through a user-centered design approach that included in-depth interviews and a series of user studies using two adapted board games. Our findings indicate that participants with and without visual impairment were able to play the adapted games, exhibiting a balanced experience whereby participants had complete autonomy and were provided with equal chances of victory. Our paper also contributes to the game and accessibility communities through the development of adaptation guidelines that allow board games to become inclusive irrespective of a player's visual impairment."
pn1500,https://doi.org/10.1145/3290605.3300861,Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment,4,Glaudiney Moreira Mendonça Junior,Federal University of Ceará,Fortaleza,Brazil,false,false,"Board games present accessibility barriers for players with visual impairment since they often employ visuals alone to communicate gameplay information. Our research focuses on board game accessibility for those with visual impairment. This paper describes a three-phase study conducted to develop board game accessibility adaptation guidelines. These guidelines were developed through a user-centered design approach that included in-depth interviews and a series of user studies using two adapted board games. Our findings indicate that participants with and without visual impairment were able to play the adapted games, exhibiting a balanced experience whereby participants had complete autonomy and were provided with equal chances of victory. Our paper also contributes to the game and accessibility communities through the development of adaptation guidelines that allow board games to become inclusive irrespective of a player's visual impairment."
pn7891,https://doi.org/10.1145/3290605.3300397,How Do One's Peers on a Leaderboard Affect Oneself?,1,Weiwen Leung,University of Toronto,Toronto,Canada,false,false,"Leaderboards are a workhorse of the gamification literature. While the effect of a leaderboard has been well studied, there is much less evidence how one's peer group affects the treatment effect of a leaderboard. Through a pre-registered field experiment involving more than 1000 users on an online movie recommender website, we expose users to leaderboards, but different sets of users are exposed to different peer groups. Contrary to what a standard behavioral model would predict, we find that a user's contribution increases when their peer's scores are more dispersed. We also find that decreasing average peer contributions motivates a user to contribute more. Moreover, these effects are themselves mediated by group size. This sheds new light on existing theories of motivation and demotivation with regards to leaderboards, and also illustrates the potential of using personalized leaderboards to increase contributions."
pn6096,https://doi.org/10.1145/3290605.3300516,Infrastructuring the Imaginary: How Sea-Level Rise Comes to Matter in the San Francisco Bay Area,1,Robert Soden,University of Colorado Boulder,Boulder,United States,false,false,"Information infrastructures have become integral components of policy debates related to climate change and sustainability. To better understand this relationship, we studied the tools used to forecast and respond to sea-level rise in the San Francisco Bay Area, where active debates on how to best prepare for this issues are underway and will have important consequences for the future of the region. Drawing on 18 months of qualitative research we argue that competing visions of the problem are intimately intertwined with different elements of information infrastructure and beliefs about the role of data in policymaking. Current infrastructure in the region, far from being a neutral actor in these debates, exhibits an infrastructural bias, privileging some approaches over others. We identify some of the tactics that community organizations deploy to subvert the claims of sea-level rise experts and advance their own perspective, which prioritizes considerations of justice over technical expertise."
pn6096,https://doi.org/10.1145/3290605.3300516,Infrastructuring the Imaginary: How Sea-Level Rise Comes to Matter in the San Francisco Bay Area,2,Nate Kauffman,"University of California, Berkeley",Berkeley,United States,false,false,"Information infrastructures have become integral components of policy debates related to climate change and sustainability. To better understand this relationship, we studied the tools used to forecast and respond to sea-level rise in the San Francisco Bay Area, where active debates on how to best prepare for this issues are underway and will have important consequences for the future of the region. Drawing on 18 months of qualitative research we argue that competing visions of the problem are intimately intertwined with different elements of information infrastructure and beliefs about the role of data in policymaking. Current infrastructure in the region, far from being a neutral actor in these debates, exhibits an infrastructural bias, privileging some approaches over others. We identify some of the tactics that community organizations deploy to subvert the claims of sea-level rise experts and advance their own perspective, which prioritizes considerations of justice over technical expertise."
pn4525,https://doi.org/10.1145/3290605.3300594,Look-From Camera Control for 3D Terrain Maps,1,Kurtis Danyluk,University of Calgary,Calgary,Canada,true,false,"We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks."
pn4525,https://doi.org/10.1145/3290605.3300594,Look-From Camera Control for 3D Terrain Maps,2,Bernhard Jenny,Monash University,Melbourne,Australia,true,false,"We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks."
pn4525,https://doi.org/10.1145/3290605.3300594,Look-From Camera Control for 3D Terrain Maps,3,Wesley Willett,University of Calgary,Calgary,Canada,true,false,"We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,1,Parastoo Abtahi,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,2,Benoit Landry,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,3,Jackie Yang,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,4,Marco Pavone,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,5,Sean Follmer,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3302,https://doi.org/10.1145/3290605.3300589,Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality,6,James Landay,Stanford University,Stanford,United States,true,false,"Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques."
pn3373,https://doi.org/10.1145/3290605.3300402,VisiBlends: A Flexible Workflow for Visual Blends,1,Lydia Chilton,Columbia University,New York,United States,false,false,"Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends."
pn3373,https://doi.org/10.1145/3290605.3300402,VisiBlends: A Flexible Workflow for Visual Blends,2,Savvas Petridis,Columbia University,New York,United States,false,false,"Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends."
pn3373,https://doi.org/10.1145/3290605.3300402,VisiBlends: A Flexible Workflow for Visual Blends,3,Maneesh Agrawala,Stanford University,Stanford,United States,false,false,"Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,1,Hasti Seifi,Max Planck Institute for Intelligent Systems,Stuttgart,Germany,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,2,Farimah Fazlollahi,Max Planck Institute for Intelligent Systems,Stuttgart,Germany,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,3,Michael Oppermann,The University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,4,John Andrew Sastrillo,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,5,Jessica Ip,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,6,Ashutosh Agrawal,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,7,Gunhyuk Park,Max Planck Institute for Intelligent Systems,Stuttgart,Germany,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,8,Katherine Kuchenbecker,Max Planck Institute for Intelligent Systems,Stuttgart,Germany,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn5775,https://doi.org/10.1145/3290605.3300788,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction and Engineering Design,9,Karon Maclean,The University of British Columbia?,Burnaby/Surrey/Vancouver,Canada,false,false,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation."
pn1227,https://doi.org/10.1145/3290605.3300673,Quantitative Measurement of Tool Embodiment for Virtual Reality Input Alternatives,1,Ayman Alzayat,University of Waterloo,Kitchener,Canada,true,false,"Virtual reality (VR) strives to replicate the sensation of the physical environment by mimicking people's perceptions and experience of being elsewhere. These experiences are of-ten mediated by the objects and tools we interact with in the virtual world (e.g., a controller). Evidence from psychology posits that when using the tool proficiently, it becomes em-bodied (i.e., an extension of one's body). There is little work,however, on how to measure this phenomenon in VR, andon how different types of tools and controllers can affect the experience of interaction. In this work, we leverage cognitive psychology and philosophy literature to construct the Locus-of-Attention Index (LAI), a measure of tool embodiment. We designed and conducted a study that measures readiness-to-hand and unreadiness-to-hand for three VR interaction techniques: hands, a physical tool, and a VR controller. The study shows that LAI can measure differences in embodiment with working and broken tools and that using the hand directly results in more embodiment than using controllers."
pn1227,https://doi.org/10.1145/3290605.3300673,Quantitative Measurement of Tool Embodiment for Virtual Reality Input Alternatives,2,Mark Hancock,University of Waterloo,Waterloo,Canada,true,false,"Virtual reality (VR) strives to replicate the sensation of the physical environment by mimicking people's perceptions and experience of being elsewhere. These experiences are of-ten mediated by the objects and tools we interact with in the virtual world (e.g., a controller). Evidence from psychology posits that when using the tool proficiently, it becomes em-bodied (i.e., an extension of one's body). There is little work,however, on how to measure this phenomenon in VR, andon how different types of tools and controllers can affect the experience of interaction. In this work, we leverage cognitive psychology and philosophy literature to construct the Locus-of-Attention Index (LAI), a measure of tool embodiment. We designed and conducted a study that measures readiness-to-hand and unreadiness-to-hand for three VR interaction techniques: hands, a physical tool, and a VR controller. The study shows that LAI can measure differences in embodiment with working and broken tools and that using the hand directly results in more embodiment than using controllers."
pn1227,https://doi.org/10.1145/3290605.3300673,Quantitative Measurement of Tool Embodiment for Virtual Reality Input Alternatives,3,Miguel Nacenta,University of St Andrews,St Andrews,United Kingdom,true,false,"Virtual reality (VR) strives to replicate the sensation of the physical environment by mimicking people's perceptions and experience of being elsewhere. These experiences are of-ten mediated by the objects and tools we interact with in the virtual world (e.g., a controller). Evidence from psychology posits that when using the tool proficiently, it becomes em-bodied (i.e., an extension of one's body). There is little work,however, on how to measure this phenomenon in VR, andon how different types of tools and controllers can affect the experience of interaction. In this work, we leverage cognitive psychology and philosophy literature to construct the Locus-of-Attention Index (LAI), a measure of tool embodiment. We designed and conducted a study that measures readiness-to-hand and unreadiness-to-hand for three VR interaction techniques: hands, a physical tool, and a VR controller. The study shows that LAI can measure differences in embodiment with working and broken tools and that using the hand directly results in more embodiment than using controllers."
pn5489,https://doi.org/10.1145/3290605.3300243,TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,1,Hemant Bhaskar Surale,University of Waterloo,Waterloo,Canada,false,false,"Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach."
pn5489,https://doi.org/10.1145/3290605.3300243,TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,2,Aakar Gupta,University of Waterloo,Waterloo,Canada,false,false,"Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach."
pn5489,https://doi.org/10.1145/3290605.3300243,TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,3,Mark Hancock,University of Waterloo,Waterloo,Canada,false,false,"Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach."
pn5489,https://doi.org/10.1145/3290605.3300243,TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,4,Daniel Vogel,University of Waterloo,Waterloo,Canada,false,false,"Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach."
pn4480,https://doi.org/10.1145/3290605.3300849,ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen & Smartphone,1,Philipp Wacker,RWTH Aachen University,Aachen,Germany,false,false,"Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems."
pn4480,https://doi.org/10.1145/3290605.3300849,ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen & Smartphone,2,Oliver Nowak,RWTH Aachen University,Aachen,Germany,false,false,"Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems."
pn4480,https://doi.org/10.1145/3290605.3300849,ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen & Smartphone,3,Simon Voelker,RWTH Aachen University,Aachen,Germany,false,false,"Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems."
pn4480,https://doi.org/10.1145/3290605.3300849,ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen & Smartphone,4,Jan Borchers,RWTH Aachen University,Aachen,Germany,false,false,"Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems."
pn5398,https://doi.org/10.1145/3290605.3300368,How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning,1,Amy Cook,Carnegie Mellon University,Pittsburgh,United States,false,false,"Peer feedback is essential for learning in project-based disciplines. However, students often need guidance when acting as either a feedback provider or a feedback receiver, both to gain from peer feedback and to criticize their peers' work. This paper explores how to more effectively scaffold this exchange such that peers more deeply engage in the feedback process. Within a game design course, we introduced different processes for feedback receivers to write questions to guide peer feedback. Feedback receivers wrote four main types of guiding questions: improve, share, brainstorm, critique. We found that ""improve"" questions tended to lead to better feedback (more specific, critical, and actionable) than other question types, but feedback receivers wrote improve questions least often. We offer insights on how best to scaffold the question-writing process to facilitate peer feedback exchange."
pn5398,https://doi.org/10.1145/3290605.3300368,How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning,2,Jessica Hammer,Carnegie Mellon University,Pittsburgh,United States,false,false,"Peer feedback is essential for learning in project-based disciplines. However, students often need guidance when acting as either a feedback provider or a feedback receiver, both to gain from peer feedback and to criticize their peers' work. This paper explores how to more effectively scaffold this exchange such that peers more deeply engage in the feedback process. Within a game design course, we introduced different processes for feedback receivers to write questions to guide peer feedback. Feedback receivers wrote four main types of guiding questions: improve, share, brainstorm, critique. We found that ""improve"" questions tended to lead to better feedback (more specific, critical, and actionable) than other question types, but feedback receivers wrote improve questions least often. We offer insights on how best to scaffold the question-writing process to facilitate peer feedback exchange."
pn5398,https://doi.org/10.1145/3290605.3300368,How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning,3,Salma Elsayed-Ali,William,Williamsburg,United States,false,false,"Peer feedback is essential for learning in project-based disciplines. However, students often need guidance when acting as either a feedback provider or a feedback receiver, both to gain from peer feedback and to criticize their peers' work. This paper explores how to more effectively scaffold this exchange such that peers more deeply engage in the feedback process. Within a game design course, we introduced different processes for feedback receivers to write questions to guide peer feedback. Feedback receivers wrote four main types of guiding questions: improve, share, brainstorm, critique. We found that ""improve"" questions tended to lead to better feedback (more specific, critical, and actionable) than other question types, but feedback receivers wrote improve questions least often. We offer insights on how best to scaffold the question-writing process to facilitate peer feedback exchange."
pn5398,https://doi.org/10.1145/3290605.3300368,How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning,4,Steven Dow,"University of California, San Diego",La Jolla,United States,false,false,"Peer feedback is essential for learning in project-based disciplines. However, students often need guidance when acting as either a feedback provider or a feedback receiver, both to gain from peer feedback and to criticize their peers' work. This paper explores how to more effectively scaffold this exchange such that peers more deeply engage in the feedback process. Within a game design course, we introduced different processes for feedback receivers to write questions to guide peer feedback. Feedback receivers wrote four main types of guiding questions: improve, share, brainstorm, critique. We found that ""improve"" questions tended to lead to better feedback (more specific, critical, and actionable) than other question types, but feedback receivers wrote improve questions least often. We offer insights on how best to scaffold the question-writing process to facilitate peer feedback exchange."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,1,Pengcheng An,Eindhoven University of Technology,Eindhoven,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,2,Saskia Bakker,Eindhoven University of Technology,Eindhoven,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,3,Sara Ordanovski,Utrecht University,Utrecht,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,4,Ruurd Taconis,Eindhoven University of Technology,Eindhoven,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,5,Chris Paffen,Utrecht University,Utrecht,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn4895,https://doi.org/10.1145/3290605.3300321,Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information,6,Berry Eggen,Eindhoven University of Technology,Eindhoven,Netherlands,true,false,"Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,1,Zhongxiu Peddycord-Liu,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,2,Veronica Cateté,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,3,Jessica Vandenberg,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,4,Tiffany Barnes,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,5,Collin Lynch,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3924,https://doi.org/10.1145/3290605.3300658,A Field Study of Teachers Using a Curriculum-integrated Digital Game,6,Teomara Rutherford,North Carolina State University,Raleigh,United States,false,false,"We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers' behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice."
pn3859,https://doi.org/10.1145/3290605.3300774,What Can We Learn from Augmented Reality (AR)?,1,Iulian Radu,Harvard University,Cambridge,United States,false,false,"Emerging technologies such as Augmented Reality (AR), have the potential to radically transform education by making challenging concepts visible and accessible to novices. In this project, we have designed a Hololens-based system in which collaborators are exposed to an unstructured learning activity in which they learned about the invisible physics involved in audio speakers. They learned topics ranging from spatial knowledge, such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships between electricity and magnetism. We compared participants' learning, attitudes and collaboration with a tangible interface through multiple experimental conditions containing varying layers of AR information. We found that educational AR representations were beneficial for learning specific knowledge and increasing participants' self-efficacy (i.e., their ability to learn concepts in physics). However, we also found that participants in conditions that did not contain AR educational content, learned some concepts better than other groups and became more curious about physics. We discuss learning and collaboration differences, as well as benefits and detriments of implementing augmented reality for unstructured learning activities."
pn3859,https://doi.org/10.1145/3290605.3300774,What Can We Learn from Augmented Reality (AR)?,2,Bertrand Schneider,Harvard University,Cambridge,United States,false,false,"Emerging technologies such as Augmented Reality (AR), have the potential to radically transform education by making challenging concepts visible and accessible to novices. In this project, we have designed a Hololens-based system in which collaborators are exposed to an unstructured learning activity in which they learned about the invisible physics involved in audio speakers. They learned topics ranging from spatial knowledge, such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships between electricity and magnetism. We compared participants' learning, attitudes and collaboration with a tangible interface through multiple experimental conditions containing varying layers of AR information. We found that educational AR representations were beneficial for learning specific knowledge and increasing participants' self-efficacy (i.e., their ability to learn concepts in physics). However, we also found that participants in conditions that did not contain AR educational content, learned some concepts better than other groups and became more curious about physics. We discuss learning and collaboration differences, as well as benefits and detriments of implementing augmented reality for unstructured learning activities."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,1,Maximilian Altmeyer,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,2,Kathrin Dernbecher,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,3,Vladislav Hnatovskiy,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,4,Marc Schubhan,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,5,Pascal Lessel,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn6007,https://doi.org/10.1145/3290605.3300412,Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads,6,Antonio Krüger,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising."
pn3612,https://doi.org/10.1145/3290605.3300690,Gamification in Science: A Study of Requirements in the Context of Reproducible Research,1,Sebastian Feger,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science."
pn3612,https://doi.org/10.1145/3290605.3300690,Gamification in Science: A Study of Requirements in the Context of Reproducible Research,2,Sünje Dallmeier-Tiessen,CERN,Geneva,Switzerland,false,false,"The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science."
pn3612,https://doi.org/10.1145/3290605.3300690,Gamification in Science: A Study of Requirements in the Context of Reproducible Research,3,Paweł Woźniak,Utrecht University,Utrecht,Netherlands,false,false,"The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science."
pn3612,https://doi.org/10.1145/3290605.3300690,Gamification in Science: A Study of Requirements in the Context of Reproducible Research,4,Albrecht Schmidt,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science."
pn3092,https://doi.org/10.1145/3290605.3300380,Enable or Disable Gamification?,1,Pascal Lessel,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper investigates a simple form of customization: giving users the choice to enable or disable gamification. We present a study (N=77) in the context of image tagging, in which a gamification approach was shown to be effective in previous work. In our case, some participants could enable or disable gamification after they had experienced the task with and without it. Other participants had no choice and did the task with or without game elements. The results indicate that those who are not attracted by the elements can be motivated to tag more through this choice. In contrast, those that like the elements are not affected by it. This suggests that systems should provide the option to disable gamification in the absence of more sophisticated tailoring."
pn3092,https://doi.org/10.1145/3290605.3300380,Enable or Disable Gamification?,2,Maximilian Altmeyer,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper investigates a simple form of customization: giving users the choice to enable or disable gamification. We present a study (N=77) in the context of image tagging, in which a gamification approach was shown to be effective in previous work. In our case, some participants could enable or disable gamification after they had experienced the task with and without it. Other participants had no choice and did the task with or without game elements. The results indicate that those who are not attracted by the elements can be motivated to tag more through this choice. In contrast, those that like the elements are not affected by it. This suggests that systems should provide the option to disable gamification in the absence of more sophisticated tailoring."
pn3092,https://doi.org/10.1145/3290605.3300380,Enable or Disable Gamification?,3,Lea Schmeer,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper investigates a simple form of customization: giving users the choice to enable or disable gamification. We present a study (N=77) in the context of image tagging, in which a gamification approach was shown to be effective in previous work. In our case, some participants could enable or disable gamification after they had experienced the task with and without it. Other participants had no choice and did the task with or without game elements. The results indicate that those who are not attracted by the elements can be motivated to tag more through this choice. In contrast, those that like the elements are not affected by it. This suggests that systems should provide the option to disable gamification in the absence of more sophisticated tailoring."
pn3092,https://doi.org/10.1145/3290605.3300380,Enable or Disable Gamification?,4,Antonio Krüger,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"This paper investigates a simple form of customization: giving users the choice to enable or disable gamification. We present a study (N=77) in the context of image tagging, in which a gamification approach was shown to be effective in previous work. In our case, some participants could enable or disable gamification after they had experienced the task with and without it. Other participants had no choice and did the task with or without game elements. The results indicate that those who are not attracted by the elements can be motivated to tag more through this choice. In contrast, those that like the elements are not affected by it. This suggests that systems should provide the option to disable gamification in the absence of more sophisticated tailoring."
pn2745,https://doi.org/10.1145/3290605.3300920,"A Badge, Not a Barrier: Designing for–and Throughout–Digital Badge Implementation",1,Caroline Pitt,University of Washington,Seattle,United States,false,false,"We synthesize insights from a multi-year project involving the design and implementation of a digital badge system with youth co-designers at a science center. Using stakeholder interviews and surveys, participatory design session data, and user analytics, we identify the sociotechnical, sociocultural, and technical challenges of long-term badge implementation and propose several recommendations for the design and implementation of future badge systems. By identifying these challenges and providing recommendations that foreground stakeholder values and participation, we show how to support implementation throughout the entire design-to-implementation cycle."
pn2745,https://doi.org/10.1145/3290605.3300920,"A Badge, Not a Barrier: Designing for–and Throughout–Digital Badge Implementation",2,Adam Bell,University of Washington,Seattle,United States,false,false,"We synthesize insights from a multi-year project involving the design and implementation of a digital badge system with youth co-designers at a science center. Using stakeholder interviews and surveys, participatory design session data, and user analytics, we identify the sociotechnical, sociocultural, and technical challenges of long-term badge implementation and propose several recommendations for the design and implementation of future badge systems. By identifying these challenges and providing recommendations that foreground stakeholder values and participation, we show how to support implementation throughout the entire design-to-implementation cycle."
pn2745,https://doi.org/10.1145/3290605.3300920,"A Badge, Not a Barrier: Designing for–and Throughout–Digital Badge Implementation",3,Edgar Onofre,University of Washington,Seattle,United States,false,false,"We synthesize insights from a multi-year project involving the design and implementation of a digital badge system with youth co-designers at a science center. Using stakeholder interviews and surveys, participatory design session data, and user analytics, we identify the sociotechnical, sociocultural, and technical challenges of long-term badge implementation and propose several recommendations for the design and implementation of future badge systems. By identifying these challenges and providing recommendations that foreground stakeholder values and participation, we show how to support implementation throughout the entire design-to-implementation cycle."
pn2745,https://doi.org/10.1145/3290605.3300920,"A Badge, Not a Barrier: Designing for–and Throughout–Digital Badge Implementation",4,Katie Davis,University of Washington,Seattle,United States,false,false,"We synthesize insights from a multi-year project involving the design and implementation of a digital badge system with youth co-designers at a science center. Using stakeholder interviews and surveys, participatory design session data, and user analytics, we identify the sociotechnical, sociocultural, and technical challenges of long-term badge implementation and propose several recommendations for the design and implementation of future badge systems. By identifying these challenges and providing recommendations that foreground stakeholder values and participation, we show how to support implementation throughout the entire design-to-implementation cycle."
pn7975,https://doi.org/10.1145/3290605.3300740,Exploring and Designing for Memory Impairments in Depression,1,Chengcheng Qu,Lancaster University,Lancaster,United Kingdom,false,false,"Depression is an affective disorder with distinctive autobiographical memory impairments, including negative bias, overgeneralization and reduced positivity. Several clinical therapies address these impairments, and there is an opportunity to develop new supports for treatment by considering depression-associated memory impairments within design. We report on interviews with ten experts in treating depression, with expertise in both neuropsychology and cognitive behavioral therapies. The interviews explore approaches for addressing each of these memory impairments. We found consistent use of positive memories for treating all memory impairments, the challenge of direct retrieval, and the need to support the experience of positive memories. We aim to sensitize HCI researchers to the limitations of memory technologies, broaden their awareness of memory impairments beyond episodic memory recall, and inspire them to engage with this less explored design space. Our findings open up new design opportunities for memory technologies for depression, including positive memory banks for active encoding and selective retrieval, novel cues for supporting generative retrieval, and novel interfaces to strengthen the reliving of positive memories."
pn7975,https://doi.org/10.1145/3290605.3300740,Exploring and Designing for Memory Impairments in Depression,2,Corina Sas,Lancaster University,Lancaster,United Kingdom,false,false,"Depression is an affective disorder with distinctive autobiographical memory impairments, including negative bias, overgeneralization and reduced positivity. Several clinical therapies address these impairments, and there is an opportunity to develop new supports for treatment by considering depression-associated memory impairments within design. We report on interviews with ten experts in treating depression, with expertise in both neuropsychology and cognitive behavioral therapies. The interviews explore approaches for addressing each of these memory impairments. We found consistent use of positive memories for treating all memory impairments, the challenge of direct retrieval, and the need to support the experience of positive memories. We aim to sensitize HCI researchers to the limitations of memory technologies, broaden their awareness of memory impairments beyond episodic memory recall, and inspire them to engage with this less explored design space. Our findings open up new design opportunities for memory technologies for depression, including positive memory banks for active encoding and selective retrieval, novel cues for supporting generative retrieval, and novel interfaces to strengthen the reliving of positive memories."
pn7975,https://doi.org/10.1145/3290605.3300740,Exploring and Designing for Memory Impairments in Depression,3,Gavin Doherty,Trinity College Dublin,Dublin,Ireland,false,false,"Depression is an affective disorder with distinctive autobiographical memory impairments, including negative bias, overgeneralization and reduced positivity. Several clinical therapies address these impairments, and there is an opportunity to develop new supports for treatment by considering depression-associated memory impairments within design. We report on interviews with ten experts in treating depression, with expertise in both neuropsychology and cognitive behavioral therapies. The interviews explore approaches for addressing each of these memory impairments. We found consistent use of positive memories for treating all memory impairments, the challenge of direct retrieval, and the need to support the experience of positive memories. We aim to sensitize HCI researchers to the limitations of memory technologies, broaden their awareness of memory impairments beyond episodic memory recall, and inspire them to engage with this less explored design space. Our findings open up new design opportunities for memory technologies for depression, including positive memory banks for active encoding and selective retrieval, novel cues for supporting generative retrieval, and novel interfaces to strengthen the reliving of positive memories."
pn7570,https://doi.org/10.1145/3290605.3300363,Visually Encoding the Lived Experience of Bipolar Disorder,1,Jaime Snyder,University of Washington,Seattle,United States,false,false,"Issues of social identity, attitudes towards self-disclosure, and potentially biased approaches to what is considered ""typical"" or ""normal"" are critical factors when designing visualizations for personal informatics systems. This is particularly true when working with vulnerable populations like those who self-track to manage serious mental illnesses like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better understand sense-making challenges related to the representation and interpretation of personal data and 2) probe the benefits, risks, and limitations of participatory approaches to designing personal data visualizations that better reflect their lived experiences. We describe our co-design process, present a series of emergent visual encoding schemas resulting from these activities, and report on the assessment of these speculative designs by participants. We conclude by summarizing important considerations and implications for designing personal data visualizations for (and with) people who self-track to manage serious mental illness."
pn7570,https://doi.org/10.1145/3290605.3300363,Visually Encoding the Lived Experience of Bipolar Disorder,2,Elizabeth Murnane,Stanford University,Stanford,United States,false,false,"Issues of social identity, attitudes towards self-disclosure, and potentially biased approaches to what is considered ""typical"" or ""normal"" are critical factors when designing visualizations for personal informatics systems. This is particularly true when working with vulnerable populations like those who self-track to manage serious mental illnesses like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better understand sense-making challenges related to the representation and interpretation of personal data and 2) probe the benefits, risks, and limitations of participatory approaches to designing personal data visualizations that better reflect their lived experiences. We describe our co-design process, present a series of emergent visual encoding schemas resulting from these activities, and report on the assessment of these speculative designs by participants. We conclude by summarizing important considerations and implications for designing personal data visualizations for (and with) people who self-track to manage serious mental illness."
pn7570,https://doi.org/10.1145/3290605.3300363,Visually Encoding the Lived Experience of Bipolar Disorder,3,Caitie Lustig,"University of California, Irvine",Irvine,United States,false,false,"Issues of social identity, attitudes towards self-disclosure, and potentially biased approaches to what is considered ""typical"" or ""normal"" are critical factors when designing visualizations for personal informatics systems. This is particularly true when working with vulnerable populations like those who self-track to manage serious mental illnesses like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better understand sense-making challenges related to the representation and interpretation of personal data and 2) probe the benefits, risks, and limitations of participatory approaches to designing personal data visualizations that better reflect their lived experiences. We describe our co-design process, present a series of emergent visual encoding schemas resulting from these activities, and report on the assessment of these speculative designs by participants. We conclude by summarizing important considerations and implications for designing personal data visualizations for (and with) people who self-track to manage serious mental illness."
pn7570,https://doi.org/10.1145/3290605.3300363,Visually Encoding the Lived Experience of Bipolar Disorder,4,Stephen Voida,University of Colorado,Boulder,United States,false,false,"Issues of social identity, attitudes towards self-disclosure, and potentially biased approaches to what is considered ""typical"" or ""normal"" are critical factors when designing visualizations for personal informatics systems. This is particularly true when working with vulnerable populations like those who self-track to manage serious mental illnesses like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better understand sense-making challenges related to the representation and interpretation of personal data and 2) probe the benefits, risks, and limitations of participatory approaches to designing personal data visualizations that better reflect their lived experiences. We describe our co-design process, present a series of emergent visual encoding schemas resulting from these activities, and report on the assessment of these speculative designs by participants. We conclude by summarizing important considerations and implications for designing personal data visualizations for (and with) people who self-track to manage serious mental illness."
pn7802,https://doi.org/10.1145/3290605.3300653,Exploring Media Capture of Meaningful Experiences to Support Families Living with Dementia,1,James Hodge,Newcastle University,Newcastle,United Kingdom,false,false,"Although designing interactive media experiences for people with dementia has become a growing interest in HCI, a strong focus on family members has rarely been recognised as worthy of design intervention. This paper presents a research through design (RTD) approach working closely with families living with dementia in order to create personalised media experiences. Three families took part in day trips, which they co-planned, with data collection during these days providing insights into their shared social experiences. Workshops were also held in order to personalise the experience of the media created during these days out. Our qualitative analysis outlines themes focusing on individuality, relationships, and accepting changed realities. Furthermore, we outline directions for future research focusing on designing for contested realities, the personhood of carers, and the ageing body and immersion."
pn7802,https://doi.org/10.1145/3290605.3300653,Exploring Media Capture of Meaningful Experiences to Support Families Living with Dementia,2,Kyle Montague,Newcastle University,Newcastle,United Kingdom,false,false,"Although designing interactive media experiences for people with dementia has become a growing interest in HCI, a strong focus on family members has rarely been recognised as worthy of design intervention. This paper presents a research through design (RTD) approach working closely with families living with dementia in order to create personalised media experiences. Three families took part in day trips, which they co-planned, with data collection during these days providing insights into their shared social experiences. Workshops were also held in order to personalise the experience of the media created during these days out. Our qualitative analysis outlines themes focusing on individuality, relationships, and accepting changed realities. Furthermore, we outline directions for future research focusing on designing for contested realities, the personhood of carers, and the ageing body and immersion."
pn7802,https://doi.org/10.1145/3290605.3300653,Exploring Media Capture of Meaningful Experiences to Support Families Living with Dementia,3,Sandra Hastings,Silverline Memories,Newcastle,United Kingdom,false,false,"Although designing interactive media experiences for people with dementia has become a growing interest in HCI, a strong focus on family members has rarely been recognised as worthy of design intervention. This paper presents a research through design (RTD) approach working closely with families living with dementia in order to create personalised media experiences. Three families took part in day trips, which they co-planned, with data collection during these days providing insights into their shared social experiences. Workshops were also held in order to personalise the experience of the media created during these days out. Our qualitative analysis outlines themes focusing on individuality, relationships, and accepting changed realities. Furthermore, we outline directions for future research focusing on designing for contested realities, the personhood of carers, and the ageing body and immersion."
pn7802,https://doi.org/10.1145/3290605.3300653,Exploring Media Capture of Meaningful Experiences to Support Families Living with Dementia,4,Kellie Morrissey,Open Lab,Newcastle,United Kingdom,false,false,"Although designing interactive media experiences for people with dementia has become a growing interest in HCI, a strong focus on family members has rarely been recognised as worthy of design intervention. This paper presents a research through design (RTD) approach working closely with families living with dementia in order to create personalised media experiences. Three families took part in day trips, which they co-planned, with data collection during these days providing insights into their shared social experiences. Workshops were also held in order to personalise the experience of the media created during these days out. Our qualitative analysis outlines themes focusing on individuality, relationships, and accepting changed realities. Furthermore, we outline directions for future research focusing on designing for contested realities, the personhood of carers, and the ageing body and immersion."
pn8092,https://doi.org/10.1145/3290605.3300582,Collaborative Futures: Co-Designing Research Methods for Younger People Living with Dementia,1,Jeanette Bell,"University of Technology, Sydney",Sydney,Australia,false,false,"Designing new technologies to support the lived experience of dementia is of increasing interest within HCI. While there is guidance on qualitative research methods to use in areas such as dementia, there is a need for more appropriate ways to research in the younger demographic. In Younger Onset Dementia (YOD), the circumstances and experiences are markedly different from dementia in the later stage of life – requiring a different approach. This paper presents insights into the methods and approaches used in fieldwork with five people living with YOD; where they engaged as co-researchers in a co-directed inquiry into their lived experiences. Through this, we make a number of methodological contributions to HCI and Participatory Action Research (PAR) for research in the YOD setting. This includes productive approaches that are sensitive, respectful and empowering to the participants. It also extends current approaches to using probes in HCI and dementia research."
pn8092,https://doi.org/10.1145/3290605.3300582,Collaborative Futures: Co-Designing Research Methods for Younger People Living with Dementia,2,Tuck Leong,University of Technology Sydney,Sydney,Australia,false,false,"Designing new technologies to support the lived experience of dementia is of increasing interest within HCI. While there is guidance on qualitative research methods to use in areas such as dementia, there is a need for more appropriate ways to research in the younger demographic. In Younger Onset Dementia (YOD), the circumstances and experiences are markedly different from dementia in the later stage of life – requiring a different approach. This paper presents insights into the methods and approaches used in fieldwork with five people living with YOD; where they engaged as co-researchers in a co-directed inquiry into their lived experiences. Through this, we make a number of methodological contributions to HCI and Participatory Action Research (PAR) for research in the YOD setting. This includes productive approaches that are sensitive, respectful and empowering to the participants. It also extends current approaches to using probes in HCI and dementia research."
pn9831,https://doi.org/10.1145/3290605.3300755,Does Being Verified Make You More Credible? Account Verification's Effect on Tweet Credibility,1,Tavish Vaidya,Georgetown University,Washington,United States,false,false,"Many popular social networking and microblogging sites support verified accounts---user accounts that are deemed of public interest and whose owners have been authenticated by the site. Importantly, the content of messages contributed by verified account owners is not verified. Such messages may be factually correct, or not. This paper investigates whether users confuse authenticity with credibility by posing the question: Are users more likely to believe content from verified accounts than from non-verified accounts? We conduct two online studies, a year apart, with 748 and 2041 participants respectively, to assess how the presence or absence of verified account indicators influences users' perceptions of tweets. Surprisingly, across both studies, we find that---in the context of unfamiliar accounts---most users can effectively distinguish between authenticity and credibility. The presence or absence of an authenticity indicator has no significant effect on willingness to share a tweet or take action based on its contents."
pn9831,https://doi.org/10.1145/3290605.3300755,Does Being Verified Make You More Credible? Account Verification's Effect on Tweet Credibility,2,Daniel Votipka,"University of Maryland, College Park",College Park,United States,false,false,"Many popular social networking and microblogging sites support verified accounts---user accounts that are deemed of public interest and whose owners have been authenticated by the site. Importantly, the content of messages contributed by verified account owners is not verified. Such messages may be factually correct, or not. This paper investigates whether users confuse authenticity with credibility by posing the question: Are users more likely to believe content from verified accounts than from non-verified accounts? We conduct two online studies, a year apart, with 748 and 2041 participants respectively, to assess how the presence or absence of verified account indicators influences users' perceptions of tweets. Surprisingly, across both studies, we find that---in the context of unfamiliar accounts---most users can effectively distinguish between authenticity and credibility. The presence or absence of an authenticity indicator has no significant effect on willingness to share a tweet or take action based on its contents."
pn9831,https://doi.org/10.1145/3290605.3300755,Does Being Verified Make You More Credible? Account Verification's Effect on Tweet Credibility,3,Michelle Mazurek,"University of  Maryland, College Park",College Park,United States,false,false,"Many popular social networking and microblogging sites support verified accounts---user accounts that are deemed of public interest and whose owners have been authenticated by the site. Importantly, the content of messages contributed by verified account owners is not verified. Such messages may be factually correct, or not. This paper investigates whether users confuse authenticity with credibility by posing the question: Are users more likely to believe content from verified accounts than from non-verified accounts? We conduct two online studies, a year apart, with 748 and 2041 participants respectively, to assess how the presence or absence of verified account indicators influences users' perceptions of tweets. Surprisingly, across both studies, we find that---in the context of unfamiliar accounts---most users can effectively distinguish between authenticity and credibility. The presence or absence of an authenticity indicator has no significant effect on willingness to share a tweet or take action based on its contents."
pn9831,https://doi.org/10.1145/3290605.3300755,Does Being Verified Make You More Credible? Account Verification's Effect on Tweet Credibility,4,Micah Sherr,Georgetown University,Washington,United States,false,false,"Many popular social networking and microblogging sites support verified accounts---user accounts that are deemed of public interest and whose owners have been authenticated by the site. Importantly, the content of messages contributed by verified account owners is not verified. Such messages may be factually correct, or not. This paper investigates whether users confuse authenticity with credibility by posing the question: Are users more likely to believe content from verified accounts than from non-verified accounts? We conduct two online studies, a year apart, with 748 and 2041 participants respectively, to assess how the presence or absence of verified account indicators influences users' perceptions of tweets. Surprisingly, across both studies, we find that---in the context of unfamiliar accounts---most users can effectively distinguish between authenticity and credibility. The presence or absence of an authenticity indicator has no significant effect on willingness to share a tweet or take action based on its contents."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,1,Rakibul Hasan,Indiana University,Bloomington,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,2,Yifang Li,Clemson University,Central,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,3,Eman Hassan,Indiana University,Bloomington,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,4,Kelly Caine,Clemson University,Clemson,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,5,David Crandall,Indiana University,Bloomington,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,6,Roberto Hoyle,Oberlin College,Oberlin,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3536,https://doi.org/10.1145/3290605.3300597,Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms,7,Apu Kapadia,Indiana University,Bloomington,United States,false,false,"Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,1,Elham Vaziripour,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,2,Devon Howard,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,3,Jake Tyler,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,4,Mark O'neill,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,5,Justin Wu,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,6,Kent Seamons,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn3540,https://doi.org/10.1145/3290605.3300323,I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,7,Daniel Zappala,Brigham Young University,Provo,United States,false,false,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies."
pn7388,https://doi.org/10.1145/3290605.3300698,Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content,1,Abu Saleh Md Noman,Indiana University,Bloomington,United States,false,false,"Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale."
pn7388,https://doi.org/10.1145/3290605.3300698,Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content,2,Sanchari Das,Indiana University,Bloomington,United States,false,false,"Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale."
pn7388,https://doi.org/10.1145/3290605.3300698,Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content,3,Sameer Patil,Indiana University,Bloomington,United States,false,false,"Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale."
pn9258,https://doi.org/10.1145/3290605.3300834,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,1,Alisa Frik,International Computer Science Institute,Berkeley,United States,false,false,"Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
pn9258,https://doi.org/10.1145/3290605.3300834,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,2,Nathan Malkin,"University of California, Berkeley",Berkeley,United States,false,false,"Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
pn9258,https://doi.org/10.1145/3290605.3300834,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,3,Marian Harbach,International Computer Science Institute,Berkeley,United States,false,false,"Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
pn9258,https://doi.org/10.1145/3290605.3300834,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,4,Eyal Peer,Hebrew University of Jerusalem,Jerusalem,Israel,false,false,"Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
pn9258,https://doi.org/10.1145/3290605.3300834,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,5,Serge Egelman,International Computer Science Institute,Berkeley,United States,false,false,"Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
pn6879,https://doi.org/10.1145/3290605.3300492,Bringing Design to the Privacy Table: Broadening,1,Richmond Wong,"University of California, Berkeley",Berkeley,United States,true,false,"In calls for privacy by design (PBD), regulators and privacy scholars have investigated the richness of the concept of ""privacy."" In contrast, ""design"" in HCI is comprised of rich and complex concepts and practices, but has received much less attention in the PBD context. Conducting a literature review of HCI publications discussing privacy and design, this paper articulates a set of dimensions along which design relates to privacy, including: the purpose of design, which actors do design work in these settings, and the envisioned beneficiaries of design work. We suggest new roles for HCI and design in PBD research and practice: utilizing values- and critically-oriented design approaches to foreground social values and help define privacy problem spaces. We argue such approaches, in addition to current ""design to solve privacy problems"" efforts, are essential to the full realization of PBD, while noting the politics involved when choosing design to address privacy."
pn6879,https://doi.org/10.1145/3290605.3300492,Bringing Design to the Privacy Table: Broadening,2,Deirdre Mulligan,"University of California, Berkeley",Berkeley,United States,true,false,"In calls for privacy by design (PBD), regulators and privacy scholars have investigated the richness of the concept of ""privacy."" In contrast, ""design"" in HCI is comprised of rich and complex concepts and practices, but has received much less attention in the PBD context. Conducting a literature review of HCI publications discussing privacy and design, this paper articulates a set of dimensions along which design relates to privacy, including: the purpose of design, which actors do design work in these settings, and the envisioned beneficiaries of design work. We suggest new roles for HCI and design in PBD research and practice: utilizing values- and critically-oriented design approaches to foreground social values and help define privacy problem spaces. We argue such approaches, in addition to current ""design to solve privacy problems"" efforts, are essential to the full realization of PBD, while noting the politics involved when choosing design to address privacy."
pn4724,https://doi.org/10.1145/3290605.3300512,"Privacy, Power, and Invisible Labor on Amazon Mechanical Turk",1,Shruti Sannon,Cornell University,Ithaca,United States,false,false,"Tasks on crowdsourcing platforms such as Amazon Mechanical Turk often request workers' personal information, raising privacy risks that may be exacerbated by requester-worker power dynamics. We interviewed 14 workers to understand how they navigate these risks. We found that Turkers' decisions to provide personal information during tasks were based on evaluations of the pay rate, the requester, the purpose, and the perceived sensitivity of the request. Participants also engaged in multiple privacy-protective behaviors, such as abandoning tasks or providing inaccurate data, though there were costs associated with these behaviors, such as wasted time and risk of rejection. Finally, their privacy concerns and practices evolved as they learned about both the platform and worker-designed tools and forums. These findings deepen our understanding of both privacy decision-making and invisible labor in paid crowdsourcing, and emphasize a general need to understand how privacy stances change over time."
pn4724,https://doi.org/10.1145/3290605.3300512,"Privacy, Power, and Invisible Labor on Amazon Mechanical Turk",2,Dan Cosley,Cornell University,Ithaca,United States,false,false,"Tasks on crowdsourcing platforms such as Amazon Mechanical Turk often request workers' personal information, raising privacy risks that may be exacerbated by requester-worker power dynamics. We interviewed 14 workers to understand how they navigate these risks. We found that Turkers' decisions to provide personal information during tasks were based on evaluations of the pay rate, the requester, the purpose, and the perceived sensitivity of the request. Participants also engaged in multiple privacy-protective behaviors, such as abandoning tasks or providing inaccurate data, though there were costs associated with these behaviors, such as wasted time and risk of rejection. Finally, their privacy concerns and practices evolved as they learned about both the platform and worker-designed tools and forums. These findings deepen our understanding of both privacy decision-making and invisible labor in paid crowdsourcing, and emphasize a general need to understand how privacy stances change over time."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,1,Matthew Bernhard,University of Michigan,Ann Arbor,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,2,Jonathan Sharman,Rice University,Houston,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,3,Claudia Acemyan,Rice University,Houston,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,4,Philip Kortum,Rice University,Houston,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,5,Dan Wallach,Rice University,Houston,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn2649,https://doi.org/10.1145/3290605.3300540,On the Usability of HTTPS Deployment,6,J. Halderman,University of Michigan,Ann Arbor,United States,false,false,"HTTPS and TLS are the backbone of Internet security, however setting up web servers to run these protocols is a notoriously difficult process. In this paper, we perform two live subjects usability studies on the deployment of HTTPS in a real-world setting. Study 1 is a within subjects comparison between traditional HTTPS configuration (purchasing a certificate and installing it on a server) and Let's Encrypt, which automates much of the process. Study 2 is a between subjects study looking at the same two systems, examining why users encounter usability issues. Overall we confirm past results that HTTPS is difficult to deploy, and we find some evidence that suggests Let's Encrypt is an easier, more efficient method for deploying HTTPS."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,1,Carolina Fuentes,University of Nottingham,Nottingham,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,2,Martin Porcheron,University of Nottingham,Nottingham,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,3,Joel Fischer,University of Nottingham,Nottingham,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,4,Enrico Costanza,University College London,London,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,5,Obaid Malilk,University of Southampton,Southampton,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5353,https://doi.org/10.1145/3290605.3300869,Tracking the Consumption of Home Essentials,6,Sarvapali Ramchurn,University of Southampton,Southampton,United Kingdom,false,false,"Predictions of people's behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people's practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue."
pn5745,https://doi.org/10.1145/3290605.3300581,Alternative Avenues for IoT: Designing with Non-Stereotypical Homes,1,Audrey Desjardins,University of Washington,Seattle,United States,true,false,"We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen."
pn5745,https://doi.org/10.1145/3290605.3300581,Alternative Avenues for IoT: Designing with Non-Stereotypical Homes,2,Jeremy Viny,University of Washington,Seattle,United States,true,false,"We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen."
pn5745,https://doi.org/10.1145/3290605.3300581,Alternative Avenues for IoT: Designing with Non-Stereotypical Homes,3,Cayla Key,University of Washington,Seattle,United States,true,false,"We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen."
pn5745,https://doi.org/10.1145/3290605.3300581,Alternative Avenues for IoT: Designing with Non-Stereotypical Homes,4,Nouela Johnston,University of Washington,Seattle,United States,true,false,"We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen."
pn4702,https://doi.org/10.1145/3290605.3300546,"""Collective Wisdom"": Inquiring into Collective Homes as a Site for HCI Design",1,Jo Shin,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"The home has been a major focus of the HCI community for over two decades. Despite this body of research, nascent works have argued that HCI's characterization of 'the home' remains narrow and requires more diverse accounts of domestic configurations. Our work contributes to this area through a four-month ethnography of three collective homes in Vancouver, Canada. Collective homes represent an alternative housing model that offers agency to individual members and the collective group by sharing values, resources, labour, space and memory. Our paper offers two contributions. First, we offer an in-depth design ethnography of three collective homes, attending to the values, ownership models, practices, and everyday interactions observed in the ongoing making of these domestic settings. Second, we interpret and synthesize our findings to provide new opportunities for expanding the way we conceptualize and design for 'the home' in HCI."
pn4702,https://doi.org/10.1145/3290605.3300546,"""Collective Wisdom"": Inquiring into Collective Homes as a Site for HCI Design",2,Gabriela Aceves Sepúlveda,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"The home has been a major focus of the HCI community for over two decades. Despite this body of research, nascent works have argued that HCI's characterization of 'the home' remains narrow and requires more diverse accounts of domestic configurations. Our work contributes to this area through a four-month ethnography of three collective homes in Vancouver, Canada. Collective homes represent an alternative housing model that offers agency to individual members and the collective group by sharing values, resources, labour, space and memory. Our paper offers two contributions. First, we offer an in-depth design ethnography of three collective homes, attending to the values, ownership models, practices, and everyday interactions observed in the ongoing making of these domestic settings. Second, we interpret and synthesize our findings to provide new opportunities for expanding the way we conceptualize and design for 'the home' in HCI."
pn4702,https://doi.org/10.1145/3290605.3300546,"""Collective Wisdom"": Inquiring into Collective Homes as a Site for HCI Design",3,William Odom,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"The home has been a major focus of the HCI community for over two decades. Despite this body of research, nascent works have argued that HCI's characterization of 'the home' remains narrow and requires more diverse accounts of domestic configurations. Our work contributes to this area through a four-month ethnography of three collective homes in Vancouver, Canada. Collective homes represent an alternative housing model that offers agency to individual members and the collective group by sharing values, resources, labour, space and memory. Our paper offers two contributions. First, we offer an in-depth design ethnography of three collective homes, attending to the values, ownership models, practices, and everyday interactions observed in the ongoing making of these domestic settings. Second, we interpret and synthesize our findings to provide new opportunities for expanding the way we conceptualize and design for 'the home' in HCI."
pn3828,https://doi.org/10.1145/3290605.3300498,Who's In Control? Interactions In Multi-User Smart Homes,1,Christine Geeng,University of Washington,Seattle,United States,false,false,"Adoption of commercial smart home devices is rapidly increasing, allowing in-situ research in people's homes. As these technologies are deployed in shared spaces, we seek to understand interactions among multiple people and devices in a smart home. We conducted a mixed-methods study with 18 participants (primarily people who drive smart device adoption in their homes) living in multi-user smart homes, combining semi-structured interviews and experience sampling. Our findings surface tensions and cooperation among users in several phases of smart device use: device selection and installation, ordinary use, when the smart home does not work as expected, and over longer term use. We observe an outsized role of the person who installs devices in terms of selecting, controlling, and fixing them; negotiations between parents and children; and minimally voiced privacy concerns among co-occupants, possibly due to participant sampling. We make design recommendations for supporting long-term smart homes and non-expert household members."
pn3828,https://doi.org/10.1145/3290605.3300498,Who's In Control? Interactions In Multi-User Smart Homes,2,Franziska Roesner,University of Washington,Seattle,United States,false,false,"Adoption of commercial smart home devices is rapidly increasing, allowing in-situ research in people's homes. As these technologies are deployed in shared spaces, we seek to understand interactions among multiple people and devices in a smart home. We conducted a mixed-methods study with 18 participants (primarily people who drive smart device adoption in their homes) living in multi-user smart homes, combining semi-structured interviews and experience sampling. Our findings surface tensions and cooperation among users in several phases of smart device use: device selection and installation, ordinary use, when the smart home does not work as expected, and over longer term use. We observe an outsized role of the person who installs devices in terms of selecting, controlling, and fixing them; negotiations between parents and children; and minimally voiced privacy concerns among co-occupants, possibly due to participant sampling. We make design recommendations for supporting long-term smart homes and non-expert household members."
pn5293,https://doi.org/10.1145/3290605.3300528,"The Promise of Empathy: Design, Disability, and Knowing the 'Other'",1,Cynthia Bennett,University of Washington,Seattle,United States,false,false,"This paper examines the promise of empathy, the name commonly given to the initial phase of the human-centered design process in which designers seek to understand their intended users in order to inform technology development. By analyzing popular empathy activities aimed at understanding people with disabilities, we examine the ways empathy works to both powerfully and problematically align designers with the values of people who may use their products. Drawing on disability studies and feminist theorizing, we describe how acts of empathy building may further distance people with disabilities from the processes designers intend to draw them into. We end by reimagining empathy as guided by the lived experiences of people with disabilities who are traditionally positioned as those to be empathized."
pn5293,https://doi.org/10.1145/3290605.3300528,"The Promise of Empathy: Design, Disability, and Knowing the 'Other'",2,Daniela Rosner,University of Washington,Seattle,United States,false,false,"This paper examines the promise of empathy, the name commonly given to the initial phase of the human-centered design process in which designers seek to understand their intended users in order to inform technology development. By analyzing popular empathy activities aimed at understanding people with disabilities, we examine the ways empathy works to both powerfully and problematically align designers with the values of people who may use their products. Drawing on disability studies and feminist theorizing, we describe how acts of empathy building may further distance people with disabilities from the processes designers intend to draw them into. We end by reimagining empathy as guided by the lived experiences of people with disabilities who are traditionally positioned as those to be empathized."
pn2508,https://doi.org/10.1145/3290605.3300385,Apprise: Supporting the Critical-Agency of Victims of Human Trafficking in Thailand,1,Hannah Thinyane,"United Nations University, Institute on Computing",Macau,Macao,false,false,"Human trafficking and forced labor are global issues affecting millions of people around the world. This paper describes an initiative that we are currently undertaking to understand the role technology can play to support the critical-agency of migrant workers in these situations of severe exploitation. Building on five consultations with more than 170 direct and indirect stakeholders in Thailand, the paper presents the co-design, development, and evaluation of Apprise, a mobile app to support the identification of victims of human trafficking using a Value Sensitive Design approach. It also provides a critical reflection on the use of digital technology in the initial screening of potential victims of human trafficking, to understand in what ways Apprise can support the critical agency of migrant workers in vulnerable situations."
pn2508,https://doi.org/10.1145/3290605.3300385,Apprise: Supporting the Critical-Agency of Victims of Human Trafficking in Thailand,2,Karthik Bhat,"United Nations University, Institute on Computing",Macau,Macao,false,false,"Human trafficking and forced labor are global issues affecting millions of people around the world. This paper describes an initiative that we are currently undertaking to understand the role technology can play to support the critical-agency of migrant workers in these situations of severe exploitation. Building on five consultations with more than 170 direct and indirect stakeholders in Thailand, the paper presents the co-design, development, and evaluation of Apprise, a mobile app to support the identification of victims of human trafficking using a Value Sensitive Design approach. It also provides a critical reflection on the use of digital technology in the initial screening of potential victims of human trafficking, to understand in what ways Apprise can support the critical agency of migrant workers in vulnerable situations."
pn4081,https://doi.org/10.1145/3290605.3300510,Engaging Gentrification as a Social Justice Issue in HCI,1,Eric Corbett,Georgia Institute of Technology,Atlanta,United States,false,false,"Gentrification—the spatial expression of economic inequality—is fundamentally a matter of social justice. Yet, even as work outside of HCI has begun to discuss how computing can enable or challenge gentrification, HCI's growing social justice agenda has not engaged with this issue. This omission creates an opportunity for HCI to develop a research and design agenda at the intersection of computing, social justice, and gentrification. We begin this work by outlining existing scholarship describing how the consumption side dynamics of gentrification are mediated by contemporary socio-technical systems. Subsequently, we build on the social justice framework introduced by Dombrowski, Harmon, and Fox to discuss how HCI may resist or counter such forces. We offer six modes of research that HCI scholars can pursue to engage gentrification."
pn4081,https://doi.org/10.1145/3290605.3300510,Engaging Gentrification as a Social Justice Issue in HCI,2,Yanni Loukissas,Georgia Institute of Technology,Atlanta,United States,false,false,"Gentrification—the spatial expression of economic inequality—is fundamentally a matter of social justice. Yet, even as work outside of HCI has begun to discuss how computing can enable or challenge gentrification, HCI's growing social justice agenda has not engaged with this issue. This omission creates an opportunity for HCI to develop a research and design agenda at the intersection of computing, social justice, and gentrification. We begin this work by outlining existing scholarship describing how the consumption side dynamics of gentrification are mediated by contemporary socio-technical systems. Subsequently, we build on the social justice framework introduced by Dombrowski, Harmon, and Fox to discuss how HCI may resist or counter such forces. We offer six modes of research that HCI scholars can pursue to engage gentrification."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,1,Alexis Hope,Massachusetts Institute of Technology,Cambridge,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,2,Catherine D'ignazio,Emerson College,Boston,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,3,Josephine Hoy,University of Washington,Seattle,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,4,Rebecca Michelson,Independent Researcher,Boston,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,5,Jennifer Roberts,Versed Education Group,Washington,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,6,Kate Krontiris,Independent Researcher,Freetown,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn7832,https://doi.org/10.1145/3290605.3300291,Hackathons as Participatory Design: Iterating Feminist Utopias,7,Ethan Zuckerman,Massachusetts Institute of Technology,Cambridge,United States,true,false,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,1,Sarah Lopez,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,2,Yi Yang,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,3,Kevin Beltran,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,4,Soo Jung Kim,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,5,Jennifer Cruz Hernandez,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,6,Chelsy Simran,University of San Francisco,San Francsico,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,7,Bingkun Yang,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn8065,https://doi.org/10.1145/3290605.3300787,Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony,8,Beste Yuksel,University of San Francisco,San Francisco,United States,true,false,"Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,1,Shlomo Berkovsky,Data61 - CSIRO,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,2,Ronnie Taib,Data61 - CSIRO,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,3,Irena Koprinska,University of Sydney,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,4,Eileen Wang,University of Sydney,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,5,Yucheng Zeng,University of Sydney,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,6,Jingjie Li,University of Wisconsin–Madison,Madison,United States,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6847,https://doi.org/10.1145/3290605.3300451,Detecting Personality Traits Using Eye-Tracking Data,7,Sabina Kleitman,University of Sydney,Sydney,Australia,false,true,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection."
pn6561,https://doi.org/10.1145/3290605.3300888,As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity,1,Ana Tajadura-Jiménez,Universidad Carlos III de Madrid,Leganés,Spain,false,false,"Supporting exercise adherence through technology remains an important HCI challenge. Recent works showed that altering walking sounds leads people perceiving themselves as thinner/lighter, happier and walking more dynamically. While this novel approach shows potential for physical activity, it raises critical questions impacting technology design. We ran two studies in the context of exertion (gym-step, stairs-climbing) to investigate how individual factors impact the effect of sound and the duration of the after-effects. The results confirm that the effects of sound in body-perception occur even in physically demanding situations and through ubiquitous wearable devices. We also show that the effect of sound interacted with participants' body weight and masculinity/femininity aspirations, but not with gender. Additionally, changes in body-perceptions did not hold once the feedback stopped; however, body-feelings or behavioural changes appeared to persist for longer. We discuss the results in terms of malleability of body-perception and highlight opportunities for supporting exercise adherence."
pn6561,https://doi.org/10.1145/3290605.3300888,As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity,2,Joseph Newbold,University College London,London,United Kingdom,false,false,"Supporting exercise adherence through technology remains an important HCI challenge. Recent works showed that altering walking sounds leads people perceiving themselves as thinner/lighter, happier and walking more dynamically. While this novel approach shows potential for physical activity, it raises critical questions impacting technology design. We ran two studies in the context of exertion (gym-step, stairs-climbing) to investigate how individual factors impact the effect of sound and the duration of the after-effects. The results confirm that the effects of sound in body-perception occur even in physically demanding situations and through ubiquitous wearable devices. We also show that the effect of sound interacted with participants' body weight and masculinity/femininity aspirations, but not with gender. Additionally, changes in body-perceptions did not hold once the feedback stopped; however, body-feelings or behavioural changes appeared to persist for longer. We discuss the results in terms of malleability of body-perception and highlight opportunities for supporting exercise adherence."
pn6561,https://doi.org/10.1145/3290605.3300888,As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity,3,Linge Zhang,University College London,London,United Kingdom,false,false,"Supporting exercise adherence through technology remains an important HCI challenge. Recent works showed that altering walking sounds leads people perceiving themselves as thinner/lighter, happier and walking more dynamically. While this novel approach shows potential for physical activity, it raises critical questions impacting technology design. We ran two studies in the context of exertion (gym-step, stairs-climbing) to investigate how individual factors impact the effect of sound and the duration of the after-effects. The results confirm that the effects of sound in body-perception occur even in physically demanding situations and through ubiquitous wearable devices. We also show that the effect of sound interacted with participants' body weight and masculinity/femininity aspirations, but not with gender. Additionally, changes in body-perceptions did not hold once the feedback stopped; however, body-feelings or behavioural changes appeared to persist for longer. We discuss the results in terms of malleability of body-perception and highlight opportunities for supporting exercise adherence."
pn6561,https://doi.org/10.1145/3290605.3300888,As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity,4,Patricia Rick,Universidad Loyola Andalucía,Seville,Spain,false,false,"Supporting exercise adherence through technology remains an important HCI challenge. Recent works showed that altering walking sounds leads people perceiving themselves as thinner/lighter, happier and walking more dynamically. While this novel approach shows potential for physical activity, it raises critical questions impacting technology design. We ran two studies in the context of exertion (gym-step, stairs-climbing) to investigate how individual factors impact the effect of sound and the duration of the after-effects. The results confirm that the effects of sound in body-perception occur even in physically demanding situations and through ubiquitous wearable devices. We also show that the effect of sound interacted with participants' body weight and masculinity/femininity aspirations, but not with gender. Additionally, changes in body-perceptions did not hold once the feedback stopped; however, body-feelings or behavioural changes appeared to persist for longer. We discuss the results in terms of malleability of body-perception and highlight opportunities for supporting exercise adherence."
pn6561,https://doi.org/10.1145/3290605.3300888,As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity,5,Nadia Bianchi-Berthouze,University College London,London,United Kingdom,false,false,"Supporting exercise adherence through technology remains an important HCI challenge. Recent works showed that altering walking sounds leads people perceiving themselves as thinner/lighter, happier and walking more dynamically. While this novel approach shows potential for physical activity, it raises critical questions impacting technology design. We ran two studies in the context of exertion (gym-step, stairs-climbing) to investigate how individual factors impact the effect of sound and the duration of the after-effects. The results confirm that the effects of sound in body-perception occur even in physically demanding situations and through ubiquitous wearable devices. We also show that the effect of sound interacted with participants' body weight and masculinity/femininity aspirations, but not with gender. Additionally, changes in body-perceptions did not hold once the feedback stopped; however, body-feelings or behavioural changes appeared to persist for longer. We discuss the results in terms of malleability of body-perception and highlight opportunities for supporting exercise adherence."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",1,Joohwan Kim,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",2,Michael Stengel,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",3,Alexander Majercik,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",4,Shalini De Mello,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",5,David Dunn,University of North Carolina - Chapel Hill,Chapel Hill,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",6,Samuli Laine,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",7,Morgan Mcguire,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn9749,https://doi.org/10.1145/3290605.3300780,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",8,David Luebke,NVIDIA,Santa Clara,United States,false,false,"Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°×40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods."
pn4969,https://doi.org/10.1145/3290605.3300646,Evaluation of Appearance-Based Methods and Implications for Gaze-Based Applications,1,Xucong Zhang,Saarland Informatics Campus,Saarbrücken,Germany,false,false,"Appearance-based gaze estimation methods that only require an off-the-shelf camera have significantly improved but they are still not yet widely used in the human-computer interaction (HCI) community. This is partly because it remains unclear how they perform compared to model-based approaches as well as dominant, special-purpose eye tracking equipment. To address this limitation, we evaluate the performance of state-of-the-art appearance-based gaze estimation for interaction scenarios with and without personal calibration, indoors and outdoors, for different sensing distances, as well as for users with and without glasses. We discuss the obtained findings and their implications for the most important gaze-based applications, namely explicit eye input, attentive user interfaces, gaze-based user modelling, and passive eye monitoring. To democratise the use of appearance-based gaze estimation and interaction in HCI, we finally present OpenGaze (www.opengaze.org), the first software toolkit for appearance-based gaze estimation and interaction."
pn4969,https://doi.org/10.1145/3290605.3300646,Evaluation of Appearance-Based Methods and Implications for Gaze-Based Applications,2,Yusuke Sugano,Osaka University,Osaka,Japan,false,false,"Appearance-based gaze estimation methods that only require an off-the-shelf camera have significantly improved but they are still not yet widely used in the human-computer interaction (HCI) community. This is partly because it remains unclear how they perform compared to model-based approaches as well as dominant, special-purpose eye tracking equipment. To address this limitation, we evaluate the performance of state-of-the-art appearance-based gaze estimation for interaction scenarios with and without personal calibration, indoors and outdoors, for different sensing distances, as well as for users with and without glasses. We discuss the obtained findings and their implications for the most important gaze-based applications, namely explicit eye input, attentive user interfaces, gaze-based user modelling, and passive eye monitoring. To democratise the use of appearance-based gaze estimation and interaction in HCI, we finally present OpenGaze (www.opengaze.org), the first software toolkit for appearance-based gaze estimation and interaction."
pn4969,https://doi.org/10.1145/3290605.3300646,Evaluation of Appearance-Based Methods and Implications for Gaze-Based Applications,3,Andreas Bulling,University of Stuttgart,Stuttgart,Germany,false,false,"Appearance-based gaze estimation methods that only require an off-the-shelf camera have significantly improved but they are still not yet widely used in the human-computer interaction (HCI) community. This is partly because it remains unclear how they perform compared to model-based approaches as well as dominant, special-purpose eye tracking equipment. To address this limitation, we evaluate the performance of state-of-the-art appearance-based gaze estimation for interaction scenarios with and without personal calibration, indoors and outdoors, for different sensing distances, as well as for users with and without glasses. We discuss the obtained findings and their implications for the most important gaze-based applications, namely explicit eye input, attentive user interfaces, gaze-based user modelling, and passive eye monitoring. To democratise the use of appearance-based gaze estimation and interaction in HCI, we finally present OpenGaze (www.opengaze.org), the first software toolkit for appearance-based gaze estimation and interaction."
pn3718,https://doi.org/10.1145/3290605.3300689,"""Like Popcorn"": Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children",1,Oussama Metatla,University of Bristol,Bristol,United Kingdom,false,false,"There is increasing interest in multisensory experiences in HCI. However, little research considers how sensory modalities interact with each other and how this may impact interactive experiences. We investigate how children associate emotions with scents and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to attribute emotional characteristics to variants of the ""Bouba/Kiki"" stimuli, presented as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings support pre-existing mappings between shapes and scents, and confirm the associations between the combination of angular shapes (""Kiki"") and lemon scent with arousing emotion, and of round shapes (""Bouba"") and vanilla scent with calming emotion. This extends prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D shapes), sample (children), and conveyed content (emotions). We outline how these findings can contribute to designing more inclusive interactive multisensory technologies."
pn3718,https://doi.org/10.1145/3290605.3300689,"""Like Popcorn"": Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children",2,Emanuela Maggioni,University of Sussex,Brighton,United Kingdom,false,false,"There is increasing interest in multisensory experiences in HCI. However, little research considers how sensory modalities interact with each other and how this may impact interactive experiences. We investigate how children associate emotions with scents and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to attribute emotional characteristics to variants of the ""Bouba/Kiki"" stimuli, presented as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings support pre-existing mappings between shapes and scents, and confirm the associations between the combination of angular shapes (""Kiki"") and lemon scent with arousing emotion, and of round shapes (""Bouba"") and vanilla scent with calming emotion. This extends prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D shapes), sample (children), and conveyed content (emotions). We outline how these findings can contribute to designing more inclusive interactive multisensory technologies."
pn3718,https://doi.org/10.1145/3290605.3300689,"""Like Popcorn"": Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children",3,Clare Cullen,University of Bristol,Bristol,United Kingdom,false,false,"There is increasing interest in multisensory experiences in HCI. However, little research considers how sensory modalities interact with each other and how this may impact interactive experiences. We investigate how children associate emotions with scents and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to attribute emotional characteristics to variants of the ""Bouba/Kiki"" stimuli, presented as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings support pre-existing mappings between shapes and scents, and confirm the associations between the combination of angular shapes (""Kiki"") and lemon scent with arousing emotion, and of round shapes (""Bouba"") and vanilla scent with calming emotion. This extends prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D shapes), sample (children), and conveyed content (emotions). We outline how these findings can contribute to designing more inclusive interactive multisensory technologies."
pn3718,https://doi.org/10.1145/3290605.3300689,"""Like Popcorn"": Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children",4,Marianna Obrist,University of Sussex,Brighton,United Kingdom,false,false,"There is increasing interest in multisensory experiences in HCI. However, little research considers how sensory modalities interact with each other and how this may impact interactive experiences. We investigate how children associate emotions with scents and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to attribute emotional characteristics to variants of the ""Bouba/Kiki"" stimuli, presented as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings support pre-existing mappings between shapes and scents, and confirm the associations between the combination of angular shapes (""Kiki"") and lemon scent with arousing emotion, and of round shapes (""Bouba"") and vanilla scent with calming emotion. This extends prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D shapes), sample (children), and conveyed content (emotions). We outline how these findings can contribute to designing more inclusive interactive multisensory technologies."
pn2881,https://doi.org/10.1145/3290605.3300826,360proto: Making Interactive Virtual Reality & Augmented Reality Prototypes from Paper,1,Michael Nebeling,University of Michigan,Ann Arbor,United States,false,false,"We explore 360 paper prototyping to rapidly create AR/VR prototypes from paper and bring them to life on AR/VR devices. Our approach is based on a set of emerging paper prototyping templates specifically for AR/VR. These templates resemble the key components of many AR/VR interfaces, including 2D representations of immersive environments, AR marker overlays and face masks, VR controller models and menus, and 2D screens and HUDs. To make prototyping with these templates effective, we developed 360proto, a suite of three novel physical--digital prototyping tools: (1) the 360proto Camera for capturing paper mockups of all components simply by taking a photo with a smartphone and seeing 360-degree panoramic previews on the phone or stereoscopic previews in Google Cardboard; (2) the 360proto Studio for organizing and editing captures, for composing AR/VR interfaces by layering the captures, and for making them interactive with Wizard of Oz via live video streaming; (3) the 360proto App for running and testing the interactive prototypes on AR/VR capable mobile devices and headsets. Through five student design jams with a total of 86 participants and our own design space explorations, we demonstrate that our approach with 360proto is useful to create relatively complex AR/VR applications."
pn2881,https://doi.org/10.1145/3290605.3300826,360proto: Making Interactive Virtual Reality & Augmented Reality Prototypes from Paper,2,Katy Madier,University of Michigan,Ann Arbor,United States,false,false,"We explore 360 paper prototyping to rapidly create AR/VR prototypes from paper and bring them to life on AR/VR devices. Our approach is based on a set of emerging paper prototyping templates specifically for AR/VR. These templates resemble the key components of many AR/VR interfaces, including 2D representations of immersive environments, AR marker overlays and face masks, VR controller models and menus, and 2D screens and HUDs. To make prototyping with these templates effective, we developed 360proto, a suite of three novel physical--digital prototyping tools: (1) the 360proto Camera for capturing paper mockups of all components simply by taking a photo with a smartphone and seeing 360-degree panoramic previews on the phone or stereoscopic previews in Google Cardboard; (2) the 360proto Studio for organizing and editing captures, for composing AR/VR interfaces by layering the captures, and for making them interactive with Wizard of Oz via live video streaming; (3) the 360proto App for running and testing the interactive prototypes on AR/VR capable mobile devices and headsets. Through five student design jams with a total of 86 participants and our own design space explorations, we demonstrate that our approach with 360proto is useful to create relatively complex AR/VR applications."
pn3622,https://doi.org/10.1145/3290605.3300664,Older Voices: Supporting Community Radio Production for Civic Participation in Later Life,1,Arlind Reuter,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests."
pn3622,https://doi.org/10.1145/3290605.3300664,Older Voices: Supporting Community Radio Production for Civic Participation in Later Life,2,Tom Bartindale,Monash University,Melbourne,Australia,false,false,"Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests."
pn3622,https://doi.org/10.1145/3290605.3300664,Older Voices: Supporting Community Radio Production for Civic Participation in Later Life,3,Kellie Morrissey,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests."
pn3622,https://doi.org/10.1145/3290605.3300664,Older Voices: Supporting Community Radio Production for Civic Participation in Later Life,4,Thomas Scharf,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests."
pn3622,https://doi.org/10.1145/3290605.3300664,Older Voices: Supporting Community Radio Production for Civic Participation in Later Life,5,Jennifer Liddle,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests."
pn7522,https://doi.org/10.1145/3290605.3300860,JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data,1,Sunil Rodger,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Recent HCI research has investigated how digital technologies might enable citizens to identify and express matters of civic concern. We extend this work by describing JourneyCam, a smartphone-based system that enables powered wheelchair users to capture video and sensor data about their experiences of mobility. Thirteen participants used JourneyCam to document journeys, after which the data they collected was used to support discussions around their experiences. Our findings highlight how the system facilitated the articulation of complex embodied experiences, and how the collected data might have particular value in surfacing these experiences to help inform urban design and policymaking. Participants valued the ways in which JourneyCam's moving image and sensor data made hard-to-express sensations apparent, as well as how it enabled them to surface previously unrecognised issues. We conclude by highlighting future opportunities for how such tools might enable citizens to inform and influence civic governance."
pn7522,https://doi.org/10.1145/3290605.3300860,JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data,2,Dan Jackson,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Recent HCI research has investigated how digital technologies might enable citizens to identify and express matters of civic concern. We extend this work by describing JourneyCam, a smartphone-based system that enables powered wheelchair users to capture video and sensor data about their experiences of mobility. Thirteen participants used JourneyCam to document journeys, after which the data they collected was used to support discussions around their experiences. Our findings highlight how the system facilitated the articulation of complex embodied experiences, and how the collected data might have particular value in surfacing these experiences to help inform urban design and policymaking. Participants valued the ways in which JourneyCam's moving image and sensor data made hard-to-express sensations apparent, as well as how it enabled them to surface previously unrecognised issues. We conclude by highlighting future opportunities for how such tools might enable citizens to inform and influence civic governance."
pn7522,https://doi.org/10.1145/3290605.3300860,JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data,3,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Recent HCI research has investigated how digital technologies might enable citizens to identify and express matters of civic concern. We extend this work by describing JourneyCam, a smartphone-based system that enables powered wheelchair users to capture video and sensor data about their experiences of mobility. Thirteen participants used JourneyCam to document journeys, after which the data they collected was used to support discussions around their experiences. Our findings highlight how the system facilitated the articulation of complex embodied experiences, and how the collected data might have particular value in surfacing these experiences to help inform urban design and policymaking. Participants valued the ways in which JourneyCam's moving image and sensor data made hard-to-express sensations apparent, as well as how it enabled them to surface previously unrecognised issues. We conclude by highlighting future opportunities for how such tools might enable citizens to inform and influence civic governance."
pn7522,https://doi.org/10.1145/3290605.3300860,JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data,4,Janice Mclaughlin,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Recent HCI research has investigated how digital technologies might enable citizens to identify and express matters of civic concern. We extend this work by describing JourneyCam, a smartphone-based system that enables powered wheelchair users to capture video and sensor data about their experiences of mobility. Thirteen participants used JourneyCam to document journeys, after which the data they collected was used to support discussions around their experiences. Our findings highlight how the system facilitated the articulation of complex embodied experiences, and how the collected data might have particular value in surfacing these experiences to help inform urban design and policymaking. Participants valued the ways in which JourneyCam's moving image and sensor data made hard-to-express sensations apparent, as well as how it enabled them to surface previously unrecognised issues. We conclude by highlighting future opportunities for how such tools might enable citizens to inform and influence civic governance."
pn7522,https://doi.org/10.1145/3290605.3300860,JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data,5,Peter Wright,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Recent HCI research has investigated how digital technologies might enable citizens to identify and express matters of civic concern. We extend this work by describing JourneyCam, a smartphone-based system that enables powered wheelchair users to capture video and sensor data about their experiences of mobility. Thirteen participants used JourneyCam to document journeys, after which the data they collected was used to support discussions around their experiences. Our findings highlight how the system facilitated the articulation of complex embodied experiences, and how the collected data might have particular value in surfacing these experiences to help inform urban design and policymaking. Participants valued the ways in which JourneyCam's moving image and sensor data made hard-to-express sensations apparent, as well as how it enabled them to surface previously unrecognised issues. We conclude by highlighting future opportunities for how such tools might enable citizens to inform and influence civic governance."
pn2922,https://doi.org/10.1145/3290605.3300485,Crowdlicit: A System for Conducting Distributed End-User Elicitation and Identification Studies,1,Abdullah Ali,University of Washington,Seattle,United States,false,false,"End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris's ""Web on the Wall"" study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris's. We evaluated the effectiveness of 49 symbols (43 from Morris and six from Crowdlicit) by conducting a crowd-powered identification study. We show that the Crowdlicit elicitation study resulted in a set of symbols that was significantly more identifiable than Morris's."
pn2922,https://doi.org/10.1145/3290605.3300485,Crowdlicit: A System for Conducting Distributed End-User Elicitation and Identification Studies,2,Meredith Morris,Microsoft Research,Redmond,United States,false,false,"End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris's ""Web on the Wall"" study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris's. We evaluated the effectiveness of 49 symbols (43 from Morris and six from Crowdlicit) by conducting a crowd-powered identification study. We show that the Crowdlicit elicitation study resulted in a set of symbols that was significantly more identifiable than Morris's."
pn2922,https://doi.org/10.1145/3290605.3300485,Crowdlicit: A System for Conducting Distributed End-User Elicitation and Identification Studies,3,Jacob Wobbrock,University of Washington,Seattle,United States,false,false,"End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris's ""Web on the Wall"" study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris's. We evaluated the effectiveness of 49 symbols (43 from Morris and six from Crowdlicit) by conducting a crowd-powered identification study. We show that the Crowdlicit elicitation study resulted in a set of symbols that was significantly more identifiable than Morris's."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,1,Guo Freeman,Clemson University,Clemson,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,2,Jeffrey Bardzell,Indiana University,Bloomington,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,3,Shaowen Bardzell,Indiana University,Bloomington,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,4,Szu-Yu (Cyn) Liu,Indiana University,Bloomington,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,5,Xi Lu,Indiana University,Bloomington,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4162,https://doi.org/10.1145/3290605.3300274,Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics,6,Diandian Cao,Indiana University,Bloomington,United States,true,false,"What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of ""placemaking"" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies."
pn4945,https://doi.org/10.1145/3290605.3300659,Feeling Fireworks: An Inclusive Tactile Firework Display,1,Dorothea Reusser,Disney Research,Zurich,Switzerland,false,false,"This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile effects are created at high spatial resolution on a flexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile firework show. The goal is to make fireworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile firework effects and corresponding visual fireworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use."
pn4945,https://doi.org/10.1145/3290605.3300659,Feeling Fireworks: An Inclusive Tactile Firework Display,2,Espen Knoop,Disney Research,Zurich,Switzerland,false,false,"This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile effects are created at high spatial resolution on a flexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile firework show. The goal is to make fireworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile firework effects and corresponding visual fireworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use."
pn4945,https://doi.org/10.1145/3290605.3300659,Feeling Fireworks: An Inclusive Tactile Firework Display,3,Roland Siegwart,ETH Zürich,Zurich,Switzerland,false,false,"This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile effects are created at high spatial resolution on a flexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile firework show. The goal is to make fireworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile firework effects and corresponding visual fireworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use."
pn4945,https://doi.org/10.1145/3290605.3300659,Feeling Fireworks: An Inclusive Tactile Firework Display,4,Paul Beardsley,Disney Research,Zurich,Switzerland,false,false,"This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile effects are created at high spatial resolution on a flexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile firework show. The goal is to make fireworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile firework effects and corresponding visual fireworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use."
pn4453,https://doi.org/10.1145/3290605.3300436,Editing Spatial Layouts through Tactile Templates for People with Visual Impairments,1,Jingyi Li,Stanford University,Stanford,United States,false,false,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors."
pn4453,https://doi.org/10.1145/3290605.3300436,Editing Spatial Layouts through Tactile Templates for People with Visual Impairments,2,Son Kim,Vista Center for the Blind and Visually Impaired,Palo Alto,United States,false,false,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors."
pn4453,https://doi.org/10.1145/3290605.3300436,Editing Spatial Layouts through Tactile Templates for People with Visual Impairments,3,Joshua Miele,The Smith-Kettlewell Eye Research Institute,San Francisco,United States,false,false,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors."
pn4453,https://doi.org/10.1145/3290605.3300436,Editing Spatial Layouts through Tactile Templates for People with Visual Impairments,4,Maneesh Agrawala,Stanford University,Stanford,United States,false,false,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors."
pn4453,https://doi.org/10.1145/3290605.3300436,Editing Spatial Layouts through Tactile Templates for People with Visual Impairments,5,Sean Follmer,Stanford University,Stanford,United States,false,false,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,1,Seita Kayukawa,Carnegie Mellon University,Tokyo,Japan,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,2,Keita Higuchi,University of Tokyo,Tokyo,Japan,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,3,João Guerreiro,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,4,Shigeo Morishima,Waseda Research Institute for Science and Engineering,Tokyo,Japan,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,5,Yoichi Sato,University of Tokyo,Tokyo,Japan,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,6,Kris Kitani,Carnegie Mellon University,Pittsburgh,United States,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn3466,https://doi.org/10.1145/3290605.3300282,BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians,7,Chieko Asakawa,Carnegie Mellon University,Yorktown Heights,United States,false,false,"We present an assistive suitcase system, BBeep, for supporting blind people when walking through crowded environments. BBeep uses pre-emptive sound notifications to help clear a path by alerting both the user and nearby pedestrians about the potential risk of collision. BBeep triggers notifications by tracking pedestrians, predicting their future position in real-time, and provides sound notifications only when it anticipates a future collision. We investigate how different types and timings of sound affect nearby pedestrian behavior. In our experiments, we found that sound emission timing has a significant impact on nearby pedestrian trajectories when compared to different sound types. Based on these findings, we performed a real-world user study at an international airport, where blind participants navigated with the suitcase in crowded areas. We observed that the proposed system significantly reduces the number of imminent collisions."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,1,Patrizia Di Campli San Vito,University of Glasgow,Glasgow,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,2,Gözel Shakeri,University of Glasgow,Glasgow,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,3,Stephen Brewster,University of Glasgow,Glasgow,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,4,Frank Pollick,University of Glasgow,Glasgow,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,5,Edward Brown,Jaguar Land Rover Ltd.,Coventry,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,6,Lee Skrypchuk,Jaguar Land Rover Ltd.,Coventry,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn8102,https://doi.org/10.1145/3290605.3300440,Haptic Navigation Cues on the Steering Wheel,7,Alexandros Mouzakitis,Jaguar Land Rover Ltd.,Coventry,United Kingdom,false,false,"Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns)."
pn2727,https://doi.org/10.1145/3290605.3300258,MindDot: Supporting Effective Cognitive Behaviors in Concept Map-Based Learning Environments,1,Shang Wang,Arizona State University,Tempe,United States,false,false,"While prior research has revealed the promising impact of concept mapping on learning, few have comprehensively modeled different cognitive behaviors during concept mapping. In addition, existing concept mapping tools lack effective feedback to support better learning behaviors. This work presents MindDot, a concept map-based learning environment that facilitates the cognitive process of comparing and integrating related concepts via two forms of support. A hyperlink support and an expert template. Study results suggested that both types of support had positive impact on the development of comparative strategies and that hyperlink support enhanced learning. We further evaluated the cognitive learning progress at a fine-grained level with two forms of visualizations. We then extracted several behavioral patterns that provided insights about the cognitive progress in learning. Lastly, we derive design recommendations that we hope will inspire future intelligent tutoring systems that automatically evaluate students' learning behaviors and foster them in developing effective learning behaviors"
pn2727,https://doi.org/10.1145/3290605.3300258,MindDot: Supporting Effective Cognitive Behaviors in Concept Map-Based Learning Environments,2,Deniz Sonmez Unal,University of Pittsburgh,Pittsburgh,United States,false,false,"While prior research has revealed the promising impact of concept mapping on learning, few have comprehensively modeled different cognitive behaviors during concept mapping. In addition, existing concept mapping tools lack effective feedback to support better learning behaviors. This work presents MindDot, a concept map-based learning environment that facilitates the cognitive process of comparing and integrating related concepts via two forms of support. A hyperlink support and an expert template. Study results suggested that both types of support had positive impact on the development of comparative strategies and that hyperlink support enhanced learning. We further evaluated the cognitive learning progress at a fine-grained level with two forms of visualizations. We then extracted several behavioral patterns that provided insights about the cognitive progress in learning. Lastly, we derive design recommendations that we hope will inspire future intelligent tutoring systems that automatically evaluate students' learning behaviors and foster them in developing effective learning behaviors"
pn2727,https://doi.org/10.1145/3290605.3300258,MindDot: Supporting Effective Cognitive Behaviors in Concept Map-Based Learning Environments,3,Erin Walker,University of Pittsburgh,Pittsburgh,United States,false,false,"While prior research has revealed the promising impact of concept mapping on learning, few have comprehensively modeled different cognitive behaviors during concept mapping. In addition, existing concept mapping tools lack effective feedback to support better learning behaviors. This work presents MindDot, a concept map-based learning environment that facilitates the cognitive process of comparing and integrating related concepts via two forms of support. A hyperlink support and an expert template. Study results suggested that both types of support had positive impact on the development of comparative strategies and that hyperlink support enhanced learning. We further evaluated the cognitive learning progress at a fine-grained level with two forms of visualizations. We then extracted several behavioral patterns that provided insights about the cognitive progress in learning. Lastly, we derive design recommendations that we hope will inspire future intelligent tutoring systems that automatically evaluate students' learning behaviors and foster them in developing effective learning behaviors"
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,1,Sherry Ruan,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,2,Liwei Jiang,Colby College,Waterville,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,3,Justin Xu,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,4,Bryce Tham,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,5,Zhengneng Qiu,HCI,Plao Alto,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,6,Yeshuang Zhu,Tsinghua University,Beijing,China,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,7,Elizabeth Murnane,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,8,Emma Brunskill,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn4765,https://doi.org/10.1145/3290605.3300587,QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge,9,James Landay,Stanford University,Stanford,United States,false,false,"Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings."
pn6703,https://doi.org/10.1145/3290605.3300387,Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities,1,Peter Börjesson,University of Gothenburg,Gothenburg,Sweden,false,false,"This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design."
pn6703,https://doi.org/10.1145/3290605.3300387,Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities,2,Wolmet Barendregt,University of Gothenburg,Gothenburg,Sweden,false,false,"This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design."
pn6703,https://doi.org/10.1145/3290605.3300387,Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities,3,Eva Eriksson,Aarhus University,Aarhus,Denmark,false,false,"This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design."
pn6703,https://doi.org/10.1145/3290605.3300387,Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities,4,Olof Torgersson,University of Gothenburg,Gothenburg,Sweden,false,false,"This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design."
pn6703,https://doi.org/10.1145/3290605.3300387,Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities,5,Tilde Bekker,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",1,Hasan Shahid Ferdous,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",2,Thuong Hoang,Deakin University,Burwood,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",3,Zaher Joukhadar,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",4,Martin Reinoso,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",5,Frank Vetere,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",6,David Kelly,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn8085,https://doi.org/10.1145/3290605.3300464,"""What's Happening at that Hip?"": Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom",7,Louisa Remedios,University of Melbourne,Melbourne,Australia,false,false,"We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body."
pn2435,https://doi.org/10.1145/3290605.3300438,Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks,1,Michael Long,University of Saskatchewan,Saskatoon,Canada,false,false,"Studies have shown certain game tasks such as targeting to be negatively and significantly affected by latencies as low as 41ms. Therefore it is important to understand the relationship between local latency - delays between an input action and resulting change in the display - and common gaming tasks such as targeting and tracking. In addition, games now use a variety of input devices, including touchscreens, mice, tablets and controllers. These devices provide very different combinations of direct/indirect input, absolute/relative movement, and position/rate control, and are likely to be affected by latency in different ways. We performed a study evaluating and comparing the effects of latency across four devices (touchscreen, mouse, controller and drawing tablet) on targeting and interception tasks. We analyze both throughput and path characteristics, identify differences between devices, and provide design considerations for game designers."
pn2435,https://doi.org/10.1145/3290605.3300438,Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks,2,Carl Gutwin,University of Saskatchewan,Saskatoon,Canada,false,false,"Studies have shown certain game tasks such as targeting to be negatively and significantly affected by latencies as low as 41ms. Therefore it is important to understand the relationship between local latency - delays between an input action and resulting change in the display - and common gaming tasks such as targeting and tracking. In addition, games now use a variety of input devices, including touchscreens, mice, tablets and controllers. These devices provide very different combinations of direct/indirect input, absolute/relative movement, and position/rate control, and are likely to be affected by latency in different ways. We performed a study evaluating and comparing the effects of latency across four devices (touchscreen, mouse, controller and drawing tablet) on targeting and interception tasks. We analyze both throughput and path characteristics, identify differences between devices, and provide design considerations for game designers."
pn3645,https://doi.org/10.1145/3290605.3300790,Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games,1,Injung Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Effects of unintended latency on gamer performance have been reported. End-to-end latency can be corrected by post-input manipulation of activation times, but this gives the player unnatural gameplay experience. For moving-target selection games such as Flappy Bird, the paper presents a predictive model of latency on error rate and a novel compensation method for the latency effects by adjusting the game's geometry design -- e.g., by modifying the size of the selection region. Without manipulation of the game clock, this can keep the user's error rate constant even if the end-to-end latency of the system changes. The approach extends the current model of moving-target selection with two additional assumptions about the effects of latency: (1) latency reduces players' cue-viewing time and (2) pushes the mean of the input distribution backward. The model and method proposed have been validated through precise experiments."
pn3645,https://doi.org/10.1145/3290605.3300790,Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games,2,Sunjun Kim,Aalto University,Helsinki,Finland,false,false,"Effects of unintended latency on gamer performance have been reported. End-to-end latency can be corrected by post-input manipulation of activation times, but this gives the player unnatural gameplay experience. For moving-target selection games such as Flappy Bird, the paper presents a predictive model of latency on error rate and a novel compensation method for the latency effects by adjusting the game's geometry design -- e.g., by modifying the size of the selection region. Without manipulation of the game clock, this can keep the user's error rate constant even if the end-to-end latency of the system changes. The approach extends the current model of moving-target selection with two additional assumptions about the effects of latency: (1) latency reduces players' cue-viewing time and (2) pushes the mean of the input distribution backward. The model and method proposed have been validated through precise experiments."
pn3645,https://doi.org/10.1145/3290605.3300790,Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games,3,Byungjoo Lee,KAIST,Daejeon,Republic Of Korea,false,false,"Effects of unintended latency on gamer performance have been reported. End-to-end latency can be corrected by post-input manipulation of activation times, but this gives the player unnatural gameplay experience. For moving-target selection games such as Flappy Bird, the paper presents a predictive model of latency on error rate and a novel compensation method for the latency effects by adjusting the game's geometry design -- e.g., by modifying the size of the selection region. Without manipulation of the game clock, this can keep the user's error rate constant even if the end-to-end latency of the system changes. The approach extends the current model of moving-target selection with two additional assumptions about the effects of latency: (1) latency reduces players' cue-viewing time and (2) pushes the mean of the input distribution backward. The model and method proposed have been validated through precise experiments."
pn4732,https://doi.org/10.1145/3290605.3300593,Aggregated Visualization of Playtesting Data,1,Günter Wallner,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Playtesting is a key component in the game development process aimed at improving the quality of games through the collection of gameplay data and identification of design issues. Visualization techniques are currently being employed to help integrate quantitative and qualitative data. Despite that, two existing challenges are to determine the level of detail to be presented to developers based on their needs and to effectively communicate the collected data so that informed design changes can be reached. In this paper, we first propose an aggregated visualization technique that makes use of clustering, territory tessellation, and trajectory aggregation to simultaneously display mixed playtesting data. Secondly, to assess the usefulness of our technique we evaluate it through interviews with professional game developers and compare it to a non-aggregated visualization. The results of this study also provide an important contribution towards identifying areas of improvement in the portrayal of gameplay data."
pn4732,https://doi.org/10.1145/3290605.3300593,Aggregated Visualization of Playtesting Data,2,Nour Halabi,University of Ontario Institute of Technology,Oshawa,Canada,false,false,"Playtesting is a key component in the game development process aimed at improving the quality of games through the collection of gameplay data and identification of design issues. Visualization techniques are currently being employed to help integrate quantitative and qualitative data. Despite that, two existing challenges are to determine the level of detail to be presented to developers based on their needs and to effectively communicate the collected data so that informed design changes can be reached. In this paper, we first propose an aggregated visualization technique that makes use of clustering, territory tessellation, and trajectory aggregation to simultaneously display mixed playtesting data. Secondly, to assess the usefulness of our technique we evaluate it through interviews with professional game developers and compare it to a non-aggregated visualization. The results of this study also provide an important contribution towards identifying areas of improvement in the portrayal of gameplay data."
pn4732,https://doi.org/10.1145/3290605.3300593,Aggregated Visualization of Playtesting Data,3,Pejman Mirza-Babaei,University of Ontario Institute of Technology,Oshawa,Canada,false,false,"Playtesting is a key component in the game development process aimed at improving the quality of games through the collection of gameplay data and identification of design issues. Visualization techniques are currently being employed to help integrate quantitative and qualitative data. Despite that, two existing challenges are to determine the level of detail to be presented to developers based on their needs and to effectively communicate the collected data so that informed design changes can be reached. In this paper, we first propose an aggregated visualization technique that makes use of clustering, territory tessellation, and trajectory aggregation to simultaneously display mixed playtesting data. Secondly, to assess the usefulness of our technique we evaluate it through interviews with professional game developers and compare it to a non-aggregated visualization. The results of this study also provide an important contribution towards identifying areas of improvement in the portrayal of gameplay data."
pn4113,https://doi.org/10.1145/3290605.3300781,Transforming Game Difficulty Curves using Function Composition,1,Anurag Sarkar,Northeastern University,Boston,United States,false,false,"Player engagement within a game is often influenced by its difficulty curve: the pace at which in-game challenges become harder. Thus, finding an optimal difficulty curve is important. In this paper, we present a flexible and formal approach to transforming game difficulty curves by leveraging function composition. This allows us to describe changes to difficulty curves, such as making them ""smoother"", in a more precise way. In an experiment with 400 players, we used function composition to modify the existing difficulty curve of the puzzle game Paradox to generate new curves. We found that transforming difficulty curves in this way impacted player engagement, including the number of levels completed and the estimated skill needed to complete those levels, as well as perceived competence. Further, we found some transformed curves dominated others with respect to engagement, indicating that different design goals can be traded-off by considering a subset of curves."
pn4113,https://doi.org/10.1145/3290605.3300781,Transforming Game Difficulty Curves using Function Composition,2,Seth Cooper,Northeastern University,Boston,United States,false,false,"Player engagement within a game is often influenced by its difficulty curve: the pace at which in-game challenges become harder. Thus, finding an optimal difficulty curve is important. In this paper, we present a flexible and formal approach to transforming game difficulty curves by leveraging function composition. This allows us to describe changes to difficulty curves, such as making them ""smoother"", in a more precise way. In an experiment with 400 players, we used function composition to modify the existing difficulty curve of the puzzle game Paradox to generate new curves. We found that transforming difficulty curves in this way impacted player engagement, including the number of levels completed and the estimated skill needed to complete those levels, as well as perceived competence. Further, we found some transformed curves dominated others with respect to engagement, indicating that different design goals can be traded-off by considering a subset of curves."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,1,Maria Roussou,National and Kapodistrian University of Athens,Athens,Greece,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,2,Sara Perry,The University of York,York,United Kingdom,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,3,Akrivi Katifori,Athena Research Center,Athens,Greece,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,4,Stavros Vassos,Helvia Technologies,Athens,Greece,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,5,Angeliki Tzouganatou,University of Hamburg,Hamburg,Germany,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn9479,https://doi.org/10.1145/3290605.3300857,Transformation through Provocation?,6,Sierra Mckinney,The University of York,York,United Kingdom,false,false,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely."
pn2273,https://doi.org/10.1145/3290605.3300680,Beyond Dyadic Interactions: Considering Chatbots as Community Members,1,Joseph Seering,Carnegie Mellon University,Pittsburgh,United States,false,false,"Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas."
pn2273,https://doi.org/10.1145/3290605.3300680,Beyond Dyadic Interactions: Considering Chatbots as Community Members,2,Michal Luria,Carnegie Mellon University,Pittsburgh,United States,false,false,"Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas."
pn2273,https://doi.org/10.1145/3290605.3300680,Beyond Dyadic Interactions: Considering Chatbots as Community Members,3,Geoff Kaufman,Carnegie Mellon University,Pittsburgh,United States,false,false,"Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas."
pn2273,https://doi.org/10.1145/3290605.3300680,Beyond Dyadic Interactions: Considering Chatbots as Community Members,4,Jessica Hammer,Carnegie Mellon University,Pittsburgh,United States,false,false,"Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas."
pn8877,https://doi.org/10.1145/3290605.3300316,Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality,1,Soomin Kim,Seoul National University,Seoul,Republic Of Korea,false,false,"This study aims to explore the feasibility of a text-based virtual agent as a new survey method to overcome the web survey's common response quality problems, which are caused by respondents' inattention. To this end, we conducted a 2 (platform: web vs. chatbot) × 2 (conversational style: formal vs. casual) experiment. We used satisficing theory to compare the responses' data quality. We found that the participants in the chatbot survey, as compared to those in the web survey, were more likely to produce differentiated responses and were less likely to satisfice; the chatbot survey thus resulted in higher-quality data. Moreover, when a casual conversational style is used, the participants were less likely to satisfice–although such effects were only found in the chatbot condition. These results imply that conversational interactivity occurs when a chat interface is accompanied by messages with effective tone. Based on an analysis of the qualitative responses, we also showed that a chatbot could perform part of a human interviewer's role by applying effective communication strategies."
pn8877,https://doi.org/10.1145/3290605.3300316,Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality,2,Joonhwan Lee,Seoul National University,Seoul,Republic Of Korea,false,false,"This study aims to explore the feasibility of a text-based virtual agent as a new survey method to overcome the web survey's common response quality problems, which are caused by respondents' inattention. To this end, we conducted a 2 (platform: web vs. chatbot) × 2 (conversational style: formal vs. casual) experiment. We used satisficing theory to compare the responses' data quality. We found that the participants in the chatbot survey, as compared to those in the web survey, were more likely to produce differentiated responses and were less likely to satisfice; the chatbot survey thus resulted in higher-quality data. Moreover, when a casual conversational style is used, the participants were less likely to satisfice–although such effects were only found in the chatbot condition. These results imply that conversational interactivity occurs when a chat interface is accompanied by messages with effective tone. Based on an analysis of the qualitative responses, we also showed that a chatbot could perform part of a human interviewer's role by applying effective communication strategies."
pn8877,https://doi.org/10.1145/3290605.3300316,Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality,3,Gahgene Gweon,Seoul National University,Seoul,Republic Of Korea,false,false,"This study aims to explore the feasibility of a text-based virtual agent as a new survey method to overcome the web survey's common response quality problems, which are caused by respondents' inattention. To this end, we conducted a 2 (platform: web vs. chatbot) × 2 (conversational style: formal vs. casual) experiment. We used satisficing theory to compare the responses' data quality. We found that the participants in the chatbot survey, as compared to those in the web survey, were more likely to produce differentiated responses and were less likely to satisfice; the chatbot survey thus resulted in higher-quality data. Moreover, when a casual conversational style is used, the participants were less likely to satisfice–although such effects were only found in the chatbot condition. These results imply that conversational interactivity occurs when a chat interface is accompanied by messages with effective tone. Based on an analysis of the qualitative responses, we also showed that a chatbot could perform part of a human interviewer's role by applying effective communication strategies."
pn5479,https://doi.org/10.1145/3290605.3300714,Co-Performing Agent: Design for Building User-Agent Partnership in Learning and Adaptive Services,1,Da-Jung Kim,KAIST,Daejeon,Republic Of Korea,false,false,"Intelligent agents have become prevalent in everyday IT products and services. To improve an agent's knowledge of a user and the quality of personalized service experience, it is important for the agent to cooperate with the user (e.g., asking users to provide their information and feedback). However, few works inform how to support such user-agent co-performance from a human-centered perspective. To fill this gap, we devised Co-Performing Agent, a Wizard-of-Oz-based research probe of an agent that cooperates with a user to learn by helping users to have a partnership mindset. By incorporating the probe, we conducted a two-month exploratory study, aiming to understand how users experience co-performing with their agent over time. Based on the findings, this paper presents the factors that affected users' co-performing behaviors and discusses design implications for supporting constructive co-performance and building a resilient user–agent partnership over time."
pn5479,https://doi.org/10.1145/3290605.3300714,Co-Performing Agent: Design for Building User-Agent Partnership in Learning and Adaptive Services,2,Youn-Kyung Lim,KAIST,Daejeon,Republic Of Korea,false,false,"Intelligent agents have become prevalent in everyday IT products and services. To improve an agent's knowledge of a user and the quality of personalized service experience, it is important for the agent to cooperate with the user (e.g., asking users to provide their information and feedback). However, few works inform how to support such user-agent co-performance from a human-centered perspective. To fill this gap, we devised Co-Performing Agent, a Wizard-of-Oz-based research probe of an agent that cooperates with a user to learn by helping users to have a partnership mindset. By incorporating the probe, we conducted a two-month exploratory study, aiming to understand how users experience co-performing with their agent over time. Based on the findings, this paper presents the factors that affected users' co-performing behaviors and discusses design implications for supporting constructive co-performance and building a resilient user–agent partnership over time."
jrnl1128,https://doi.org/10.1145/3290607.3313849,Interpretive Impacts of Text Visualization: Mitigating Political Framing Effects,1,Eric Baumer,Lehigh University,Bethlehem,United States,false,false,"Information visualizations are often evaluated as a tool in terms of their ability to support performance of a specific task. This paper argues that value can be gained by instead evaluating visualizations from a communicative perspective. Specifically, it explores how text visualization can influence the impacts that framing has on the perception of political issues. Using data from a controlled laboratory study, the results presented here demonstrate that exposure to a text visualization can mitigate framing effects. Furthermore, it also shows a transfer effect, where participants who saw the visualization remained uninfluenced by framing in subsequent texts, even when the visualization was absent. These results carry implications for the methods used to evaluate information visualization systems, for understanding the cognitive and interpretive mechanisms by which framing effects occur, and for exploring the design space of interactive text visualization."
jrnl1128,https://doi.org/10.1145/3290607.3313849,Interpretive Impacts of Text Visualization: Mitigating Political Framing Effects,2,Jaime Snyder,University of Washington,Seattle,United States,false,false,"Information visualizations are often evaluated as a tool in terms of their ability to support performance of a specific task. This paper argues that value can be gained by instead evaluating visualizations from a communicative perspective. Specifically, it explores how text visualization can influence the impacts that framing has on the perception of political issues. Using data from a controlled laboratory study, the results presented here demonstrate that exposure to a text visualization can mitigate framing effects. Furthermore, it also shows a transfer effect, where participants who saw the visualization remained uninfluenced by framing in subsequent texts, even when the visualization was absent. These results carry implications for the methods used to evaluate information visualization systems, for understanding the cognitive and interpretive mechanisms by which framing effects occur, and for exploring the design space of interactive text visualization."
jrnl1128,https://doi.org/10.1145/3290607.3313849,Interpretive Impacts of Text Visualization: Mitigating Political Framing Effects,3,Geraldine Gay,Cornell University,Ithaca,United States,false,false,"Information visualizations are often evaluated as a tool in terms of their ability to support performance of a specific task. This paper argues that value can be gained by instead evaluating visualizations from a communicative perspective. Specifically, it explores how text visualization can influence the impacts that framing has on the perception of political issues. Using data from a controlled laboratory study, the results presented here demonstrate that exposure to a text visualization can mitigate framing effects. Furthermore, it also shows a transfer effect, where participants who saw the visualization remained uninfluenced by framing in subsequent texts, even when the visualization was absent. These results carry implications for the methods used to evaluate information visualization systems, for understanding the cognitive and interpretive mechanisms by which framing effects occur, and for exploring the design space of interactive text visualization."
jrnl1115,https://doi.org/10.1145/3290607.3313842,Hidden Work and the Challenges of Scalability and Sustainability in Ambulatory Assisted Living,1,Joe Wherton,Oxford University,Oxford,United Kingdom,false,false,"Assisted living technologies may help people live independently while also —potentially— reducing health and care costs. But they are notoriously difficult to implement at scale and many devices are abandoned following initial adoption. We report findings from a study of global positioning system (GPS) tracking devices intended to support the independent living of people with cognitive impairment. Our aims were threefold: to understand (through ethnography) such individuals' lived experience of GPS tracking; to facilitate (through action research) the customization and adaptation of technologies and care services to provide effective, ongoing support; and to explore the possibilities for a co-production methodology that would enable people with cognitive impairment and their families to work with professionals and technical designers to shape these devices and services to meet their particular needs in a sustainable way. We found that the articulation work needed for maintaining the GPS technology in ""working order"" was extensive and ongoing. This articulation work does not merely supplement formal procedures, a lot of it is needed to get round them, but it is also often invisible and thus its importance goes largely unrecognized. If GPS technologies are to be implemented at scale and sustainably, methods must be found to capitalize on the skills and tacit knowledge held within the care network (professional and lay) to resolve problems, improve device design, devise new service solutions, and foster organizational learning"
jrnl1115,https://doi.org/10.1145/3290607.3313842,Hidden Work and the Challenges of Scalability and Sustainability in Ambulatory Assisted Living,2,Trisha Greenhalgh,Oxford University,Oxford,United Kingdom,false,false,"Assisted living technologies may help people live independently while also —potentially— reducing health and care costs. But they are notoriously difficult to implement at scale and many devices are abandoned following initial adoption. We report findings from a study of global positioning system (GPS) tracking devices intended to support the independent living of people with cognitive impairment. Our aims were threefold: to understand (through ethnography) such individuals' lived experience of GPS tracking; to facilitate (through action research) the customization and adaptation of technologies and care services to provide effective, ongoing support; and to explore the possibilities for a co-production methodology that would enable people with cognitive impairment and their families to work with professionals and technical designers to shape these devices and services to meet their particular needs in a sustainable way. We found that the articulation work needed for maintaining the GPS technology in ""working order"" was extensive and ongoing. This articulation work does not merely supplement formal procedures, a lot of it is needed to get round them, but it is also often invisible and thus its importance goes largely unrecognized. If GPS technologies are to be implemented at scale and sustainably, methods must be found to capitalize on the skills and tacit knowledge held within the care network (professional and lay) to resolve problems, improve device design, devise new service solutions, and foster organizational learning"
jrnl1126,https://doi.org/10.1145/3290607.3313848,Looking South: Learning Urban Perception in Developing Cities,1,Darshan Santani,Idiap Research Institute,Martigny/Lausanne,Switzerland,false,false,"Mobile and social technologies are providing new opportunities to document, characterize, and gather impressions of urban environments. In this article, we present a study that examines urban perceptions of three cities in central Mexico; the study integrates a mobile crowdsourcing framework to collect geo-localized images of urban environments by a local youth community, an online crowdsourcing platform to gather impressions of urban environments along 12 physical and psychological dimensions, and a deep learning framework to automatically infer human impressions of outdoor urban scenes. Our study resulted in a collection of 7,000 geo-localized images containing outdoor scenes and views of each city's built environment, including touristic, historical, and residential neighborhoods, and 144,000 individual judgments from Amazon Mechanical Turk. Statistical analyses show that outdoor environments can be assessed in terms of interrater agreement for most of the urban dimensions by the observers of crowdsourced images. Furthermore, we proposed a methodology to automatically infer human perceptions of outdoor scenes using a variety of low-level image features and generic deep learning (CNN) features. We found that CNN features consistently outperformed all the individual low-level image features for all the studied urban dimensions. We obtained a maximum R2 of 0.49 using CNN features; for 9 out of 12 labels, the obtained R2 values exceeded 0.44."
jrnl1126,https://doi.org/10.1145/3290607.3313848,Looking South: Learning Urban Perception in Developing Cities,2,Salvador Ruiz Correa,Instituto Potosino de Investigación Científica y Tecnológica,San Luis Potosí,Mexico,false,false,"Mobile and social technologies are providing new opportunities to document, characterize, and gather impressions of urban environments. In this article, we present a study that examines urban perceptions of three cities in central Mexico; the study integrates a mobile crowdsourcing framework to collect geo-localized images of urban environments by a local youth community, an online crowdsourcing platform to gather impressions of urban environments along 12 physical and psychological dimensions, and a deep learning framework to automatically infer human impressions of outdoor urban scenes. Our study resulted in a collection of 7,000 geo-localized images containing outdoor scenes and views of each city's built environment, including touristic, historical, and residential neighborhoods, and 144,000 individual judgments from Amazon Mechanical Turk. Statistical analyses show that outdoor environments can be assessed in terms of interrater agreement for most of the urban dimensions by the observers of crowdsourced images. Furthermore, we proposed a methodology to automatically infer human perceptions of outdoor scenes using a variety of low-level image features and generic deep learning (CNN) features. We found that CNN features consistently outperformed all the individual low-level image features for all the studied urban dimensions. We obtained a maximum R2 of 0.49 using CNN features; for 9 out of 12 labels, the obtained R2 values exceeded 0.44."
jrnl1126,https://doi.org/10.1145/3290607.3313848,Looking South: Learning Urban Perception in Developing Cities,3,Daniel Gatica-Perez,Idiap-EPFL,Lausanne,Switzerland,false,false,"Mobile and social technologies are providing new opportunities to document, characterize, and gather impressions of urban environments. In this article, we present a study that examines urban perceptions of three cities in central Mexico; the study integrates a mobile crowdsourcing framework to collect geo-localized images of urban environments by a local youth community, an online crowdsourcing platform to gather impressions of urban environments along 12 physical and psychological dimensions, and a deep learning framework to automatically infer human impressions of outdoor urban scenes. Our study resulted in a collection of 7,000 geo-localized images containing outdoor scenes and views of each city's built environment, including touristic, historical, and residential neighborhoods, and 144,000 individual judgments from Amazon Mechanical Turk. Statistical analyses show that outdoor environments can be assessed in terms of interrater agreement for most of the urban dimensions by the observers of crowdsourced images. Furthermore, we proposed a methodology to automatically infer human perceptions of outdoor scenes using a variety of low-level image features and generic deep learning (CNN) features. We found that CNN features consistently outperformed all the individual low-level image features for all the studied urban dimensions. We obtained a maximum R2 of 0.49 using CNN features; for 9 out of 12 labels, the obtained R2 values exceeded 0.44."
pn8708,https://doi.org/10.1145/3290605.3300474,Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania,1,Evan Peck,Bucknell University,Lewisburg,United States,false,true,"Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the 'data poor'. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/"
pn8708,https://doi.org/10.1145/3290605.3300474,Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania,2,Sofia Ayuso,Bucknell University,Lewisburg,United States,false,true,"Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the 'data poor'. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/"
pn8708,https://doi.org/10.1145/3290605.3300474,Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania,3,Omar El-Etr,Bucknell University,Lewisburg,United States,false,true,"Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the 'data poor'. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/"
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,1,Nam Wook Kim,Harvard University,Cambridge,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,2,Hyejin Im,Tufts University,Medford,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,3,Nathalie Henry Riche,Microsoft Research,Redmond,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,4,Alicia Wang,Troy High School,Fullerton,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,5,Krzysztof Gajos,Harvard University,Cambridge,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn8881,https://doi.org/10.1145/3290605.3300309,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,6,Hanspeter Pfister,Harvard University,Cambridge,United States,false,false,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data."
pn3940,https://doi.org/10.1145/3290605.3300912,A Bayesian Cognition Approach to Improve Data Visualization,1,Yea-Seul Kim,University of Washington,Seattle,United States,false,false,"People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty."
pn3940,https://doi.org/10.1145/3290605.3300912,A Bayesian Cognition Approach to Improve Data Visualization,2,Logan Walls,University of Washington,Seattle,United States,false,false,"People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty."
pn3940,https://doi.org/10.1145/3290605.3300912,A Bayesian Cognition Approach to Improve Data Visualization,3,Peter Krafft,University of Washington,Seattle,United States,false,false,"People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty."
pn3940,https://doi.org/10.1145/3290605.3300912,A Bayesian Cognition Approach to Improve Data Visualization,4,Jessica Hullman,Northwestern University,Evanston,United States,false,false,"People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,1,In Kwon Choi,Indiana University-Purdue University Indianapolis,Indianapolis,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,2,Taylor Childers,Indiana University-Purdue University Indianapolis,Indianapolis,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,3,Nirmal Kumar Raveendranath,Indiana University-Purdue University Indianapolis,Indianapolis,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,4,Swati Mishra,Cornell University,Ithaca,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,5,Kyle Harris,Indiana University-Purdue University Indianapolis,Indianapolis,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn5724,https://doi.org/10.1145/3290605.3300298,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,6,Khairi Reda,Indiana University-Purdue University Indianapolis,Indianapolis,United States,false,false,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved."
pn4284,https://doi.org/10.1145/3290605.3300343,Thermporal: An Easy-To-Deploy Temporal Thermographic Sensor System to Support Residential Energy Audits,1,Matthew Mauriello,"University of Maryland, College Park",College Park,United States,false,false,"Underperforming, degraded, and missing insulation in US residential buildings is common. Detecting these issues, however, can be difficult. Using thermal cameras during energy audits can aid in locating potential insulation issues, but prior work indicates it is challenging to determine their severity using thermal imagery alone. In this work, we present an easy-to-deploy, temporal thermographic sensor system designed to support residential energy audits through quantitative analysis of building envelope performance. We then offer an evaluation of the system through two studies: (i) a one-week, in-home field study in five homes and (ii) a semi-structured interview study with five professional energy auditors. Our results show our system helps raise awareness, improves homeowners' ability to gauge the severity of issues, and provides opportunities for new interactions between homeowners, building data, and professional auditors."
pn4284,https://doi.org/10.1145/3290605.3300343,Thermporal: An Easy-To-Deploy Temporal Thermographic Sensor System to Support Residential Energy Audits,2,Brenna Mcnally,"University of Maryland, College Park",College Park,United States,false,false,"Underperforming, degraded, and missing insulation in US residential buildings is common. Detecting these issues, however, can be difficult. Using thermal cameras during energy audits can aid in locating potential insulation issues, but prior work indicates it is challenging to determine their severity using thermal imagery alone. In this work, we present an easy-to-deploy, temporal thermographic sensor system designed to support residential energy audits through quantitative analysis of building envelope performance. We then offer an evaluation of the system through two studies: (i) a one-week, in-home field study in five homes and (ii) a semi-structured interview study with five professional energy auditors. Our results show our system helps raise awareness, improves homeowners' ability to gauge the severity of issues, and provides opportunities for new interactions between homeowners, building data, and professional auditors."
pn4284,https://doi.org/10.1145/3290605.3300343,Thermporal: An Easy-To-Deploy Temporal Thermographic Sensor System to Support Residential Energy Audits,3,Jon Froehlich,University of Washington,Seattle,United States,false,false,"Underperforming, degraded, and missing insulation in US residential buildings is common. Detecting these issues, however, can be difficult. Using thermal cameras during energy audits can aid in locating potential insulation issues, but prior work indicates it is challenging to determine their severity using thermal imagery alone. In this work, we present an easy-to-deploy, temporal thermographic sensor system designed to support residential energy audits through quantitative analysis of building envelope performance. We then offer an evaluation of the system through two studies: (i) a one-week, in-home field study in five homes and (ii) a semi-structured interview study with five professional energy auditors. Our results show our system helps raise awareness, improves homeowners' ability to gauge the severity of issues, and provides opportunities for new interactions between homeowners, building data, and professional auditors."
pn6901,https://doi.org/10.1145/3290605.3300894,Designing Participatory Sensing with Remote Communities to Conserve Endangered Species,1,Tshering Dema,Queensland University of Technology,Brisbane,Australia,false,false,"The increasing loss of species globally calls for effective monitoring tools and strategies to inform conservation action. The dominant approach to citizens engagement has been smart phone and platform-centric, tasking crowds to collect and analyze data. However, many critically endangered species inhabit remote areas, characterized by sparsely populated communities with poor internet connectivity. Approaches need to garner high engagement relative to population size, with data collection and knowledge synthesis suited to the local context. We conducted a field study in remote communities to understand how to enhance conservation of Bhutan's critically endangered White-bellied heron by exploring existing monitoring practices and trialing acoustic sensing technologies. We found that knowledge about the species is partial, heterogeneous, situated within and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces, and playful probes provided new ways for the community to 'see' and discuss their local environment fostering them to share and grow their knowledge together. We contribute a synthesis of key considerations for designing effective community participation to conserve species in remote communities."
pn6901,https://doi.org/10.1145/3290605.3300894,Designing Participatory Sensing with Remote Communities to Conserve Endangered Species,2,Margot Brereton,Queensland University of Technology,Brisbane,Australia,false,false,"The increasing loss of species globally calls for effective monitoring tools and strategies to inform conservation action. The dominant approach to citizens engagement has been smart phone and platform-centric, tasking crowds to collect and analyze data. However, many critically endangered species inhabit remote areas, characterized by sparsely populated communities with poor internet connectivity. Approaches need to garner high engagement relative to population size, with data collection and knowledge synthesis suited to the local context. We conducted a field study in remote communities to understand how to enhance conservation of Bhutan's critically endangered White-bellied heron by exploring existing monitoring practices and trialing acoustic sensing technologies. We found that knowledge about the species is partial, heterogeneous, situated within and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces, and playful probes provided new ways for the community to 'see' and discuss their local environment fostering them to share and grow their knowledge together. We contribute a synthesis of key considerations for designing effective community participation to conserve species in remote communities."
pn6901,https://doi.org/10.1145/3290605.3300894,Designing Participatory Sensing with Remote Communities to Conserve Endangered Species,3,Paul Roe,Queensland University of Technology,Brisbane,Australia,false,false,"The increasing loss of species globally calls for effective monitoring tools and strategies to inform conservation action. The dominant approach to citizens engagement has been smart phone and platform-centric, tasking crowds to collect and analyze data. However, many critically endangered species inhabit remote areas, characterized by sparsely populated communities with poor internet connectivity. Approaches need to garner high engagement relative to population size, with data collection and knowledge synthesis suited to the local context. We conducted a field study in remote communities to understand how to enhance conservation of Bhutan's critically endangered White-bellied heron by exploring existing monitoring practices and trialing acoustic sensing technologies. We found that knowledge about the species is partial, heterogeneous, situated within and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces, and playful probes provided new ways for the community to 'see' and discuss their local environment fostering them to share and grow their knowledge together. We contribute a synthesis of key considerations for designing effective community participation to conserve species in remote communities."
pn7904,https://doi.org/10.1145/3290605.3300627,Evaluating Sustainable Interaction Design of Digital Services: The Case of YouTube,1,Chris Preist,University of Bristol,Bristol,United Kingdom,true,false,"Recent research has advocated for a broader conception of evaluation for Sustainable HCI (SHCI), using interdisciplinary insights and methods. In this paper, we put this into practice to conduct an evaluation of Sustainable Interaction Design (SID) of digital services. We explore how SID can contribute to corporate greenhouse gas (GHG) reduction strategies. We show how a Digital Service Provider (DSP) might incorporate SID into their design process and quantitatively evaluate a specific SID intervention by combining user analytics data with environmental life cycle assessment. We illustrate this by considering YouTube. Replacing user analytics data with aggregate estimates from publicly available sources, we estimate emissions associated with the deployment of YouTube to be approximately 10MtCO2e p.a. We estimate emissions reductions enabled through the use of an SID intervention from prior literature to be approximately 300KtCO2e p.a., and demonstrate that this is significant when considered alongside other emissions reduction interventions used by DSPs."
pn7904,https://doi.org/10.1145/3290605.3300627,Evaluating Sustainable Interaction Design of Digital Services: The Case of YouTube,2,Daniel Schien,University of Bristol,Bristol,United Kingdom,true,false,"Recent research has advocated for a broader conception of evaluation for Sustainable HCI (SHCI), using interdisciplinary insights and methods. In this paper, we put this into practice to conduct an evaluation of Sustainable Interaction Design (SID) of digital services. We explore how SID can contribute to corporate greenhouse gas (GHG) reduction strategies. We show how a Digital Service Provider (DSP) might incorporate SID into their design process and quantitatively evaluate a specific SID intervention by combining user analytics data with environmental life cycle assessment. We illustrate this by considering YouTube. Replacing user analytics data with aggregate estimates from publicly available sources, we estimate emissions associated with the deployment of YouTube to be approximately 10MtCO2e p.a. We estimate emissions reductions enabled through the use of an SID intervention from prior literature to be approximately 300KtCO2e p.a., and demonstrate that this is significant when considered alongside other emissions reduction interventions used by DSPs."
pn7904,https://doi.org/10.1145/3290605.3300627,Evaluating Sustainable Interaction Design of Digital Services: The Case of YouTube,3,Paul Shabajee,University of Bristol,Bristol,United Kingdom,true,false,"Recent research has advocated for a broader conception of evaluation for Sustainable HCI (SHCI), using interdisciplinary insights and methods. In this paper, we put this into practice to conduct an evaluation of Sustainable Interaction Design (SID) of digital services. We explore how SID can contribute to corporate greenhouse gas (GHG) reduction strategies. We show how a Digital Service Provider (DSP) might incorporate SID into their design process and quantitatively evaluate a specific SID intervention by combining user analytics data with environmental life cycle assessment. We illustrate this by considering YouTube. Replacing user analytics data with aggregate estimates from publicly available sources, we estimate emissions associated with the deployment of YouTube to be approximately 10MtCO2e p.a. We estimate emissions reductions enabled through the use of an SID intervention from prior literature to be approximately 300KtCO2e p.a., and demonstrate that this is significant when considered alongside other emissions reduction interventions used by DSPs."
pn9423,https://doi.org/10.1145/3290605.3300253,"The Breaking Hand: Skills, Care, and Sufferings of the Hands of an Electronic Waste Worker in Bangladesh",1,Mohammad Rashidujjaman Rifat,University of Toronto,Toronto,Canada,true,false,"While repair work has recently been getting increasing attention in HCI, recycling practices have still remained relatively understudied, especially in the context of the Global South. To this end, building on our eight-month-long ethnography, this paper reports the electronic waste ('e-waste', henceforth) recycling practices among the e-waste recycler ('bhangari') communities in Dhaka, Bangladesh. In doing so, this paper offers the work of the bhangaris through an articulation of their hands and their uses. Drawing from a rich body of scholarly work on social science, we define and contextualize three characteristics of the hand of a bhangari: knowledge, care, and skills and collaboration. Our study also highlights the pains and sufferings involved in this profession. By explaining bhangari work through the hand, we also discuss its implications for design, and its connection to HCI's broader interest in sustainability."
pn9423,https://doi.org/10.1145/3290605.3300253,"The Breaking Hand: Skills, Care, and Sufferings of the Hands of an Electronic Waste Worker in Bangladesh",2,Hasan Mahmud Prottoy,Bangladesh University of Engineering and Technology,Dhaka,Bangladesh,true,false,"While repair work has recently been getting increasing attention in HCI, recycling practices have still remained relatively understudied, especially in the context of the Global South. To this end, building on our eight-month-long ethnography, this paper reports the electronic waste ('e-waste', henceforth) recycling practices among the e-waste recycler ('bhangari') communities in Dhaka, Bangladesh. In doing so, this paper offers the work of the bhangaris through an articulation of their hands and their uses. Drawing from a rich body of scholarly work on social science, we define and contextualize three characteristics of the hand of a bhangari: knowledge, care, and skills and collaboration. Our study also highlights the pains and sufferings involved in this profession. By explaining bhangari work through the hand, we also discuss its implications for design, and its connection to HCI's broader interest in sustainability."
pn9423,https://doi.org/10.1145/3290605.3300253,"The Breaking Hand: Skills, Care, and Sufferings of the Hands of an Electronic Waste Worker in Bangladesh",3,Syed Ishtiaque Ahmed,University of Toronto,Toronto,Canada,true,false,"While repair work has recently been getting increasing attention in HCI, recycling practices have still remained relatively understudied, especially in the context of the Global South. To this end, building on our eight-month-long ethnography, this paper reports the electronic waste ('e-waste', henceforth) recycling practices among the e-waste recycler ('bhangari') communities in Dhaka, Bangladesh. In doing so, this paper offers the work of the bhangaris through an articulation of their hands and their uses. Drawing from a rich body of scholarly work on social science, we define and contextualize three characteristics of the hand of a bhangari: knowledge, care, and skills and collaboration. Our study also highlights the pains and sufferings involved in this profession. By explaining bhangari work through the hand, we also discuss its implications for design, and its connection to HCI's broader interest in sustainability."
pn3350,https://doi.org/10.1145/3290605.3300637,Understanding and Mitigating Worker Biases in the Crowdsourced Collection of Subjective Judgments,1,Christoph Hube,Leibniz Universtät Hannover,Hannover,Germany,false,false,"Crowdsourced data acquired from tasks that comprise a subjective component (e.g. opinion detection, sentiment analysis) is potentially affected by the inherent bias of crowd workers who contribute to the tasks. This can lead to biased and noisy ground-truth data, propagating the undesirable bias and noise when used in turn to train machine learning models or evaluate systems. In this work, we aim to understand the influence of workers' own opinions on their performance in the subjective task of bias detection. We analyze the influence of workers' opinions on their annotations corresponding to different topics. Our findings reveal that workers with strong opinions tend to produce biased annotations. We show that such bias can be mitigated to improve the overall quality of the data collected. Experienced crowd workers also fail to distance themselves from their own opinions to provide unbiased annotations."
pn3350,https://doi.org/10.1145/3290605.3300637,Understanding and Mitigating Worker Biases in the Crowdsourced Collection of Subjective Judgments,2,Besnik Fetahu,Leibniz Universtät Hannover,Hannover,Germany,false,false,"Crowdsourced data acquired from tasks that comprise a subjective component (e.g. opinion detection, sentiment analysis) is potentially affected by the inherent bias of crowd workers who contribute to the tasks. This can lead to biased and noisy ground-truth data, propagating the undesirable bias and noise when used in turn to train machine learning models or evaluate systems. In this work, we aim to understand the influence of workers' own opinions on their performance in the subjective task of bias detection. We analyze the influence of workers' opinions on their annotations corresponding to different topics. Our findings reveal that workers with strong opinions tend to produce biased annotations. We show that such bias can be mitigated to improve the overall quality of the data collected. Experienced crowd workers also fail to distance themselves from their own opinions to provide unbiased annotations."
pn3350,https://doi.org/10.1145/3290605.3300637,Understanding and Mitigating Worker Biases in the Crowdsourced Collection of Subjective Judgments,3,Ujwal Gadiraju,Leibniz Universtät Hannover,Hannover,Germany,false,false,"Crowdsourced data acquired from tasks that comprise a subjective component (e.g. opinion detection, sentiment analysis) is potentially affected by the inherent bias of crowd workers who contribute to the tasks. This can lead to biased and noisy ground-truth data, propagating the undesirable bias and noise when used in turn to train machine learning models or evaluate systems. In this work, we aim to understand the influence of workers' own opinions on their performance in the subjective task of bias detection. We analyze the influence of workers' opinions on their annotations corresponding to different topics. Our findings reveal that workers with strong opinions tend to produce biased annotations. We show that such bias can be mitigated to improve the overall quality of the data collected. Experienced crowd workers also fail to distance themselves from their own opinions to provide unbiased annotations."
pn3464,https://doi.org/10.1145/3290605.3300390,"Volunteer Moderators in Twitch Micro Communities: How They Get Involved, the Roles They Play, and the Emotional Labor They Experience",1,Donghee Yvette Wohn,New Jersey Institute of Technology,Newark,United States,false,false,"The ability to engage in real-time text conversations is an important feature on live streaming platforms. The moderation of this text content relies heavily on the work of unpaid volunteers. This study reports on interviews with 20 people who moderate for Twitch micro communities, defined as channels that are built around a single or group of streamers, rather than the broadcast of an event. The study identifies how people become moderators, their different styles of moderating, and the difficulties that come with the job. In addition to the hardships of dealing with negative content, moderators also have complex interpersonal relationships with the streamers and viewers, where the boundaries between emotional labor, physical labor, and fun are intertwined."
pn4375,https://doi.org/10.1145/3290605.3300719,"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments",1,Matin Yarmand,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies."
pn4375,https://doi.org/10.1145/3290605.3300719,"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments",2,Dongwook Yoon,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies."
pn4375,https://doi.org/10.1145/3290605.3300719,"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments",3,Samuel Dodson,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies."
pn4375,https://doi.org/10.1145/3290605.3300719,"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments",4,Ido Roll,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies."
pn4375,https://doi.org/10.1145/3290605.3300719,"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments",5,Sidney Fels,University of British Columbia,Burnaby/Surrey/Vancouver,Canada,true,false,"As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,1,Hao-Ping Lee,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,2,Kuan-Yin Chen,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,3,Chih-Heng Lin,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,4,Chia-Yu Chen,National Chengchi University,Taipei,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,5,Yu-Lin Chung,National Tsing Hua University,Hsinchu,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,6,Yung-Ju Chang,National Chiao Tung University,Hsinchu,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn8583,https://doi.org/10.1145/3290605.3300756,Does Who Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages,7,Chien-Ru Sun,National Chengchi University,Taipei,Taiwan Roc,false,false,"This study examines the characteristics of mobile instant-messaging users' relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale."
pn9967,https://doi.org/10.1145/3290605.3300289,An Evaluation of Radar Metaphors for Providing Directional Stimuli Using Non-Verbal Sound,1,Brendan Cassidy,University of Central Lancashire,Preston,United Kingdom,false,false,"We compared four audio-based radar metaphors for providing directional stimuli to users of AR headsets. The metaphors are clock face, compass, white noise, and scale. Each metaphor, or method, signals the movement of a virtual arm in a radar sweep. In a user study, statistically significant differences were observed for accuracy and response time. Beat-based methods (clock face, compass) elicited responses biased to the left of the stimulus location, and non-beat-based methods (white noise, scale) produced responses biased to the right of the stimulus location. The beat methods were more accurate than the non-beat methods. However, the non-beat methods elicited quicker responses. We also discuss how response accuracy varies along the radar sweep between methods. These observations contribute design insights for non-verbal, non-visual directional prompting."
pn9967,https://doi.org/10.1145/3290605.3300289,An Evaluation of Radar Metaphors for Providing Directional Stimuli Using Non-Verbal Sound,2,Janet Read,University of Central Lancashire,Preston,United Kingdom,false,false,"We compared four audio-based radar metaphors for providing directional stimuli to users of AR headsets. The metaphors are clock face, compass, white noise, and scale. Each metaphor, or method, signals the movement of a virtual arm in a radar sweep. In a user study, statistically significant differences were observed for accuracy and response time. Beat-based methods (clock face, compass) elicited responses biased to the left of the stimulus location, and non-beat-based methods (white noise, scale) produced responses biased to the right of the stimulus location. The beat methods were more accurate than the non-beat methods. However, the non-beat methods elicited quicker responses. We also discuss how response accuracy varies along the radar sweep between methods. These observations contribute design insights for non-verbal, non-visual directional prompting."
pn9967,https://doi.org/10.1145/3290605.3300289,An Evaluation of Radar Metaphors for Providing Directional Stimuli Using Non-Verbal Sound,3,I. Mackenzie,York University,Toronto,Canada,false,false,"We compared four audio-based radar metaphors for providing directional stimuli to users of AR headsets. The metaphors are clock face, compass, white noise, and scale. Each metaphor, or method, signals the movement of a virtual arm in a radar sweep. In a user study, statistically significant differences were observed for accuracy and response time. Beat-based methods (clock face, compass) elicited responses biased to the left of the stimulus location, and non-beat-based methods (white noise, scale) produced responses biased to the right of the stimulus location. The beat methods were more accurate than the non-beat methods. However, the non-beat methods elicited quicker responses. We also discuss how response accuracy varies along the radar sweep between methods. These observations contribute design insights for non-verbal, non-visual directional prompting."
pn3983,https://doi.org/10.1145/3290605.3300288,A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays,1,Julian Petford,University of St Andrews,St Andrews,United Kingdom,false,false,"Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view - meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments."
pn3983,https://doi.org/10.1145/3290605.3300288,A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays,2,Iain Carson,University of St Andrews,St Andrews,United Kingdom,false,false,"Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view - meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments."
pn3983,https://doi.org/10.1145/3290605.3300288,A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays,3,Miguel Nacenta,University of St Andrews,St Andrews,United Kingdom,false,false,"Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view - meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments."
pn3983,https://doi.org/10.1145/3290605.3300288,A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays,4,Carl Gutwin,University of Saskatchewan,Saskatoon,Canada,false,false,"Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view - meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments."
pn7258,https://doi.org/10.1145/3290605.3300488,"Hey Google, Can I Ask You Something in Private? The Effects of Modality and Device in Sensitive Health Information Acquisition from Voice Assistants",1,Eugene Cho,Pennsylvania State University,University Park,United States,false,false,"MModern day voice-activated virtual assistants allow users to share and ask for information that could be considered as personal through different input modalities and devices. Using Google Assistant, this study examined if the differences in modality (i.e., voice vs. text) and device (i.e., smartphone vs. smart home device) affect user perceptions when users attempt to retrieve sensitive health information from voice assistants. Major findings from this study suggest that voice (vs. text) interaction significantly enhanced perceived social presence of the voice assistant, but only when the users solicited less sensitive health-related information. Furthermore, when individuals reported less privacy concerns, voice (vs. text) interaction elicited positive attitudes toward the voice assistant via increased social presence, but only in the low (vs. high) information sensitivity condition. Contrary to modality, the device difference did not exert any significant impact on the attitudes toward the voice assistant regardless of the sensitivity level of the health information being asked or the level of individuals' privacy concerns."
pn4197,https://doi.org/10.1145/3290605.3300420,Detecting Perception of Smartphone Notifications Using Skin Conductance Responses,1,Pascal Fortin,McGill University,Montreal,Canada,true,false,"Today's smartphone notification systems are incapable of determining whether a notification has been successfully perceived without explicit interaction from the user. If the system incorrectly assumes that a notification has not been perceived, it may repeat it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly assumes that a notification was perceived, and therefore fails to repeat it, the notification will be missed altogether (e.g., text message). Results from a laboratory study confirm, for the first time, that both vibrotactile and auditory smartphone notifications induce skin conductance responses (SCR), that the induced responses differ from that of arbitrary stimuli, and that they could be employed to predict perception of smartphone notifications after their presentation using wearable sensors."
pn4197,https://doi.org/10.1145/3290605.3300420,Detecting Perception of Smartphone Notifications Using Skin Conductance Responses,2,Elisabeth Sulmont,McGill University,Montreal,Canada,true,false,"Today's smartphone notification systems are incapable of determining whether a notification has been successfully perceived without explicit interaction from the user. If the system incorrectly assumes that a notification has not been perceived, it may repeat it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly assumes that a notification was perceived, and therefore fails to repeat it, the notification will be missed altogether (e.g., text message). Results from a laboratory study confirm, for the first time, that both vibrotactile and auditory smartphone notifications induce skin conductance responses (SCR), that the induced responses differ from that of arbitrary stimuli, and that they could be employed to predict perception of smartphone notifications after their presentation using wearable sensors."
pn4197,https://doi.org/10.1145/3290605.3300420,Detecting Perception of Smartphone Notifications Using Skin Conductance Responses,3,Jeremy Cooperstock,McGill University,Montreal,Canada,true,false,"Today's smartphone notification systems are incapable of determining whether a notification has been successfully perceived without explicit interaction from the user. If the system incorrectly assumes that a notification has not been perceived, it may repeat it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly assumes that a notification was perceived, and therefore fails to repeat it, the notification will be missed altogether (e.g., text message). Results from a laboratory study confirm, for the first time, that both vibrotactile and auditory smartphone notifications induce skin conductance responses (SCR), that the induced responses differ from that of arbitrary stimuli, and that they could be employed to predict perception of smartphone notifications after their presentation using wearable sensors."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,1,Ruta Desai,Carnegie Mellon University,Pittsburgh,United States,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,2,Fraser Anderson,Autodesk Research,Toronto,Canada,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,3,Justin Matejka,Autodesk Research,Toronto,Canada,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,4,Stelian Coros,ETH Zurich,Zurich,Switzerland,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,5,James Mccann,Carnegie Mellon University,Pittsburgh,United States,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,6,George Fitzmaurice,Autodesk Research,Toronto,Canada,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn9958,https://doi.org/10.1145/3290605.3300599,Geppetto: Enabling Semantic Design of Expressive Robot Behaviors,7,Tovi Grossman,Autodesk Research,Toronto,Canada,false,true,"Expressive robots are useful in many contexts, from industrial to entertainment applications. However, designing expressive robot behaviors requires editing a large number of unintuitive control parameters. We present an interactive, data-driven system that allows editing of these complex parameters in a semantic space. Our system combines a physics-based simulation that captures the robot's motion capabilities, and a crowd-powered framework that extracts relationships between the robot's motion parameters and the desired semantic behavior. These relationships enable mixed-initiative exploration of possible robot motions. We specifically demonstrate our system in the context of designing emotionally expressive behaviors. A user-study finds the system to be useful for more quickly developing desirable robot behaviors, compared to manual parameter editing."
pn3957,https://doi.org/10.1145/3290605.3300242,LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence,1,Xujing Zhang,Queen's University,Kingston,Canada,false,false,"LightBee is a novel ""hologrammatic"" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene."
pn3957,https://doi.org/10.1145/3290605.3300242,LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence,2,Sean Braley,Queen's University,Kingston,Canada,false,false,"LightBee is a novel ""hologrammatic"" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene."
pn3957,https://doi.org/10.1145/3290605.3300242,LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence,3,Calvin Rubens,Queen's University,Kingston,Canada,false,false,"LightBee is a novel ""hologrammatic"" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene."
pn3957,https://doi.org/10.1145/3290605.3300242,LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence,4,Timothy Merritt,Aalborg University,Aalborg,Denmark,false,false,"LightBee is a novel ""hologrammatic"" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene."
pn3957,https://doi.org/10.1145/3290605.3300242,LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence,5,Roel Vertegaal,Queen's University,Kingston,Canada,false,false,"LightBee is a novel ""hologrammatic"" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",1,Jessy Ceha,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",2,Nalin Chhibber,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",3,Joslin Goh,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",4,Corina Mcdonald,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",5,Pierre-Yves Oudeyer,Inria Bordeaux Sud-Ouest,Talence,France,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",6,Dana Kuli?,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn5907,https://doi.org/10.1145/3290605.3300636,"Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour",7,Edith Law,University of Waterloo,Waterloo,Canada,false,false,"Curiosity–the intrinsic desire for new information–can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants."
pn9088,https://doi.org/10.1145/3290605.3300675,Trigger-Action Programming for Personalising Humanoid Robot Behaviour,1,Nicola Leonardi,CNR-ISTI,Pisa,Italy,false,false,"In the coming years humanoid robots will be increasingly used in a variety of contexts, thereby presenting many opportunities to exploit their capabilities in terms of what they can sense and do. One main challenge is to design technologies that enable those who are not programming experts to personalize robot behaviour. We propose an end user development solution based on trigger-action personalization rules. We describe how it supports editing such rules and its underlying software architecture, and report on a user test that involved end user developers. The test results show that users were able to perform the robot personalization tasks with limited effort, and found the trigger-action environment usable and suitable for the proposed tasks. Overall, we show the potential for using trigger-action programming to make robot behaviour personalization possible even to people who are not professional software developers."
pn9088,https://doi.org/10.1145/3290605.3300675,Trigger-Action Programming for Personalising Humanoid Robot Behaviour,2,Marco Manca,CNR-ISTI,Pisa,Italy,false,false,"In the coming years humanoid robots will be increasingly used in a variety of contexts, thereby presenting many opportunities to exploit their capabilities in terms of what they can sense and do. One main challenge is to design technologies that enable those who are not programming experts to personalize robot behaviour. We propose an end user development solution based on trigger-action personalization rules. We describe how it supports editing such rules and its underlying software architecture, and report on a user test that involved end user developers. The test results show that users were able to perform the robot personalization tasks with limited effort, and found the trigger-action environment usable and suitable for the proposed tasks. Overall, we show the potential for using trigger-action programming to make robot behaviour personalization possible even to people who are not professional software developers."
pn9088,https://doi.org/10.1145/3290605.3300675,Trigger-Action Programming for Personalising Humanoid Robot Behaviour,3,Fabio Paternò,CNR-ISTI,Pisa,Italy,false,false,"In the coming years humanoid robots will be increasingly used in a variety of contexts, thereby presenting many opportunities to exploit their capabilities in terms of what they can sense and do. One main challenge is to design technologies that enable those who are not programming experts to personalize robot behaviour. We propose an end user development solution based on trigger-action personalization rules. We describe how it supports editing such rules and its underlying software architecture, and report on a user test that involved end user developers. The test results show that users were able to perform the robot personalization tasks with limited effort, and found the trigger-action environment usable and suitable for the proposed tasks. Overall, we show the potential for using trigger-action programming to make robot behaviour personalization possible even to people who are not professional software developers."
pn9088,https://doi.org/10.1145/3290605.3300675,Trigger-Action Programming for Personalising Humanoid Robot Behaviour,4,Carmen Santoro,CNR-ISTI,Pisa,Italy,false,false,"In the coming years humanoid robots will be increasingly used in a variety of contexts, thereby presenting many opportunities to exploit their capabilities in terms of what they can sense and do. One main challenge is to design technologies that enable those who are not programming experts to personalize robot behaviour. We propose an end user development solution based on trigger-action personalization rules. We describe how it supports editing such rules and its underlying software architecture, and report on a user test that involved end user developers. The test results show that users were able to perform the robot personalization tasks with limited effort, and found the trigger-action environment usable and suitable for the proposed tasks. Overall, we show the potential for using trigger-action programming to make robot behaviour personalization possible even to people who are not professional software developers."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,1,Luma Tabbaa,University of Kent,Kent,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,2,Chee Siang Ang,University of Kent,Canterbury,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,3,Vienna Rose,St. Andrew's Healthcare,Northampton,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,4,Panote Siriaraya,Kyoto Sangyo University,Kyoto,Japan,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,5,Inga Stewart,St Andrew's Healthcare,Northampton,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,6,Keith Jenkins,St Andrew's Healthcare,Northampton,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn7893,https://doi.org/10.1145/3290605.3300466,Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals,7,Maria Matsangidou,University of Kent,Canterbury,United Kingdom,false,false,"Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting."
pn4482,https://doi.org/10.1145/3290605.3300688,Making Healthcare Infrastructure Work: Unpacking the Infrastructuring Work of Individuals,1,Xinning Gui,"University of California, Irvine",Irvine,United States,true,false,"The U.S. healthcare infrastructure is fragmented with various breakdowns. Patients or caregivers have to rely on their own to overcome barriers and fix breakdowns in order to obtain necessary service, that is, infrastructuring work to make the healthcare infrastructure work for them. So far little attention has been paid to such infrastructuring work in healthcare. We present an interview study of 32 U.S. parents of young children to discuss the work of infrastructuring our participants carry out to deal with breakdowns within the healthcare infrastructure. We report how they repaired unexpected failures happening at the individual level, aligned components at organizational and cross-organizational level, and circumvented infrastructural constraints (e.g., policy and financial ones) that were perceived as ambiguous and demanding. We discuss infrastructuring work in light of the literature on patients' and caregivers' work, reflect upon the notion of patient engagement, and explore nuances along several dimensions of infrastructuring work."
pn4482,https://doi.org/10.1145/3290605.3300688,Making Healthcare Infrastructure Work: Unpacking the Infrastructuring Work of Individuals,2,Yunan Chen,"University of California, Irvine",Irvine,United States,true,false,"The U.S. healthcare infrastructure is fragmented with various breakdowns. Patients or caregivers have to rely on their own to overcome barriers and fix breakdowns in order to obtain necessary service, that is, infrastructuring work to make the healthcare infrastructure work for them. So far little attention has been paid to such infrastructuring work in healthcare. We present an interview study of 32 U.S. parents of young children to discuss the work of infrastructuring our participants carry out to deal with breakdowns within the healthcare infrastructure. We report how they repaired unexpected failures happening at the individual level, aligned components at organizational and cross-organizational level, and circumvented infrastructural constraints (e.g., policy and financial ones) that were perceived as ambiguous and demanding. We discuss infrastructuring work in light of the literature on patients' and caregivers' work, reflect upon the notion of patient engagement, and explore nuances along several dimensions of infrastructuring work."
pn7940,https://doi.org/10.1145/3290605.3300596,Beyond the Patient Portal: Supporting Needs of Hospitalized Patients,1,Shefali Haldar,University of Washington,Seattle,United States,false,false,"Although patient portals—technologies that give patients access to their health information—are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and care- givers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and care- givers as primary stakeholders in their health care."
pn7940,https://doi.org/10.1145/3290605.3300596,Beyond the Patient Portal: Supporting Needs of Hospitalized Patients,2,Sonali Mishra,University of Washington,Seattle,United States,false,false,"Although patient portals—technologies that give patients access to their health information—are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and care- givers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and care- givers as primary stakeholders in their health care."
pn7940,https://doi.org/10.1145/3290605.3300596,Beyond the Patient Portal: Supporting Needs of Hospitalized Patients,3,Maher Khelifi,University of Washington,Seattle,United States,false,false,"Although patient portals—technologies that give patients access to their health information—are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and care- givers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and care- givers as primary stakeholders in their health care."
pn7940,https://doi.org/10.1145/3290605.3300596,Beyond the Patient Portal: Supporting Needs of Hospitalized Patients,4,Ari Pollack,Seattle Children's Hospital,Seattle,United States,false,false,"Although patient portals—technologies that give patients access to their health information—are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and care- givers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and care- givers as primary stakeholders in their health care."
pn7940,https://doi.org/10.1145/3290605.3300596,Beyond the Patient Portal: Supporting Needs of Hospitalized Patients,5,Wanda Pratt,University of Washington,Seattle,United States,false,false,"Although patient portals—technologies that give patients access to their health information—are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and care- givers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and care- givers as primary stakeholders in their health care."
pn6058,https://doi.org/10.1145/3290605.3300468,"Unremarkable AI: Fitting Intelligent Decision Support into Critical, Clinical Decision-Making Processes",1,Qian Yang,Carnegie Mellon University,"Pittsburgh, Pa",United States,false,true,"Clinical decision support tools (DST) promise improved healthcare outcomes by offering data-driven insights. While effective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual fit as the cause. This paper describes the design and field evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have significant importance for the users yet remain unobtrusive. Our field evaluation suggests clinicians are more likely to encounter and embrace such a DST.Drawing on their responses, we discuss the importance and intricacies of finding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience."
pn6058,https://doi.org/10.1145/3290605.3300468,"Unremarkable AI: Fitting Intelligent Decision Support into Critical, Clinical Decision-Making Processes",2,Aaron Steinfeld,Carnegie Mellon University,Pittsburgh,United States,false,true,"Clinical decision support tools (DST) promise improved healthcare outcomes by offering data-driven insights. While effective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual fit as the cause. This paper describes the design and field evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have significant importance for the users yet remain unobtrusive. Our field evaluation suggests clinicians are more likely to encounter and embrace such a DST.Drawing on their responses, we discuss the importance and intricacies of finding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience."
pn6058,https://doi.org/10.1145/3290605.3300468,"Unremarkable AI: Fitting Intelligent Decision Support into Critical, Clinical Decision-Making Processes",3,John Zimmerman,Carnegie Mellon University,Pittsburgh,United States,false,true,"Clinical decision support tools (DST) promise improved healthcare outcomes by offering data-driven insights. While effective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual fit as the cause. This paper describes the design and field evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have significant importance for the users yet remain unobtrusive. Our field evaluation suggests clinicians are more likely to encounter and embrace such a DST.Drawing on their responses, we discuss the importance and intricacies of finding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",1,Matthew Guzdial,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",2,Nicholas Liao,Georgia Institute of Technology,Altanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",3,Jonathan Chen,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",4,Shao-Yu Chen,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",5,Shukan Shah,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",6,Vishwa Shah,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",7,Joshua Reno,Georgia Institute of Technology,Atlanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",8,Gillian Smith,Worcester Polytechnic Institute,Worcester,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn6540,https://doi.org/10.1145/3290605.3300854,"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators",9,Mark Riedl,Georgia Institute of Technology,Altanta,United States,false,false,"Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression.To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI."
pn8226,https://doi.org/10.1145/3290605.3300693,Dynamic Difficulty Adjustment Impact on Players' Confidence,1,Thomas Constant,Conservatoire National des Arts et Métiers,Paris,France,false,false,"Difficulty is one of the major motivational pull of video games, and thus many games use Dynamic Difficulty Adjustment (DDA) systems to improve the game experience. This paper describes our research investigating the influence of DDA systems on player's confidence, evaluated using an in-game bet system. Our hypothesis is that DDA systems may lead players to overconfidence, revealed by an overestimation of their success chances when betting. This boost of confidence may be a part of the positive impact of DDA systems on the quality of game experience. We explain our method to evaluate player's confidence and implement it into three games related to logical, motor and sensory difficulties. We describe two experimental conditions where difficulty is either randomly chosen or adapted using a DDA algorithm. Results show how DDA systems can lead players to high level of overconfidence."
pn8226,https://doi.org/10.1145/3290605.3300693,Dynamic Difficulty Adjustment Impact on Players' Confidence,2,Guillaume Levieux,Conservatoire National des Arts et Métiers,Paris,France,false,false,"Difficulty is one of the major motivational pull of video games, and thus many games use Dynamic Difficulty Adjustment (DDA) systems to improve the game experience. This paper describes our research investigating the influence of DDA systems on player's confidence, evaluated using an in-game bet system. Our hypothesis is that DDA systems may lead players to overconfidence, revealed by an overestimation of their success chances when betting. This boost of confidence may be a part of the positive impact of DDA systems on the quality of game experience. We explain our method to evaluate player's confidence and implement it into three games related to logical, motor and sensory difficulties. We describe two experimental conditions where difficulty is either randomly chosen or adapted using a DDA algorithm. Results show how DDA systems can lead players to high level of overconfidence."
pn6023,https://doi.org/10.1145/3290605.3300325,Implicit Communication of Actionable Information in Human-AI teams,1,Claire Liang,Cornell University,Ithaca,United States,true,false,"Humans expect their collaborators to look beyond the explicit interpretation of their words. Implicature is a common form of implicit communication that arises in natural language discourse when an utterance leverages context to imply information beyond what the words literally convey. Whereas computational methods have been proposed for interpreting and using different forms of implicature, its role in human and artificial agent collaboration has not yet been explored in a concrete domain. The results of this paper provide insights to how artificial agents should be structured to facilitate natural and efficient communication of actionable information with humans. We investigated implicature by implementing two strategies for playing Hanabi, a cooperative card game that relies heavily on communication of actionable implicit information to achieve a shared goal. In a user study with 904 completed games and 246 completed surveys, human players randomly paired with an implicature AI are 71% more likely to think their partner is human than players paired with a non-implicature AI. These teams demonstrated game performance similar to other state of the art approaches."
pn6023,https://doi.org/10.1145/3290605.3300325,Implicit Communication of Actionable Information in Human-AI teams,2,Julia Proft,Cornell University,Ithaca,United States,true,false,"Humans expect their collaborators to look beyond the explicit interpretation of their words. Implicature is a common form of implicit communication that arises in natural language discourse when an utterance leverages context to imply information beyond what the words literally convey. Whereas computational methods have been proposed for interpreting and using different forms of implicature, its role in human and artificial agent collaboration has not yet been explored in a concrete domain. The results of this paper provide insights to how artificial agents should be structured to facilitate natural and efficient communication of actionable information with humans. We investigated implicature by implementing two strategies for playing Hanabi, a cooperative card game that relies heavily on communication of actionable implicit information to achieve a shared goal. In a user study with 904 completed games and 246 completed surveys, human players randomly paired with an implicature AI are 71% more likely to think their partner is human than players paired with a non-implicature AI. These teams demonstrated game performance similar to other state of the art approaches."
pn6023,https://doi.org/10.1145/3290605.3300325,Implicit Communication of Actionable Information in Human-AI teams,3,Erik Andersen,Cornell University,Ithaca,United States,true,false,"Humans expect their collaborators to look beyond the explicit interpretation of their words. Implicature is a common form of implicit communication that arises in natural language discourse when an utterance leverages context to imply information beyond what the words literally convey. Whereas computational methods have been proposed for interpreting and using different forms of implicature, its role in human and artificial agent collaboration has not yet been explored in a concrete domain. The results of this paper provide insights to how artificial agents should be structured to facilitate natural and efficient communication of actionable information with humans. We investigated implicature by implementing two strategies for playing Hanabi, a cooperative card game that relies heavily on communication of actionable implicit information to achieve a shared goal. In a user study with 904 completed games and 246 completed surveys, human players randomly paired with an implicature AI are 71% more likely to think their partner is human than players paired with a non-implicature AI. These teams demonstrated game performance similar to other state of the art approaches."
pn6023,https://doi.org/10.1145/3290605.3300325,Implicit Communication of Actionable Information in Human-AI teams,4,Ross Knepper,Cornell University,Ithaca,United States,true,false,"Humans expect their collaborators to look beyond the explicit interpretation of their words. Implicature is a common form of implicit communication that arises in natural language discourse when an utterance leverages context to imply information beyond what the words literally convey. Whereas computational methods have been proposed for interpreting and using different forms of implicature, its role in human and artificial agent collaboration has not yet been explored in a concrete domain. The results of this paper provide insights to how artificial agents should be structured to facilitate natural and efficient communication of actionable information with humans. We investigated implicature by implementing two strategies for playing Hanabi, a cooperative card game that relies heavily on communication of actionable implicit information to achieve a shared goal. In a user study with 904 completed games and 246 completed surveys, human players randomly paired with an implicature AI are 71% more likely to think their partner is human than players paired with a non-implicature AI. These teams demonstrated game performance similar to other state of the art approaches."
pn9002,https://doi.org/10.1145/3290605.3300567,Friending to Flame: How Social Features Affect Player Behaviours in an Online Collectible Card Game,1,Selen Turkay,Queensland University of Technology,Brisbane,Australia,false,false,"Online Collectible Card Games (OCCGs) are enormously popular worldwide. Previous studies found that the social aspects of physical CCGs are crucial for player engagement. However, we know little about the different types of sociability that OCCGs afford. Nor to what extent they influence players' social experiences. This mixed method online survey study focuses on a representative OCCG, Hearthstone \citeblizzard_inc._hearthstone_2018 to 1) identify and define social design features and examine the extent to which players' use of these features predict their sense of community; 2) investigate participants' attitudes towards and experiences with the game community. The results show that players rarely use social features, and these features contribute differently to predicting players' sense of community. We also found emergent toxic behaviors, afforded by the social features. Findings can inform the best practices and principles in the design of OCCGs, and contribute to our understanding of players' perceptions of OCCG communities."
pn9002,https://doi.org/10.1145/3290605.3300567,Friending to Flame: How Social Features Affect Player Behaviours in an Online Collectible Card Game,2,Sonam Adinolf,Queensland University of Technology,Brisbane,Australia,false,false,"Online Collectible Card Games (OCCGs) are enormously popular worldwide. Previous studies found that the social aspects of physical CCGs are crucial for player engagement. However, we know little about the different types of sociability that OCCGs afford. Nor to what extent they influence players' social experiences. This mixed method online survey study focuses on a representative OCCG, Hearthstone \citeblizzard_inc._hearthstone_2018 to 1) identify and define social design features and examine the extent to which players' use of these features predict their sense of community; 2) investigate participants' attitudes towards and experiences with the game community. The results show that players rarely use social features, and these features contribute differently to predicting players' sense of community. We also found emergent toxic behaviors, afforded by the social features. Findings can inform the best practices and principles in the design of OCCGs, and contribute to our understanding of players' perceptions of OCCG communities."
pn2973,https://doi.org/10.1145/3290605.3300431,Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction,1,Theophilus Teo,University of South Australia,Adelaide,Australia,true,false,"Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement."
pn2973,https://doi.org/10.1145/3290605.3300431,Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction,2,Louise Lawrence,University of South Australia,Adelaide,Australia,true,false,"Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement."
pn2973,https://doi.org/10.1145/3290605.3300431,Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction,3,Gun Lee,University of South Australia,Adelaide,Australia,true,false,"Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement."
pn2973,https://doi.org/10.1145/3290605.3300431,Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction,4,Mark Billinghurst,University of South Australia,Adelaide,Australia,true,false,"Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement."
pn2973,https://doi.org/10.1145/3290605.3300431,Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction,5,Matt Adcock,CSIRO,Canberra,Australia,true,false,"Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently become a popular way for people from different places to work together. Local workers can collaborate with remote helpers by sharing 360-degree live video or 3D virtual reconstruction of their surroundings. However, each of these techniques has benefits and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together for remote collaboration, by preserving benefits of both systems while reducing drawbacks of each. We developed a hybrid prototype and conducted user study to compare benefits and problems of using 360 or 3D alone to clarify the needs for mixing the two, and also to evaluate the prototype system. We found participants performed significantly better on collaborative search tasks in 360 and felt higher social presence, yet 3D also showed potential to complement. Participant feedback collected after trying our hybrid system provided directions for improvement."
pn9278,https://doi.org/10.1145/3290605.3300515,Can Mobile Augmented Reality Stimulate a Honeypot Effect? Observations from Santa's Lil Helper,1,Ryan Kelly,The University of Melbourne,Melbourne,Australia,true,false,"In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space."
pn9278,https://doi.org/10.1145/3290605.3300515,Can Mobile Augmented Reality Stimulate a Honeypot Effect? Observations from Santa's Lil Helper,2,Hasan Shahid Ferdous,The University of Melbourne,Melbourne,Australia,true,false,"In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space."
pn9278,https://doi.org/10.1145/3290605.3300515,Can Mobile Augmented Reality Stimulate a Honeypot Effect? Observations from Santa's Lil Helper,3,Niels Wouters,The University of Melbourne,Melbourne,Australia,true,false,"In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space."
pn9278,https://doi.org/10.1145/3290605.3300515,Can Mobile Augmented Reality Stimulate a Honeypot Effect? Observations from Santa's Lil Helper,4,Frank Vetere,The University of Melbourne,Melbourne,Australia,true,false,"In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space."
pn6704,https://doi.org/10.1145/3290605.3300727,Eye-Write: Gaze Sharing for Collaborative Writing,1,Grete Kütt,Pomona College,Claremont,United States,false,false,"Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner's gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author's activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing."
pn6704,https://doi.org/10.1145/3290605.3300727,Eye-Write: Gaze Sharing for Collaborative Writing,2,Kevin Lee,Pomona College,Claremont,United States,false,false,"Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner's gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author's activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing."
pn6704,https://doi.org/10.1145/3290605.3300727,Eye-Write: Gaze Sharing for Collaborative Writing,3,Ethan Hardacre,Pomona College,Claremont,United States,false,false,"Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner's gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author's activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing."
pn6704,https://doi.org/10.1145/3290605.3300727,Eye-Write: Gaze Sharing for Collaborative Writing,4,Alexandra Papoutsaki,Pomona College,Claremont,United States,false,false,"Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner's gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author's activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing."
pn4810,https://doi.org/10.1145/3290605.3300405,Usability of Gamified Knowledge Learning in VR and Desktop-3D,1,Sebastian Oberdörfer,University of Würzburg,Würzburg,Germany,false,false,"Affine Transformations (ATs) often escape an intuitive approach due to their high complexity. Therefore, we developed GEtiT that directly encodes ATs in its game mechanics and scales the knowledge's level of abstraction. This results in an intuitive application as well as audiovisual presentation of ATs and hence in a knowledge learning. We also developed a specific Virtual Reality (VR) version to explore the effects of immersive VR on the learning outcomes. This paper presents our approach of directly encoding abstract knowledge in game mechanics, the conceptual design of GEtiT and its technical implementation. Both versions are compared in regard to their usability in a user study. The results show that both GEtiT versions induce a high degree of flow and elicit a good intuitive use. They validate the effectiveness of the design and the resulting knowledge application requirements. Participants favored GEtiT VR thus showing a potentially higher learning quality when using VR."
pn4810,https://doi.org/10.1145/3290605.3300405,Usability of Gamified Knowledge Learning in VR and Desktop-3D,2,David Heidrich,University of Würzburg,Würzburg,Germany,false,false,"Affine Transformations (ATs) often escape an intuitive approach due to their high complexity. Therefore, we developed GEtiT that directly encodes ATs in its game mechanics and scales the knowledge's level of abstraction. This results in an intuitive application as well as audiovisual presentation of ATs and hence in a knowledge learning. We also developed a specific Virtual Reality (VR) version to explore the effects of immersive VR on the learning outcomes. This paper presents our approach of directly encoding abstract knowledge in game mechanics, the conceptual design of GEtiT and its technical implementation. Both versions are compared in regard to their usability in a user study. The results show that both GEtiT versions induce a high degree of flow and elicit a good intuitive use. They validate the effectiveness of the design and the resulting knowledge application requirements. Participants favored GEtiT VR thus showing a potentially higher learning quality when using VR."
pn4810,https://doi.org/10.1145/3290605.3300405,Usability of Gamified Knowledge Learning in VR and Desktop-3D,3,Marc Erich Latoschik,University of Würzburg,Würzburg,Germany,false,false,"Affine Transformations (ATs) often escape an intuitive approach due to their high complexity. Therefore, we developed GEtiT that directly encodes ATs in its game mechanics and scales the knowledge's level of abstraction. This results in an intuitive application as well as audiovisual presentation of ATs and hence in a knowledge learning. We also developed a specific Virtual Reality (VR) version to explore the effects of immersive VR on the learning outcomes. This paper presents our approach of directly encoding abstract knowledge in game mechanics, the conceptual design of GEtiT and its technical implementation. Both versions are compared in regard to their usability in a user study. The results show that both GEtiT versions induce a high degree of flow and elicit a good intuitive use. They validate the effectiveness of the design and the resulting knowledge application requirements. Participants favored GEtiT VR thus showing a potentially higher learning quality when using VR."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,1,Tom Feltwell,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,2,Gavin Wood,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,3,Scarlett Rowland,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,4,Kiel Long,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,5,Chris Elsden,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,6,Phillip Brooker,University of Liverpool,Liverpool,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,7,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,8,Pamela Briggs,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,9,Julie Barnett,University of Bath,Bath,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn2588,https://doi.org/10.1145/3290605.3300300,Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV,10,Shaun Lawson,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"Public commentary related to reality TV can be overwhelmed by thoughtless reactions and negative sentiments, which often problematically reinforce the cultural stereotyping typically employed in such media. We describe the design, and month-long evaluation, of a mobile ""second-screening"" application, Screenr, which uses co-voting and live textual tagging to encourage more critical co-viewing in these contexts. Our findings highlight how Screenr supported interrogation of the production qualities and claims of shows, promoted critical discourse around the motivations of programmes, and engaged participants in reflecting on their own assumptions and views. We situate our results within the context of existing second-screening co-viewing work, discuss implications for such technologies to support critical engagement with socio-political media, and provide design implications for future digital technologies in this domain."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,1,Mitchell Gordon,Stanford University,Stanford,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,2,Leon Gatys,Apple Inc.,Cupertino,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,3,Carlos Guestrin,Apple Inc.,Cupertino,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,4,Jeffrey Bigham,Apple Inc.,Cupertino,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,5,Andrew Trister,Apple Inc.,Cupertino,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn3911,https://doi.org/10.1145/3290605.3300398,App Usage Predicts Cognitive Ability in Older Adults,6,Kayur Patel,Apple Inc.,Cupertino,United States,false,false,"We have limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the ""cognitively young"" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function."
pn1309,https://doi.org/10.1145/3290605.3300463,Talking about Chat at Work in the Global South: An Ethnographic Study of Chat Use in India and Kenya,1,Moira Mcgregor,Stockholm University,Stockholm,Sweden,false,false,"In this paper, we examine how two chat apps fit into the communication ecosystem of six large distributed enterprises, in India and Kenya. From the perspective of management, these chat apps promised to foster greater communication and awareness between workers in the field, and between fieldworkers and the enterprises administration and management centres. Each organisation had multiple different types of chat groups, characterised by the types of content and interaction patterns they mediate, and the different organisational functions they fulfil. Examining the interplay between chat and existing local practices for coordination, collaboration and knowledge-sharing, we discuss how chat manifests in the distributed workplace and how it fits -- or otherwise -- alongside the rhythms of both local and remote work. We contribute to understandings of chat apps for workplace communication and provide insights for shaping their ongoing development."
pn1309,https://doi.org/10.1145/3290605.3300463,Talking about Chat at Work in the Global South: An Ethnographic Study of Chat Use in India and Kenya,2,Nicola Bidwell,International University of Management,University Of Windhoek,Namibia,false,false,"In this paper, we examine how two chat apps fit into the communication ecosystem of six large distributed enterprises, in India and Kenya. From the perspective of management, these chat apps promised to foster greater communication and awareness between workers in the field, and between fieldworkers and the enterprises administration and management centres. Each organisation had multiple different types of chat groups, characterised by the types of content and interaction patterns they mediate, and the different organisational functions they fulfil. Examining the interplay between chat and existing local practices for coordination, collaboration and knowledge-sharing, we discuss how chat manifests in the distributed workplace and how it fits -- or otherwise -- alongside the rhythms of both local and remote work. We contribute to understandings of chat apps for workplace communication and provide insights for shaping their ongoing development."
pn1309,https://doi.org/10.1145/3290605.3300463,Talking about Chat at Work in the Global South: An Ethnographic Study of Chat Use in India and Kenya,3,Vidya Sarangapani,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"In this paper, we examine how two chat apps fit into the communication ecosystem of six large distributed enterprises, in India and Kenya. From the perspective of management, these chat apps promised to foster greater communication and awareness between workers in the field, and between fieldworkers and the enterprises administration and management centres. Each organisation had multiple different types of chat groups, characterised by the types of content and interaction patterns they mediate, and the different organisational functions they fulfil. Examining the interplay between chat and existing local practices for coordination, collaboration and knowledge-sharing, we discuss how chat manifests in the distributed workplace and how it fits -- or otherwise -- alongside the rhythms of both local and remote work. We contribute to understandings of chat apps for workplace communication and provide insights for shaping their ongoing development."
pn1309,https://doi.org/10.1145/3290605.3300463,Talking about Chat at Work in the Global South: An Ethnographic Study of Chat Use in India and Kenya,4,Jonathan Appavoo,Boston University,Brookline,United States,false,false,"In this paper, we examine how two chat apps fit into the communication ecosystem of six large distributed enterprises, in India and Kenya. From the perspective of management, these chat apps promised to foster greater communication and awareness between workers in the field, and between fieldworkers and the enterprises administration and management centres. Each organisation had multiple different types of chat groups, characterised by the types of content and interaction patterns they mediate, and the different organisational functions they fulfil. Examining the interplay between chat and existing local practices for coordination, collaboration and knowledge-sharing, we discuss how chat manifests in the distributed workplace and how it fits -- or otherwise -- alongside the rhythms of both local and remote work. We contribute to understandings of chat apps for workplace communication and provide insights for shaping their ongoing development."
pn1309,https://doi.org/10.1145/3290605.3300463,Talking about Chat at Work in the Global South: An Ethnographic Study of Chat Use in India and Kenya,5,Jacki O'neill,Microsoft Research India,Bangalore,India,false,false,"In this paper, we examine how two chat apps fit into the communication ecosystem of six large distributed enterprises, in India and Kenya. From the perspective of management, these chat apps promised to foster greater communication and awareness between workers in the field, and between fieldworkers and the enterprises administration and management centres. Each organisation had multiple different types of chat groups, characterised by the types of content and interaction patterns they mediate, and the different organisational functions they fulfil. Examining the interplay between chat and existing local practices for coordination, collaboration and knowledge-sharing, we discuss how chat manifests in the distributed workplace and how it fits -- or otherwise -- alongside the rhythms of both local and remote work. We contribute to understandings of chat apps for workplace communication and provide insights for shaping their ongoing development."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,1,Diego Gómez-Zará,Pontificia Universidad Católica de Chile,Santiago,Chile,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,2,Matthew Paras,Northwestern University,Evanston,United States,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,3,Marlon Twyman,Northwestern University,Evanston,United States,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,4,Jacqueline Lane,Harvard Business School,Boston,United States,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,5,Leslie Dechurch,Northwestern University,Evanston,United States,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn3236,https://doi.org/10.1145/3290605.3300889,Who Would You Like to Work With?,6,Noshir Contractor,Northwestern University,Evanston,United States,false,false,"People and organizations are increasingly using online platforms to assemble teams. In response, HCI researchers have theorized frameworks and created systems to support team assembly. However, little is known about how users search for and choose teammates on these platforms. We conducted a field study where 530 participants used a team formation system to assemble project teams. We describe how users' traits and social networks influence their teammate searches, teammate choices, and team composition. Our results show that (a) what users initially search for differs from what they finally choose: initially they search for experts and sociable users, but they are ultimately more likely to choose their prior social connections as their teammates; (b) users' decisions lead to non-diverse and segregated teams, where most of the expertise and social capital are concentrated in a few teams. We discuss the implications of these results for designing team formation systems than promote users' agency."
pn8817,https://doi.org/10.1145/3290605.3300618,Empowering End Users in Debugging Trigger-Action Rules,1,Fulvio Corno,Politecnico di Torino,Torino,Italy,false,false,"End users can program trigger-action rules to personalize the joint behavior of their smart devices and online services. Trigger-action programming is, however, a complex task for non-programmers and errors made during the composition of rules may lead to unpredictable behaviors and security issues, e.g., a lamp that is continuously flashing or a door that is unexpectedly unlocked. In this paper, we introduce EUDebug, a system that enables end users to debug trigger-action rules. With EUDebug, users compose rules in a web-based application like IFTTT. EUDebug highlights possible problems that the set of all defined rules may generate and allows their step-by-step simulation. Under the hood, a hybrid Semantic Colored Petri Net (SCPN) models, checks, and simulates trigger-action rules and their interactions. An exploratory study on 15 end users shows that EUDebug helps identifying and understanding problems in trigger-action rules, which are not easily discoverable in existing platforms."
pn8817,https://doi.org/10.1145/3290605.3300618,Empowering End Users in Debugging Trigger-Action Rules,2,Luigi De Russis,Politecnico di Torino,Torino,Italy,false,false,"End users can program trigger-action rules to personalize the joint behavior of their smart devices and online services. Trigger-action programming is, however, a complex task for non-programmers and errors made during the composition of rules may lead to unpredictable behaviors and security issues, e.g., a lamp that is continuously flashing or a door that is unexpectedly unlocked. In this paper, we introduce EUDebug, a system that enables end users to debug trigger-action rules. With EUDebug, users compose rules in a web-based application like IFTTT. EUDebug highlights possible problems that the set of all defined rules may generate and allows their step-by-step simulation. Under the hood, a hybrid Semantic Colored Petri Net (SCPN) models, checks, and simulates trigger-action rules and their interactions. An exploratory study on 15 end users shows that EUDebug helps identifying and understanding problems in trigger-action rules, which are not easily discoverable in existing platforms."
pn8817,https://doi.org/10.1145/3290605.3300618,Empowering End Users in Debugging Trigger-Action Rules,3,Alberto Monge Roffarello,Politecnico di Torino,Torino,Italy,false,false,"End users can program trigger-action rules to personalize the joint behavior of their smart devices and online services. Trigger-action programming is, however, a complex task for non-programmers and errors made during the composition of rules may lead to unpredictable behaviors and security issues, e.g., a lamp that is continuously flashing or a door that is unexpectedly unlocked. In this paper, we introduce EUDebug, a system that enables end users to debug trigger-action rules. With EUDebug, users compose rules in a web-based application like IFTTT. EUDebug highlights possible problems that the set of all defined rules may generate and allows their step-by-step simulation. Under the hood, a hybrid Semantic Colored Petri Net (SCPN) models, checks, and simulates trigger-action rules and their interactions. An exploratory study on 15 end users shows that EUDebug helps identifying and understanding problems in trigger-action rules, which are not easily discoverable in existing platforms."
pn4979,https://doi.org/10.1145/3290605.3300728,Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects,1,Mitchell Karchemsky,"University of California, Berkeley",Berkeley,United States,true,false,"Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits."
pn4979,https://doi.org/10.1145/3290605.3300728,Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects,2,J.D. Zamfirescu-Pereira,Cornell Tech,New York,United States,true,false,"Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits."
pn4979,https://doi.org/10.1145/3290605.3300728,Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects,3,Kuan-Ju Wu,"University of California, Berkeley",Berkeley,United States,true,false,"Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits."
pn4979,https://doi.org/10.1145/3290605.3300728,Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects,4,François Guimbretière,Cornell University,Ithaca,United States,true,false,"Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits."
pn4979,https://doi.org/10.1145/3290605.3300728,Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects,5,Bjoern Hartmann,"University of California, Berkeley",Berkeley,United States,true,false,"Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits."
pn3659,https://doi.org/10.1145/3290605.3300487,Predicting Cognitive Load in Future Code Puzzles,1,Caitlin Kelleher,Washington University in St. Louis,St Louis,United States,false,false,"Code puzzles are an increasingly popular way to introduce youth to programming. Yet our knowledge about how to maximize learning from puzzles is incomplete. We conducted a data collection study and trained a model that predicts cognitive load, the mental effort necessary to complete a task, on a future puzzle. Controlling cognitive load can lead to more effective learning. Our model suggests that it is possible to predict Cognitive Load on future problems; the model could correctly distinguish the more difficult puzzle within a pair 71%-79% of the time. Further, studying the model itself provides new insights into the sources of puzzle difficulty, the factors that contribute to Cognitive Load, and their inter-relationships. Finally, the ability to predict Cognitive Load on a future puzzle is an important step towards the creation of adaptive code puzzle systems."
pn3659,https://doi.org/10.1145/3290605.3300487,Predicting Cognitive Load in Future Code Puzzles,2,Wint Hnin,Washington University in St. Louis,St Louis,United States,false,false,"Code puzzles are an increasingly popular way to introduce youth to programming. Yet our knowledge about how to maximize learning from puzzles is incomplete. We conducted a data collection study and trained a model that predicts cognitive load, the mental effort necessary to complete a task, on a future puzzle. Controlling cognitive load can lead to more effective learning. Our model suggests that it is possible to predict Cognitive Load on future problems; the model could correctly distinguish the more difficult puzzle within a pair 71%-79% of the time. Further, studying the model itself provides new insights into the sources of puzzle difficulty, the factors that contribute to Cognitive Load, and their inter-relationships. Finally, the ability to predict Cognitive Load on a future puzzle is an important step towards the creation of adaptive code puzzle systems."
pn9898,https://doi.org/10.1145/3290605.3300650,On the Latency of USB-Connected Input Devices,1,Raphael Wimmer,University of Regensburg,Regensburg,Germany,false,false,"We propose a method for accurately and precisely measuring the intrinsic latency of input devices and document measurements for 36 keyboards, mice and gamepads connected via USB. Our research shows that devices differ not only in average latency, but also in the distribution of their latencies, and that forced polling at 1000 Hz decreases latency for some but not all devices. Existing practices - measuring end-to-end latency as a proxy of input latency and reporting only mean values and standard deviations - hide these characteristic latency distributions caused by device intrinsics and polling rates. A probabilistic model of input device latency demonstrates these issues and matches our measurements. Thus, our work offers guidance for researchers, engineers, and hobbyists who want to measure the latency of input devices or select devices with low latency."
pn9898,https://doi.org/10.1145/3290605.3300650,On the Latency of USB-Connected Input Devices,2,Andreas Schmid,University of Regensburg,Regensburg,Germany,false,false,"We propose a method for accurately and precisely measuring the intrinsic latency of input devices and document measurements for 36 keyboards, mice and gamepads connected via USB. Our research shows that devices differ not only in average latency, but also in the distribution of their latencies, and that forced polling at 1000 Hz decreases latency for some but not all devices. Existing practices - measuring end-to-end latency as a proxy of input latency and reporting only mean values and standard deviations - hide these characteristic latency distributions caused by device intrinsics and polling rates. A probabilistic model of input device latency demonstrates these issues and matches our measurements. Thus, our work offers guidance for researchers, engineers, and hobbyists who want to measure the latency of input devices or select devices with low latency."
pn9898,https://doi.org/10.1145/3290605.3300650,On the Latency of USB-Connected Input Devices,3,Florian Bockes,University of Regensburg,Regensburg,Germany,false,false,"We propose a method for accurately and precisely measuring the intrinsic latency of input devices and document measurements for 36 keyboards, mice and gamepads connected via USB. Our research shows that devices differ not only in average latency, but also in the distribution of their latencies, and that forced polling at 1000 Hz decreases latency for some but not all devices. Existing practices - measuring end-to-end latency as a proxy of input latency and reporting only mean values and standard deviations - hide these characteristic latency distributions caused by device intrinsics and polling rates. A probabilistic model of input device latency demonstrates these issues and matches our measurements. Thus, our work offers guidance for researchers, engineers, and hobbyists who want to measure the latency of input devices or select devices with low latency."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,1,Alyssa Alcorn,University College London,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,2,Katerina Avramides,University College London,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,3,Sandra Beale,Birkbeck College,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,4,Sara Bernardini,Royal Halloway,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,5,Mary Ellen Foster,University of Glasgow,Glasgow,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,6,Christopher Frauenberger,TU Wien,Vienna,Austria,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,7,Judith Good,University of Sussex,"Falmer, Brighton",United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,8,Karen Guldberg,University of Birmingham,Birmingham,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,9,Wendy Keay-Bright,Cardiff Metropolitan University,Cardiff,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,10,Lila Kossyvaki,University of Birmingham,Birmingham,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,11,Oliver Lemon,Heriot Watt University,Edinburgh,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,12,Marilena Mademtzi,Yale University,New Haven,United States,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,13,Rachel Menzies,University of Dundee,Dundee,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,14,Helen Pain,Edinburgh University,Edinburgh,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,15,Gnanathusharan Rajendran,Heriot-Watt University,Edinburgh,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,16,Annalu Waller,University of Dundee,Dundee,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,17,Sam Wass,University of East London,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1106,https://doi.org/10.1145/3290607.3313837,Blending Human and Artificial Intelligence to Support Autistic Children's Social Communication Skills,18,Tim J Smith,Birkbeck College,London,United Kingdom,false,false,"This paper examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4-14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this paper offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners and researchers."
jrnl1108,https://doi.org/10.1145/3290607.3313853,Digital Behaviour Change Interventions to Break and Form Habits,1,Charlie Pinder,Aarhus University,Aarhus,Denmark,false,false,"Digital behaviour change interventions, particularly those using pervasive computing technology, hold great promise in supporting users to change their behaviour. However, most interventions fail to take habitual behaviour into account, limiting their potential impact. This failure is partly driven by a plethora of overlapping behaviour change theories and related strategies that do not consider the role of habits. We critically review the main theories and models used in the research to analyse their application to designing effective habitual behaviour change interventions. We highlight the potential for Dual Process Theory, modern habit theory and Goal Setting Theory, which together model how users form and break habits, to drive effective digital interventions. We synthesise these theories into an explanatory framework, the Habit Alteration Model, and use it to outline the state of the art. We identify the opportunities and challenges of habit-focused interventions."
jrnl1108,https://doi.org/10.1145/3290607.3313853,Digital Behaviour Change Interventions to Break and Form Habits,2,Jo Vermeulen,Aarhus University,Aarhus,Denmark,false,false,"Digital behaviour change interventions, particularly those using pervasive computing technology, hold great promise in supporting users to change their behaviour. However, most interventions fail to take habitual behaviour into account, limiting their potential impact. This failure is partly driven by a plethora of overlapping behaviour change theories and related strategies that do not consider the role of habits. We critically review the main theories and models used in the research to analyse their application to designing effective habitual behaviour change interventions. We highlight the potential for Dual Process Theory, modern habit theory and Goal Setting Theory, which together model how users form and break habits, to drive effective digital interventions. We synthesise these theories into an explanatory framework, the Habit Alteration Model, and use it to outline the state of the art. We identify the opportunities and challenges of habit-focused interventions."
jrnl1108,https://doi.org/10.1145/3290607.3313853,Digital Behaviour Change Interventions to Break and Form Habits,3,Benjamin Cowan,University College Dublin,Dublin,Ireland,false,false,"Digital behaviour change interventions, particularly those using pervasive computing technology, hold great promise in supporting users to change their behaviour. However, most interventions fail to take habitual behaviour into account, limiting their potential impact. This failure is partly driven by a plethora of overlapping behaviour change theories and related strategies that do not consider the role of habits. We critically review the main theories and models used in the research to analyse their application to designing effective habitual behaviour change interventions. We highlight the potential for Dual Process Theory, modern habit theory and Goal Setting Theory, which together model how users form and break habits, to drive effective digital interventions. We synthesise these theories into an explanatory framework, the Habit Alteration Model, and use it to outline the state of the art. We identify the opportunities and challenges of habit-focused interventions."
jrnl1108,https://doi.org/10.1145/3290607.3313853,Digital Behaviour Change Interventions to Break and Form Habits,4,Russell Beale,University of Birmingham,Birmingham,United Kingdom,false,false,"Digital behaviour change interventions, particularly those using pervasive computing technology, hold great promise in supporting users to change their behaviour. However, most interventions fail to take habitual behaviour into account, limiting their potential impact. This failure is partly driven by a plethora of overlapping behaviour change theories and related strategies that do not consider the role of habits. We critically review the main theories and models used in the research to analyse their application to designing effective habitual behaviour change interventions. We highlight the potential for Dual Process Theory, modern habit theory and Goal Setting Theory, which together model how users form and break habits, to drive effective digital interventions. We synthesise these theories into an explanatory framework, the Habit Alteration Model, and use it to outline the state of the art. We identify the opportunities and challenges of habit-focused interventions."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,1,Carman Neustaedter,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,2,Samarth Singhal,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,3,Rui Pan,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,4,Yasamin Heshmat,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,5,Azadeh Forghani,Simon Fraser University,Burnaby/Surrey/Vancouver,Canada,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1105,https://doi.org/10.1145/3290607.3313836,From Being There to Watching: Shared and Dedicated Telepresence Robot Usage at Academic Conferences,6,John Tang,Microsoft,Mountain View,United States,false,false,"Telepresence attendance at academic conferences is now a reality and allows people who cannot attend in person with the opportunity to still be 'present.' This is valuable for people who face accessibility challenges, cost or travel restrictions, or limited time for travel. We have deployed and studied the use of telepresence robots at three ACM conferences, Ubicomp/ISWC 2014, CSCW 2016, and CHI 2016, ranging from remote users having dedicated telepresence robots to users sharing telepresence robots both synchronously and asynchronously. In this article, we report on the telepresence offerings along with the user behaviors, experiences, and the social norms found for remote conference attendance. Our results across the studies focus around three main themes: shared vs. dedicated robot usage, identity presentation and the value and challenges associated with it; and local in-person support through proxies and instant messaging backchannels. These themes point to three different areas of design exploration for telepresence robots, pointing out the limitations of existing design solutions with respect to each theme, areas for future telepresence design work, and the value in considering varied telepresence robot solutions, including both dedicated and shared telepresence robots."
jrnl1118,https://doi.org/10.1145/3290607.3313843,Speed-Accuracy Tradeoff: A Formal Information-Theoretic Transmission Scheme (FITTS),1,Julien Gori,Telecom ParisTech,Paris,France,false,false,"The rationale for Fitts' law is that pointing tasks have the information-theoretic analogy of sending a signal over a noisy channel, thereby matching Shannon's capacity formula. Yet, the currently received analysis is incomplete and unsatisfactory: There is no explicit communication model for pointing; there is a confusion between central concepts of capacity (a mathematical limit), throughput (an average performance measure), and bandwidth (a physical quantity); and there is also a confusion between source and channel coding so that Shannon's Theorem 17 can be misinterpreted. We develop an information-theoretic model for pointing tasks where the index of difficulty (ID) is the expression of both a source entropy and a zero-error channel capacity. Then, we extend the model to include misses at rate ? and prove that ID should be adjusted to (1??) ID. Finally, we reflect on Shannon's channel coding theorem and argue that only minimum movement times, not performance averages, should be considered."
jrnl1118,https://doi.org/10.1145/3290607.3313843,Speed-Accuracy Tradeoff: A Formal Information-Theoretic Transmission Scheme (FITTS),2,Olivier Rioul,Telecom ParisTech,Paris,France,false,false,"The rationale for Fitts' law is that pointing tasks have the information-theoretic analogy of sending a signal over a noisy channel, thereby matching Shannon's capacity formula. Yet, the currently received analysis is incomplete and unsatisfactory: There is no explicit communication model for pointing; there is a confusion between central concepts of capacity (a mathematical limit), throughput (an average performance measure), and bandwidth (a physical quantity); and there is also a confusion between source and channel coding so that Shannon's Theorem 17 can be misinterpreted. We develop an information-theoretic model for pointing tasks where the index of difficulty (ID) is the expression of both a source entropy and a zero-error channel capacity. Then, we extend the model to include misses at rate ? and prove that ID should be adjusted to (1??) ID. Finally, we reflect on Shannon's channel coding theorem and argue that only minimum movement times, not performance averages, should be considered."
jrnl1118,https://doi.org/10.1145/3290607.3313843,Speed-Accuracy Tradeoff: A Formal Information-Theoretic Transmission Scheme (FITTS),3,Yves Guiard,CNRS,Orsay/Paris,France,false,false,"The rationale for Fitts' law is that pointing tasks have the information-theoretic analogy of sending a signal over a noisy channel, thereby matching Shannon's capacity formula. Yet, the currently received analysis is incomplete and unsatisfactory: There is no explicit communication model for pointing; there is a confusion between central concepts of capacity (a mathematical limit), throughput (an average performance measure), and bandwidth (a physical quantity); and there is also a confusion between source and channel coding so that Shannon's Theorem 17 can be misinterpreted. We develop an information-theoretic model for pointing tasks where the index of difficulty (ID) is the expression of both a source entropy and a zero-error channel capacity. Then, we extend the model to include misses at rate ? and prove that ID should be adjusted to (1??) ID. Finally, we reflect on Shannon's channel coding theorem and argue that only minimum movement times, not performance averages, should be considered."
pn3256,https://doi.org/10.1145/3290605.3300830,Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?,1,Kenneth Holstein,Carnegie Mellon University,Pittsburgh,United States,false,false,"The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs."
pn3256,https://doi.org/10.1145/3290605.3300830,Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?,2,Jennifer Wortman Vaughan,Microsoft Research,New York,United States,false,false,"The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs."
pn3256,https://doi.org/10.1145/3290605.3300830,Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?,3,Hal Daumé,Microsoft Research,New York,United States,false,false,"The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs."
pn3256,https://doi.org/10.1145/3290605.3300830,Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?,4,Miro Dudik,Microsoft Research,New York,United States,false,false,"The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs."
pn3256,https://doi.org/10.1145/3290605.3300830,Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?,5,Hanna Wallach,Microsoft Research,New York,United States,false,false,"The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs."
pn3787,https://doi.org/10.1145/3290605.3300677,A is for Artificial Intelligence: The Impact of Artificial Intelligence Activities on Young Children's Perceptions of Robots,1,Randi Williams,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We developed a novel early childhood artificial intelligence (AI) platform, PopBots, where preschool children train and interact with social robots to learn three AI concepts: knowledge-based systems, supervised machine learning, and generative AI. We evaluated how much children learned by using AI assessments we developed for each activity. The median score on the cumulative assessment was 70% and children understood knowledge-based systems the best. Then, we analyzed the impact of the activities on children's perceptions of robots. Younger children came to see robots as toys that were smarter than them, but their older counterparts saw them more as people that were not as smart as them. Children who performed worse on the AI assessments believed that robots were like toys that were not as smart as them, however children who did better on the assessments saw robots as people who were smarter than them. We believe early AI education can empower children to understand the AI devices that are increasingly in their lives."
pn3787,https://doi.org/10.1145/3290605.3300677,A is for Artificial Intelligence: The Impact of Artificial Intelligence Activities on Young Children's Perceptions of Robots,2,Hae Won Park,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We developed a novel early childhood artificial intelligence (AI) platform, PopBots, where preschool children train and interact with social robots to learn three AI concepts: knowledge-based systems, supervised machine learning, and generative AI. We evaluated how much children learned by using AI assessments we developed for each activity. The median score on the cumulative assessment was 70% and children understood knowledge-based systems the best. Then, we analyzed the impact of the activities on children's perceptions of robots. Younger children came to see robots as toys that were smarter than them, but their older counterparts saw them more as people that were not as smart as them. Children who performed worse on the AI assessments believed that robots were like toys that were not as smart as them, however children who did better on the assessments saw robots as people who were smarter than them. We believe early AI education can empower children to understand the AI devices that are increasingly in their lives."
pn3787,https://doi.org/10.1145/3290605.3300677,A is for Artificial Intelligence: The Impact of Artificial Intelligence Activities on Young Children's Perceptions of Robots,3,Cynthia Breazeal,Massachusetts Institute of Technology,Cambridge,United States,false,false,"We developed a novel early childhood artificial intelligence (AI) platform, PopBots, where preschool children train and interact with social robots to learn three AI concepts: knowledge-based systems, supervised machine learning, and generative AI. We evaluated how much children learned by using AI assessments we developed for each activity. The median score on the cumulative assessment was 70% and children understood knowledge-based systems the best. Then, we analyzed the impact of the activities on children's perceptions of robots. Younger children came to see robots as toys that were smarter than them, but their older counterparts saw them more as people that were not as smart as them. Children who performed worse on the AI assessments believed that robots were like toys that were not as smart as them, however children who did better on the assessments saw robots as people who were smarter than them. We believe early AI education can empower children to understand the AI devices that are increasingly in their lives."
pn1410,https://doi.org/10.1145/3290605.3300509,Understanding the Effect of Accuracy on Trust in Machine Learning Models,1,Ming Yin,Purdue University,West Lafayette,United States,true,false,"We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline."
pn1410,https://doi.org/10.1145/3290605.3300509,Understanding the Effect of Accuracy on Trust in Machine Learning Models,2,Jennifer Wortman Vaughan,Microsoft Research,New York,United States,true,false,"We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline."
pn1410,https://doi.org/10.1145/3290605.3300509,Understanding the Effect of Accuracy on Trust in Machine Learning Models,3,Hanna Wallach,Microsoft Research,New York,United States,true,false,"We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline."
pn5013,https://doi.org/10.1145/3290605.3300709,Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis,1,Chanda Phelan,University of Michigan,Ann Arbor,United States,false,false,"Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI."
pn5013,https://doi.org/10.1145/3290605.3300709,Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis,2,Jessica Hullman,Northwestern University,Evanston,United States,false,false,"Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI."
pn5013,https://doi.org/10.1145/3290605.3300709,Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis,3,Matthew Kay,University of Michigan,Ann Arbor,United States,false,false,"Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI."
pn5013,https://doi.org/10.1145/3290605.3300709,Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis,4,Paul Resnick,University of Michigan,Ann Arbor,United States,false,false,"Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI."
pn2495,https://doi.org/10.1145/3290605.3300310,PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers,1,Julie Williamson,University of Glasgow,Glasgow,United Kingdom,false,false,"Virtual reality (VR) headsets allow wearers to escape their physical surroundings, immersing themselves in a virtual world. Although escape may not be realistic or acceptable in many everyday situations, air travel is one context where early adoption of VR could be very attractive. While travelling, passengers are seated in restricted spaces for long durations, reliant on limited seat-back displays or mobile devices. This paper explores the social acceptability and usability of VR for in-flight entertainment. In an initial survey, we captured respondents' attitudes towards the social acceptability of VR headsets during air travel. Based on the survey results, we developed a VR in-flight entertainment prototype and evaluated this in a focus group study. Our results discuss methods for improving the acceptability of VR in-flight, including using mixed reality to help users transition between virtual and physical environments and supporting interruption from other co-located people."
pn2495,https://doi.org/10.1145/3290605.3300310,PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers,2,Mark Mcgill,University of Glasgow,Glasgow,United Kingdom,false,false,"Virtual reality (VR) headsets allow wearers to escape their physical surroundings, immersing themselves in a virtual world. Although escape may not be realistic or acceptable in many everyday situations, air travel is one context where early adoption of VR could be very attractive. While travelling, passengers are seated in restricted spaces for long durations, reliant on limited seat-back displays or mobile devices. This paper explores the social acceptability and usability of VR for in-flight entertainment. In an initial survey, we captured respondents' attitudes towards the social acceptability of VR headsets during air travel. Based on the survey results, we developed a VR in-flight entertainment prototype and evaluated this in a focus group study. Our results discuss methods for improving the acceptability of VR in-flight, including using mixed reality to help users transition between virtual and physical environments and supporting interruption from other co-located people."
pn2495,https://doi.org/10.1145/3290605.3300310,PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers,3,Khari Outram,University of Glasgow,Glasgow,United Kingdom,false,false,"Virtual reality (VR) headsets allow wearers to escape their physical surroundings, immersing themselves in a virtual world. Although escape may not be realistic or acceptable in many everyday situations, air travel is one context where early adoption of VR could be very attractive. While travelling, passengers are seated in restricted spaces for long durations, reliant on limited seat-back displays or mobile devices. This paper explores the social acceptability and usability of VR for in-flight entertainment. In an initial survey, we captured respondents' attitudes towards the social acceptability of VR headsets during air travel. Based on the survey results, we developed a VR in-flight entertainment prototype and evaluated this in a focus group study. Our results discuss methods for improving the acceptability of VR in-flight, including using mixed reality to help users transition between virtual and physical environments and supporting interruption from other co-located people."
pn1988,https://doi.org/10.1145/3290605.3300691,Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events,1,Tao Bi,University College London,London,United Kingdom,false,false,"Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&S' shared experience during LDRE and how technology can enrich this experience. We propose a two-layer DyPECS framework, highlighting the rich dynamics of the R&S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&S during LDRE."
pn1988,https://doi.org/10.1145/3290605.3300691,Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events,2,Nadia Bianchi-Berthouze,University College London,London,United Kingdom,false,false,"Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&S' shared experience during LDRE and how technology can enrich this experience. We propose a two-layer DyPECS framework, highlighting the rich dynamics of the R&S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&S during LDRE."
pn1988,https://doi.org/10.1145/3290605.3300691,Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events,3,Aneesha Singh,University College London,London,United Kingdom,false,false,"Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&S' shared experience during LDRE and how technology can enrich this experience. We propose a two-layer DyPECS framework, highlighting the rich dynamics of the R&S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&S during LDRE."
pn1988,https://doi.org/10.1145/3290605.3300691,Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events,4,Enrico Costanza,University College London,London,United Kingdom,false,false,"Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&S' shared experience during LDRE and how technology can enrich this experience. We propose a two-layer DyPECS framework, highlighting the rich dynamics of the R&S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&S during LDRE."
pn5861,https://doi.org/10.1145/3290605.3300521,Effects of Locomotion and Visual Overview on Spatial Memory when Interacting with Wall Displays,1,Yvonne Jansen,CNRS – Sorbonne Université,Paris,France,false,false,"Wall displays support people in interacting with large information spaces in two ways: On the one hand, the physical space in front of such displays enables them to navigate information spaces physically. On the other hand, the visual overview of the information space on the display may promote the formation of spatial memory; from studies of desktop computers we know this can boost performance. However, it remains unclear how the benefits of locomotion and overviews relate and whether one is more important than the other. We study this question through a wall display adaptation of the classic Data Mountain system to separate the effects of locomotion and visual overview. Our findings suggest that overview improves recall and that the combination of overview and locomotion outperforms all other combinations of factors."
pn5861,https://doi.org/10.1145/3290605.3300521,Effects of Locomotion and Visual Overview on Spatial Memory when Interacting with Wall Displays,2,Jonas Schjerlund,University of Copenhagen,Copenhagen,Denmark,false,false,"Wall displays support people in interacting with large information spaces in two ways: On the one hand, the physical space in front of such displays enables them to navigate information spaces physically. On the other hand, the visual overview of the information space on the display may promote the formation of spatial memory; from studies of desktop computers we know this can boost performance. However, it remains unclear how the benefits of locomotion and overviews relate and whether one is more important than the other. We study this question through a wall display adaptation of the classic Data Mountain system to separate the effects of locomotion and visual overview. Our findings suggest that overview improves recall and that the combination of overview and locomotion outperforms all other combinations of factors."
pn5861,https://doi.org/10.1145/3290605.3300521,Effects of Locomotion and Visual Overview on Spatial Memory when Interacting with Wall Displays,3,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,false,false,"Wall displays support people in interacting with large information spaces in two ways: On the one hand, the physical space in front of such displays enables them to navigate information spaces physically. On the other hand, the visual overview of the information space on the display may promote the formation of spatial memory; from studies of desktop computers we know this can boost performance. However, it remains unclear how the benefits of locomotion and overviews relate and whether one is more important than the other. We study this question through a wall display adaptation of the classic Data Mountain system to separate the effects of locomotion and visual overview. Our findings suggest that overview improves recall and that the combination of overview and locomotion outperforms all other combinations of factors."
pn1295,https://doi.org/10.1145/3290605.3300870,Peripheral Notifications in Large Displays: Effects of Feature Combination and Task Interference,1,Aristides Mairena,University of Saskatchewan,Saskatoon,Canada,false,false,"Visual notifications are integral to interactive computing systems. With large displays, however, much of the content is in the user's visual periphery, where human capacity to notice visual effects is diminished. One design strategy for enhancing noticeability is to combine visual features, such as motion and colour. Yet little is known about how feature combinations affect noticeability across the visual field, or about how peripheral noticeability changes when a user's primary task involves the same visual features as the notification. We addressed these questions by conducting two studies. Results of the first study showed that noticeability of feature combinations were approximately equal to the better of the individual features. Results of the second study suggest that there can be interference between the features of primary tasks and the visual features in the notifications. Our findings contribute to a better understanding of how visual features operate when used as peripheral notifications."
pn1295,https://doi.org/10.1145/3290605.3300870,Peripheral Notifications in Large Displays: Effects of Feature Combination and Task Interference,2,Carl Gutwin,University of Saskatchewan,Saskatoon,Canada,false,false,"Visual notifications are integral to interactive computing systems. With large displays, however, much of the content is in the user's visual periphery, where human capacity to notice visual effects is diminished. One design strategy for enhancing noticeability is to combine visual features, such as motion and colour. Yet little is known about how feature combinations affect noticeability across the visual field, or about how peripheral noticeability changes when a user's primary task involves the same visual features as the notification. We addressed these questions by conducting two studies. Results of the first study showed that noticeability of feature combinations were approximately equal to the better of the individual features. Results of the second study suggest that there can be interference between the features of primary tasks and the visual features in the notifications. Our findings contribute to a better understanding of how visual features operate when used as peripheral notifications."
pn1295,https://doi.org/10.1145/3290605.3300870,Peripheral Notifications in Large Displays: Effects of Feature Combination and Task Interference,3,Andy Cockburn,University of Canterbury,Christchurch,New Zealand,false,false,"Visual notifications are integral to interactive computing systems. With large displays, however, much of the content is in the user's visual periphery, where human capacity to notice visual effects is diminished. One design strategy for enhancing noticeability is to combine visual features, such as motion and colour. Yet little is known about how feature combinations affect noticeability across the visual field, or about how peripheral noticeability changes when a user's primary task involves the same visual features as the notification. We addressed these questions by conducting two studies. Results of the first study showed that noticeability of feature combinations were approximately equal to the better of the individual features. Results of the second study suggest that there can be interference between the features of primary tasks and the visual features in the notifications. Our findings contribute to a better understanding of how visual features operate when used as peripheral notifications."
pn5762,https://doi.org/10.1145/3290605.3300261,"The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups",1,Diyi Yang,Carnegie Mellon University,Pittsburgh,United States,true,false,"People with health concerns go to online health support groups to obtain help and advice. To do so, they frequently disclose personal details, many times in public. Although research in non-health settings suggests that people self-disclose less in public than in private, this pattern may not apply to health support groups where people want to get relevant help. Our work examines how the use of private and public channels influences members' self-disclosure in an online cancer support group, and how channels moderate the influence of self-disclosure on reciprocity and receiving support. By automatically measuring people's self-disclosure at scale, we found that members of cancer support groups revealed more negative self-disclosure in the public channels compared to the private channels. Although one's self-disclosure leads others to self-disclose and to provide support, these effects were generally stronger in the private channel. These channel effects probably occur because the public channels are the primary venue for support exchange, while the private channels are mainly used for follow-up conversations. We discuss theoretical and practical implications of our work."
pn5762,https://doi.org/10.1145/3290605.3300261,"The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups",2,Zheng Yao,Carnegie Mellon University,Pittsburgh,United States,true,false,"People with health concerns go to online health support groups to obtain help and advice. To do so, they frequently disclose personal details, many times in public. Although research in non-health settings suggests that people self-disclose less in public than in private, this pattern may not apply to health support groups where people want to get relevant help. Our work examines how the use of private and public channels influences members' self-disclosure in an online cancer support group, and how channels moderate the influence of self-disclosure on reciprocity and receiving support. By automatically measuring people's self-disclosure at scale, we found that members of cancer support groups revealed more negative self-disclosure in the public channels compared to the private channels. Although one's self-disclosure leads others to self-disclose and to provide support, these effects were generally stronger in the private channel. These channel effects probably occur because the public channels are the primary venue for support exchange, while the private channels are mainly used for follow-up conversations. We discuss theoretical and practical implications of our work."
pn5762,https://doi.org/10.1145/3290605.3300261,"The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups",3,Joseph Seering,Carnegie Mellon University,Pittsburgh,United States,true,false,"People with health concerns go to online health support groups to obtain help and advice. To do so, they frequently disclose personal details, many times in public. Although research in non-health settings suggests that people self-disclose less in public than in private, this pattern may not apply to health support groups where people want to get relevant help. Our work examines how the use of private and public channels influences members' self-disclosure in an online cancer support group, and how channels moderate the influence of self-disclosure on reciprocity and receiving support. By automatically measuring people's self-disclosure at scale, we found that members of cancer support groups revealed more negative self-disclosure in the public channels compared to the private channels. Although one's self-disclosure leads others to self-disclose and to provide support, these effects were generally stronger in the private channel. These channel effects probably occur because the public channels are the primary venue for support exchange, while the private channels are mainly used for follow-up conversations. We discuss theoretical and practical implications of our work."
pn5762,https://doi.org/10.1145/3290605.3300261,"The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups",4,Robert Kraut,Carnegie Mellon University,Pittsburgh,United States,true,false,"People with health concerns go to online health support groups to obtain help and advice. To do so, they frequently disclose personal details, many times in public. Although research in non-health settings suggests that people self-disclose less in public than in private, this pattern may not apply to health support groups where people want to get relevant help. Our work examines how the use of private and public channels influences members' self-disclosure in an online cancer support group, and how channels moderate the influence of self-disclosure on reciprocity and receiving support. By automatically measuring people's self-disclosure at scale, we found that members of cancer support groups revealed more negative self-disclosure in the public channels compared to the private channels. Although one's self-disclosure leads others to self-disclose and to provide support, these effects were generally stronger in the private channel. These channel effects probably occur because the public channels are the primary venue for support exchange, while the private channels are mainly used for follow-up conversations. We discuss theoretical and practical implications of our work."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,1,Jie Li,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,2,Yiping Kong,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,3,Thomas Röggla,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,4,Francesca De Simone,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,5,Swamy Ananthanarayan,University of Oldenburg,Oldenburg,Germany,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,6,Huib De Ridder,Delft University of Technology,Delft,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,7,Abdallah El Ali,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn7164,https://doi.org/10.1145/3290605.3300897,Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality,8,Pablo Cesar,Centrum Wiskunde,Amsterdam,Netherlands,false,false,"Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,1,Julie Doyle,Dundalk Institute of Technology,Dundalk,Ireland,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,2,Emma Murphy,Trinity College Dublin,Dublin,Ireland,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,3,Janneke Kuiper,Vrije Universiteit Brussel,Brussels,Belgium,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,4,Suzanne Smith,Dundalk Institute of Technology,Dundalk,Ireland,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,5,Caoimhe Hannigan,Trinity College Dublin,Dublin,Ireland,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,6,An Jacobs,Vrije Universiteit Brussel,Brussel,Belgium,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn5390,https://doi.org/10.1145/3290605.3300629,Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions,7,John Dinsmore,Trinity College Dublin,Dublin,Ireland,true,false,"Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study."
pn4368,https://doi.org/10.1145/3290605.3300681,Face and Ecological Validity in Simulations: Lessons from Search-and-Rescue HRI,1,Lorin Dole,Cornell Tech,New York,United States,false,false,"In fields where in situ performance cannot be measured, ecological validity is difficult to estimate. Drawing on theory from social psychology and virtual reality, we argue that face validity can be a useful proxy for ecological validity. We provide illustrative examples of this relationship from work in search-and-rescue HRI, and conclude with some practical guidelines for the construction of immersive simulations in general."
pn4368,https://doi.org/10.1145/3290605.3300681,Face and Ecological Validity in Simulations: Lessons from Search-and-Rescue HRI,2,Wendy Ju,Cornell Tech,New York,United States,false,false,"In fields where in situ performance cannot be measured, ecological validity is difficult to estimate. Drawing on theory from social psychology and virtual reality, we argue that face validity can be a useful proxy for ecological validity. We provide illustrative examples of this relationship from work in search-and-rescue HRI, and conclude with some practical guidelines for the construction of immersive simulations in general."
pn6795,https://doi.org/10.1145/3290605.3300840,Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia,1,Sarah Foley,University College Cork,Cork,Ireland,false,false,"While there have been considerable developments in designing for dementia within HCI, there is still a lack of empirical understanding of the experience of people with advanced dementia and the ways in which design can support and enrich their lives. In this paper, we present our findings from a long-term ethnographic study, which aimed to gain an understanding of their lived experience and inform design practices for and with people with advanced dementia in residential care. We present our findings using the social theory of recognition as an analytic lens to account for recognition in practice and its challenges in care and research. We discuss how we, as the HCI community, can pragmatically engage with people with advanced dementia and propose a set of considerations for those who wish to design for and with the values of recognition theory to promote collaboration, agency and social identity in advanced dementia care."
pn6795,https://doi.org/10.1145/3290605.3300840,Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia,2,Nadia Pantidi,University College Cork,Cork,Ireland,false,false,"While there have been considerable developments in designing for dementia within HCI, there is still a lack of empirical understanding of the experience of people with advanced dementia and the ways in which design can support and enrich their lives. In this paper, we present our findings from a long-term ethnographic study, which aimed to gain an understanding of their lived experience and inform design practices for and with people with advanced dementia in residential care. We present our findings using the social theory of recognition as an analytic lens to account for recognition in practice and its challenges in care and research. We discuss how we, as the HCI community, can pragmatically engage with people with advanced dementia and propose a set of considerations for those who wish to design for and with the values of recognition theory to promote collaboration, agency and social identity in advanced dementia care."
pn6795,https://doi.org/10.1145/3290605.3300840,Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia,3,John Mccarthy,University College Cork,Cork,Ireland,false,false,"While there have been considerable developments in designing for dementia within HCI, there is still a lack of empirical understanding of the experience of people with advanced dementia and the ways in which design can support and enrich their lives. In this paper, we present our findings from a long-term ethnographic study, which aimed to gain an understanding of their lived experience and inform design practices for and with people with advanced dementia in residential care. We present our findings using the social theory of recognition as an analytic lens to account for recognition in practice and its challenges in care and research. We discuss how we, as the HCI community, can pragmatically engage with people with advanced dementia and propose a set of considerations for those who wish to design for and with the values of recognition theory to promote collaboration, agency and social identity in advanced dementia care."
pn3013,https://doi.org/10.1145/3290605.3300339,Position Exchange Workshops: A Method to Design for Each Other in Families,1,Diego Muñoz,Queensland University of Technology,Brisbane,Australia,false,false,"Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me & You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships."
pn3013,https://doi.org/10.1145/3290605.3300339,Position Exchange Workshops: A Method to Design for Each Other in Families,2,Bernd Ploderer,Queensland University of Technology,Brisbane,Australia,false,false,"Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me & You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships."
pn3013,https://doi.org/10.1145/3290605.3300339,Position Exchange Workshops: A Method to Design for Each Other in Families,3,Margot Brereton,Queensland University of Technology,Brisbane,Australia,false,false,"Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me & You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships."
pn4177,https://doi.org/10.1145/3290605.3300251,Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum,1,Cara Wilson,Queensland University of Technology,Brisbane,Australia,false,false,"Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimally-verbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based methods from Speech and Language Therapy which are child-led and interests-based. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimally-verbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities."
pn4177,https://doi.org/10.1145/3290605.3300251,Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum,2,Margot Brereton,Queensland University of Technology,Brisbane,Australia,false,false,"Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimally-verbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based methods from Speech and Language Therapy which are child-led and interests-based. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimally-verbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities."
pn4177,https://doi.org/10.1145/3290605.3300251,Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum,3,Bernd Ploderer,Queensland University of Technology,Brisbane,Australia,false,false,"Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimally-verbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based methods from Speech and Language Therapy which are child-led and interests-based. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimally-verbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities."
pn4177,https://doi.org/10.1145/3290605.3300251,Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum,4,Laurianne Sitbon,Queensland University of Technology,Brisbane,Australia,false,false,"Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimally-verbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based methods from Speech and Language Therapy which are child-led and interests-based. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimally-verbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,1,Michael Crabb,University of Dundee,Dundee,United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,2,Michael Heron,Robert Gordon University,Aberdeen,United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,3,Rhianne Jones,BBC Research and Development,"Salford, Manchester",United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,4,Mike Armstrong,BBC Research and Development,"Salford, Manchester",United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,5,Hayley Reid,FinancialForce,Harrogate,United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn5336,https://doi.org/10.1145/3290605.3300446,Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support,6,Amy Wilson,Robert Gordon University,Aberdeen,United Kingdom,true,false,"When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,1,Jay Rainey,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,2,Kyle Montague,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,3,Pamela Briggs,Northumbria University,Newcastle Upon Tyne,United Kingdom,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,4,Robert Anderson,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,5,Thomas Nappey,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn8981,https://doi.org/10.1145/3290605.3300607,Gabber: Supporting Voice in Participatory Qualitative Practices,6,Patrick Olivier,Monash University,Melbourne,Australia,false,false,"We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices."
pn7304,https://doi.org/10.1145/3290605.3300448,Socio-technical Dynamics: Cooperation of Emergent and Established Organisations in Crises and Disasters,1,Daniel Auferbauer,AIT Austrian Institute of Technology,Vienna,Austria,true,false,"Increasing ubiquitousness of information and communication technology exerts influence on crisis and disaster management. New media enable citizens to rapidly self-organise in emergent groups. Theoretical framing of their interactions with established organisations is lacking. To address this, we conduct a thematic analysis on qualitative data from the European migration crisis of 2015. We draw on context-rich material from both emergent groups and established organisation. To represent our findings, we introduce the notion of socio-technical dynamics. We derive implications for computer supported cooperative work in crises and disasters. These insights contribute to the efficient involvement of emergent groups in established systems."
pn7304,https://doi.org/10.1145/3290605.3300448,Socio-technical Dynamics: Cooperation of Emergent and Established Organisations in Crises and Disasters,2,Hilda Tellio?Lu,TU Wien,Vienna,Austria,true,false,"Increasing ubiquitousness of information and communication technology exerts influence on crisis and disaster management. New media enable citizens to rapidly self-organise in emergent groups. Theoretical framing of their interactions with established organisations is lacking. To address this, we conduct a thematic analysis on qualitative data from the European migration crisis of 2015. We draw on context-rich material from both emergent groups and established organisation. To represent our findings, we introduce the notion of socio-technical dynamics. We derive implications for computer supported cooperative work in crises and disasters. These insights contribute to the efficient involvement of emergent groups in established systems."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,1,Bettina Nissen,Edinburgh University,Edinburgh,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,2,Victoria Neumann,Lancaster University,Lancaster,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,3,Mateusz Mikusz,Lancaster University,Lancaster,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,4,Rory Gianni,The University of Edinburgh,Edinburgh,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,5,Sarah Clinch,University of Manchester,Manchester,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,6,Chris Speed,Edinburgh University,Edinburgh,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn6958,https://doi.org/10.1145/3290605.3300745,Should I Agree? Delegating Consent Decisions Beyond the Individual,7,Nigel Davies,Lancaster University,Lancaster,United Kingdom,false,false,"Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice."
pn8405,https://doi.org/10.1145/3290605.3300297,When Do People Trust Their Social Groups?,1,Xiao Ma,"Jacobs Institute, Cornell Tech",New York,United States,false,false,"Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals' general propensity to trust, as well as the factors that contribute to their trust in specific groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual's propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group's overall friendship-network structure and an individual's position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties."
pn8405,https://doi.org/10.1145/3290605.3300297,When Do People Trust Their Social Groups?,2,Justin Cheng,Facebook,Menlo Park,United States,false,false,"Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals' general propensity to trust, as well as the factors that contribute to their trust in specific groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual's propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group's overall friendship-network structure and an individual's position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties."
pn8405,https://doi.org/10.1145/3290605.3300297,When Do People Trust Their Social Groups?,3,Shankar Iyer,Facebook,Menlo Park,United States,false,false,"Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals' general propensity to trust, as well as the factors that contribute to their trust in specific groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual's propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group's overall friendship-network structure and an individual's position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties."
pn8405,https://doi.org/10.1145/3290605.3300297,When Do People Trust Their Social Groups?,4,Mor Naaman,"Jacobs Institute, Cornell Tech",New York,United States,false,false,"Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals' general propensity to trust, as well as the factors that contribute to their trust in specific groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual's propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group's overall friendship-network structure and an individual's position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,1,Tom Hitron,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,2,Yoav Orlev,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,3,Iddo Wald,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,4,Ariel Shamir,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,5,Hadas Erel,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn1116,https://doi.org/10.1145/3290605.3300645,Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes,6,Oren Zuckerman,Interdisciplinary Center,Herzliya,Israel,true,false,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them."
pn2244,https://doi.org/10.1145/3290605.3300886,Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors,1,Joshua Shi,Northwestern University,Evanston,United States,false,false,"While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study."
pn2244,https://doi.org/10.1145/3290605.3300886,Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors,2,Armaan Shah,Northwestern University,Evanston,United States,false,false,"While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study."
pn2244,https://doi.org/10.1145/3290605.3300886,Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors,3,Garrett Hedman,Northwestern University,Chicago,United States,false,false,"While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study."
pn2244,https://doi.org/10.1145/3290605.3300886,Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors,4,Eleanor O'rourke,Northwestern University,Evanston,United States,false,false,"While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study."
pn3146,https://doi.org/10.1145/3290605.3300729,HOPE for Computing Education: Towards the Infrastructuring of Support for University-School Partnerships,1,Megan Venn-Wycherley,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"The state of computing education in the UK is described as ""patchy and fragile"" with universities tasked to provide further support to schools. However, little guidance exists towards the provision of this support. To explore the development of university-school partnerships, we present findings of an extended educational engagement coordinated by Newcastle University, as part of the national ""Create, Learn and Inspire with the micro:bit and the BBC"" initiative. Following an action research approach, we explore the experiences of undergraduate students, schoolteachers and an educational broker through the process, including recruitment, content development, and delivery of over 30 computing lessons by nine undergraduates. We identify a number of design considerations towards the development of High Opportunity Progression Ecosystems for the improvement of computing education, such as student identity, workload model,and process visibility. We then discuss the potential role of technology in infrastructuring support for university-school partnerships"
pn3146,https://doi.org/10.1145/3290605.3300729,HOPE for Computing Education: Towards the Infrastructuring of Support for University-School Partnerships,2,Ahmed Kharrufa,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"The state of computing education in the UK is described as ""patchy and fragile"" with universities tasked to provide further support to schools. However, little guidance exists towards the provision of this support. To explore the development of university-school partnerships, we present findings of an extended educational engagement coordinated by Newcastle University, as part of the national ""Create, Learn and Inspire with the micro:bit and the BBC"" initiative. Following an action research approach, we explore the experiences of undergraduate students, schoolteachers and an educational broker through the process, including recruitment, content development, and delivery of over 30 computing lessons by nine undergraduates. We identify a number of design considerations towards the development of High Opportunity Progression Ecosystems for the improvement of computing education, such as student identity, workload model,and process visibility. We then discuss the potential role of technology in infrastructuring support for university-school partnerships"
pn4421,https://doi.org/10.1145/3290605.3300493,"Practitioners Teaching Data Science in Industry and Academia: Expectations, Workflows, and Challenges",1,Sean Kross,"University of California, San Diego",La Jolla,United States,true,false,"Data science has been growing in prominence across both academia and industry, but there is still little formal consensus about how to teach it. Many people who currently teach data science are practitioners such as computational researchers in academia or data scientists in industry. To understand how these practitioner-instructors pass their knowledge onto novices and how that contrasts with teaching more traditional forms of programming, we interviewed 20 data scientists who teach in settings ranging from small-group workshops to large online courses. We found that: 1) they must empathize with a diverse array of student backgrounds and expectations, 2) they teach technical workflows that integrate authentic practices surrounding code, data, and communication, 3) they face challenges involving authenticity versus abstraction in software setup, finding and curating pedagogically-relevant datasets, and acclimating students to live with uncertainty in data analysis. These findings can point the way toward better tools for data science education and help bring data literacy to more people around the world."
pn4421,https://doi.org/10.1145/3290605.3300493,"Practitioners Teaching Data Science in Industry and Academia: Expectations, Workflows, and Challenges",2,Philip Guo,"University of California, San Diego",La Jolla,United States,true,false,"Data science has been growing in prominence across both academia and industry, but there is still little formal consensus about how to teach it. Many people who currently teach data science are practitioners such as computational researchers in academia or data scientists in industry. To understand how these practitioner-instructors pass their knowledge onto novices and how that contrasts with teaching more traditional forms of programming, we interviewed 20 data scientists who teach in settings ranging from small-group workshops to large online courses. We found that: 1) they must empathize with a diverse array of student backgrounds and expectations, 2) they teach technical workflows that integrate authentic practices surrounding code, data, and communication, 3) they face challenges involving authenticity versus abstraction in software setup, finding and curating pedagogically-relevant datasets, and acclimating students to live with uncertainty in data analysis. These findings can point the way toward better tools for data science education and help bring data literacy to more people around the world."
pn8227,https://doi.org/10.1145/3290605.3300383,r/science: Challenges and Opportunities in Online Science Communication,1,Ridley Jones,University of Washington,Seattle,United States,false,false,"Online discussion websites, such as Reddit's r/science forum, have the potential to foster science communication between researchers and the general public. However, little is known about who participates, what is discussed, and whether such websites are successful in achieving meaningful science discussions. To find out, we conducted a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with 18 community members. Our results show that r/science facilitates rich information exchange and that the comments section provides a unique science communication document that guides engagement with scientific research. However, this community-sourced science communication comes largely from a knowledgeable public. We conclude with design suggestions for a number of critical problems that we uncovered: addressing the problem of topic newsworthiness and balancing broader participation and rigor."
pn8227,https://doi.org/10.1145/3290605.3300383,r/science: Challenges and Opportunities in Online Science Communication,2,Lucas Colusso,University of Washington,Seattle,United States,false,false,"Online discussion websites, such as Reddit's r/science forum, have the potential to foster science communication between researchers and the general public. However, little is known about who participates, what is discussed, and whether such websites are successful in achieving meaningful science discussions. To find out, we conducted a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with 18 community members. Our results show that r/science facilitates rich information exchange and that the comments section provides a unique science communication document that guides engagement with scientific research. However, this community-sourced science communication comes largely from a knowledgeable public. We conclude with design suggestions for a number of critical problems that we uncovered: addressing the problem of topic newsworthiness and balancing broader participation and rigor."
pn8227,https://doi.org/10.1145/3290605.3300383,r/science: Challenges and Opportunities in Online Science Communication,3,Katharina Reinecke,University of Washington,Seattle,United States,false,false,"Online discussion websites, such as Reddit's r/science forum, have the potential to foster science communication between researchers and the general public. However, little is known about who participates, what is discussed, and whether such websites are successful in achieving meaningful science discussions. To find out, we conducted a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with 18 community members. Our results show that r/science facilitates rich information exchange and that the comments section provides a unique science communication document that guides engagement with scientific research. However, this community-sourced science communication comes largely from a knowledgeable public. We conclude with design suggestions for a number of critical problems that we uncovered: addressing the problem of topic newsworthiness and balancing broader participation and rigor."
pn8227,https://doi.org/10.1145/3290605.3300383,r/science: Challenges and Opportunities in Online Science Communication,4,Gary Hsieh,University of Washington,Seattle,United States,false,false,"Online discussion websites, such as Reddit's r/science forum, have the potential to foster science communication between researchers and the general public. However, little is known about who participates, what is discussed, and whether such websites are successful in achieving meaningful science discussions. To find out, we conducted a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with 18 community members. Our results show that r/science facilitates rich information exchange and that the comments section provides a unique science communication document that guides engagement with scientific research. However, this community-sourced science communication comes largely from a knowledgeable public. We conclude with design suggestions for a number of critical problems that we uncovered: addressing the problem of topic newsworthiness and balancing broader participation and rigor."
pn3955,https://doi.org/10.1145/3290605.3300294,Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums,1,Yada Pruksachatkun,New York University,New York,United States,false,false,"Clinical psychology literature indicates that reframing ir- rational thoughts can help bring positive cognitive change to those suffering from mental distress. Through data from an online mental health forum, we study how these cognitive processes play out in peer-to-peer conversations. Acknowledging the complexity of measuring cognitive change, we first provide an operational definition of a ""moment of change"" based on sentiment change in online conversations. Using this definition, we propose a predictive model that can identify whether a conversation thread or a post is associated with a moment of cognitive change. Consistent with psychological literature, we find that markers of language associated with sentiment and and affect are the most predictive. Further, cultural differences play an important role: predictive models trained on one country generalize poorly to others. To understand how a moment of change happens, we build a model that explicitly tracks topic and associated sentiment in a forum thread."
pn3955,https://doi.org/10.1145/3290605.3300294,Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums,2,Sachin Pendse,Microsoft Research India,Bangalore,India,false,false,"Clinical psychology literature indicates that reframing ir- rational thoughts can help bring positive cognitive change to those suffering from mental distress. Through data from an online mental health forum, we study how these cognitive processes play out in peer-to-peer conversations. Acknowledging the complexity of measuring cognitive change, we first provide an operational definition of a ""moment of change"" based on sentiment change in online conversations. Using this definition, we propose a predictive model that can identify whether a conversation thread or a post is associated with a moment of cognitive change. Consistent with psychological literature, we find that markers of language associated with sentiment and and affect are the most predictive. Further, cultural differences play an important role: predictive models trained on one country generalize poorly to others. To understand how a moment of change happens, we build a model that explicitly tracks topic and associated sentiment in a forum thread."
pn3955,https://doi.org/10.1145/3290605.3300294,Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums,3,Amit Sharma,Microsoft Research India,Bangalore,India,false,false,"Clinical psychology literature indicates that reframing ir- rational thoughts can help bring positive cognitive change to those suffering from mental distress. Through data from an online mental health forum, we study how these cognitive processes play out in peer-to-peer conversations. Acknowledging the complexity of measuring cognitive change, we first provide an operational definition of a ""moment of change"" based on sentiment change in online conversations. Using this definition, we propose a predictive model that can identify whether a conversation thread or a post is associated with a moment of cognitive change. Consistent with psychological literature, we find that markers of language associated with sentiment and and affect are the most predictive. Further, cultural differences play an important role: predictive models trained on one country generalize poorly to others. To understand how a moment of change happens, we build a model that explicitly tracks topic and associated sentiment in a forum thread."
pn3307,https://doi.org/10.1145/3290605.3300757,#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act,1,Brooke Auxier,"University of Maryland, College Park",College Park,United States,false,false,"Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives."
pn3307,https://doi.org/10.1145/3290605.3300757,#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act,2,Cody Buntain,"University of Maryland, College Park",College Park,United States,false,false,"Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives."
pn3307,https://doi.org/10.1145/3290605.3300757,#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act,3,Paul Jaeger,"University of Maryland, College Park",College Park,United States,false,false,"Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives."
pn3307,https://doi.org/10.1145/3290605.3300757,#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act,4,Jennifer Golbeck,"University of Maryland, College Park",College Park,United States,false,false,"Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives."
pn3307,https://doi.org/10.1145/3290605.3300757,#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act,5,Hernisa Kacorri,"University of Maryland, College Park",College Park,United States,false,false,"Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives."
pn9760,https://doi.org/10.1145/3290605.3300545,Communicating Hurricane Risks: Multi-Method Examination of Risk Imagery Diffusion,1,Melissa Bica,University of Colorado Boulder,Boulder,United States,false,false,"Conveying uncertainty in information artifacts is difficult; the challenge only grows as the demand for mass communication through multiple channels expands. In particular, as natural hazards increase with changing global conditions, including hurricanes which threaten coastal areas, we need better means of communicating uncertainty around risks that empower people to make good decisions. We examine how people share and respond to a range of visual representations of risk from authoritative sources during hurricane events. Because these images are now shared widely on social media platforms, Twitter provides the means to study them on a large scale as close to in vivo as possible. Using mixed methods, this study analyzes diffusion of and reactions to forecast and other risk imagery during the highly damaging 2017 Atlantic hurricane season to describe the collective response to visual representations of risk."
pn9760,https://doi.org/10.1145/3290605.3300545,Communicating Hurricane Risks: Multi-Method Examination of Risk Imagery Diffusion,2,Julie Demuth,National Center for Atmospheric Research,Boulder,United States,false,false,"Conveying uncertainty in information artifacts is difficult; the challenge only grows as the demand for mass communication through multiple channels expands. In particular, as natural hazards increase with changing global conditions, including hurricanes which threaten coastal areas, we need better means of communicating uncertainty around risks that empower people to make good decisions. We examine how people share and respond to a range of visual representations of risk from authoritative sources during hurricane events. Because these images are now shared widely on social media platforms, Twitter provides the means to study them on a large scale as close to in vivo as possible. Using mixed methods, this study analyzes diffusion of and reactions to forecast and other risk imagery during the highly damaging 2017 Atlantic hurricane season to describe the collective response to visual representations of risk."
pn9760,https://doi.org/10.1145/3290605.3300545,Communicating Hurricane Risks: Multi-Method Examination of Risk Imagery Diffusion,3,James Dykes,University of Colorado Boulder,Boulder,United States,false,false,"Conveying uncertainty in information artifacts is difficult; the challenge only grows as the demand for mass communication through multiple channels expands. In particular, as natural hazards increase with changing global conditions, including hurricanes which threaten coastal areas, we need better means of communicating uncertainty around risks that empower people to make good decisions. We examine how people share and respond to a range of visual representations of risk from authoritative sources during hurricane events. Because these images are now shared widely on social media platforms, Twitter provides the means to study them on a large scale as close to in vivo as possible. Using mixed methods, this study analyzes diffusion of and reactions to forecast and other risk imagery during the highly damaging 2017 Atlantic hurricane season to describe the collective response to visual representations of risk."
pn9760,https://doi.org/10.1145/3290605.3300545,Communicating Hurricane Risks: Multi-Method Examination of Risk Imagery Diffusion,4,Leysia Palen,University of Colorado Boulder,Boulder,United States,false,false,"Conveying uncertainty in information artifacts is difficult; the challenge only grows as the demand for mass communication through multiple channels expands. In particular, as natural hazards increase with changing global conditions, including hurricanes which threaten coastal areas, we need better means of communicating uncertainty around risks that empower people to make good decisions. We examine how people share and respond to a range of visual representations of risk from authoritative sources during hurricane events. Because these images are now shared widely on social media platforms, Twitter provides the means to study them on a large scale as close to in vivo as possible. Using mixed methods, this study analyzes diffusion of and reactions to forecast and other risk imagery during the highly damaging 2017 Atlantic hurricane season to describe the collective response to visual representations of risk."
pn7135,https://doi.org/10.1145/3290605.3300392,Paragraph-based Faded Text Facilitates Reading Comprehension,1,Jumpei Kobayashi,"Dai Nippon Printing Co., Ltd.",Shinjuku,Japan,false,false,"We propose a new text layout that facilitates reading comprehension. By sequentially fading out characters sentence-by-sentence from the beginning of each paragraph, we highlight the paragraph structure of the entire text and the relative positions of the sentences. To evaluate the effectiveness of the paragraph-based faded text in a reading comprehension, we measure the comprehension, eye movements, and recognition for both the proposed method and a conventional standard method. In the proposed method, rates of correct answers to text comprehension questions are improved. Moreover, the proposed method leads to slower reading speeds and better recognition rates for the first sentences of paragraphs, which are displayed in a relatively thicker mode. With the paragraph-based faded text, the reader is naturally facilitated to pay attention to the first sentence of each paragraph, suggesting that this reading style could result in a more accurate text comprehension."
pn7135,https://doi.org/10.1145/3290605.3300392,Paragraph-based Faded Text Facilitates Reading Comprehension,2,Toshio Kawashima,Future University Hakodate,Hakodate,Japan,false,false,"We propose a new text layout that facilitates reading comprehension. By sequentially fading out characters sentence-by-sentence from the beginning of each paragraph, we highlight the paragraph structure of the entire text and the relative positions of the sentences. To evaluate the effectiveness of the paragraph-based faded text in a reading comprehension, we measure the comprehension, eye movements, and recognition for both the proposed method and a conventional standard method. In the proposed method, rates of correct answers to text comprehension questions are improved. Moreover, the proposed method leads to slower reading speeds and better recognition rates for the first sentences of paragraphs, which are displayed in a relatively thicker mode. With the paragraph-based faded text, the reader is naturally facilitated to pay attention to the first sentence of each paragraph, suggesting that this reading style could result in a more accurate text comprehension."
pn6431,https://doi.org/10.1145/3290605.3300415,Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence,1,Qian Yang,Carnegie Mellon University,Pittsburgh,United States,true,false,"This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications."
pn6431,https://doi.org/10.1145/3290605.3300415,Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence,2,Justin Cranshaw,Microsoft Research,Redmond,United States,true,false,"This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications."
pn6431,https://doi.org/10.1145/3290605.3300415,Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence,3,Saleema Amershi,Microsoft Research,Seattle,United States,true,false,"This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications."
pn6431,https://doi.org/10.1145/3290605.3300415,Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence,4,Shamsi Iqbal,Microsoft Research,Redmond,United States,true,false,"This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications."
pn6431,https://doi.org/10.1145/3290605.3300415,Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence,5,Jaime Teevan,Microsoft Research,Redmond,United States,true,false,"This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications."
pn5035,https://doi.org/10.1145/3290605.3300461,Multi-Modal Approaches for Post-Editing Machine Translation,1,Nico Herbig,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Current advances in machine translation increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and improves quality. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Our results of an elicitation study with professional translators indicate that a combination of pen, touch, and speech could well support common PE tasks, and received high subjective ratings by our participants. Therefore, we argue that future translation environment research should focus more strongly on these modalities in addition to mouse- and keyboard-based approaches. On the other hand, eye tracking and gesture modalities seem less important. An additional interview regarding interface design revealed that most translators would also see value in automatically receiving additional resources when a high cognitive load is detected during PE."
pn5035,https://doi.org/10.1145/3290605.3300461,Multi-Modal Approaches for Post-Editing Machine Translation,2,Santanu Pal,Saarland University,Saarbrücken,Germany,false,false,"Current advances in machine translation increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and improves quality. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Our results of an elicitation study with professional translators indicate that a combination of pen, touch, and speech could well support common PE tasks, and received high subjective ratings by our participants. Therefore, we argue that future translation environment research should focus more strongly on these modalities in addition to mouse- and keyboard-based approaches. On the other hand, eye tracking and gesture modalities seem less important. An additional interview regarding interface design revealed that most translators would also see value in automatically receiving additional resources when a high cognitive load is detected during PE."
pn5035,https://doi.org/10.1145/3290605.3300461,Multi-Modal Approaches for Post-Editing Machine Translation,3,Josef Van Genabith,Saarland University,Saarbrücken,Germany,false,false,"Current advances in machine translation increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and improves quality. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Our results of an elicitation study with professional translators indicate that a combination of pen, touch, and speech could well support common PE tasks, and received high subjective ratings by our participants. Therefore, we argue that future translation environment research should focus more strongly on these modalities in addition to mouse- and keyboard-based approaches. On the other hand, eye tracking and gesture modalities seem less important. An additional interview regarding interface design revealed that most translators would also see value in automatically receiving additional resources when a high cognitive load is detected during PE."
pn5035,https://doi.org/10.1145/3290605.3300461,Multi-Modal Approaches for Post-Editing Machine Translation,4,Antonio Krüger,"German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus",Saarbrücken,Germany,false,false,"Current advances in machine translation increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and improves quality. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Our results of an elicitation study with professional translators indicate that a combination of pen, touch, and speech could well support common PE tasks, and received high subjective ratings by our participants. Therefore, we argue that future translation environment research should focus more strongly on these modalities in addition to mouse- and keyboard-based approaches. On the other hand, eye tracking and gesture modalities seem less important. An additional interview regarding interface design revealed that most translators would also see value in automatically receiving additional resources when a high cognitive load is detected during PE."
pn9642,https://doi.org/10.1145/3290605.3300507,Cultivating Care through Ambiguity: Lessons from a Service Learning Course,1,Samar Sabie,Cornell University,New York,United States,false,false,"Given the focus of professional graduate ICT programs on technical and managerial skills, pedagogical engagement with external organizations tends to be transactional and artifact-centered. This inhibits the students' ability to understand social, technical and ethical issues in context, or to develop affective relationships with users and other stakeholders. To address this, we designed a service learning course that partnered students with non-profit organizations to help with their technology challenges. The service project was deliberately left open-ended to force students (and partners) to tackle important questions around project scoping and impact. By drawing parallels to soil care practices, we explore how ""care time"" emerged in this context, and how the incorporation of ambiguity galvanized students, community, and faculty to make time to navigate it. This led to non-tangible yet vital outcomes such as overcoming social limitations, building symbiotic relationships, and enacting acts of care necessary for more ethical orchestration of technology."
pn9642,https://doi.org/10.1145/3290605.3300507,Cultivating Care through Ambiguity: Lessons from a Service Learning Course,2,Tapan Parikh,Cornell University,New York,United States,false,false,"Given the focus of professional graduate ICT programs on technical and managerial skills, pedagogical engagement with external organizations tends to be transactional and artifact-centered. This inhibits the students' ability to understand social, technical and ethical issues in context, or to develop affective relationships with users and other stakeholders. To address this, we designed a service learning course that partnered students with non-profit organizations to help with their technology challenges. The service project was deliberately left open-ended to force students (and partners) to tackle important questions around project scoping and impact. By drawing parallels to soil care practices, we explore how ""care time"" emerged in this context, and how the incorporation of ambiguity galvanized students, community, and faculty to make time to navigate it. This led to non-tangible yet vital outcomes such as overcoming social limitations, building symbiotic relationships, and enacting acts of care necessary for more ethical orchestration of technology."
pn9641,https://doi.org/10.1145/3290605.3300305,Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning,1,Amanda Swearngin,University of Washington,Seattle,United States,false,false,"Tapping is an immensely important gesture in mobile touchscreen interfaces, yet people still frequently are required to learn which elements are tappable through trial and error. Predicting human behavior for this everyday gesture can help mobile app designers understand an important aspect of the usability of their apps without having to run a user study. In this paper, we present an approach for modeling tappability of mobile interfaces at scale. We conducted large-scale data collection of interface tappability over a rich set of mobile apps using crowdsourcing and computationally investigated a variety of signifiers that people use to distinguish tappable versus not-tappable elements. Based on the dataset, we developed and trained a deep neural network that predicts how likely a user will perceive an interface element as tappable versus not tappable. Using the trained tappability model, we developed TapShoe, a tool that automatically diagnoses mismatches between the tappability of each element as perceived by a human user---predicted by our model, and the intended or actual tappable state of the element specified by the developer or designer. Our model achieved reasonable accuracy: mean precision 90.2% and recall 87.0%, in matching human perception on identifying tappable UI elements. The tappability model and TapShoe were well received by designers via an informal evaluation with 7 professional interaction designers."
pn9641,https://doi.org/10.1145/3290605.3300305,Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning,2,Yang Li,Google Research,Mountain View,United States,false,false,"Tapping is an immensely important gesture in mobile touchscreen interfaces, yet people still frequently are required to learn which elements are tappable through trial and error. Predicting human behavior for this everyday gesture can help mobile app designers understand an important aspect of the usability of their apps without having to run a user study. In this paper, we present an approach for modeling tappability of mobile interfaces at scale. We conducted large-scale data collection of interface tappability over a rich set of mobile apps using crowdsourcing and computationally investigated a variety of signifiers that people use to distinguish tappable versus not-tappable elements. Based on the dataset, we developed and trained a deep neural network that predicts how likely a user will perceive an interface element as tappable versus not tappable. Using the trained tappability model, we developed TapShoe, a tool that automatically diagnoses mismatches between the tappability of each element as perceived by a human user---predicted by our model, and the intended or actual tappable state of the element specified by the developer or designer. Our model achieved reasonable accuracy: mean precision 90.2% and recall 87.0%, in matching human perception on identifying tappable UI elements. The tappability model and TapShoe were well received by designers via an informal evaluation with 7 professional interaction designers."
pn1999,https://doi.org/10.1145/3290605.3300301,TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction,1,Jaeyeon Lee,Microsoft Research,Daejeon,Republic Of Korea,false,false,"Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller."
pn1999,https://doi.org/10.1145/3290605.3300301,TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction,2,Mike Sinclair,Microsoft,Redmond,United States,false,false,"Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller."
pn1999,https://doi.org/10.1145/3290605.3300301,TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction,3,Mar Gonzalez-Franco,Microsoft Research,Redmond,United States,false,false,"Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller."
pn1999,https://doi.org/10.1145/3290605.3300301,TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction,4,Eyal Ofek,Microsoft Research,Redmond,United States,false,false,"Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller."
pn1999,https://doi.org/10.1145/3290605.3300301,TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction,5,Christian Holz,Microsoft Research,Redmond,United States,false,false,"Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,1,Rachel Jacobs,University of Nottingham,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,2,Holger Schnädelbach,University of Nottingham,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,3,Nils Jäger,University of Loughborough,Loughborough,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,4,Silvia Leal,Independent Creative,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,5,Robin Shackford,Independent Creative,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,6,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
pn3855,https://doi.org/10.1145/3290605.3300630,The Performative Mirror Space,7,Roma Patel,University of Nottingham,Nottingham,United Kingdom,false,false,"Interactive mirrors, typically combining semi-transparent mirrors, digital screens and interaction mechanisms have been developed for a variety of application areas. Drawing on existing techniques to create interactive mirror spaces, we investigated their performative qualities through artistic discovery and collaborative prototyping. We document a linked set of design explorations and two public, site-specific experiences that brought together artists, communities, and HCI researchers. We illustrate the abstracted interactive mirror space that practitioners in the performance art, theatre and museum sectors can work with. In turn, we also discuss six performative design strategies concerning the use of physical context, movement and narrative that HCI researchers who wish to deploy interactive mirrors in more mainstream settings need to consider."
jrnl1107,https://doi.org/10.1145/3290607.3313834,Design Guideline for Developing Safe Systems that Apply Electricity to the Human Body,1,Michinari Kono,The University of Tokyo,Bunkyo-Ku,Japan,false,false,"The human body has unique electrical characteristics. These characteristics have been investigated in various studies in human-computer interaction (HCI) and related research fields. Such studies include applications for using the body as a conductive lead for transmission or electric field sensing and activating human muscles or organs. However, electricity is not completely safe for the human body; therefore, to avoid harming users, careful consideration is essential when developing such devices. The knowledge required for such consideration is spread throughout a large number research fields, and it can be difficult for researchers in the HCI field to comprehend all of them. The purpose of this article is to support researchers in developing systems that apply electricity to the human body and to serve as a basis for further research. This article reviews previous research pertaining to HCI in which users come into contact with electricity. In addition, considerations of how and where this type of research can be expanded, along with guidelines grounded in other fields for designing systems safely and addressing ethical concerns, are presented. An understanding of the field and of the related safety issues will enhance the understanding of limitations and potential and can clarify the design space."
jrnl1107,https://doi.org/10.1145/3290607.3313834,Design Guideline for Developing Safe Systems that Apply Electricity to the Human Body,2,Takumi Takahashi,The University of Tokyo,Bunkyo-Ku,Japan,false,false,"The human body has unique electrical characteristics. These characteristics have been investigated in various studies in human-computer interaction (HCI) and related research fields. Such studies include applications for using the body as a conductive lead for transmission or electric field sensing and activating human muscles or organs. However, electricity is not completely safe for the human body; therefore, to avoid harming users, careful consideration is essential when developing such devices. The knowledge required for such consideration is spread throughout a large number research fields, and it can be difficult for researchers in the HCI field to comprehend all of them. The purpose of this article is to support researchers in developing systems that apply electricity to the human body and to serve as a basis for further research. This article reviews previous research pertaining to HCI in which users come into contact with electricity. In addition, considerations of how and where this type of research can be expanded, along with guidelines grounded in other fields for designing systems safely and addressing ethical concerns, are presented. An understanding of the field and of the related safety issues will enhance the understanding of limitations and potential and can clarify the design space."
jrnl1107,https://doi.org/10.1145/3290607.3313834,Design Guideline for Developing Safe Systems that Apply Electricity to the Human Body,3,Hiromi Nakamura,AIST,Tsukuba,Japan,false,false,"The human body has unique electrical characteristics. These characteristics have been investigated in various studies in human-computer interaction (HCI) and related research fields. Such studies include applications for using the body as a conductive lead for transmission or electric field sensing and activating human muscles or organs. However, electricity is not completely safe for the human body; therefore, to avoid harming users, careful consideration is essential when developing such devices. The knowledge required for such consideration is spread throughout a large number research fields, and it can be difficult for researchers in the HCI field to comprehend all of them. The purpose of this article is to support researchers in developing systems that apply electricity to the human body and to serve as a basis for further research. This article reviews previous research pertaining to HCI in which users come into contact with electricity. In addition, considerations of how and where this type of research can be expanded, along with guidelines grounded in other fields for designing systems safely and addressing ethical concerns, are presented. An understanding of the field and of the related safety issues will enhance the understanding of limitations and potential and can clarify the design space."
jrnl1107,https://doi.org/10.1145/3290607.3313834,Design Guideline for Developing Safe Systems that Apply Electricity to the Human Body,4,Takashi Miyaki,The University of Tokyo,Bunkyo-Ku,Japan,false,false,"The human body has unique electrical characteristics. These characteristics have been investigated in various studies in human-computer interaction (HCI) and related research fields. Such studies include applications for using the body as a conductive lead for transmission or electric field sensing and activating human muscles or organs. However, electricity is not completely safe for the human body; therefore, to avoid harming users, careful consideration is essential when developing such devices. The knowledge required for such consideration is spread throughout a large number research fields, and it can be difficult for researchers in the HCI field to comprehend all of them. The purpose of this article is to support researchers in developing systems that apply electricity to the human body and to serve as a basis for further research. This article reviews previous research pertaining to HCI in which users come into contact with electricity. In addition, considerations of how and where this type of research can be expanded, along with guidelines grounded in other fields for designing systems safely and addressing ethical concerns, are presented. An understanding of the field and of the related safety issues will enhance the understanding of limitations and potential and can clarify the design space."
jrnl1107,https://doi.org/10.1145/3290607.3313834,Design Guideline for Developing Safe Systems that Apply Electricity to the Human Body,5,Jun Rekimoto,Sony CSL,Shinagawa-Ku/Tokyo,Japan,false,false,"The human body has unique electrical characteristics. These characteristics have been investigated in various studies in human-computer interaction (HCI) and related research fields. Such studies include applications for using the body as a conductive lead for transmission or electric field sensing and activating human muscles or organs. However, electricity is not completely safe for the human body; therefore, to avoid harming users, careful consideration is essential when developing such devices. The knowledge required for such consideration is spread throughout a large number research fields, and it can be difficult for researchers in the HCI field to comprehend all of them. The purpose of this article is to support researchers in developing systems that apply electricity to the human body and to serve as a basis for further research. This article reviews previous research pertaining to HCI in which users come into contact with electricity. In addition, considerations of how and where this type of research can be expanded, along with guidelines grounded in other fields for designing systems safely and addressing ethical concerns, are presented. An understanding of the field and of the related safety issues will enhance the understanding of limitations and potential and can clarify the design space."
pn4991,https://doi.org/10.1145/3290605.3300537,Privacy and Security Considerations For Digital Technology Use in Elementary Schools,1,Priya Kumar,"University of Maryland, College Park",College Park,United States,false,false,"Elementary school educators increasingly use digital technologies to teach students, manage classrooms, and complete everyday tasks. Prior work has considered the educational and pedagogical implications of technology use, but little research has examined how educators consider privacy and security in relation to classroom technology use. To better understand what privacy and security mean to elementary school educators, we conducted nine focus groups with 25 educators across three metropolitan regions in the northeast U.S. Our findings suggest that technology use is an integral part of elementary school classrooms, that educators consider digital privacy and security through the lens of curricular and classroom management goals, and that lessons to teach children about digital privacy and security are rare. Using Bronfenbrenner's ecological systems theory, we identify design opportunities to help educators integrate privacy and security into decisions about digital technology use and to help children learn about digital privacy and security."
pn4991,https://doi.org/10.1145/3290605.3300537,Privacy and Security Considerations For Digital Technology Use in Elementary Schools,2,Marshini Chetty,Princeton University,Princeton,United States,false,false,"Elementary school educators increasingly use digital technologies to teach students, manage classrooms, and complete everyday tasks. Prior work has considered the educational and pedagogical implications of technology use, but little research has examined how educators consider privacy and security in relation to classroom technology use. To better understand what privacy and security mean to elementary school educators, we conducted nine focus groups with 25 educators across three metropolitan regions in the northeast U.S. Our findings suggest that technology use is an integral part of elementary school classrooms, that educators consider digital privacy and security through the lens of curricular and classroom management goals, and that lessons to teach children about digital privacy and security are rare. Using Bronfenbrenner's ecological systems theory, we identify design opportunities to help educators integrate privacy and security into decisions about digital technology use and to help children learn about digital privacy and security."
pn4991,https://doi.org/10.1145/3290605.3300537,Privacy and Security Considerations For Digital Technology Use in Elementary Schools,3,Tamara Clegg,"University of Maryland, College Park",College Park,United States,false,false,"Elementary school educators increasingly use digital technologies to teach students, manage classrooms, and complete everyday tasks. Prior work has considered the educational and pedagogical implications of technology use, but little research has examined how educators consider privacy and security in relation to classroom technology use. To better understand what privacy and security mean to elementary school educators, we conducted nine focus groups with 25 educators across three metropolitan regions in the northeast U.S. Our findings suggest that technology use is an integral part of elementary school classrooms, that educators consider digital privacy and security through the lens of curricular and classroom management goals, and that lessons to teach children about digital privacy and security are rare. Using Bronfenbrenner's ecological systems theory, we identify design opportunities to help educators integrate privacy and security into decisions about digital technology use and to help children learn about digital privacy and security."
pn4991,https://doi.org/10.1145/3290605.3300537,Privacy and Security Considerations For Digital Technology Use in Elementary Schools,4,Jessica Vitak,"University of Maryland, College Park",College Park,United States,false,false,"Elementary school educators increasingly use digital technologies to teach students, manage classrooms, and complete everyday tasks. Prior work has considered the educational and pedagogical implications of technology use, but little research has examined how educators consider privacy and security in relation to classroom technology use. To better understand what privacy and security mean to elementary school educators, we conducted nine focus groups with 25 educators across three metropolitan regions in the northeast U.S. Our findings suggest that technology use is an integral part of elementary school classrooms, that educators consider digital privacy and security through the lens of curricular and classroom management goals, and that lessons to teach children about digital privacy and security are rare. Using Bronfenbrenner's ecological systems theory, we identify design opportunities to help educators integrate privacy and security into decisions about digital technology use and to help children learn about digital privacy and security."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,1,Meng Xia,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,2,Mingfei Sun,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,3,Huan Wei,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,4,Qing Chen,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,5,Yong Wang,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,6,Lei Shi,Beihang University,Beijing,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,7,Huamin Qu,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn5418,https://doi.org/10.1145/3290605.3300864,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,8,Xiaojuan Ma,The Hong Kong University of Science and Technology,Hong Kong,China,false,false,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive."
pn6862,https://doi.org/10.1145/3290605.3300238,Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies,1,Alexis Hiniker,University of Washington,Seattle,United States,false,true,"Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during field deployments with young children. AAS offers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defined by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application."
pn6862,https://doi.org/10.1145/3290605.3300238,Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies,2,Jon Froehlich,University of Washington,Seattle,United States,false,true,"Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during field deployments with young children. AAS offers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defined by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application."
pn6862,https://doi.org/10.1145/3290605.3300238,Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies,3,Mingrui Zhang,University of Washington,Seattle,United States,false,true,"Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during field deployments with young children. AAS offers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defined by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application."
pn6862,https://doi.org/10.1145/3290605.3300238,Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies,4,Erin Beneteau,University of Washington,Seattle,United States,false,true,"Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during field deployments with young children. AAS offers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defined by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application."
pn7444,https://doi.org/10.1145/3290605.3300608,Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,1,Oussama Metatla,University of Bristol,Bristol,United Kingdom,false,true,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space."
pn7444,https://doi.org/10.1145/3290605.3300608,Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,2,Alison Oldfield,University of Bristol,Bristol,United Kingdom,false,true,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space."
pn7444,https://doi.org/10.1145/3290605.3300608,Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,3,Taimur Ahmed,University of Bristol,Bristol,United Kingdom,false,true,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space."
pn7444,https://doi.org/10.1145/3290605.3300608,Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,4,Antonis Vafeas,University of Bristol,Bristol,United Kingdom,false,true,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space."
pn7444,https://doi.org/10.1145/3290605.3300608,Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,5,Sunny Miglani,University of Bristol,Bristol,United Kingdom,false,true,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space."
pn5810,https://doi.org/10.1145/3290605.3300569,Human-Computer Insurrection: Notes on an Anarchist HCI,1,Os Keyes,University of Washington,Seattle,United States,false,false,"The HCI community has worked to expand and improve our consideration of the societal implications of our work and our corresponding responsibilities. Despite this increased engagement, HCI continues to lack an explicitly articulated politic, which we argue re-inscribes and amplifies systemic oppression. In this paper, we set out an explicit political vision of an HCI grounded in emancipatory autonomy—an anarchist HCI, aimed at dismantling all oppressive systems by mandating suspicion of and a reckoning with imbalanced distributions of power. We outline some of the principles and accountability mechanisms that constitute an anarchist HCI. We offer a potential framework for radically reorienting the field towards creating prefigurative counterpower—systems and spaces that exemplify the world we wish to see, as we go about building the revolution in increment."
pn5810,https://doi.org/10.1145/3290605.3300569,Human-Computer Insurrection: Notes on an Anarchist HCI,2,Josephine Hoy,University of Washington,Seattle,United States,false,false,"The HCI community has worked to expand and improve our consideration of the societal implications of our work and our corresponding responsibilities. Despite this increased engagement, HCI continues to lack an explicitly articulated politic, which we argue re-inscribes and amplifies systemic oppression. In this paper, we set out an explicit political vision of an HCI grounded in emancipatory autonomy—an anarchist HCI, aimed at dismantling all oppressive systems by mandating suspicion of and a reckoning with imbalanced distributions of power. We outline some of the principles and accountability mechanisms that constitute an anarchist HCI. We offer a potential framework for radically reorienting the field towards creating prefigurative counterpower—systems and spaces that exemplify the world we wish to see, as we go about building the revolution in increment."
pn5810,https://doi.org/10.1145/3290605.3300569,Human-Computer Insurrection: Notes on an Anarchist HCI,3,Margaret Drouhard,University of Washington,Seattle,United States,false,false,"The HCI community has worked to expand and improve our consideration of the societal implications of our work and our corresponding responsibilities. Despite this increased engagement, HCI continues to lack an explicitly articulated politic, which we argue re-inscribes and amplifies systemic oppression. In this paper, we set out an explicit political vision of an HCI grounded in emancipatory autonomy—an anarchist HCI, aimed at dismantling all oppressive systems by mandating suspicion of and a reckoning with imbalanced distributions of power. We outline some of the principles and accountability mechanisms that constitute an anarchist HCI. We offer a potential framework for radically reorienting the field towards creating prefigurative counterpower—systems and spaces that exemplify the world we wish to see, as we go about building the revolution in increment."
jrnl1116,https://doi.org/10.1145/3290607.3313841,Getting There: Barriers and Facilitators to Transportation Access in Underserved Communities,1,Tawanna Dillahunt,University of Michigan,Ann Arbor,United States,false,false,"Advances in Information and Communication Technologies (ICTs) offer new opportunities for addressing transportation needs; however, past research suggests that opportunities are not equally shared by millions of low-income Americans. We draw from four empirical studies and two case studies to contribute descriptions of the 11 everyday transportation models currently used by residents of low-income and underserved communities to enhance their access to health-enhancing resources. These models fell into personal, private, public, and interpersonal categories. We contribute insights regarding the following barriers and facilitators associated with these models: (1) affordability; (2) individual capabilities; (3) interpersonal trust, care and/or reciprocity; (4) trust in technology; (5) service availability/eligibility; (6) spatial and temporal matches; (7) match between transportation mode and physical needs; (8) service reliability and quality; and (9) infrastructure access. To address these barriers and build on these facilitators, we contribute six supportive policy and design principles. Operationalizing these principles, we propose four new ICT-enhanced models: (1) smart jitneys; (2) generalized, favor based models; (3) expanded resource pooling; and (4) transportation clubs. The focus of these models on socio-technical integration with current capabilities and resources holds promise for enhancing access to jobs, food, and health care for residents of low-income communities."
jrnl1116,https://doi.org/10.1145/3290607.3313841,Getting There: Barriers and Facilitators to Transportation Access in Underserved Communities,2,Tiffany Veinot,University of Michigan,Ann Arbor,United States,false,false,"Advances in Information and Communication Technologies (ICTs) offer new opportunities for addressing transportation needs; however, past research suggests that opportunities are not equally shared by millions of low-income Americans. We draw from four empirical studies and two case studies to contribute descriptions of the 11 everyday transportation models currently used by residents of low-income and underserved communities to enhance their access to health-enhancing resources. These models fell into personal, private, public, and interpersonal categories. We contribute insights regarding the following barriers and facilitators associated with these models: (1) affordability; (2) individual capabilities; (3) interpersonal trust, care and/or reciprocity; (4) trust in technology; (5) service availability/eligibility; (6) spatial and temporal matches; (7) match between transportation mode and physical needs; (8) service reliability and quality; and (9) infrastructure access. To address these barriers and build on these facilitators, we contribute six supportive policy and design principles. Operationalizing these principles, we propose four new ICT-enhanced models: (1) smart jitneys; (2) generalized, favor based models; (3) expanded resource pooling; and (4) transportation clubs. The focus of these models on socio-technical integration with current capabilities and resources holds promise for enhancing access to jobs, food, and health care for residents of low-income communities."
jrnl1120,https://doi.org/10.1145/3290607.3313844,Infrastructural Inaccessibility: Tech Entrepreneurs in Occupied Palestine,1,Pernille Bjørn,University of Copenhagen,Seattle,United States,false,false,"In this article, we examine the fundamental and taken-for-granted infrastructures that make tech entrepreneurship possible. We report from a longitudinal ethnographic study of tech entrepreneurs situated in occupied Palestine. By investigating this polar case of tech entrepreneurship, we identify critical infrastructures that are otherwise invisible and go unnoticed. We propose infrastructural accessibility as a method to identify available and absent infrastructures in concrete trans-local situations. Infrastructural accessibility leads us to identify multiple dimensions of critical infrastructures necessary for the success of tech startups. This includes infrastructures related to location, community, funding, digital platforms, politics, and history. Our study shows how these multiple dimensions of infrastructural accessibility shape the everyday practices of tech entrepreneurs. Furthermore, our study reveals how Palestinian tech entrepreneurship is characterized by infrastructural inaccessibility due to missing infrastructures related to mobility, legal frameworks, payment gateways, and mobile Internet. Infrastructural inaccessibility seriously limits tech entrepreneurs' potential to succeed in creating a long-term sustainable tech industry."
jrnl1120,https://doi.org/10.1145/3290607.3313844,Infrastructural Inaccessibility: Tech Entrepreneurs in Occupied Palestine,2,Nina Boulus-Rodje,Roskilde University,Roskilde,Denmark,false,false,"In this article, we examine the fundamental and taken-for-granted infrastructures that make tech entrepreneurship possible. We report from a longitudinal ethnographic study of tech entrepreneurs situated in occupied Palestine. By investigating this polar case of tech entrepreneurship, we identify critical infrastructures that are otherwise invisible and go unnoticed. We propose infrastructural accessibility as a method to identify available and absent infrastructures in concrete trans-local situations. Infrastructural accessibility leads us to identify multiple dimensions of critical infrastructures necessary for the success of tech startups. This includes infrastructures related to location, community, funding, digital platforms, politics, and history. Our study shows how these multiple dimensions of infrastructural accessibility shape the everyday practices of tech entrepreneurs. Furthermore, our study reveals how Palestinian tech entrepreneurship is characterized by infrastructural inaccessibility due to missing infrastructures related to mobility, legal frameworks, payment gateways, and mobile Internet. Infrastructural inaccessibility seriously limits tech entrepreneurs' potential to succeed in creating a long-term sustainable tech industry."
jrnl1140,https://doi.org/10.1145/3290607.3313855,Fast and Precise Touch-Based Text Entry for Head-Mounted Augmented Reality with Variable Occlusion,1,John Dudley,University of Cambridge,Cambridge,United Kingdom,false,false,"We present the VISAR keyboard: an augmented reality (AR) head-mounted display (HMD) system that supports text entry via a virtualised input surface. Users select keys on the virtual keyboard by imitating the process of single-hand typing on a physical touchscreen display. Our system uses a statistical decoder to infer users' intended text and to provide error-tolerant predictions. There is also a high-precision fall-back mechanism to support users in indicating which keys should be unmodified by the auto-correction process. A unique advantage of leveraging the well-established touch input paradigm is that our system enables text entry with minimal visual clutter on the see-through display, thus preserving the user's field-of-view. We iteratively designed and evaluated our system and show that the final iteration of the system supports a mean entry rate of 17.75 wpm with a mean character error rate less than 1%. This performance represents a 19.6% improvement relative to the state-of-the-art baseline investigated: a gaze-then-gesture text entry technique derived from the system keyboard on the Microsoft HoloLens. Finally, we validate that the system is effective in supporting text entry in a fully mobile usage scenario likely to be encountered in industrial applications of AR HMDs."
jrnl1140,https://doi.org/10.1145/3290607.3313855,Fast and Precise Touch-Based Text Entry for Head-Mounted Augmented Reality with Variable Occlusion,2,Keith Vertanen,Michigan Technological University,Houghton,United States,false,false,"We present the VISAR keyboard: an augmented reality (AR) head-mounted display (HMD) system that supports text entry via a virtualised input surface. Users select keys on the virtual keyboard by imitating the process of single-hand typing on a physical touchscreen display. Our system uses a statistical decoder to infer users' intended text and to provide error-tolerant predictions. There is also a high-precision fall-back mechanism to support users in indicating which keys should be unmodified by the auto-correction process. A unique advantage of leveraging the well-established touch input paradigm is that our system enables text entry with minimal visual clutter on the see-through display, thus preserving the user's field-of-view. We iteratively designed and evaluated our system and show that the final iteration of the system supports a mean entry rate of 17.75 wpm with a mean character error rate less than 1%. This performance represents a 19.6% improvement relative to the state-of-the-art baseline investigated: a gaze-then-gesture text entry technique derived from the system keyboard on the Microsoft HoloLens. Finally, we validate that the system is effective in supporting text entry in a fully mobile usage scenario likely to be encountered in industrial applications of AR HMDs."
jrnl1140,https://doi.org/10.1145/3290607.3313855,Fast and Precise Touch-Based Text Entry for Head-Mounted Augmented Reality with Variable Occlusion,3,Per Ola Kristensson,University of Cambridge,Cambridge,United Kingdom,false,false,"We present the VISAR keyboard: an augmented reality (AR) head-mounted display (HMD) system that supports text entry via a virtualised input surface. Users select keys on the virtual keyboard by imitating the process of single-hand typing on a physical touchscreen display. Our system uses a statistical decoder to infer users' intended text and to provide error-tolerant predictions. There is also a high-precision fall-back mechanism to support users in indicating which keys should be unmodified by the auto-correction process. A unique advantage of leveraging the well-established touch input paradigm is that our system enables text entry with minimal visual clutter on the see-through display, thus preserving the user's field-of-view. We iteratively designed and evaluated our system and show that the final iteration of the system supports a mean entry rate of 17.75 wpm with a mean character error rate less than 1%. This performance represents a 19.6% improvement relative to the state-of-the-art baseline investigated: a gaze-then-gesture text entry technique derived from the system keyboard on the Microsoft HoloLens. Finally, we validate that the system is effective in supporting text entry in a fully mobile usage scenario likely to be encountered in industrial applications of AR HMDs."
jrnl1129,https://doi.org/10.1145/3290607.3313850,BotMap: Non-Visual Panning and Zooming with an Actuated Tabletop Tangible Interface,1,Julie Ducasse,CNRS,Toulouse,France,false,false,"The development of novel shape-changing or actuated tabletop tangible interfaces opens new perspectives for the design of physical and dynamic maps, especially for visually impaired (VI) users. Such maps would allow non-visual haptic exploration with advanced functions, such as panning and zooming. In this study, we designed an actuated tangible tabletop interface, called BotMap, allowing the exploration of geographic data through non-visual panning and zooming. In BotMap, small robots represent landmarks and move to their correct position whenever the map is refreshed. Users can interact with the robots to retrieve the names of the landmarks they represent. We designed two interfaces, named Keyboard and Sliders, which enable users to pan and zoom. Two evaluations were conducted with, respectively, ten blindfolded and eight VI participants. Results show that both interfaces were usable, with a slight advantage for the Keyboard interface in terms of navigation performance and map comprehension, and that, even when many panning and zooming operations were required, VI participants were able to understand the maps. Most participants managed to accurately reconstruct maps after exploration. Finally, we observed three VI people using the system and performing a classical task consisting in finding the more appropriate itinerary for a journey."
jrnl1129,https://doi.org/10.1145/3290607.3313850,BotMap: Non-Visual Panning and Zooming with an Actuated Tabletop Tangible Interface,2,Marc Macé,CNRS,Toulouse,France,false,false,"The development of novel shape-changing or actuated tabletop tangible interfaces opens new perspectives for the design of physical and dynamic maps, especially for visually impaired (VI) users. Such maps would allow non-visual haptic exploration with advanced functions, such as panning and zooming. In this study, we designed an actuated tangible tabletop interface, called BotMap, allowing the exploration of geographic data through non-visual panning and zooming. In BotMap, small robots represent landmarks and move to their correct position whenever the map is refreshed. Users can interact with the robots to retrieve the names of the landmarks they represent. We designed two interfaces, named Keyboard and Sliders, which enable users to pan and zoom. Two evaluations were conducted with, respectively, ten blindfolded and eight VI participants. Results show that both interfaces were usable, with a slight advantage for the Keyboard interface in terms of navigation performance and map comprehension, and that, even when many panning and zooming operations were required, VI participants were able to understand the maps. Most participants managed to accurately reconstruct maps after exploration. Finally, we observed three VI people using the system and performing a classical task consisting in finding the more appropriate itinerary for a journey."
jrnl1129,https://doi.org/10.1145/3290607.3313850,BotMap: Non-Visual Panning and Zooming with an Actuated Tabletop Tangible Interface,3,Bernard Oriola,CNRS,Toulouse,France,false,false,"The development of novel shape-changing or actuated tabletop tangible interfaces opens new perspectives for the design of physical and dynamic maps, especially for visually impaired (VI) users. Such maps would allow non-visual haptic exploration with advanced functions, such as panning and zooming. In this study, we designed an actuated tangible tabletop interface, called BotMap, allowing the exploration of geographic data through non-visual panning and zooming. In BotMap, small robots represent landmarks and move to their correct position whenever the map is refreshed. Users can interact with the robots to retrieve the names of the landmarks they represent. We designed two interfaces, named Keyboard and Sliders, which enable users to pan and zoom. Two evaluations were conducted with, respectively, ten blindfolded and eight VI participants. Results show that both interfaces were usable, with a slight advantage for the Keyboard interface in terms of navigation performance and map comprehension, and that, even when many panning and zooming operations were required, VI participants were able to understand the maps. Most participants managed to accurately reconstruct maps after exploration. Finally, we observed three VI people using the system and performing a classical task consisting in finding the more appropriate itinerary for a journey."
jrnl1129,https://doi.org/10.1145/3290607.3313850,BotMap: Non-Visual Panning and Zooming with an Actuated Tabletop Tangible Interface,4,Christophe Jouffrais,CNRS,Toulouse,France,false,false,"The development of novel shape-changing or actuated tabletop tangible interfaces opens new perspectives for the design of physical and dynamic maps, especially for visually impaired (VI) users. Such maps would allow non-visual haptic exploration with advanced functions, such as panning and zooming. In this study, we designed an actuated tangible tabletop interface, called BotMap, allowing the exploration of geographic data through non-visual panning and zooming. In BotMap, small robots represent landmarks and move to their correct position whenever the map is refreshed. Users can interact with the robots to retrieve the names of the landmarks they represent. We designed two interfaces, named Keyboard and Sliders, which enable users to pan and zoom. Two evaluations were conducted with, respectively, ten blindfolded and eight VI participants. Results show that both interfaces were usable, with a slight advantage for the Keyboard interface in terms of navigation performance and map comprehension, and that, even when many panning and zooming operations were required, VI participants were able to understand the maps. Most participants managed to accurately reconstruct maps after exploration. Finally, we observed three VI people using the system and performing a classical task consisting in finding the more appropriate itinerary for a journey."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,1,Long Sha,Queensland University of Technology,Chicago,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,2,Patrick Lucey,STATS LLC,Chicago,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,3,Yisong Yue,California Institute of Technology,Pasadena,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,4,Xinyu Wei,STATS LLC,Chicago,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,5,Jennifer Hobbs,STATS,Chicago,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,6,Charlie Rohlf,STATS LLC,Chicago,United States,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1124,https://doi.org/10.1145/3290607.3313846,Interactive Sports Analytics: An Intelligent Interface for Utilizing Trajectories for Interactive Sports Play Retrieval and Analytics,7,Sridha Sridharan,Queensland University of Technology,Brisbane,Australia,false,false,"Analytics in professional sports has experienced a dramatic growth in the last decade due to the wide deployment of player and ball tracking systems in team sports, such as basketball and soccer. With the massive amount of fine-grained data being generated, new data-points are being generated, which can shed light on player and team performance. However, due to the complexity of plays in continuous sports, these data-points often lack the specificity and context to enable meaningful retrieval and analytics. In this article, we present an intelligent human--computer interface that utilizes trajectories instead of words, which enables specific play retrieval in sports. Various techniques of alignment, templating, and hashing were utilized by our system and they are tailored to multi-agent scenario so that interactive speeds can be achieved. We conduct a user study to compare our method to the conventional keywords-based system and the results show that our method significantly improves the retrieval quality. We also show how our interface can be utilized for broadcast purposes, where a user can draw and interact with trajectories on a broadcast view using computer vision techniques. Additionally, we show that our method can also be used for interactive analytics of player performance, which enables the users to move players around and see how performance changes as a function of position and proximity to other players."
jrnl1112,https://doi.org/10.1145/3290607.3313839,Personal Mobile Messaging in Context: Chat Augmentations for Expressiveness and Awareness,1,Daniel Buschek,LMU Munich,Munich,Germany,false,false,"Mobile text messaging is one of the most important communication channels today, but it suffers from lack of expressiveness, context and emotional awareness, compared to face-to-face communication. We address this problem by augmenting text messaging with information about users and contexts. We present and reflect on lessons learned from three field studies, in which we deployed augmentation concepts as prototype chat apps in users' daily lives. We studied (1) subtly conveying context via dynamic font personalisation (TapScript), (2) integrating and sharing physiological data - namely heart rate -–implicitly or explicitly (HeartChat) and (3) automatic annotation of various context cues: music, distance, weather and activities (ContextChat). Based on our studies, we discuss chat augmentation with respect to privacy concerns, understandability, connectedness and inferring context in addition to methodological lessons learned. Finally, we propose a design space for chat augmentation to guide future research, and conclude with practical design implications."
jrnl1112,https://doi.org/10.1145/3290607.3313839,Personal Mobile Messaging in Context: Chat Augmentations for Expressiveness and Awareness,2,Mariam Hassib,Group for Media Informatics,Munich,Germany,false,false,"Mobile text messaging is one of the most important communication channels today, but it suffers from lack of expressiveness, context and emotional awareness, compared to face-to-face communication. We address this problem by augmenting text messaging with information about users and contexts. We present and reflect on lessons learned from three field studies, in which we deployed augmentation concepts as prototype chat apps in users' daily lives. We studied (1) subtly conveying context via dynamic font personalisation (TapScript), (2) integrating and sharing physiological data - namely heart rate -–implicitly or explicitly (HeartChat) and (3) automatic annotation of various context cues: music, distance, weather and activities (ContextChat). Based on our studies, we discuss chat augmentation with respect to privacy concerns, understandability, connectedness and inferring context in addition to methodological lessons learned. Finally, we propose a design space for chat augmentation to guide future research, and conclude with practical design implications."
jrnl1112,https://doi.org/10.1145/3290607.3313839,Personal Mobile Messaging in Context: Chat Augmentations for Expressiveness and Awareness,3,Florian Alt,Bundeswehr University Munich,Munich,Germany,false,false,"Mobile text messaging is one of the most important communication channels today, but it suffers from lack of expressiveness, context and emotional awareness, compared to face-to-face communication. We address this problem by augmenting text messaging with information about users and contexts. We present and reflect on lessons learned from three field studies, in which we deployed augmentation concepts as prototype chat apps in users' daily lives. We studied (1) subtly conveying context via dynamic font personalisation (TapScript), (2) integrating and sharing physiological data - namely heart rate -–implicitly or explicitly (HeartChat) and (3) automatic annotation of various context cues: music, distance, weather and activities (ContextChat). Based on our studies, we discuss chat augmentation with respect to privacy concerns, understandability, connectedness and inferring context in addition to methodological lessons learned. Finally, we propose a design space for chat augmentation to guide future research, and conclude with practical design implications."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,1,Ken Pfeuffer,Bundeswehr University Munich,Munich,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,2,Matthias Geiger,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,3,Sarah Prange,Munich University of Applied Sciences,München,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,4,Lukas Mecke,University of Applied Sciences Munich,Munich,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,5,Daniel Buschek,Ludwig Maximilian University of Munich,Munich,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn7792,https://doi.org/10.1145/3290605.3300340,Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality,6,Florian Alt,Bundeswehr University Munich,Munich,Germany,false,false,"Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations where multiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users' preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality."
pn1543,https://doi.org/10.1145/3290605.3300454,The Dissimilarity-Consensus Approach to Agreement Analysis in Gesture Elicitation Studies,1,Radu-Daniel Vatavu,University Ştefan cel Mare of Suceava,Suceava,Romania,false,false,"We introduce the dissimilarity-consensus method, a new approach to computing objective measures of consensus between users' gesture preferences to support data analysis in end-user gesture elicitation studies. Our method models and quantifies the relationship between users' consensus over gesture articulation and numerical measures of gesture dissimilarity, e.g., Dynamic Time Warping or Hausdorff distances, by employing growth curves and logistic functions. We exemplify our method on 1,312 whole-body gestures elicited from 30 children, ages 3 to 6 years, and we report the first empirical results in the literature on the consensus between whole-body gestures produced by children this young. We provide C# and R software implementations of our method and make our gesture dataset publicly available."
pn7738,https://doi.org/10.1145/3290605.3300708,Only one item left? Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control,1,Daniel Reinhardt,Julius-Maximilians-Universität,Würzburg,Germany,false,false,"Pursuing the goal of a healthy diet may be challenging, especially when self-control resources are low. Yet many persuasive user interfaces fostering healthy choices are designed for situations with ample self-control, e.g. showing nutritional information to support reflective decision making. In this paper we propose that under low self-control, persuasive user interfaces need to rely on simple heuristic decision making to be successful. We report an experiment that tested this assumption in a 2 (low vs. high self-control) x 2 (calorie vs. heuristic information) design. The results reveal a significant interaction effect. Participants with low self-control resources chose the healthy snack more often when snacks were labelled with heuristic information than when they were labelled with calorie information. Both strategies were about equally successful for participants with high self-control. Exploiting situations of low self-control with heuristic information is a new and promising approach to designing persuasive technology for healthy eating."
pn7738,https://doi.org/10.1145/3290605.3300708,Only one item left? Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control,2,Jörn Hurtienne,Julius-Maximilians-Universität,Würzburg,Germany,false,false,"Pursuing the goal of a healthy diet may be challenging, especially when self-control resources are low. Yet many persuasive user interfaces fostering healthy choices are designed for situations with ample self-control, e.g. showing nutritional information to support reflective decision making. In this paper we propose that under low self-control, persuasive user interfaces need to rely on simple heuristic decision making to be successful. We report an experiment that tested this assumption in a 2 (low vs. high self-control) x 2 (calorie vs. heuristic information) design. The results reveal a significant interaction effect. Participants with low self-control resources chose the healthy snack more often when snacks were labelled with heuristic information than when they were labelled with calorie information. Both strategies were about equally successful for participants with high self-control. Exploiting situations of low self-control with heuristic information is a new and promising approach to designing persuasive technology for healthy eating."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,1,Benjamin Tag,Keio University,Yokohama,Japan,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,2,Andrew Vargo,The Kyoto College of Graduate Studies for Informatics,Kyoto,Japan,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,3,Aman Gupta,Keio University,Yokohama,Japan,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,4,George Chernyshov,Keio University,Yokohama,Japan,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,5,Kai Kunze,Keio University,Yokohama,Japan,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn6477,https://doi.org/10.1145/3290605.3300694,Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild,6,Tilman Dingler,University of Melbourne,Melbourne,Australia,false,false,"As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day."
pn5203,https://doi.org/10.1145/3290605.3300231,A Translational Science Model for HCI,1,Lucas Colusso,University of Washington,Seattle,United States,false,true,"Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice."
pn5203,https://doi.org/10.1145/3290605.3300231,A Translational Science Model for HCI,2,Ridley Jones,University of Washington,Seattle,United States,false,true,"Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice."
pn5203,https://doi.org/10.1145/3290605.3300231,A Translational Science Model for HCI,3,Sean Munson,University of Washington,Seattle,United States,false,true,"Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice."
pn5203,https://doi.org/10.1145/3290605.3300231,A Translational Science Model for HCI,4,Gary Hsieh,University of Washington,Seattle,United States,false,true,"Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,1,Julia Himmelsbach,AIT Austrian Institute of Technology GmbH,Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,2,Stephanie Schwarz,AIT Austrian Institute of Technology GmbH,Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,3,Cornelia Gerdenitsch,AIT Austrian Institute of Technology GmbH,Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,4,Beatrix Wais-Zechmann,AIT Austrian Institute of Technology GmbH,Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,5,Jan Bobeth,AIT Austrian Institute of Technology GmbH,Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn5759,https://doi.org/10.1145/3290605.3300720,Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research,6,Manfred Tscheligi,University of Salzburg,Salzburg & Vienna,Austria,false,false,"In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI."
pn4934,https://doi.org/10.1145/3290605.3300648,Charting Subtle Interaction in the HCI Literature,1,Henning Pohl,University of Copenhagen,Copenhagen,Denmark,true,false,"Human-computer interaction is replete with ways of talking about qualities of interaction or interfaces, including if they are expressive, rich, fluid, or playful. An example of such a quality is subtle. While this word is frequently used in the literature, we lack a coherent account of what it means to be subtle, how to achieve subtleness in an interface, and what theoretical backing subtleness has. To create such an account, we analyze a sample of 55 publications that use the word subtle. We describe the variants of subtle interaction in the literature, including claimed benefits, empirical approaches, and ethical considerations. Not only does this create a basis for thinking about subtleness as a quality of interaction, it also works to show how to solidify varieties of quality in HCI. We conclude by outlining some open empirical and conceptual questions about subtleness."
pn4934,https://doi.org/10.1145/3290605.3300648,Charting Subtle Interaction in the HCI Literature,2,Andreea Muresan,University of Copenhagen,Copenhagen,Denmark,true,false,"Human-computer interaction is replete with ways of talking about qualities of interaction or interfaces, including if they are expressive, rich, fluid, or playful. An example of such a quality is subtle. While this word is frequently used in the literature, we lack a coherent account of what it means to be subtle, how to achieve subtleness in an interface, and what theoretical backing subtleness has. To create such an account, we analyze a sample of 55 publications that use the word subtle. We describe the variants of subtle interaction in the literature, including claimed benefits, empirical approaches, and ethical considerations. Not only does this create a basis for thinking about subtleness as a quality of interaction, it also works to show how to solidify varieties of quality in HCI. We conclude by outlining some open empirical and conceptual questions about subtleness."
pn4934,https://doi.org/10.1145/3290605.3300648,Charting Subtle Interaction in the HCI Literature,3,Kasper Hornbæk,University of Copenhagen,Copenhagen,Denmark,true,false,"Human-computer interaction is replete with ways of talking about qualities of interaction or interfaces, including if they are expressive, rich, fluid, or playful. An example of such a quality is subtle. While this word is frequently used in the literature, we lack a coherent account of what it means to be subtle, how to achieve subtleness in an interface, and what theoretical backing subtleness has. To create such an account, we analyze a sample of 55 publications that use the word subtle. We describe the variants of subtle interaction in the literature, including claimed benefits, empirical approaches, and ethical considerations. Not only does this create a basis for thinking about subtleness as a quality of interaction, it also works to show how to solidify varieties of quality in HCI. We conclude by outlining some open empirical and conceptual questions about subtleness."
pn6602,https://doi.org/10.1145/3290605.3300538,Relations are more than Bytes: Re-thinking the Benefits of Smart Services through People and Things,1,Claude Heath,"Royal Holloway, University of London",London,United Kingdom,false,false,"Critical approaches to smart technologies have emerged in HCI that question the conditions necessary for smart technologies to benefit people. Smart services rely on a relation of trust and sense of security between people and technology requiring a more expansive definition of security. Using established design methods, we worked with two residents' groups to critically explore and rethink smart services in the home and city. From our data analysis, we derive insights about perceptions and understandings of trust, privacy and security of smart devices, and identify how technological security needs to work in concert with social and relational forms of security for smart services to be effective. We conclude with an orientation for HCI that focuses on designing services for and with smart people and things."
pn6602,https://doi.org/10.1145/3290605.3300538,Relations are more than Bytes: Re-thinking the Benefits of Smart Services through People and Things,2,Clara Crivellaro,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Critical approaches to smart technologies have emerged in HCI that question the conditions necessary for smart technologies to benefit people. Smart services rely on a relation of trust and sense of security between people and technology requiring a more expansive definition of security. Using established design methods, we worked with two residents' groups to critically explore and rethink smart services in the home and city. From our data analysis, we derive insights about perceptions and understandings of trust, privacy and security of smart devices, and identify how technological security needs to work in concert with social and relational forms of security for smart services to be effective. We conclude with an orientation for HCI that focuses on designing services for and with smart people and things."
pn6602,https://doi.org/10.1145/3290605.3300538,Relations are more than Bytes: Re-thinking the Benefits of Smart Services through People and Things,3,Lizzie Coles-Kemp,"Royal Holloway, University of London",London,United Kingdom,false,false,"Critical approaches to smart technologies have emerged in HCI that question the conditions necessary for smart technologies to benefit people. Smart services rely on a relation of trust and sense of security between people and technology requiring a more expansive definition of security. Using established design methods, we worked with two residents' groups to critically explore and rethink smart services in the home and city. From our data analysis, we derive insights about perceptions and understandings of trust, privacy and security of smart devices, and identify how technological security needs to work in concert with social and relational forms of security for smart services to be effective. We conclude with an orientation for HCI that focuses on designing services for and with smart people and things."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,1,Aditya Shekhar Nittala,Saarland University,Saarbrücken,Germany,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,2,Klaus Kruttwig,INM-Leibniz Institute for New Materials,Saarbrücken,Germany,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,3,Jaeyeon Lee,KAIST,Daejeon,Republic Of Korea,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,4,Roland Bennewitz,INM-Leibniz Institute for New Materials,Saarbrücken,Germany,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,5,Eduard Arzt,INM-Leibniz Institute for New Materials,Saarbrücken,Germany,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn7228,https://doi.org/10.1145/3290605.3300610,Like A Second Skin: Understanding How Epidermal Devices Affect Human Tactile Perception,6,Jürgen Steimle,"Saarland University, Saarland Informatics Campus",Saarbrücken,Germany,true,false,"The emerging class of epidermal devices opens up new opportunities for skin-based sensing, computing, and interaction. Future design of these devices requires an understanding of how skin-worn devices affect the natural tactile perception. In this study, we approach this research challenge by proposing a novel classification system for epidermal devices based on flexural rigidity and by testing advanced adhesive materials, including tattoo paper and thin films of poly (dimethylsiloxane) (PDMS). We report on the results of three psychophysical experiments that investigated the effect of epidermal devices of different rigidity on passive and active tactile perception. We analyzed human tactile sensitivity thresholds, two-point discrimination thresholds, and roughness discrimination abilities on three different body locations (fingertip, hand, forearm). Generally, a correlation was found between device rigidity and tactile sensitivity thresholds as well as roughness discrimination ability. Surprisingly, thin epidermal devices based on PDMS with a hundred times the rigidity of commonly used tattoo paper resulted in comparable levels of tactile acuity. The material offers the benefit of increased robustness against wear and the option to re-use the device. Based on our findings, we derive design recommendations for epidermal devices that combine tactile perception with device robustness."
pn2458,https://doi.org/10.1145/3290605.3300465,Optimising the Encoding for Vibrotactile Skin Reading,1,Granit Luzhnica,Know Center,Graz,Austria,false,false,"This paper proposes methods of optimising alphabet encoding for skin reading in order to avoid perception errors. First, a user study with 16 participants using two body locations serves to identify issues in recognition of both individual letters and words. To avoid such issues, a two-step optimisation method of the symbol encoding is proposed and validated in a second user study with eight participants using the optimised encoding with a seven vibromotor wearable layout on the back of the hand. The results show significant improvements in the recognition accuracy of letters (97%) and words (97%) when compared to the non-optimised encoding."
pn2458,https://doi.org/10.1145/3290605.3300465,Optimising the Encoding for Vibrotactile Skin Reading,2,Eduardo Veas,Graz University of Technology,Graz,Austria,false,false,"This paper proposes methods of optimising alphabet encoding for skin reading in order to avoid perception errors. First, a user study with 16 participants using two body locations serves to identify issues in recognition of both individual letters and words. To avoid such issues, a two-step optimisation method of the symbol encoding is proposed and validated in a second user study with eight participants using the optimised encoding with a seven vibromotor wearable layout on the back of the hand. The results show significant improvements in the recognition accuracy of letters (97%) and words (97%) when compared to the non-optimised encoding."
pn4521,https://doi.org/10.1145/3290605.3300524,Frequency-Based Design of Smart Textiles,1,Jussi Mikkonen,Syddansk Universitet,Kolding,Denmark,false,false,"Despite the increasing amount of smart textile design practitioners, the methods and tools commonly available have not progressed to the same scale. Most smart textile interaction designs today rely on detecting changes in resistance. The tools and sensors for this are generally limited to DC-voltage-divider based sensors and multimeters. Furthermore, the textiles and the materials used in smart textile design can exhibit behaviour making it difficult to identify even simple interactions using those means. For instance, steel-based textiles exhibit intrinsic semiconductive properties that are difficult to identify with current methods. In this paper, we show an alternative way to measure interaction with smart textiles. By relying on visualisation known as Lissajous-figures and frequency-based signals, we can detect even subtle and varied forms of interaction with smart textiles. We also show an approach to measuring frequency-based signals and present an Arduino-based system called Teksig to support this type of textile practice."
pn4521,https://doi.org/10.1145/3290605.3300524,Frequency-Based Design of Smart Textiles,2,Riikka Townsend,Aalto University,Helsinki,Finland,false,false,"Despite the increasing amount of smart textile design practitioners, the methods and tools commonly available have not progressed to the same scale. Most smart textile interaction designs today rely on detecting changes in resistance. The tools and sensors for this are generally limited to DC-voltage-divider based sensors and multimeters. Furthermore, the textiles and the materials used in smart textile design can exhibit behaviour making it difficult to identify even simple interactions using those means. For instance, steel-based textiles exhibit intrinsic semiconductive properties that are difficult to identify with current methods. In this paper, we show an alternative way to measure interaction with smart textiles. By relying on visualisation known as Lissajous-figures and frequency-based signals, we can detect even subtle and varied forms of interaction with smart textiles. We also show an approach to measuring frequency-based signals and present an Arduino-based system called Teksig to support this type of textile practice."
pn2372,https://doi.org/10.1145/3290605.3300575,AdaCAD: Crafting Software For Smart Textiles Design,1,Mikhaila Friske,University of Colorado Boulder,Boulder,United States,true,false,"Woven smart textiles are useful in creating flexible electronics because they integrate circuitry into the structure of the fabric itself. However, there do not yet exist tools that support the specific needs of smart textiles weavers. This paper describes the process and development of AdaCAD, an application for composing smart textile weave drafts. By augmenting traditional weaving drafts, AdaCAD allows weavers to design woven structures and circuitry in tandem and offers specific support for common smart textiles techniques. We describe these techniques, how our tool supports them alongside feedback from smart textiles weavers. We conclude with a reflection on smart textiles practice more broadly and suggest that the metaphor of coproduction can be fruitful in creating effective tools and envisioning future applications in this space."
pn2372,https://doi.org/10.1145/3290605.3300575,AdaCAD: Crafting Software For Smart Textiles Design,2,Shanel Wu,University of Colorado Boulder,Boulder,United States,true,false,"Woven smart textiles are useful in creating flexible electronics because they integrate circuitry into the structure of the fabric itself. However, there do not yet exist tools that support the specific needs of smart textiles weavers. This paper describes the process and development of AdaCAD, an application for composing smart textile weave drafts. By augmenting traditional weaving drafts, AdaCAD allows weavers to design woven structures and circuitry in tandem and offers specific support for common smart textiles techniques. We describe these techniques, how our tool supports them alongside feedback from smart textiles weavers. We conclude with a reflection on smart textiles practice more broadly and suggest that the metaphor of coproduction can be fruitful in creating effective tools and envisioning future applications in this space."
pn2372,https://doi.org/10.1145/3290605.3300575,AdaCAD: Crafting Software For Smart Textiles Design,3,Laura Devendorf,University of Colorado Boulder,Boulder,United States,true,false,"Woven smart textiles are useful in creating flexible electronics because they integrate circuitry into the structure of the fabric itself. However, there do not yet exist tools that support the specific needs of smart textiles weavers. This paper describes the process and development of AdaCAD, an application for composing smart textile weave drafts. By augmenting traditional weaving drafts, AdaCAD allows weavers to design woven structures and circuitry in tandem and offers specific support for common smart textiles techniques. We describe these techniques, how our tool supports them alongside feedback from smart textiles weavers. We conclude with a reflection on smart textiles practice more broadly and suggest that the metaphor of coproduction can be fruitful in creating effective tools and envisioning future applications in this space."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,1,Jocelyn Spence,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,2,Benjamin Bedwell,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,3,Michelle Coleman,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,4,Steve Benford,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,5,Boriana Koleva,University of Nottingham,Nottingham,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,6,Matt Adams,Blast Theory,Brighton,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,7,Ju Row Farr,Blast Theory,Brighton,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,8,Nick Tandavanitj,Blast Theory,Brighton,United Kingdom,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2019,https://doi.org/10.1145/3290605.3300235,Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,9,Anders Løvlie,IT University of Copenhagen,Copenhagen,Denmark,false,false,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage."
pn2565,https://doi.org/10.1145/3290605.3300614,Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity,1,Somi Ju,Ulsan National Institute of Science and Technology,Ulsan,Republic Of Korea,false,false,"We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation."
pn2565,https://doi.org/10.1145/3290605.3300614,Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity,2,Kyung-Ryong Lee,Ulsan National Institute of Science and Technology,Ulsan,Republic Of Korea,false,false,"We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation."
pn2565,https://doi.org/10.1145/3290605.3300614,Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity,3,Subin Kim,Ulsan National Institute of Science and Technology,Ulsan,Republic Of Korea,false,false,"We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation."
pn2565,https://doi.org/10.1145/3290605.3300614,Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity,4,Young-Woo Park,Ulsan National Institute of Science and Technology,Ulsan,Republic Of Korea,false,false,"We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation."
pn4798,https://doi.org/10.1145/3290605.3300236,Design and Plural Heritages: Composing Critical Futures,1,Tom Schofield,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice."
pn4798,https://doi.org/10.1145/3290605.3300236,Design and Plural Heritages: Composing Critical Futures,2,Daniel Foster Smith,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice."
pn4798,https://doi.org/10.1145/3290605.3300236,Design and Plural Heritages: Composing Critical Futures,3,Gönül Bozoglu,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice."
pn4798,https://doi.org/10.1145/3290605.3300236,Design and Plural Heritages: Composing Critical Futures,4,Christopher Whitehead,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice."
pn9257,https://doi.org/10.1145/3290605.3300741,Understanding Kinaesthetic Creativity in Dance,1,Stacy Hsueh,INRIA,Paris,France,false,false,"Kinaesthetic creativity refers to the body's ability to generate alternate futures in activities such as role-playing in participatory design workshops. This has relevance not only to the design of methods for inspiring creativity but also to the design of systems that promote engaging experiences via bodily interaction. This paper probes this creative process by studying how dancers interact with technology to generate ideas. We developed a series of parameterized interactive visuals and asked dance practitioners to use them in generating movement materials. From our study, we define a taxonomy that comprises different relationships and movement responses dancers form with the visuals. Against this taxonomy, we describe six types of interaction patterns and demonstrate how dance creativity is driven by the ability to shift between these patterns. We then propose a set of interaction design qualities to support kinaesthetic creativity."
pn9257,https://doi.org/10.1145/3290605.3300741,Understanding Kinaesthetic Creativity in Dance,2,Sarah Fdili Alaoui,INRIA,Paris,France,false,false,"Kinaesthetic creativity refers to the body's ability to generate alternate futures in activities such as role-playing in participatory design workshops. This has relevance not only to the design of methods for inspiring creativity but also to the design of systems that promote engaging experiences via bodily interaction. This paper probes this creative process by studying how dancers interact with technology to generate ideas. We developed a series of parameterized interactive visuals and asked dance practitioners to use them in generating movement materials. From our study, we define a taxonomy that comprises different relationships and movement responses dancers form with the visuals. Against this taxonomy, we describe six types of interaction patterns and demonstrate how dance creativity is driven by the ability to shift between these patterns. We then propose a set of interaction design qualities to support kinaesthetic creativity."
pn9257,https://doi.org/10.1145/3290605.3300741,Understanding Kinaesthetic Creativity in Dance,3,Wendy Mackay,INRIA,Paris,France,false,false,"Kinaesthetic creativity refers to the body's ability to generate alternate futures in activities such as role-playing in participatory design workshops. This has relevance not only to the design of methods for inspiring creativity but also to the design of systems that promote engaging experiences via bodily interaction. This paper probes this creative process by studying how dancers interact with technology to generate ideas. We developed a series of parameterized interactive visuals and asked dance practitioners to use them in generating movement materials. From our study, we define a taxonomy that comprises different relationships and movement responses dancers form with the visuals. Against this taxonomy, we describe six types of interaction patterns and demonstrate how dance creativity is driven by the ability to shift between these patterns. We then propose a set of interaction design qualities to support kinaesthetic creativity."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,1,Shuai Ma,"Institute of Software, Chinese Academy of Sciences",Beijing,China,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,2,Zijun Wei,Stony Brook University,Stony Brook,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,3,Feng Tian,"Institute of software, Chinese Academy of Sciences",Beijing,China,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,4,Xiangmin Fan,"Institute of Software, Chinese Academy of Sciences",Beijing,China,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,5,Jianming Zhang,Adobe Research,San Jose,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,6,Xiaohui Shen,ByteDance AI Lab,Menlo Park,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,7,Zhe Lin,Adobe Research,San Jose,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,8,Jin Huang,Chinese Academy of Sciences,Beijing,China,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,9,Radomir M?Ch,Adobe Research,San Jose,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,10,Dimitris Samaras,Stony Brook University,Stony Brook,United States,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn1054,https://doi.org/10.1145/3290605.3300701,SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network,11,Hongan Wang,"Institute of Software, Chinese Academy of Sciences",Beijing,China,true,false,"Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,1,Carl Gutwin,University of Saskatchewan,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,2,Michael Van Der Kamp,University of Saskatchewan,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,3,Md. Sami Uddin,University of Saskatchewan,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,4,Kevin Stanley,University of Saskatchewan,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,5,Ian Stavness,University of Saskatchewan,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn7484,https://doi.org/10.1145/3290605.3300785,Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading,6,Sally Vail,Agriculture and Agri-Food Canada,Saskatoon,Canada,false,false,"Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique."
pn3231,https://doi.org/10.1145/3290605.3300527,RePlay: Contextually Presenting Learning Videos Across Software Applications,1,C. Ailie Fraser,"University of California, San Diego",La Jolla,United States,true,false,"Complex activities often require people to work across multiple software applications. However, people frequently lack valuable knowledge about at least one application, especially as software changes and new software emerges. Existing help systems either lack contextual knowledge or are tightly-knit into a single application. We introduce an application-independent approach for contextually presenting video learning resources and demonstrate it through the RePlay system. RePlay uses accessibility APIs to gather context about the user's activity. It leverages an existing search engine to present relevant videos and highlights key segments within them using video captions. We report on a week-long field study (n=7) and a lab study (n=24) showing that contextual assistance helps people spend less time away from their task than web video search and replaces current video navigation strategies. Our findings highlight challenges with representing and using context across applications."
pn3231,https://doi.org/10.1145/3290605.3300527,RePlay: Contextually Presenting Learning Videos Across Software Applications,2,Tricia Ngoon,"University of California, San Diego",La Jolla,United States,true,false,"Complex activities often require people to work across multiple software applications. However, people frequently lack valuable knowledge about at least one application, especially as software changes and new software emerges. Existing help systems either lack contextual knowledge or are tightly-knit into a single application. We introduce an application-independent approach for contextually presenting video learning resources and demonstrate it through the RePlay system. RePlay uses accessibility APIs to gather context about the user's activity. It leverages an existing search engine to present relevant videos and highlights key segments within them using video captions. We report on a week-long field study (n=7) and a lab study (n=24) showing that contextual assistance helps people spend less time away from their task than web video search and replaces current video navigation strategies. Our findings highlight challenges with representing and using context across applications."
pn3231,https://doi.org/10.1145/3290605.3300527,RePlay: Contextually Presenting Learning Videos Across Software Applications,3,Mira Dontcheva,Adobe Research,Seattle,United States,true,false,"Complex activities often require people to work across multiple software applications. However, people frequently lack valuable knowledge about at least one application, especially as software changes and new software emerges. Existing help systems either lack contextual knowledge or are tightly-knit into a single application. We introduce an application-independent approach for contextually presenting video learning resources and demonstrate it through the RePlay system. RePlay uses accessibility APIs to gather context about the user's activity. It leverages an existing search engine to present relevant videos and highlights key segments within them using video captions. We report on a week-long field study (n=7) and a lab study (n=24) showing that contextual assistance helps people spend less time away from their task than web video search and replaces current video navigation strategies. Our findings highlight challenges with representing and using context across applications."
pn3231,https://doi.org/10.1145/3290605.3300527,RePlay: Contextually Presenting Learning Videos Across Software Applications,4,Scott Klemmer,"University of California, San Diego",La Jolla,United States,true,false,"Complex activities often require people to work across multiple software applications. However, people frequently lack valuable knowledge about at least one application, especially as software changes and new software emerges. Existing help systems either lack contextual knowledge or are tightly-knit into a single application. We introduce an application-independent approach for contextually presenting video learning resources and demonstrate it through the RePlay system. RePlay uses accessibility APIs to gather context about the user's activity. It leverages an existing search engine to present relevant videos and highlights key segments within them using video captions. We report on a week-long field study (n=7) and a lab study (n=24) showing that contextual assistance helps people spend less time away from their task than web video search and replaces current video navigation strategies. Our findings highlight challenges with representing and using context across applications."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,1,Peter Mohr,Graz University of Technology,Graz,Austria,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,2,Markus Tatzgern,Salzburg University of Applied Sciences,Puch,Austria,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,3,Tobias Langlotz,University of Otago,Dunedin,New Zealand,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,4,Andreas Lang,Graz University of Technology,Puch,Austria,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,5,Dieter Schmalstieg,Graz University of Technology,Graz,Austria,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5492,https://doi.org/10.1145/3290605.3300815,TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays,6,Denis Kalkofen,Graz University of Technology,Graz,Austria,false,false,"The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities."
pn5992,https://doi.org/10.1145/3290605.3300372,Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit,1,Bryan Dosono,Syracuse University,Syracuse,United States,false,false,"We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms."
pn5992,https://doi.org/10.1145/3290605.3300372,Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit,2,Bryan Semaan,Syracuse University,Syracuse,United States,false,false,"We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms."
pn8044,https://doi.org/10.1145/3290605.3300247,Effects of Moderation and Opinion Heterogeneity on Attitude towards the Online Deliberation Experience,1,Simon Perrault,Yale-NUS College,Singapore,Singapore,false,false,"Online deliberation offers a way for citizens to collectively discuss an issue and provide input for policymakers. The overall experience of online deliberation can be affected by multiple factors. We decided to investigate the effects of moderation and opinion heterogeneity on the perceived deliberation experience, by running the first online deliberation experiment in Singapore. Our study took place in three months with three phases. In phase 1, our 2,006 participants answered a survey, that we used to create groups of different opinion heterogeneity. During the second phase, 510 participants discussed about the population issue on the online platform we developed. We gathered data on their online deliberation experience during phase 3. We found out that higher levels of moderation negatively impact the experience of deliberation on perceived procedural fairness, validity claim and policy legitimacy; and that high opinion heterogeneity is important in order to get a fair assessment of the deliberation experience."
pn8044,https://doi.org/10.1145/3290605.3300247,Effects of Moderation and Opinion Heterogeneity on Attitude towards the Online Deliberation Experience,2,Weiyu Zhang,National University of Singapore,Singapore,Singapore,false,false,"Online deliberation offers a way for citizens to collectively discuss an issue and provide input for policymakers. The overall experience of online deliberation can be affected by multiple factors. We decided to investigate the effects of moderation and opinion heterogeneity on the perceived deliberation experience, by running the first online deliberation experiment in Singapore. Our study took place in three months with three phases. In phase 1, our 2,006 participants answered a survey, that we used to create groups of different opinion heterogeneity. During the second phase, 510 participants discussed about the population issue on the online platform we developed. We gathered data on their online deliberation experience during phase 3. We found out that higher levels of moderation negatively impact the experience of deliberation on perceived procedural fairness, validity claim and policy legitimacy; and that high opinion heterogeneity is important in order to get a fair assessment of the deliberation experience."
pn4640,https://doi.org/10.1145/3290605.3300563,Rumors and Collective Sensemaking: Managing Ambiguity in an Informal Marketplace,1,Priyank Chandra,University of Michigan,Ann Arbor,United States,false,false,"Rumors are an enduring form of communication across socio-cultural landscapes globally. Counter to their typical negative association, rumors play a nuanced role, helping people collectively deal with problems through constructing a representation of an uncertain situation. Drawing on unstructured interviews and participant observation from a technology goods marketplace in Bangalore, India, we study the circulation of rumors related to the government's recent policy of demonetization and entry of online marketplaces and digital wallets, all of which disrupted existing market practices. These rumors emerge as attempts at sensemaking when a community is faced with ambiguity. Through highlighting the relationship of institutional trust with rumors, the paper argues that the study of rumors can help us identify the concerns of a community in the face of differential power relations. Further, rumors are a form of social bonding which help communities make sense of their place in society and shape existing practices."
pn4640,https://doi.org/10.1145/3290605.3300563,Rumors and Collective Sensemaking: Managing Ambiguity in an Informal Marketplace,2,Joyojeet Pal,University of Michigan,Ann Arbor,United States,false,false,"Rumors are an enduring form of communication across socio-cultural landscapes globally. Counter to their typical negative association, rumors play a nuanced role, helping people collectively deal with problems through constructing a representation of an uncertain situation. Drawing on unstructured interviews and participant observation from a technology goods marketplace in Bangalore, India, we study the circulation of rumors related to the government's recent policy of demonetization and entry of online marketplaces and digital wallets, all of which disrupted existing market practices. These rumors emerge as attempts at sensemaking when a community is faced with ambiguity. Through highlighting the relationship of institutional trust with rumors, the paper argues that the study of rumors can help us identify the concerns of a community in the face of differential power relations. Further, rumors are a form of social bonding which help communities make sense of their place in society and shape existing practices."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,1,Motahhare Eslami,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,2,Kristen Vaccaro,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,3,Min Kyung Lee,Carnegie Mellon University,Pittsburgh,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,4,Amit Elazari Bar On,"University of California, Berkeley",Berkeley,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,5,Eric Gilbert,University of Michigan,Ann Arbor,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn6899,https://doi.org/10.1145/3290605.3300724,User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms,6,Karrie Karahalios,University of Illinois at Urbana-Champaign,Urbana,United States,false,false,"Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform."
pn2774,https://doi.org/10.1145/3290605.3300478,"Pay Attention, Please: Formal Language Improves Attention in Volunteer and Paid Online Experiments",1,Tal August,University of Washington,Seattle,United States,false,false,"Participant engagement in online studies is key to collecting reliable data, yet achieving it remains an often discussed challenge in the research community. One factor that might impact engagement is the formality of language used to communicate with participants throughout the study. Prior work has found that language formality can convey social cues and power hierarchies, affecting people's responses and actions. We explore how formality influences engagement, measured by attention, dropout, time spent on the study and participant performance, in an online study with 369 participants on Mechanical Turk (paid) and LabintheWild (volunteer). Formal language improves participant attention compared to using casual language in both paid and volunteer conditions, but does not affect dropout, time spent, or participant performance. We suggest using more formal language in studies containing complex tasks where fully reading instructions is especially important. We also highlight trade-offs that different recruitment incentives provide in online experimentation."
pn2774,https://doi.org/10.1145/3290605.3300478,"Pay Attention, Please: Formal Language Improves Attention in Volunteer and Paid Online Experiments",2,Katharina Reinecke,University of Washington,Seattle,United States,false,false,"Participant engagement in online studies is key to collecting reliable data, yet achieving it remains an often discussed challenge in the research community. One factor that might impact engagement is the formality of language used to communicate with participants throughout the study. Prior work has found that language formality can convey social cues and power hierarchies, affecting people's responses and actions. We explore how formality influences engagement, measured by attention, dropout, time spent on the study and participant performance, in an online study with 369 participants on Mechanical Turk (paid) and LabintheWild (volunteer). Formal language improves participant attention compared to using casual language in both paid and volunteer conditions, but does not affect dropout, time spent, or participant performance. We suggest using more formal language in studies containing complex tasks where fully reading instructions is especially important. We also highlight trade-offs that different recruitment incentives provide in online experimentation."
pn8510,https://doi.org/10.1145/3290605.3300432,Decision-Making Under Uncertainty in Research Synthesis: Designing for the Garden of Forking Paths,1,Alex Kale,University of Washington,Seattle,United States,false,false,"To make evidence-based recommendations to decision-makers, researchers conducting systematic reviews and meta-analyses must navigate a garden of forking paths: a series of analytical decision-points, each of which has the potential to influence findings. To identify challenges and opportunities related to designing systems to help researchers manage uncertainty around which of multiple analyses is best, we interviewed 11 professional researchers who conduct research synthesis to inform decision-making within three organizations. We conducted a qualitative analysis identifying 480 analytical decisions made by researchers throughout the scientific process. We present descriptions of current practices in applied research synthesis and corresponding design challenges: making it more feasible for researchers to try and compare analyses, shifting researchers' attention from rationales for decisions to impacts on results, and supporting communication techniques that acknowledge decision-makers' aversions to uncertainty. We identify opportunities to design systems which help researchers explore, reason about, and communicate uncertainty in decision-making about possible analyses in research synthesis."
pn8510,https://doi.org/10.1145/3290605.3300432,Decision-Making Under Uncertainty in Research Synthesis: Designing for the Garden of Forking Paths,2,Matthew Kay,University of Michigan,Ann Arbor,United States,false,false,"To make evidence-based recommendations to decision-makers, researchers conducting systematic reviews and meta-analyses must navigate a garden of forking paths: a series of analytical decision-points, each of which has the potential to influence findings. To identify challenges and opportunities related to designing systems to help researchers manage uncertainty around which of multiple analyses is best, we interviewed 11 professional researchers who conduct research synthesis to inform decision-making within three organizations. We conducted a qualitative analysis identifying 480 analytical decisions made by researchers throughout the scientific process. We present descriptions of current practices in applied research synthesis and corresponding design challenges: making it more feasible for researchers to try and compare analyses, shifting researchers' attention from rationales for decisions to impacts on results, and supporting communication techniques that acknowledge decision-makers' aversions to uncertainty. We identify opportunities to design systems which help researchers explore, reason about, and communicate uncertainty in decision-making about possible analyses in research synthesis."
pn8510,https://doi.org/10.1145/3290605.3300432,Decision-Making Under Uncertainty in Research Synthesis: Designing for the Garden of Forking Paths,3,Jessica Hullman,Northwestern University,Evanston,United States,false,false,"To make evidence-based recommendations to decision-makers, researchers conducting systematic reviews and meta-analyses must navigate a garden of forking paths: a series of analytical decision-points, each of which has the potential to influence findings. To identify challenges and opportunities related to designing systems to help researchers manage uncertainty around which of multiple analyses is best, we interviewed 11 professional researchers who conduct research synthesis to inform decision-making within three organizations. We conducted a qualitative analysis identifying 480 analytical decisions made by researchers throughout the scientific process. We present descriptions of current practices in applied research synthesis and corresponding design challenges: making it more feasible for researchers to try and compare analyses, shifting researchers' attention from rationales for decisions to impacts on results, and supporting communication techniques that acknowledge decision-makers' aversions to uncertainty. We identify opportunities to design systems which help researchers explore, reason about, and communicate uncertainty in decision-making about possible analyses in research synthesis."
pn6390,https://doi.org/10.1145/3290605.3300314,­Understanding the Boundaries between Policymaking and HCI,1,Anne Spaa,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts."
pn6390,https://doi.org/10.1145/3290605.3300314,­Understanding the Boundaries between Policymaking and HCI,2,Abigail Durrant,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts."
pn6390,https://doi.org/10.1145/3290605.3300314,­Understanding the Boundaries between Policymaking and HCI,3,Chris Elsden,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts."
pn6390,https://doi.org/10.1145/3290605.3300314,­Understanding the Boundaries between Policymaking and HCI,4,John Vines,Northumbria University,Newcastle Upon Tyne,United Kingdom,true,false,"There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,1,Pedro Sanches,KTH Royal Institute of Technology in Stockholm,Stockholm,Sweden,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,2,Axel Janson,KTH Royal Institute of Technology in Stockholm,Stockholm,Sweden,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,3,Pavel Karpashevich,KTH Royal Institute of Technology in Stockholm,Stockholm,Sweden,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,4,Camille Nadal,Trinity College Dublin,Dublin,Ireland,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,5,Chengcheng Qu,Lancaster University,Lancaster,United Kingdom,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,6,Claudia Daudén Roquet,Lancaster University,Lancaster,United Kingdom,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,7,Muhammad Umair,Lancaster University,Lancaster,United Kingdom,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,8,Charles Windlin,KTH Royal Institute of Technology in Stockholm,Stockholm,Sweden,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,9,Gavin Doherty,Trinity College Dublin,Dublin,Ireland,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,10,Kristina Höök,Royal Institute of Technology KTH,Stockholm,Sweden,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn3929,https://doi.org/10.1145/3290605.3300475,HCI and Affective Health: Taking stock of a decade of studies and charting future research directions,11,Corina Sas,Lancaster University,Lancaster,United Kingdom,true,false,"In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies."
pn2540,https://doi.org/10.1145/3290605.3300439,"Chatbots, Humbots, and the Quest for Artificial General Intelligence",1,Jonathan Grudin,Microsoft Corporation,Redmond,United States,false,false,"What began as a quest for artificial general intelligence branched into several pursuits, including intelligent assistants developed by tech companies and task-oriented chatbots that deliver more information or services in specific domains. Progress quickened with the spread of low-latency networking, then accelerated dramatically a few years ago. In 2016, task-focused chatbots became a centerpiece of machine intelligence, promising interfaces that are more engaging than robotic answering systems and that can accommodate our increasingly phone-based information needs. Hundreds of thousands were built. Creating successful non-trivial chatbots proved more difficult than anticipated. Some developers now design for human-chatbot (humbot) teams, with people handling difficult queries. This paper describes the conversational agent space, difficulties in meeting user expectations, potential new design approaches, uses of human-bot hybrids, and implications for the ultimate goal of creating software with general intelligence."
pn2540,https://doi.org/10.1145/3290605.3300439,"Chatbots, Humbots, and the Quest for Artificial General Intelligence",2,Richard Jacques,Microsoft Corporation,Redmond,United States,false,false,"What began as a quest for artificial general intelligence branched into several pursuits, including intelligent assistants developed by tech companies and task-oriented chatbots that deliver more information or services in specific domains. Progress quickened with the spread of low-latency networking, then accelerated dramatically a few years ago. In 2016, task-focused chatbots became a centerpiece of machine intelligence, promising interfaces that are more engaging than robotic answering systems and that can accommodate our increasingly phone-based information needs. Hundreds of thousands were built. Creating successful non-trivial chatbots proved more difficult than anticipated. Some developers now design for human-chatbot (humbot) teams, with people handling difficult queries. This paper describes the conversational agent space, difficulties in meeting user expectations, potential new design approaches, uses of human-bot hybrids, and implications for the ultimate goal of creating software with general intelligence."
pn7468,https://doi.org/10.1145/3290605.3300520,"""Wait, Do I Know This Person?"": Understanding Misdirected Email",1,Emilee Rader,Michigan State University,East Lansing,United States,false,false,"Email is an essential tool for communication and social interaction. It also functions as a broadcast medium connecting businesses with their customers, as an authentication mechanism, and as a vector for scams and security threats. These uses are enabled by the fact that the only barrier to reaching someone by email is knowing his or her email address. This feature has given rise to the spam email industry but also has another side-effect that is becoming increasingly common: misdirected email, or legitimate emails that are intended for somebody else but are sent to the wrong recipient. In this paper we present findings from an interview study and survey focusing on characteristics of misdirected email messages, possible reasons why they happen, and how people manage these messages when they receive them. Misdirected email arises as a result of signifiers (usernames) which were selected by people for social and self-representation purposes, that are also used by machines for addressing. Because there is no mechanism for dealing with misdirected emails in a systematic way, individual recipients must choose whether to take action and how much effort to put forth to prevent potential negative consequences for themselves and others."
pn7468,https://doi.org/10.1145/3290605.3300520,"""Wait, Do I Know This Person?"": Understanding Misdirected Email",2,Anjali Munasinghe,Michigan State University,East Lansing,United States,false,false,"Email is an essential tool for communication and social interaction. It also functions as a broadcast medium connecting businesses with their customers, as an authentication mechanism, and as a vector for scams and security threats. These uses are enabled by the fact that the only barrier to reaching someone by email is knowing his or her email address. This feature has given rise to the spam email industry but also has another side-effect that is becoming increasingly common: misdirected email, or legitimate emails that are intended for somebody else but are sent to the wrong recipient. In this paper we present findings from an interview study and survey focusing on characteristics of misdirected email messages, possible reasons why they happen, and how people manage these messages when they receive them. Misdirected email arises as a result of signifiers (usernames) which were selected by people for social and self-representation purposes, that are also used by machines for addressing. Because there is no mechanism for dealing with misdirected emails in a systematic way, individual recipients must choose whether to take action and how much effort to put forth to prevent potential negative consequences for themselves and others."
pn3893,https://doi.org/10.1145/3290605.3300604,Opportunities for Automating Email Processing: A Need-Finding Study,1,Soya Park,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user's inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions."
pn3893,https://doi.org/10.1145/3290605.3300604,Opportunities for Automating Email Processing: A Need-Finding Study,2,Amy Zhang,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user's inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions."
pn3893,https://doi.org/10.1145/3290605.3300604,Opportunities for Automating Email Processing: A Need-Finding Study,3,Luke Murray,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user's inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions."
pn3893,https://doi.org/10.1145/3290605.3300604,Opportunities for Automating Email Processing: A Need-Finding Study,4,David Karger,Massachusetts Institute of Technology,Cambridge,United States,false,false,"Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user's inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,1,Hao-Fei Cheng,University of Minnesota,Minneapolis,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,2,Ruotong Wang,Macalester College,Saint Paul,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,3,Zheng Zhang,University of Minnesota,Minneapolis,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,4,Fiona O'connell,University of Chicago,Chicago,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,5,Terrance Gray,University of Minnesota,Minneapolis,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,6,F. Harper,University of Minnesota,Minneapolis,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn9057,https://doi.org/10.1145/3290605.3300789,Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders,7,Haiyi Zhu,University of Minnesota,Minneapolis,United States,false,false,"Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' ""right to explanation"". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and ""white-box"" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm."
pn7895,https://doi.org/10.1145/3290605.3300907,Sound Forest: Evaluation of an Accessible Multisensory Music Installation,1,Emma Frid,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play."
pn7895,https://doi.org/10.1145/3290605.3300907,Sound Forest: Evaluation of an Accessible Multisensory Music Installation,2,Hans Lindetorp,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play."
pn7895,https://doi.org/10.1145/3290605.3300907,Sound Forest: Evaluation of an Accessible Multisensory Music Installation,3,Kjetil Hansen,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play."
pn7895,https://doi.org/10.1145/3290605.3300907,Sound Forest: Evaluation of an Accessible Multisensory Music Installation,4,Ludvig Elblaus,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play."
pn7895,https://doi.org/10.1145/3290605.3300907,Sound Forest: Evaluation of an Accessible Multisensory Music Installation,5,Roberto Bresin,KTH Royal Institute of Technology,Stockholm,Sweden,false,false,"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play."
pn8444,https://doi.org/10.1145/3290605.3300290,Integrated Workflows: Generating Feedback Between Digital and Physical Realms,1,Emrecan Gulay,Aalto University,Helsinki,Finland,false,false,"As design thinking shifted away from conventional methods with the rapid adoption of computer-aided design and fabrication technologies, architects have been seeking ways to initiate a comprehensive dialogue between the virtual and the material realms. Current methodologies do not offer embodied workflows that utilize the feedback obtained through a subsequent transition process between physical and digital design. Therefore, narrowing the separation between these two platforms remains as a research problem. This literature review elaborates the divide between physical and digital design, testing and manufacturing techniques in the morphological process of architectural form. We first review the digital transformation in the architectural design discourse. Then, we proceed by introducing a variety of methods that are integrating digital and physical workflows and suggesting an alternative approach. Our work unveils that there is a need for empirical research with a focus on integrated approaches to create intuitively embodied experiences for architectural designers."
pn8444,https://doi.org/10.1145/3290605.3300290,Integrated Workflows: Generating Feedback Between Digital and Physical Realms,2,Andrés Lucero,Aalto University,Helsinki,Finland,false,false,"As design thinking shifted away from conventional methods with the rapid adoption of computer-aided design and fabrication technologies, architects have been seeking ways to initiate a comprehensive dialogue between the virtual and the material realms. Current methodologies do not offer embodied workflows that utilize the feedback obtained through a subsequent transition process between physical and digital design. Therefore, narrowing the separation between these two platforms remains as a research problem. This literature review elaborates the divide between physical and digital design, testing and manufacturing techniques in the morphological process of architectural form. We first review the digital transformation in the architectural design discourse. Then, we proceed by introducing a variety of methods that are integrating digital and physical workflows and suggesting an alternative approach. Our work unveils that there is a need for empirical research with a focus on integrated approaches to create intuitively embodied experiences for architectural designers."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,1,Jack Forman,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,2,Taylor Tabb,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,3,Youngwook Do,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,4,Meng-Han Yeh,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,5,Adrian Galvin,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn4180,https://doi.org/10.1145/3290605.3300890,ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction,6,Lining Yao,Carnegie Mellon University,Pittsburgh,United States,false,false,"Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations."
pn3303,https://doi.org/10.1145/3290605.3300906,VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications,1,Seungjae Oh,Pohang University of Science and Technology (POSTECH),Pohang,Republic Of Korea,false,false,"We present VibEye: a vibration-mediated recognition system of objects for tangible interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers a vibration from one finger, and the vibration that has propagated through the object is sensed at the other finger. This vibration includes information about the object's identity, and we represent it using a spectrogram. Collecting the spectrograms of many objects, we formulate the object recognition problem to a classical classification problem among the images. This simple method, when tested with 20 users, shows 92.5% accuracy for 16 objects of the same shape with various materials. This material-based classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate several tangible applications where VibEye provides the needed functionality while enhancing user experiences. VibEye is particularly effective for recognizing objects made of different materials, which is difficult to distinguish by other means such as light and sound."
pn3303,https://doi.org/10.1145/3290605.3300906,VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications,2,Gyeore Yun,Pohang University of Science and Technology (POSTECH),Pohang,Republic Of Korea,false,false,"We present VibEye: a vibration-mediated recognition system of objects for tangible interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers a vibration from one finger, and the vibration that has propagated through the object is sensed at the other finger. This vibration includes information about the object's identity, and we represent it using a spectrogram. Collecting the spectrograms of many objects, we formulate the object recognition problem to a classical classification problem among the images. This simple method, when tested with 20 users, shows 92.5% accuracy for 16 objects of the same shape with various materials. This material-based classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate several tangible applications where VibEye provides the needed functionality while enhancing user experiences. VibEye is particularly effective for recognizing objects made of different materials, which is difficult to distinguish by other means such as light and sound."
pn3303,https://doi.org/10.1145/3290605.3300906,VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications,3,Chaeyong Park,Pohang University of Science and Technology (POSTECH),Pohang,Republic Of Korea,false,false,"We present VibEye: a vibration-mediated recognition system of objects for tangible interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers a vibration from one finger, and the vibration that has propagated through the object is sensed at the other finger. This vibration includes information about the object's identity, and we represent it using a spectrogram. Collecting the spectrograms of many objects, we formulate the object recognition problem to a classical classification problem among the images. This simple method, when tested with 20 users, shows 92.5% accuracy for 16 objects of the same shape with various materials. This material-based classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate several tangible applications where VibEye provides the needed functionality while enhancing user experiences. VibEye is particularly effective for recognizing objects made of different materials, which is difficult to distinguish by other means such as light and sound."
pn3303,https://doi.org/10.1145/3290605.3300906,VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications,4,Jinsoo Kim,Pohang University of Science and Technology (POSTECH),Pohang,Republic Of Korea,false,false,"We present VibEye: a vibration-mediated recognition system of objects for tangible interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers a vibration from one finger, and the vibration that has propagated through the object is sensed at the other finger. This vibration includes information about the object's identity, and we represent it using a spectrogram. Collecting the spectrograms of many objects, we formulate the object recognition problem to a classical classification problem among the images. This simple method, when tested with 20 users, shows 92.5% accuracy for 16 objects of the same shape with various materials. This material-based classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate several tangible applications where VibEye provides the needed functionality while enhancing user experiences. VibEye is particularly effective for recognizing objects made of different materials, which is difficult to distinguish by other means such as light and sound."
pn3303,https://doi.org/10.1145/3290605.3300906,VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications,5,Seungmoon Choi,Pohang University of Science and Technology (POSTECH),Pohang,Republic Of Korea,false,false,"We present VibEye: a vibration-mediated recognition system of objects for tangible interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers a vibration from one finger, and the vibration that has propagated through the object is sensed at the other finger. This vibration includes information about the object's identity, and we represent it using a spectrogram. Collecting the spectrograms of many objects, we formulate the object recognition problem to a classical classification problem among the images. This simple method, when tested with 20 users, shows 92.5% accuracy for 16 objects of the same shape with various materials. This material-based classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate several tangible applications where VibEye provides the needed functionality while enhancing user experiences. VibEye is particularly effective for recognizing objects made of different materials, which is difficult to distinguish by other means such as light and sound."
pn6273,https://doi.org/10.1145/3290605.3300457,"""Everything's the Phone"": Understanding the Phone's Supercharged Role in Parent-Teen Relationships",1,Katie Davis,University of Washington,Seattle,United States,false,false,"Through focus groups (n=61) and surveys (n=2,083) of parents and teens, we investigated how parents and their teen children experience their own and each other's phone use in the context of parent-teen relationships. Both expressed a lack of agency in their own and each other's phone use, feeling overly reliant on their own phone and displaced by the other's phone. In a classic example of the fundamental attribution error, each party placed primary blame on the other, and rationalized their own behavior with legitimizing excuses. We present a conceptual model showing how parents' and teens' relationships to their phones and perceptions of each other's phone use are inextricably linked, and how, together, they contribute to parent-teen tensions and disconnections. We use the model to consider how the phone might play a less highly charged role in family life and contribute to positive connections between parents and their teen children."
pn6273,https://doi.org/10.1145/3290605.3300457,"""Everything's the Phone"": Understanding the Phone's Supercharged Role in Parent-Teen Relationships",2,Anja Dinhopl,Facebook,Menlo Park,United States,false,false,"Through focus groups (n=61) and surveys (n=2,083) of parents and teens, we investigated how parents and their teen children experience their own and each other's phone use in the context of parent-teen relationships. Both expressed a lack of agency in their own and each other's phone use, feeling overly reliant on their own phone and displaced by the other's phone. In a classic example of the fundamental attribution error, each party placed primary blame on the other, and rationalized their own behavior with legitimizing excuses. We present a conceptual model showing how parents' and teens' relationships to their phones and perceptions of each other's phone use are inextricably linked, and how, together, they contribute to parent-teen tensions and disconnections. We use the model to consider how the phone might play a less highly charged role in family life and contribute to positive connections between parents and their teen children."
pn6273,https://doi.org/10.1145/3290605.3300457,"""Everything's the Phone"": Understanding the Phone's Supercharged Role in Parent-Teen Relationships",3,Alexis Hiniker,University of Washington,Seattle,United States,false,false,"Through focus groups (n=61) and surveys (n=2,083) of parents and teens, we investigated how parents and their teen children experience their own and each other's phone use in the context of parent-teen relationships. Both expressed a lack of agency in their own and each other's phone use, feeling overly reliant on their own phone and displaced by the other's phone. In a classic example of the fundamental attribution error, each party placed primary blame on the other, and rationalized their own behavior with legitimizing excuses. We present a conceptual model showing how parents' and teens' relationships to their phones and perceptions of each other's phone use are inextricably linked, and how, together, they contribute to parent-teen tensions and disconnections. We use the model to consider how the phone might play a less highly charged role in family life and contribute to positive connections between parents and their teen children."
pn7270,https://doi.org/10.1145/3290605.3300695,"""Everyone Brings Their Grain of Salt"": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in Côte d'Ivoire",1,Michael Madaio,Carnegie Mellon University,Pittsburgh,United States,false,false,"Significant research has demonstrated the crucial role that parents play in supporting the development of children's literacy, but in contexts where adults may lack sufficient literacy in the target language, it is not clear how to most effectively scaffold parental support for children's literacy. Prior work has designed technologies to teach children literacy directly, but this work has not focused on designing for low-literate parents, particularly for multilingual and developing contexts. In this paper, we describe findings from a qualitative study conducted in several regions of rural Côte d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French literacy. We discuss themes that emerged from these interviews, surrounding ideas of trust, collaboration, and culturally-responsive design, and we highlight implications for the design of technology to scaffold low-literate parental support for children's literacy."
pn7270,https://doi.org/10.1145/3290605.3300695,"""Everyone Brings Their Grain of Salt"": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in Côte d'Ivoire",2,Fabrice Tanoh,Université Félix Houphouët-Boigny,Abidjan,Ivory Coast,false,false,"Significant research has demonstrated the crucial role that parents play in supporting the development of children's literacy, but in contexts where adults may lack sufficient literacy in the target language, it is not clear how to most effectively scaffold parental support for children's literacy. Prior work has designed technologies to teach children literacy directly, but this work has not focused on designing for low-literate parents, particularly for multilingual and developing contexts. In this paper, we describe findings from a qualitative study conducted in several regions of rural Côte d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French literacy. We discuss themes that emerged from these interviews, surrounding ideas of trust, collaboration, and culturally-responsive design, and we highlight implications for the design of technology to scaffold low-literate parental support for children's literacy."
pn7270,https://doi.org/10.1145/3290605.3300695,"""Everyone Brings Their Grain of Salt"": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in Côte d'Ivoire",3,Axel Seri,Institut de la Dignité et des Droits Humains,Abidjan,Ivory Coast,false,false,"Significant research has demonstrated the crucial role that parents play in supporting the development of children's literacy, but in contexts where adults may lack sufficient literacy in the target language, it is not clear how to most effectively scaffold parental support for children's literacy. Prior work has designed technologies to teach children literacy directly, but this work has not focused on designing for low-literate parents, particularly for multilingual and developing contexts. In this paper, we describe findings from a qualitative study conducted in several regions of rural Côte d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French literacy. We discuss themes that emerged from these interviews, surrounding ideas of trust, collaboration, and culturally-responsive design, and we highlight implications for the design of technology to scaffold low-literate parental support for children's literacy."
pn7270,https://doi.org/10.1145/3290605.3300695,"""Everyone Brings Their Grain of Salt"": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in Côte d'Ivoire",4,Kaja Jasinska,University of Delaware,Newark,United States,false,false,"Significant research has demonstrated the crucial role that parents play in supporting the development of children's literacy, but in contexts where adults may lack sufficient literacy in the target language, it is not clear how to most effectively scaffold parental support for children's literacy. Prior work has designed technologies to teach children literacy directly, but this work has not focused on designing for low-literate parents, particularly for multilingual and developing contexts. In this paper, we describe findings from a qualitative study conducted in several regions of rural Côte d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French literacy. We discuss themes that emerged from these interviews, surrounding ideas of trust, collaboration, and culturally-responsive design, and we highlight implications for the design of technology to scaffold low-literate parental support for children's literacy."
pn7270,https://doi.org/10.1145/3290605.3300695,"""Everyone Brings Their Grain of Salt"": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in Côte d'Ivoire",5,Amy Ogan,Carnegie Mellon University,Pittsburgh,United States,false,false,"Significant research has demonstrated the crucial role that parents play in supporting the development of children's literacy, but in contexts where adults may lack sufficient literacy in the target language, it is not clear how to most effectively scaffold parental support for children's literacy. Prior work has designed technologies to teach children literacy directly, but this work has not focused on designing for low-literate parents, particularly for multilingual and developing contexts. In this paper, we describe findings from a qualitative study conducted in several regions of rural Côte d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French literacy. We discuss themes that emerged from these interviews, surrounding ideas of trust, collaboration, and culturally-responsive design, and we highlight implications for the design of technology to scaffold low-literate parental support for children's literacy."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,1,Michela Ferron,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,2,Chiara Leonardi,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,3,Paolo Massa,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,4,Gianluca Schiavo,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,5,Amy Murphy,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn7314,https://doi.org/10.1145/3290605.3300827,A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility,6,Elisabetta Farella,Fondazione Bruno Kessler,Trento,Italy,true,false,"Technology increasingly offers parents more and more opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a school-year long field study, we report findings on children's and parents' experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children's proximity to the volunteers' smartphone. We discuss parents' needs and concerns toward monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility."
pn1158,https://doi.org/10.1145/3290605.3300837,"The ""Comadre"" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities",1,Alexander Cho,"University of California, Irvine",Irvine,United States,false,false,"Participation in out-of-school learning programs has been shown to generate significant academic, social/emotional, and institutional benefits for young learners, and today's wealthy families are disproportionately reaping these benefits. This paper presents the results of an asset-based/human-centered design research process and pilot aimed at connecting low-income families in a Southern California city with local low-cost out-of-school learning opportunities. Based on background research including qualitative interviewing, home visits, technology inventories and use walkthroughs with 40 low-income, majority Latinx families, we created and piloted a free subscription SMS service that automatically pushes bilingual SMS messages with curated information on local low-cost enrichment learning opportunities to low-income families. We framed our human-centered design process through an intersectional, ""asset-based approach,"" which recognizes that marginalized communities have already developed robust, culturally-specific social practices to enable them to navigate the world, seeks to amplify them, and refrains from imposing a top-down or pre-conceived ""idea"" of intervention."
pn1158,https://doi.org/10.1145/3290605.3300837,"The ""Comadre"" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities",2,Roxana Herrera,"University of California, Irvine",Irvine,United States,false,false,"Participation in out-of-school learning programs has been shown to generate significant academic, social/emotional, and institutional benefits for young learners, and today's wealthy families are disproportionately reaping these benefits. This paper presents the results of an asset-based/human-centered design research process and pilot aimed at connecting low-income families in a Southern California city with local low-cost out-of-school learning opportunities. Based on background research including qualitative interviewing, home visits, technology inventories and use walkthroughs with 40 low-income, majority Latinx families, we created and piloted a free subscription SMS service that automatically pushes bilingual SMS messages with curated information on local low-cost enrichment learning opportunities to low-income families. We framed our human-centered design process through an intersectional, ""asset-based approach,"" which recognizes that marginalized communities have already developed robust, culturally-specific social practices to enable them to navigate the world, seeks to amplify them, and refrains from imposing a top-down or pre-conceived ""idea"" of intervention."
pn1158,https://doi.org/10.1145/3290605.3300837,"The ""Comadre"" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities",3,Luis Chaidez,"University of California, Irvine",Irvine,United States,false,false,"Participation in out-of-school learning programs has been shown to generate significant academic, social/emotional, and institutional benefits for young learners, and today's wealthy families are disproportionately reaping these benefits. This paper presents the results of an asset-based/human-centered design research process and pilot aimed at connecting low-income families in a Southern California city with local low-cost out-of-school learning opportunities. Based on background research including qualitative interviewing, home visits, technology inventories and use walkthroughs with 40 low-income, majority Latinx families, we created and piloted a free subscription SMS service that automatically pushes bilingual SMS messages with curated information on local low-cost enrichment learning opportunities to low-income families. We framed our human-centered design process through an intersectional, ""asset-based approach,"" which recognizes that marginalized communities have already developed robust, culturally-specific social practices to enable them to navigate the world, seeks to amplify them, and refrains from imposing a top-down or pre-conceived ""idea"" of intervention."
pn1158,https://doi.org/10.1145/3290605.3300837,"The ""Comadre"" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities",4,Adilene Uriostegui,"University of California, Irvine",Irvine,United States,false,false,"Participation in out-of-school learning programs has been shown to generate significant academic, social/emotional, and institutional benefits for young learners, and today's wealthy families are disproportionately reaping these benefits. This paper presents the results of an asset-based/human-centered design research process and pilot aimed at connecting low-income families in a Southern California city with local low-cost out-of-school learning opportunities. Based on background research including qualitative interviewing, home visits, technology inventories and use walkthroughs with 40 low-income, majority Latinx families, we created and piloted a free subscription SMS service that automatically pushes bilingual SMS messages with curated information on local low-cost enrichment learning opportunities to low-income families. We framed our human-centered design process through an intersectional, ""asset-based approach,"" which recognizes that marginalized communities have already developed robust, culturally-specific social practices to enable them to navigate the world, seeks to amplify them, and refrains from imposing a top-down or pre-conceived ""idea"" of intervention."
pn6854,https://doi.org/10.1145/3290605.3300330,Collaborative Practices with Structured Data: Do Tools Support What Users Need?,1,Laura Koesten,University of Southampton,Southampton,United Kingdom,false,false,"Collaborative work with data is increasingly common and spans a broad range of activities - from creating or analysing data in a team, to sharing it with others, to reusing someone else's data in a new context. In this paper, we explore collaboration practices around structured data and how they are supported by current technology. We present the results of an interview study with twenty data practitioners, from which we derive four high-level user needs for tool support. We compare them against the capabilities of twenty systems that are commonly associated with data activities, including data publishing software, wikis, web-based collaboration tools, and online community platforms. Our findings suggest that data-centric collaborative work would benefit from: structured documentation of data and its lifecycle; advanced affordances for conversations among collaborators; better change control; and custom data access. The findings help us formalise practices around data teamwork, and build a better understanding how people's motivations and barriers when working with structured data."
pn6854,https://doi.org/10.1145/3290605.3300330,Collaborative Practices with Structured Data: Do Tools Support What Users Need?,2,Emilia Kacprzak,University of Southampton,Southampton,United Kingdom,false,false,"Collaborative work with data is increasingly common and spans a broad range of activities - from creating or analysing data in a team, to sharing it with others, to reusing someone else's data in a new context. In this paper, we explore collaboration practices around structured data and how they are supported by current technology. We present the results of an interview study with twenty data practitioners, from which we derive four high-level user needs for tool support. We compare them against the capabilities of twenty systems that are commonly associated with data activities, including data publishing software, wikis, web-based collaboration tools, and online community platforms. Our findings suggest that data-centric collaborative work would benefit from: structured documentation of data and its lifecycle; advanced affordances for conversations among collaborators; better change control; and custom data access. The findings help us formalise practices around data teamwork, and build a better understanding how people's motivations and barriers when working with structured data."
pn6854,https://doi.org/10.1145/3290605.3300330,Collaborative Practices with Structured Data: Do Tools Support What Users Need?,3,Jeni Tennison,The Open Data Institute,London,United Kingdom,false,false,"Collaborative work with data is increasingly common and spans a broad range of activities - from creating or analysing data in a team, to sharing it with others, to reusing someone else's data in a new context. In this paper, we explore collaboration practices around structured data and how they are supported by current technology. We present the results of an interview study with twenty data practitioners, from which we derive four high-level user needs for tool support. We compare them against the capabilities of twenty systems that are commonly associated with data activities, including data publishing software, wikis, web-based collaboration tools, and online community platforms. Our findings suggest that data-centric collaborative work would benefit from: structured documentation of data and its lifecycle; advanced affordances for conversations among collaborators; better change control; and custom data access. The findings help us formalise practices around data teamwork, and build a better understanding how people's motivations and barriers when working with structured data."
pn6854,https://doi.org/10.1145/3290605.3300330,Collaborative Practices with Structured Data: Do Tools Support What Users Need?,4,Elena Simperl,University of Southampton,Southampton,United Kingdom,false,false,"Collaborative work with data is increasingly common and spans a broad range of activities - from creating or analysing data in a team, to sharing it with others, to reusing someone else's data in a new context. In this paper, we explore collaboration practices around structured data and how they are supported by current technology. We present the results of an interview study with twenty data practitioners, from which we derive four high-level user needs for tool support. We compare them against the capabilities of twenty systems that are commonly associated with data activities, including data publishing software, wikis, web-based collaboration tools, and online community platforms. Our findings suggest that data-centric collaborative work would benefit from: structured documentation of data and its lifecycle; advanced affordances for conversations among collaborators; better change control; and custom data access. The findings help us formalise practices around data teamwork, and build a better understanding how people's motivations and barriers when working with structured data."
pn2196,https://doi.org/10.1145/3290605.3300667,Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video,1,Tom Bartindale,Monash University,Melbourne,Australia,false,false,"Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M & E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents significant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work flow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the field, and was specifically developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale."
pn2196,https://doi.org/10.1145/3290605.3300667,Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video,2,Delvin Varghese,Newcastle University,Newcastle Upon Tyne,United Kingdom,false,false,"Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M & E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents significant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work flow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the field, and was specifically developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale."
pn2196,https://doi.org/10.1145/3290605.3300667,Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video,3,Guy Schofield,University of York,York,United Kingdom,false,false,"Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M & E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents significant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work flow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the field, and was specifically developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale."
pn2196,https://doi.org/10.1145/3290605.3300667,Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video,4,Miki Tsukamoto,International Federation of Red Cross,Geneva,Switzerland,false,false,"Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M & E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents significant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work flow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the field, and was specifically developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale."
pn6332,https://doi.org/10.1145/3290605.3300702,People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety,1,Amanda Menking,University of Washington,Seattle,United States,false,false,"Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors—a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users."
pn6332,https://doi.org/10.1145/3290605.3300702,People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety,2,Ingrid Erickson,Syracuse University,Syracuse,United States,false,false,"Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors—a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users."
pn6332,https://doi.org/10.1145/3290605.3300702,People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety,3,Wanda Pratt,University of Washington,Seattle,United States,false,false,"Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors—a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users."
pn3780,https://doi.org/10.1145/3290605.3300749,Encoding Materials and Data for Iterative Personalization,1,Troy Nachtigall,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Data is changing how we design consumer products. Shoe production is a prime example of this; foot size, footstep pressure and personal preferences can be used to design personalized shoes. Research done around metamaterials, programming materials and computational composites illustrate the possibilities of creating complex data & material relationships. These new relationships allow us to look at future products almost like software apps, becoming a kind of product service systems, where the focus is on its iterative personalization improvement over time. Can we create systems of such data driven objects that in turn allow us to design new objects that are informed by the data trail? In this paper we report on four RtD project iterations that explore this challenge and provide a set of insights on how to close this new iterative loop."
pn3780,https://doi.org/10.1145/3290605.3300749,Encoding Materials and Data for Iterative Personalization,2,Oscar Tomico,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Data is changing how we design consumer products. Shoe production is a prime example of this; foot size, footstep pressure and personal preferences can be used to design personalized shoes. Research done around metamaterials, programming materials and computational composites illustrate the possibilities of creating complex data & material relationships. These new relationships allow us to look at future products almost like software apps, becoming a kind of product service systems, where the focus is on its iterative personalization improvement over time. Can we create systems of such data driven objects that in turn allow us to design new objects that are informed by the data trail? In this paper we report on four RtD project iterations that explore this challenge and provide a set of insights on how to close this new iterative loop."
pn3780,https://doi.org/10.1145/3290605.3300749,Encoding Materials and Data for Iterative Personalization,3,Ron Wakkary,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Data is changing how we design consumer products. Shoe production is a prime example of this; foot size, footstep pressure and personal preferences can be used to design personalized shoes. Research done around metamaterials, programming materials and computational composites illustrate the possibilities of creating complex data & material relationships. These new relationships allow us to look at future products almost like software apps, becoming a kind of product service systems, where the focus is on its iterative personalization improvement over time. Can we create systems of such data driven objects that in turn allow us to design new objects that are informed by the data trail? In this paper we report on four RtD project iterations that explore this challenge and provide a set of insights on how to close this new iterative loop."
pn3780,https://doi.org/10.1145/3290605.3300749,Encoding Materials and Data for Iterative Personalization,4,Pauline Van Dongen,Eindhoven University of Technology,Eindhoven,Netherlands,false,false,"Data is changing how we design consumer products. Shoe production is a prime example of this; foot size, footstep pressure and personal preferences can be used to design personalized shoes. Research done around metamaterials, programming materials and computational composites illustrate the possibilities of creating complex data & material relationships. These new relationships allow us to look at future products almost like software apps, becoming a kind of product service systems, where the focus is on its iterative personalization improvement over time. Can we create systems of such data driven objects that in turn allow us to design new objects that are informed by the data trail? In this paper we report on four RtD project iterations that explore this challenge and provide a set of insights on how to close this new iterative loop."
jrnl1131,https://doi.org/10.1145/3290607.3313854,Collective Privacy Management in Social Media: A Cross-cultural Validation,1,Hichang Cho,National University of Singapore,Singapore,Singapore,false,false,"If one wants to study privacy from an intercultural perspective, one must first validate whether there are any cultural variations in the concept of ""privacy"" itself. This study systematically examines cultural differences in collective privacy management strategies, and highlights methodological precautions that must be taken in quantitative intercultural privacy research. Using survey data of 498 Facebook users from the US, Singapore, and South Korea, we test the validity and cultural invariance of the measurement model and predictive model associated with collective privacy management. The results show that the measurement model is only partially culturally invariant, indicating that social media users in different countries interpret the same instruments in different ways. Also, cross-national comparisons of the structural model show that causal pathways from collective privacy management strategies to privacy-related outcomes vary significantly across countries. The findings suggest significant cultural variations in privacy management practices, both with regard to the conceptualization of its theoretical constructs, and with respect to causal pathways."
jrnl1131,https://doi.org/10.1145/3290607.3313854,Collective Privacy Management in Social Media: A Cross-cultural Validation,2,Bart Knijnenburg,Clemson University,Clemson,United States,false,false,"If one wants to study privacy from an intercultural perspective, one must first validate whether there are any cultural variations in the concept of ""privacy"" itself. This study systematically examines cultural differences in collective privacy management strategies, and highlights methodological precautions that must be taken in quantitative intercultural privacy research. Using survey data of 498 Facebook users from the US, Singapore, and South Korea, we test the validity and cultural invariance of the measurement model and predictive model associated with collective privacy management. The results show that the measurement model is only partially culturally invariant, indicating that social media users in different countries interpret the same instruments in different ways. Also, cross-national comparisons of the structural model show that causal pathways from collective privacy management strategies to privacy-related outcomes vary significantly across countries. The findings suggest significant cultural variations in privacy management practices, both with regard to the conceptualization of its theoretical constructs, and with respect to causal pathways."
jrnl1131,https://doi.org/10.1145/3290607.3313854,Collective Privacy Management in Social Media: A Cross-cultural Validation,3,Alfred Kobsa,"University of California, Irvine",Irvine,United States,false,false,"If one wants to study privacy from an intercultural perspective, one must first validate whether there are any cultural variations in the concept of ""privacy"" itself. This study systematically examines cultural differences in collective privacy management strategies, and highlights methodological precautions that must be taken in quantitative intercultural privacy research. Using survey data of 498 Facebook users from the US, Singapore, and South Korea, we test the validity and cultural invariance of the measurement model and predictive model associated with collective privacy management. The results show that the measurement model is only partially culturally invariant, indicating that social media users in different countries interpret the same instruments in different ways. Also, cross-national comparisons of the structural model show that causal pathways from collective privacy management strategies to privacy-related outcomes vary significantly across countries. The findings suggest significant cultural variations in privacy management practices, both with regard to the conceptualization of its theoretical constructs, and with respect to causal pathways."
jrnl1131,https://doi.org/10.1145/3290607.3313854,Collective Privacy Management in Social Media: A Cross-cultural Validation,4,Yao Li,"University of California, Irvine",Irvine,United States,false,false,"If one wants to study privacy from an intercultural perspective, one must first validate whether there are any cultural variations in the concept of ""privacy"" itself. This study systematically examines cultural differences in collective privacy management strategies, and highlights methodological precautions that must be taken in quantitative intercultural privacy research. Using survey data of 498 Facebook users from the US, Singapore, and South Korea, we test the validity and cultural invariance of the measurement model and predictive model associated with collective privacy management. The results show that the measurement model is only partially culturally invariant, indicating that social media users in different countries interpret the same instruments in different ways. Also, cross-national comparisons of the structural model show that causal pathways from collective privacy management strategies to privacy-related outcomes vary significantly across countries. The findings suggest significant cultural variations in privacy management practices, both with regard to the conceptualization of its theoretical constructs, and with respect to causal pathways."
jrnl1109,https://doi.org/10.1145/3290607.3313851,"Social Support, Reciprocity, and Anonymity in Responses to Sexual Abuse Disclosures on Social Media",1,Nazanin Andalibi,University of Michigan,Ann Arbor,United States,false,false,"Seeking and providing support is challenging. When people disclose sensitive information, audience responses can substantially impact the discloser's wellbeing. We use mixed methods to understand responses to online sexual abuse-related disclosures on Reddit. We characterize disclosure responses, then investigate relationships between post content, comment content, and anonymity. We illustrate what types of support sought and provided in posts and comments co-occur. We find that posts seeking support receive more comments, and comments from ""throwaway"" (i.e., anonymous) accounts are more likely on posts also from throwaway accounts. Anonymous commenting enables commenters to share intimate content such as reciprocal disclosures and supportive messages, and commenter anonymity is not associated with aggressive or unsupportive comments. We argue that anonymity is an essential factor in designing social technologies that facilitate support seeking and provision in socially stigmatized contexts, and provide implications for social media site design. CAUTION: This article includes content about sexual abuse."
jrnl1109,https://doi.org/10.1145/3290607.3313851,"Social Support, Reciprocity, and Anonymity in Responses to Sexual Abuse Disclosures on Social Media",2,Oliver Haimson,University of Michigan,Ann Arbor,United States,false,false,"Seeking and providing support is challenging. When people disclose sensitive information, audience responses can substantially impact the discloser's wellbeing. We use mixed methods to understand responses to online sexual abuse-related disclosures on Reddit. We characterize disclosure responses, then investigate relationships between post content, comment content, and anonymity. We illustrate what types of support sought and provided in posts and comments co-occur. We find that posts seeking support receive more comments, and comments from ""throwaway"" (i.e., anonymous) accounts are more likely on posts also from throwaway accounts. Anonymous commenting enables commenters to share intimate content such as reciprocal disclosures and supportive messages, and commenter anonymity is not associated with aggressive or unsupportive comments. We argue that anonymity is an essential factor in designing social technologies that facilitate support seeking and provision in socially stigmatized contexts, and provide implications for social media site design. CAUTION: This article includes content about sexual abuse."
jrnl1109,https://doi.org/10.1145/3290607.3313851,"Social Support, Reciprocity, and Anonymity in Responses to Sexual Abuse Disclosures on Social Media",3,Munmun De Choudhury,Georgia Institute of Technology,Atlanta,United States,false,false,"Seeking and providing support is challenging. When people disclose sensitive information, audience responses can substantially impact the discloser's wellbeing. We use mixed methods to understand responses to online sexual abuse-related disclosures on Reddit. We characterize disclosure responses, then investigate relationships between post content, comment content, and anonymity. We illustrate what types of support sought and provided in posts and comments co-occur. We find that posts seeking support receive more comments, and comments from ""throwaway"" (i.e., anonymous) accounts are more likely on posts also from throwaway accounts. Anonymous commenting enables commenters to share intimate content such as reciprocal disclosures and supportive messages, and commenter anonymity is not associated with aggressive or unsupportive comments. We argue that anonymity is an essential factor in designing social technologies that facilitate support seeking and provision in socially stigmatized contexts, and provide implications for social media site design. CAUTION: This article includes content about sexual abuse."
jrnl1109,https://doi.org/10.1145/3290607.3313851,"Social Support, Reciprocity, and Anonymity in Responses to Sexual Abuse Disclosures on Social Media",4,Andrea Forte,Drexel University,Philadelphia,United States,false,false,"Seeking and providing support is challenging. When people disclose sensitive information, audience responses can substantially impact the discloser's wellbeing. We use mixed methods to understand responses to online sexual abuse-related disclosures on Reddit. We characterize disclosure responses, then investigate relationships between post content, comment content, and anonymity. We illustrate what types of support sought and provided in posts and comments co-occur. We find that posts seeking support receive more comments, and comments from ""throwaway"" (i.e., anonymous) accounts are more likely on posts also from throwaway accounts. Anonymous commenting enables commenters to share intimate content such as reciprocal disclosures and supportive messages, and commenter anonymity is not associated with aggressive or unsupportive comments. We argue that anonymity is an essential factor in designing social technologies that facilitate support seeking and provision in socially stigmatized contexts, and provide implications for social media site design. CAUTION: This article includes content about sexual abuse."
jrnl1110,https://doi.org/10.1145/3290607.3313852,Responding to Sensitive Disclosures on Social Media: A Decision Making Framework,1,Nazanin Andalibi,University of Michigan,Ann Arbor,United States,false,false,"When people disclose information on social media that is sensitive or potentially stigmatized (e.g., mental illness, pregnancy loss), how do others decide to respond? We use interviews and vignettes to provide a response decision-making framework (RDM) that explains factors informing whether and how individuals respond to sensitive disclosures from their social media connections. The RDM framework includes factors related to the self, poster, and disclosure context (i.e., relational, temporal, social). Our findings include how people's decisions are complicated by balancing their own needs (e.g., privacy, wellbeing) as well as the posters' (e.g., support) when seeing what they consider sensitive posts on social media. We identify empirically grounded insights and information that social media designs could surface to support both potential disclosers and responders. We argue that social media sites should provide privacy controls for both disclosers and responders, and facilitate the visibility of network-level support."
jrnl1110,https://doi.org/10.1145/3290607.3313852,Responding to Sensitive Disclosures on Social Media: A Decision Making Framework,2,Andrea Forte,Drexel University,Philadelphia,United States,false,false,"When people disclose information on social media that is sensitive or potentially stigmatized (e.g., mental illness, pregnancy loss), how do others decide to respond? We use interviews and vignettes to provide a response decision-making framework (RDM) that explains factors informing whether and how individuals respond to sensitive disclosures from their social media connections. The RDM framework includes factors related to the self, poster, and disclosure context (i.e., relational, temporal, social). Our findings include how people's decisions are complicated by balancing their own needs (e.g., privacy, wellbeing) as well as the posters' (e.g., support) when seeing what they consider sensitive posts on social media. We identify empirically grounded insights and information that social media designs could surface to support both potential disclosers and responders. We argue that social media sites should provide privacy controls for both disclosers and responders, and facilitate the visibility of network-level support."
pn3015,https://doi.org/10.1145/3290605.3300471,Virtual Hubs: Understanding Relational Aspects and Remediating Incubation,1,Jandy Luik,University of York,York,United Kingdom,false,false,"We have recently seen the emergence of new platforms that aim to provide remotely located entrepreneurs and startup companies with support analogous to that found within traditional incubation or acceleration spaces. This paper offers an understanding of these 'virtual hubs', and the inherently socio-technical interactions that occur between their members. Our study analyzes a sample of existing virtual hubs in two stages. First, we contribute broader insight into the current landscape of virtual hubs by documenting and categorizing 25 hubs regarding their form, support offered and a selection of further qualities. Second, we contribute detailed insight into the operation and experience of such hubs, from an analysis of 10 semi-structured interviews with organizers and participants of virtual hubs. We conclude by analyzing our findings in terms of relational aspects of non-virtual hubs from the literature and remediation theory, and propose opportunities for advancing the design of such platforms."
pn3015,https://doi.org/10.1145/3290605.3300471,Virtual Hubs: Understanding Relational Aspects and Remediating Incubation,2,Jenna Ng,University of York,York,United Kingdom,false,false,"We have recently seen the emergence of new platforms that aim to provide remotely located entrepreneurs and startup companies with support analogous to that found within traditional incubation or acceleration spaces. This paper offers an understanding of these 'virtual hubs', and the inherently socio-technical interactions that occur between their members. Our study analyzes a sample of existing virtual hubs in two stages. First, we contribute broader insight into the current landscape of virtual hubs by documenting and categorizing 25 hubs regarding their form, support offered and a selection of further qualities. Second, we contribute detailed insight into the operation and experience of such hubs, from an analysis of 10 semi-structured interviews with organizers and participants of virtual hubs. We conclude by analyzing our findings in terms of relational aspects of non-virtual hubs from the literature and remediation theory, and propose opportunities for advancing the design of such platforms."
pn3015,https://doi.org/10.1145/3290605.3300471,Virtual Hubs: Understanding Relational Aspects and Remediating Incubation,3,Jonathan Hook,University of York,York,United Kingdom,false,false,"We have recently seen the emergence of new platforms that aim to provide remotely located entrepreneurs and startup companies with support analogous to that found within traditional incubation or acceleration spaces. This paper offers an understanding of these 'virtual hubs', and the inherently socio-technical interactions that occur between their members. Our study analyzes a sample of existing virtual hubs in two stages. First, we contribute broader insight into the current landscape of virtual hubs by documenting and categorizing 25 hubs regarding their form, support offered and a selection of further qualities. Second, we contribute detailed insight into the operation and experience of such hubs, from an analysis of 10 semi-structured interviews with organizers and participants of virtual hubs. We conclude by analyzing our findings in terms of relational aspects of non-virtual hubs from the literature and remediation theory, and propose opportunities for advancing the design of such platforms."
jrnl1002,https://doi.org/10.1145/3290607.3313835,Online Idea Management for Civic Engagement: A Study on the Benefits of Integration with Social Networking,1,Jorge Saldivar,Catholic University,Asuncia,Paraguay,false,false,"Idea Management (IM) has increasingly been adopted in the civic domain as a tool to engage the citizenry in processes oriented toward innovating plans, policies, and services. While Idea Management Systems (IMSs), i.e., the software systems that instrument IM, definitely help manage this practice, they require citizens to be committed to a separate virtual space for which they need to register, they must learn how to operate, and they must return to frequently. This paper presents an approach that integrates IMS with today's most popular digital spaces of participation, the social networking sites, enabling citizens to engage in IM processes using ordinary tools and without having to step outside their daily habits. Our goal is to reach out and pull into IM the large and demographically diverse sectors of the society that are already present and participating in social networking sites. Through a real case study of IM in the public sector that mixed both qualitative and quantitative data collection methods, our proposal demonstrates to be a promising approach to reduce the barriers of participation. We conclude with an analysis of the strengths and limitations of our proposal."
jrnl1002,https://doi.org/10.1145/3290607.3313835,Online Idea Management for Civic Engagement: A Study on the Benefits of Integration with Social Networking,2,Florian Daniel,Politecnico di Milano,Milan,Italy,false,false,"Idea Management (IM) has increasingly been adopted in the civic domain as a tool to engage the citizenry in processes oriented toward innovating plans, policies, and services. While Idea Management Systems (IMSs), i.e., the software systems that instrument IM, definitely help manage this practice, they require citizens to be committed to a separate virtual space for which they need to register, they must learn how to operate, and they must return to frequently. This paper presents an approach that integrates IMS with today's most popular digital spaces of participation, the social networking sites, enabling citizens to engage in IM processes using ordinary tools and without having to step outside their daily habits. Our goal is to reach out and pull into IM the large and demographically diverse sectors of the society that are already present and participating in social networking sites. Through a real case study of IM in the public sector that mixed both qualitative and quantitative data collection methods, our proposal demonstrates to be a promising approach to reduce the barriers of participation. We conclude with an analysis of the strengths and limitations of our proposal."
jrnl1002,https://doi.org/10.1145/3290607.3313835,Online Idea Management for Civic Engagement: A Study on the Benefits of Integration with Social Networking,3,Luca Cernuzzi,Catholic University of Asuncion,Asuncion,Paraguay,false,false,"Idea Management (IM) has increasingly been adopted in the civic domain as a tool to engage the citizenry in processes oriented toward innovating plans, policies, and services. While Idea Management Systems (IMSs), i.e., the software systems that instrument IM, definitely help manage this practice, they require citizens to be committed to a separate virtual space for which they need to register, they must learn how to operate, and they must return to frequently. This paper presents an approach that integrates IMS with today's most popular digital spaces of participation, the social networking sites, enabling citizens to engage in IM processes using ordinary tools and without having to step outside their daily habits. Our goal is to reach out and pull into IM the large and demographically diverse sectors of the society that are already present and participating in social networking sites. Through a real case study of IM in the public sector that mixed both qualitative and quantitative data collection methods, our proposal demonstrates to be a promising approach to reduce the barriers of participation. We conclude with an analysis of the strengths and limitations of our proposal."
jrnl1002,https://doi.org/10.1145/3290607.3313835,Online Idea Management for Civic Engagement: A Study on the Benefits of Integration with Social Networking,4,Fabio Casati,University of Trento,Trento,Italy,false,false,"Idea Management (IM) has increasingly been adopted in the civic domain as a tool to engage the citizenry in processes oriented toward innovating plans, policies, and services. While Idea Management Systems (IMSs), i.e., the software systems that instrument IM, definitely help manage this practice, they require citizens to be committed to a separate virtual space for which they need to register, they must learn how to operate, and they must return to frequently. This paper presents an approach that integrates IMS with today's most popular digital spaces of participation, the social networking sites, enabling citizens to engage in IM processes using ordinary tools and without having to step outside their daily habits. Our goal is to reach out and pull into IM the large and demographically diverse sectors of the society that are already present and participating in social networking sites. Through a real case study of IM in the public sector that mixed both qualitative and quantitative data collection methods, our proposal demonstrates to be a promising approach to reduce the barriers of participation. We conclude with an analysis of the strengths and limitations of our proposal."
jrnl1113,https://doi.org/10.1145/3290607.3313840,Older Adults' Deployment of 'Distrust',1,Bran Knowles,Lancaster University,Lancaster,United Kingdom,false,false,"Older adults frequently deploy the concept of distrust when discussing digital technologies, and it is tempting to assume that distrust is largely responsible for the reduced uptake by older adults witnessed in the latest surveys of technology use. To help understand the impact of distrust on adoption behavior, we conducted focus groups with older adults exploring how, in what circumstances, and to what effect older adults articulate distrust in digital technologies. Our findings indicate that distrust is not especially relevant to older adults' practical decision making around technology (non-)use. The older adults in our study used the language of distrust to open up discussions around digital technologies to larger issues related to values. This suggests that looking to distrust as a predictor of non-use (e.g., in Technology Acceptance Model studies) may be uniquely unhelpful in the case of older adults, as it narrows the discussion of technology acceptance and trust to interactional issues, when their use of distrust pertains to much wider concerns. Likewise, technology adoption should not be viewed as indicative of trust or an endorsement of technology acceptability. Older adults using-while-distrusting offers important insights into how to design truly acceptable digital technologies."
jrnl1113,https://doi.org/10.1145/3290607.3313840,Older Adults' Deployment of 'Distrust',2,Vicki Hanson,Rochester Institute of Technology,Rochester,United States,false,false,"Older adults frequently deploy the concept of distrust when discussing digital technologies, and it is tempting to assume that distrust is largely responsible for the reduced uptake by older adults witnessed in the latest surveys of technology use. To help understand the impact of distrust on adoption behavior, we conducted focus groups with older adults exploring how, in what circumstances, and to what effect older adults articulate distrust in digital technologies. Our findings indicate that distrust is not especially relevant to older adults' practical decision making around technology (non-)use. The older adults in our study used the language of distrust to open up discussions around digital technologies to larger issues related to values. This suggests that looking to distrust as a predictor of non-use (e.g., in Technology Acceptance Model studies) may be uniquely unhelpful in the case of older adults, as it narrows the discussion of technology acceptance and trust to interactional issues, when their use of distrust pertains to much wider concerns. Likewise, technology adoption should not be viewed as indicative of trust or an endorsement of technology acceptability. Older adults using-while-distrusting offers important insights into how to design truly acceptable digital technologies."
jrnl1111,https://doi.org/10.1145/3290607.3313838,"Personal Informatics for Sport: Meaning, Body, and Social Relations in Amateur and Elite Athletes",1,Amon Rapp,University of Torino,Torino,Italy,false,false,"Technological advances in wearable computing are changing the sports domain. A variety of Personal Informatics (PI) tools are starting to provide support and improve athletes' performance in many sports. In this article, we interviewed 20 amateur and elite athletes of different disciplines, using an array of PI devices, to explore how sports, as well as athletes' experience, are affected by such instruments. We discovered that amateur athletes present different patterns of usage compared to elite ones. Moreover, we found that elite athletes make sense of their data by exploiting the knowledge they have about their own body and sports practice. We then proposed four considerations for design that we believe should be explored in the future, to reflect on how self-tracking is changing our perspective on sports, and, by and large, on our everyday life."
jrnl1111,https://doi.org/10.1145/3290607.3313838,"Personal Informatics for Sport: Meaning, Body, and Social Relations in Amateur and Elite Athletes",2,Lia Tirabeni,University of Torino,Torino,Italy,false,false,"Technological advances in wearable computing are changing the sports domain. A variety of Personal Informatics (PI) tools are starting to provide support and improve athletes' performance in many sports. In this article, we interviewed 20 amateur and elite athletes of different disciplines, using an array of PI devices, to explore how sports, as well as athletes' experience, are affected by such instruments. We discovered that amateur athletes present different patterns of usage compared to elite ones. Moreover, we found that elite athletes make sense of their data by exploiting the knowledge they have about their own body and sports practice. We then proposed four considerations for design that we believe should be explored in the future, to reflect on how self-tracking is changing our perspective on sports, and, by and large, on our everyday life."
